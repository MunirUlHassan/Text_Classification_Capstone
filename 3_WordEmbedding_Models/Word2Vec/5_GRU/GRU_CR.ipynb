{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using GRU model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaknesses are minor the feel and layout of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many of our disney movies do n 't play on this...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player has a problem with dual layer dvd 's su...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know the saying is you get what you pay for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will never purchase apex again .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>so far , the anti spam feature seems to be ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>i did not have any of the installation problem...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>their products have been great and have saved ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     weaknesses are minor the feel and layout of th...      0  train\n",
       "1     many of our disney movies do n 't play on this...      0  train\n",
       "2     player has a problem with dual layer dvd 's su...      0  train\n",
       "3     i know the saying is you get what you pay for ...      0  train\n",
       "4                      will never purchase apex again .      0  train\n",
       "...                                                 ...    ...    ...\n",
       "3770  so far , the anti spam feature seems to be ver...      1  train\n",
       "3771  i downloaded a trial version of computer assoc...      1  train\n",
       "3772  i did not have any of the installation problem...      1  train\n",
       "3773  their products have been great and have saved ...      1  train\n",
       "3774                                                         1  train\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/CR/CR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3775 entries, 0 to 3774\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3775 non-null   object\n",
      " 1   label     3775 non-null   int32 \n",
      " 2   split     3775 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 73.9+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2407</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          1368   1368\n",
       "1          2407   2407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  will never purchase apex again .\n",
      "Into a sequence of int: [72, 194, 285, 207, 286]\n",
      "Into a padded sequence: [ 72 194 285 207 286   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "and 3\n",
      "i 4\n",
      "it 5\n",
      "to 6\n",
      "a 7\n",
      "is 8\n",
      "of 9\n",
      "this 10\n",
      "5336\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "<img src=\"model.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "#         tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Bidirectional((tf.keras.layers.GRU(64))),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Propagate X through a Dense layer with 1 unit\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 440,673\n",
      "Trainable params: 440,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 43s 309ms/step - loss: 0.6296 - accuracy: 0.6404 - val_loss: 0.4986 - val_accuracy: 0.7513\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 24s 229ms/step - loss: 0.2904 - accuracy: 0.8794 - val_loss: 0.4936 - val_accuracy: 0.7672\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.1148 - accuracy: 0.9613 - val_loss: 0.5883 - val_accuracy: 0.7487\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 0.6880 - val_accuracy: 0.7619\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.8613 - val_accuracy: 0.7381\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 22s 201ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.0451 - val_accuracy: 0.7593\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 1.2537 - val_accuracy: 0.7513\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.1701 - val_accuracy: 0.7487\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 1.3299 - val_accuracy: 0.7407\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 1.5681 - val_accuracy: 0.7381\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.0028 - accuracy: 0.9974 - val_loss: 1.6954 - val_accuracy: 0.7407\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 9.2867e-04 - accuracy: 0.9995 - val_loss: 1.7912 - val_accuracy: 0.7407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Training 2: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 32s 204ms/step - loss: 0.6190 - accuracy: 0.6587 - val_loss: 0.4415 - val_accuracy: 0.7989\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 17s 162ms/step - loss: 0.2923 - accuracy: 0.8905 - val_loss: 0.4515 - val_accuracy: 0.7751\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.1284 - accuracy: 0.9611 - val_loss: 0.5211 - val_accuracy: 0.7857\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 0.6666 - val_accuracy: 0.7804\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.8450 - val_accuracy: 0.7857\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.9504 - val_accuracy: 0.7884\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 1.0475 - val_accuracy: 0.7751\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 1.1982 - val_accuracy: 0.7593\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 1.2937 - val_accuracy: 0.7725\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.4011 - val_accuracy: 0.7672\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 16s 145ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.4512 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Training 3: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 79s 616ms/step - loss: 0.6336 - accuracy: 0.6359 - val_loss: 0.4578 - val_accuracy: 0.7751\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.2939 - accuracy: 0.8792 - val_loss: 0.4663 - val_accuracy: 0.7857\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 63s 586ms/step - loss: 0.1274 - accuracy: 0.9605 - val_loss: 0.5844 - val_accuracy: 0.7725\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 63s 591ms/step - loss: 0.0547 - accuracy: 0.9863 - val_loss: 0.7783 - val_accuracy: 0.7646\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.9939 - val_accuracy: 0.7593\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 63s 588ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 1.1034 - val_accuracy: 0.7593\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 1.1587 - val_accuracy: 0.7778\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.3302 - val_accuracy: 0.7434\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 63s 585ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.4329 - val_accuracy: 0.7646\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 63s 589ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 1.5455 - val_accuracy: 0.7698\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 63s 588ms/step - loss: 0.0019 - accuracy: 0.9986 - val_loss: 1.6190 - val_accuracy: 0.7698\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 64s 596ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.6839 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.57142686843872\n",
      "Training 4: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 83s 671ms/step - loss: 0.6298 - accuracy: 0.6438 - val_loss: 0.4223 - val_accuracy: 0.8148\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 68s 640ms/step - loss: 0.2950 - accuracy: 0.8904 - val_loss: 0.4085 - val_accuracy: 0.8280\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 64s 598ms/step - loss: 0.1340 - accuracy: 0.9581 - val_loss: 0.5217 - val_accuracy: 0.8122\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 64s 598ms/step - loss: 0.0559 - accuracy: 0.9820 - val_loss: 0.5972 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 63s 592ms/step - loss: 0.0471 - accuracy: 0.9850 - val_loss: 0.7249 - val_accuracy: 0.7937\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 63s 589ms/step - loss: 0.0199 - accuracy: 0.9971 - val_loss: 0.7942 - val_accuracy: 0.7910\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 64s 596ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.8650 - val_accuracy: 0.7910\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 64s 594ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.8907 - val_accuracy: 0.7804\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 1.0569 - val_accuracy: 0.7910\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.1376 - val_accuracy: 0.7989\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 1.2140 - val_accuracy: 0.7884\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2542 - val_accuracy: 0.7910\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.80423283576965\n",
      "Training 5: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 58s 438ms/step - loss: 0.6388 - accuracy: 0.6151 - val_loss: 0.4527 - val_accuracy: 0.7725\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 41s 385ms/step - loss: 0.3098 - accuracy: 0.8694 - val_loss: 0.4149 - val_accuracy: 0.8122\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.1297 - accuracy: 0.9543 - val_loss: 0.4942 - val_accuracy: 0.7857\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0635 - accuracy: 0.9829 - val_loss: 0.5914 - val_accuracy: 0.7884\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0252 - accuracy: 0.9930 - val_loss: 0.8111 - val_accuracy: 0.7725\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 36s 333ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.9364 - val_accuracy: 0.7698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "107/107 [==============================] - 36s 333ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.9987 - val_accuracy: 0.7804\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.1415 - val_accuracy: 0.7804\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 1.2575 - val_accuracy: 0.7857\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 1.2993 - val_accuracy: 0.7751\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 35s 328ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.3994 - val_accuracy: 0.7778\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0014 - accuracy: 0.9991 - val_loss: 1.4575 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Training 6: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 41s 292ms/step - loss: 0.6241 - accuracy: 0.6480 - val_loss: 0.4593 - val_accuracy: 0.7639\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.2725 - accuracy: 0.8996 - val_loss: 0.4489 - val_accuracy: 0.8170\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 0.1200 - accuracy: 0.9581 - val_loss: 0.5913 - val_accuracy: 0.8064\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0626 - accuracy: 0.9802 - val_loss: 0.7950 - val_accuracy: 0.7984\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.9397 - val_accuracy: 0.7931\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 1.0385 - val_accuracy: 0.7984\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 1.0404 - val_accuracy: 0.8011\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 1.2376 - val_accuracy: 0.7851\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.3866 - val_accuracy: 0.7798\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.9862 - val_accuracy: 0.7878\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0101 - accuracy: 0.9959 - val_loss: 1.3433 - val_accuracy: 0.7560\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 1.1628 - val_accuracy: 0.7772\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Training 7: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 51s 378ms/step - loss: 0.6289 - accuracy: 0.6365 - val_loss: 0.4440 - val_accuracy: 0.7745\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 39s 366ms/step - loss: 0.2883 - accuracy: 0.8851 - val_loss: 0.4712 - val_accuracy: 0.7719\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 41s 383ms/step - loss: 0.1251 - accuracy: 0.9594 - val_loss: 0.6416 - val_accuracy: 0.7639\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 41s 382ms/step - loss: 0.0620 - accuracy: 0.9804 - val_loss: 0.7890 - val_accuracy: 0.7480\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 41s 385ms/step - loss: 0.0261 - accuracy: 0.9945 - val_loss: 0.9578 - val_accuracy: 0.7480\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 1.0668 - val_accuracy: 0.7613\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.2892 - val_accuracy: 0.7507\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 73s 686ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 1.4442 - val_accuracy: 0.7533\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 74s 693ms/step - loss: 0.0033 - accuracy: 0.9981 - val_loss: 1.4690 - val_accuracy: 0.7374\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 1.7214 - val_accuracy: 0.7533\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 74s 694ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.6448 - val_accuracy: 0.7480\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 77.45358347892761\n",
      "Training 8: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 88s 728ms/step - loss: 0.6287 - accuracy: 0.6396 - val_loss: 0.4594 - val_accuracy: 0.7851\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 74s 688ms/step - loss: 0.2751 - accuracy: 0.8982 - val_loss: 0.4934 - val_accuracy: 0.7772\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 73s 684ms/step - loss: 0.1310 - accuracy: 0.9563 - val_loss: 0.6380 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 73s 685ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.7229 - val_accuracy: 0.7798\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 73s 683ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.9703 - val_accuracy: 0.7560\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 74s 694ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 1.1489 - val_accuracy: 0.7586\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 1.0146 - val_accuracy: 0.7533\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 1.2082 - val_accuracy: 0.7613\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 74s 692ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.4499 - val_accuracy: 0.7586\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 74s 695ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.2231 - val_accuracy: 0.7560\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 74s 693ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.1156 - val_accuracy: 0.7454\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 74s 695ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.1657 - val_accuracy: 0.7507\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.4421 - val_accuracy: 0.7560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Training 9: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 98s 818ms/step - loss: 0.6246 - accuracy: 0.6500 - val_loss: 0.3954 - val_accuracy: 0.8223\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 89s 830ms/step - loss: 0.2925 - accuracy: 0.8908 - val_loss: 0.3832 - val_accuracy: 0.8249\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 88s 822ms/step - loss: 0.1376 - accuracy: 0.9574 - val_loss: 0.4778 - val_accuracy: 0.8170\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 87s 814ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.6666 - val_accuracy: 0.7825\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 86s 809ms/step - loss: 0.0324 - accuracy: 0.9875 - val_loss: 0.7384 - val_accuracy: 0.7905\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 86s 805ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.9594 - val_accuracy: 0.7931\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 86s 805ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.9591 - val_accuracy: 0.7905\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 1.1568 - val_accuracy: 0.7931\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.1579 - val_accuracy: 0.7958\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 86s 802ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.2415 - val_accuracy: 0.8011\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 86s 802ms/step - loss: 0.0023 - accuracy: 0.9974 - val_loss: 1.2908 - val_accuracy: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 7.1514e-04 - accuracy: 0.9997 - val_loss: 1.3317 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.49337077140808\n",
      "Training 10: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 105s 883ms/step - loss: 0.6272 - accuracy: 0.6474 - val_loss: 0.4421 - val_accuracy: 0.7878\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 72s 673ms/step - loss: 0.2698 - accuracy: 0.8879 - val_loss: 0.4446 - val_accuracy: 0.8143\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 63s 589ms/step - loss: 0.1214 - accuracy: 0.9597 - val_loss: 0.5284 - val_accuracy: 0.7825\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 62s 578ms/step - loss: 0.0701 - accuracy: 0.9792 - val_loss: 0.7685 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.9923 - val_accuracy: 0.7798\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 61s 575ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 1.2048 - val_accuracy: 0.7878\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 62s 579ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 1.4466 - val_accuracy: 0.7401\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 62s 578ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 1.3172 - val_accuracy: 0.7745\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 61s 573ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 1.5097 - val_accuracy: 0.7639\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.3565 - val_accuracy: 0.7560\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 1.4394 - val_accuracy: 0.7533\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 61s 573ms/step - loss: 0.0074 - accuracy: 0.9967 - val_loss: 1.3746 - val_accuracy: 0.7533\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  76.719576  79.894179  78.571427  82.804233  81.216931  81.697613   \n",
      "\n",
      "        acc7       acc8       acc9     acc10        AVG  \n",
      "0  77.453583  79.045093  82.493371  81.43236  80.132837  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model(input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=30, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.719576</td>\n",
       "      <td>79.894179</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>82.804233</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>77.453583</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>82.493371</td>\n",
       "      <td>81.43236</td>\n",
       "      <td>80.132837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  76.719576  79.894179  78.571427  82.804233  81.216931  81.697613   \n",
       "\n",
       "        acc7       acc8       acc9     acc10        AVG  \n",
       "0  77.453583  79.045093  82.493371  81.43236  80.132837  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('GRU_CR.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5046 words present from 5336 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    \n",
    "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
    "            \n",
    "        # initialize the unknown word with standard normal distribution values\n",
    "        else:\n",
    "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.7279541 , -1.3389816 , -0.41429527, ...,  0.25257593,\n",
       "        -0.89658364, -0.78454617],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "#         tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Bidirectional((tf.keras.layers.GRU(64))),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Propagate X through a Dense layer with 1 unit\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_34 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_34 (Bidirectio (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 440,673\n",
      "Trainable params: 140,673\n",
      "Non-trainable params: 300,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 49s 356ms/step - loss: 0.6286 - accuracy: 0.6436 - val_loss: 0.5425 - val_accuracy: 0.7302\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 33s 313ms/step - loss: 0.4783 - accuracy: 0.7621 - val_loss: 0.4727 - val_accuracy: 0.7672\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 32s 299ms/step - loss: 0.3967 - accuracy: 0.8207 - val_loss: 0.5047 - val_accuracy: 0.7672\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 31s 293ms/step - loss: 0.3805 - accuracy: 0.8338 - val_loss: 0.4941 - val_accuracy: 0.7725\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 32s 296ms/step - loss: 0.3284 - accuracy: 0.8569 - val_loss: 0.4671 - val_accuracy: 0.7884\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.2972 - accuracy: 0.8701 - val_loss: 0.4906 - val_accuracy: 0.7751\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.2807 - accuracy: 0.8816 - val_loss: 0.4757 - val_accuracy: 0.7857\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.2499 - accuracy: 0.8955 - val_loss: 0.5223 - val_accuracy: 0.7778\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 33s 311ms/step - loss: 0.2274 - accuracy: 0.9085 - val_loss: 0.5033 - val_accuracy: 0.7857\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.1745 - accuracy: 0.9303 - val_loss: 0.5951 - val_accuracy: 0.7513\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.1708 - accuracy: 0.9272 - val_loss: 0.5291 - val_accuracy: 0.7725\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.1554 - accuracy: 0.9423 - val_loss: 0.6459 - val_accuracy: 0.7487\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 33s 308ms/step - loss: 0.1676 - accuracy: 0.9312 - val_loss: 0.6105 - val_accuracy: 0.7751\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 33s 312ms/step - loss: 0.1043 - accuracy: 0.9594 - val_loss: 0.7007 - val_accuracy: 0.7672\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.1022 - accuracy: 0.9635 - val_loss: 0.7384 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 60s 467ms/step - loss: 0.6417 - accuracy: 0.6102 - val_loss: 0.5572 - val_accuracy: 0.7090\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 41s 380ms/step - loss: 0.5053 - accuracy: 0.7408 - val_loss: 0.5120 - val_accuracy: 0.7513\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.4171 - accuracy: 0.8155 - val_loss: 0.4696 - val_accuracy: 0.7831\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 35s 323ms/step - loss: 0.3563 - accuracy: 0.8404 - val_loss: 0.4574 - val_accuracy: 0.7725\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 35s 323ms/step - loss: 0.3340 - accuracy: 0.8534 - val_loss: 0.4675 - val_accuracy: 0.7910\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 34s 321ms/step - loss: 0.3054 - accuracy: 0.8700 - val_loss: 0.5126 - val_accuracy: 0.7751\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 34s 320ms/step - loss: 0.2573 - accuracy: 0.8970 - val_loss: 0.4572 - val_accuracy: 0.7910\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.2244 - accuracy: 0.9071 - val_loss: 0.5387 - val_accuracy: 0.7751\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 33s 307ms/step - loss: 0.2087 - accuracy: 0.9109 - val_loss: 0.5750 - val_accuracy: 0.7698\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 33s 308ms/step - loss: 0.1994 - accuracy: 0.9193 - val_loss: 0.5317 - val_accuracy: 0.7910\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 33s 308ms/step - loss: 0.1527 - accuracy: 0.9405 - val_loss: 0.5082 - val_accuracy: 0.7751\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 33s 306ms/step - loss: 0.1761 - accuracy: 0.9250 - val_loss: 0.5952 - val_accuracy: 0.7751\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 33s 306ms/step - loss: 0.1107 - accuracy: 0.9570 - val_loss: 0.6158 - val_accuracy: 0.7804\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 32s 302ms/step - loss: 0.0884 - accuracy: 0.9703 - val_loss: 0.7067 - val_accuracy: 0.7646\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 32s 304ms/step - loss: 0.1019 - accuracy: 0.9612 - val_loss: 0.6547 - val_accuracy: 0.7672\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 51s 380ms/step - loss: 0.6355 - accuracy: 0.6282 - val_loss: 0.5480 - val_accuracy: 0.7143\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 35s 326ms/step - loss: 0.4914 - accuracy: 0.7550 - val_loss: 0.4795 - val_accuracy: 0.7275\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 34s 319ms/step - loss: 0.3919 - accuracy: 0.8189 - val_loss: 0.4629 - val_accuracy: 0.7646\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 33s 312ms/step - loss: 0.3534 - accuracy: 0.8470 - val_loss: 0.4450 - val_accuracy: 0.7884\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 33s 312ms/step - loss: 0.3381 - accuracy: 0.8470 - val_loss: 0.4526 - val_accuracy: 0.7646\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.3065 - accuracy: 0.8679 - val_loss: 0.4519 - val_accuracy: 0.8042\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.2769 - accuracy: 0.8836 - val_loss: 0.4398 - val_accuracy: 0.7804\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 33s 307ms/step - loss: 0.2585 - accuracy: 0.8959 - val_loss: 0.4514 - val_accuracy: 0.7937\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 33s 307ms/step - loss: 0.2293 - accuracy: 0.9094 - val_loss: 0.4410 - val_accuracy: 0.7963\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 33s 306ms/step - loss: 0.2120 - accuracy: 0.9097 - val_loss: 0.5152 - val_accuracy: 0.7778\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 33s 307ms/step - loss: 0.2001 - accuracy: 0.9160 - val_loss: 0.4875 - val_accuracy: 0.7989\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 33s 306ms/step - loss: 0.1599 - accuracy: 0.9342 - val_loss: 0.5311 - val_accuracy: 0.7831\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 33s 305ms/step - loss: 0.1370 - accuracy: 0.9446 - val_loss: 0.5582 - val_accuracy: 0.7778\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 33s 305ms/step - loss: 0.0990 - accuracy: 0.9681 - val_loss: 0.6469 - val_accuracy: 0.7804\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 33s 305ms/step - loss: 0.0843 - accuracy: 0.9638 - val_loss: 0.6154 - val_accuracy: 0.7910\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 33s 306ms/step - loss: 0.0928 - accuracy: 0.9638 - val_loss: 0.7128 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 41s 292ms/step - loss: 0.6456 - accuracy: 0.6413 - val_loss: 0.5713 - val_accuracy: 0.6746\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 28s 259ms/step - loss: 0.4988 - accuracy: 0.7505 - val_loss: 0.4991 - val_accuracy: 0.7566\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 27s 252ms/step - loss: 0.4029 - accuracy: 0.8069 - val_loss: 0.4484 - val_accuracy: 0.7884\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.3662 - accuracy: 0.8299 - val_loss: 0.4490 - val_accuracy: 0.7937\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 27s 253ms/step - loss: 0.3317 - accuracy: 0.8575 - val_loss: 0.4803 - val_accuracy: 0.7937\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 27s 253ms/step - loss: 0.2997 - accuracy: 0.8711 - val_loss: 0.4914 - val_accuracy: 0.7804\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 27s 252ms/step - loss: 0.2964 - accuracy: 0.8744 - val_loss: 0.6289 - val_accuracy: 0.7354\n",
      "Epoch 8/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 27s 249ms/step - loss: 0.2603 - accuracy: 0.8893 - val_loss: 0.6280 - val_accuracy: 0.7698\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 27s 248ms/step - loss: 0.2284 - accuracy: 0.8965 - val_loss: 0.5804 - val_accuracy: 0.7778\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 26s 248ms/step - loss: 0.1856 - accuracy: 0.9250 - val_loss: 0.6722 - val_accuracy: 0.7593\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.2162 - accuracy: 0.9120 - val_loss: 0.6150 - val_accuracy: 0.7751\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 26s 247ms/step - loss: 0.1686 - accuracy: 0.9327 - val_loss: 0.7688 - val_accuracy: 0.7698\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.1110 - accuracy: 0.9620 - val_loss: 0.7036 - val_accuracy: 0.7566\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 26s 244ms/step - loss: 0.1280 - accuracy: 0.9504 - val_loss: 0.7041 - val_accuracy: 0.7857\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 59s 454ms/step - loss: 0.6373 - accuracy: 0.6236 - val_loss: 0.5613 - val_accuracy: 0.6931\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.4883 - accuracy: 0.7532 - val_loss: 0.4789 - val_accuracy: 0.7540\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 45s 422ms/step - loss: 0.3909 - accuracy: 0.8170 - val_loss: 0.4687 - val_accuracy: 0.7646\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 45s 418ms/step - loss: 0.3560 - accuracy: 0.8396 - val_loss: 0.5210 - val_accuracy: 0.7646\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 45s 422ms/step - loss: 0.3354 - accuracy: 0.8466 - val_loss: 0.4502 - val_accuracy: 0.7963\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 46s 426ms/step - loss: 0.3079 - accuracy: 0.8631 - val_loss: 0.4496 - val_accuracy: 0.8069\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 46s 428ms/step - loss: 0.2678 - accuracy: 0.8870 - val_loss: 0.4737 - val_accuracy: 0.8095\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 46s 426ms/step - loss: 0.2573 - accuracy: 0.8800 - val_loss: 0.4601 - val_accuracy: 0.8148\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.2207 - accuracy: 0.9097 - val_loss: 0.4603 - val_accuracy: 0.8148\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.2060 - accuracy: 0.9172 - val_loss: 0.4512 - val_accuracy: 0.8307\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 45s 422ms/step - loss: 0.2024 - accuracy: 0.9106 - val_loss: 0.5239 - val_accuracy: 0.8254\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 45s 422ms/step - loss: 0.1667 - accuracy: 0.9314 - val_loss: 0.6150 - val_accuracy: 0.8201\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 45s 422ms/step - loss: 0.1229 - accuracy: 0.9532 - val_loss: 0.5463 - val_accuracy: 0.8254\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 45s 420ms/step - loss: 0.1092 - accuracy: 0.9606 - val_loss: 0.5286 - val_accuracy: 0.8201\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0884 - accuracy: 0.9660 - val_loss: 0.6626 - val_accuracy: 0.8466\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0667 - accuracy: 0.9749 - val_loss: 0.6538 - val_accuracy: 0.8122\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 46s 427ms/step - loss: 0.0707 - accuracy: 0.9765 - val_loss: 0.7408 - val_accuracy: 0.8175\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0448 - accuracy: 0.9875 - val_loss: 0.7622 - val_accuracy: 0.8254\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.0310 - accuracy: 0.9946 - val_loss: 0.7952 - val_accuracy: 0.8280\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0521 - accuracy: 0.9816 - val_loss: 0.8083 - val_accuracy: 0.8307\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 46s 426ms/step - loss: 0.0210 - accuracy: 0.9964 - val_loss: 0.8276 - val_accuracy: 0.8122\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 45s 425ms/step - loss: 0.0403 - accuracy: 0.9858 - val_loss: 0.7737 - val_accuracy: 0.8201\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 46s 428ms/step - loss: 0.0244 - accuracy: 0.9934 - val_loss: 0.9018 - val_accuracy: 0.8254\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 45s 424ms/step - loss: 0.0309 - accuracy: 0.9912 - val_loss: 0.9583 - val_accuracy: 0.8228\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0086 - accuracy: 0.9995 - val_loss: 1.0375 - val_accuracy: 0.8307\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 84.65608358383179\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 65s 505ms/step - loss: 0.6412 - accuracy: 0.6223 - val_loss: 0.5143 - val_accuracy: 0.7613\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.4769 - accuracy: 0.7688 - val_loss: 0.4881 - val_accuracy: 0.7639\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 42s 389ms/step - loss: 0.4145 - accuracy: 0.8076 - val_loss: 0.4639 - val_accuracy: 0.7825\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 42s 389ms/step - loss: 0.3706 - accuracy: 0.8268 - val_loss: 0.5082 - val_accuracy: 0.7347\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 41s 386ms/step - loss: 0.3408 - accuracy: 0.8542 - val_loss: 0.5032 - val_accuracy: 0.7613\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 41s 385ms/step - loss: 0.2924 - accuracy: 0.8688 - val_loss: 0.5131 - val_accuracy: 0.7507\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.2699 - accuracy: 0.8887 - val_loss: 0.6200 - val_accuracy: 0.7374\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.2640 - accuracy: 0.8805 - val_loss: 0.5770 - val_accuracy: 0.7347\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.2385 - accuracy: 0.8930 - val_loss: 0.7181 - val_accuracy: 0.7294\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.2136 - accuracy: 0.9085 - val_loss: 0.7088 - val_accuracy: 0.7268\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 42s 389ms/step - loss: 0.1679 - accuracy: 0.9342 - val_loss: 0.7284 - val_accuracy: 0.7268\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 42s 388ms/step - loss: 0.1651 - accuracy: 0.9356 - val_loss: 0.8777 - val_accuracy: 0.7294\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.1387 - accuracy: 0.9473 - val_loss: 0.9017 - val_accuracy: 0.7294\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 59s 457ms/step - loss: 0.6305 - accuracy: 0.6375 - val_loss: 0.5388 - val_accuracy: 0.7347\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 41s 383ms/step - loss: 0.4761 - accuracy: 0.7715 - val_loss: 0.5350 - val_accuracy: 0.7268\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 39s 365ms/step - loss: 0.3947 - accuracy: 0.8199 - val_loss: 0.5215 - val_accuracy: 0.7507\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 39s 362ms/step - loss: 0.3578 - accuracy: 0.8400 - val_loss: 0.5013 - val_accuracy: 0.7719\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.3258 - accuracy: 0.8553 - val_loss: 0.5467 - val_accuracy: 0.7719\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.2880 - accuracy: 0.8826 - val_loss: 0.5425 - val_accuracy: 0.7692\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 38s 356ms/step - loss: 0.2809 - accuracy: 0.8843 - val_loss: 0.7796 - val_accuracy: 0.7162\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.2680 - accuracy: 0.8835 - val_loss: 0.5182 - val_accuracy: 0.7772\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 39s 361ms/step - loss: 0.2099 - accuracy: 0.9142 - val_loss: 0.5895 - val_accuracy: 0.7958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/40\n",
      "107/107 [==============================] - 39s 361ms/step - loss: 0.1869 - accuracy: 0.9228 - val_loss: 0.5842 - val_accuracy: 0.7613\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 38s 352ms/step - loss: 0.1735 - accuracy: 0.9238 - val_loss: 0.7467 - val_accuracy: 0.7639\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 37s 350ms/step - loss: 0.1423 - accuracy: 0.9458 - val_loss: 0.7044 - val_accuracy: 0.7454\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 37s 349ms/step - loss: 0.1687 - accuracy: 0.9292 - val_loss: 0.7855 - val_accuracy: 0.7639\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.1025 - accuracy: 0.9707 - val_loss: 0.8180 - val_accuracy: 0.7639\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 38s 351ms/step - loss: 0.0959 - accuracy: 0.9638 - val_loss: 0.7940 - val_accuracy: 0.7586\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.0774 - accuracy: 0.9757 - val_loss: 1.0218 - val_accuracy: 0.7639\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 36s 336ms/step - loss: 0.0441 - accuracy: 0.9876 - val_loss: 1.0867 - val_accuracy: 0.7639\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 36s 336ms/step - loss: 0.0387 - accuracy: 0.9884 - val_loss: 1.0296 - val_accuracy: 0.7825\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 36s 337ms/step - loss: 0.0239 - accuracy: 0.9918 - val_loss: 1.0685 - val_accuracy: 0.7692\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 51s 388ms/step - loss: 0.6444 - accuracy: 0.6364 - val_loss: 0.5621 - val_accuracy: 0.7003\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 38s 353ms/step - loss: 0.4758 - accuracy: 0.7759 - val_loss: 0.4916 - val_accuracy: 0.7374\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 37s 349ms/step - loss: 0.4014 - accuracy: 0.8155 - val_loss: 0.4934 - val_accuracy: 0.7480\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.3672 - accuracy: 0.8332 - val_loss: 0.4435 - val_accuracy: 0.7666\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 38s 353ms/step - loss: 0.3477 - accuracy: 0.8388 - val_loss: 0.4258 - val_accuracy: 0.7851\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.3034 - accuracy: 0.8631 - val_loss: 0.4622 - val_accuracy: 0.7798\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.2795 - accuracy: 0.8828 - val_loss: 0.4467 - val_accuracy: 0.8064\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 38s 350ms/step - loss: 0.2330 - accuracy: 0.9047 - val_loss: 0.4656 - val_accuracy: 0.8037\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 37s 350ms/step - loss: 0.2303 - accuracy: 0.8960 - val_loss: 0.5237 - val_accuracy: 0.7798\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 37s 347ms/step - loss: 0.1917 - accuracy: 0.9203 - val_loss: 0.5381 - val_accuracy: 0.7878\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 37s 348ms/step - loss: 0.1745 - accuracy: 0.9321 - val_loss: 0.7067 - val_accuracy: 0.7719\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 37s 351ms/step - loss: 0.1526 - accuracy: 0.9391 - val_loss: 0.7423 - val_accuracy: 0.7613\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 38s 351ms/step - loss: 0.1261 - accuracy: 0.9569 - val_loss: 0.7075 - val_accuracy: 0.7772\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 38s 352ms/step - loss: 0.1154 - accuracy: 0.9602 - val_loss: 0.7313 - val_accuracy: 0.7745\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 38s 351ms/step - loss: 0.0810 - accuracy: 0.9721 - val_loss: 1.0800 - val_accuracy: 0.7507\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 37s 350ms/step - loss: 0.0741 - accuracy: 0.9774 - val_loss: 0.9645 - val_accuracy: 0.7480\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 37s 350ms/step - loss: 0.0584 - accuracy: 0.9809 - val_loss: 0.8854 - val_accuracy: 0.7215\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 52s 391ms/step - loss: 0.6290 - accuracy: 0.6440 - val_loss: 0.4764 - val_accuracy: 0.7772\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 38s 359ms/step - loss: 0.4884 - accuracy: 0.7548 - val_loss: 0.3927 - val_accuracy: 0.8170\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 38s 359ms/step - loss: 0.4152 - accuracy: 0.8117 - val_loss: 0.3776 - val_accuracy: 0.8196\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 38s 356ms/step - loss: 0.3638 - accuracy: 0.8334 - val_loss: 0.4042 - val_accuracy: 0.8143\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.3518 - accuracy: 0.8325 - val_loss: 0.3690 - val_accuracy: 0.8196\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.2963 - accuracy: 0.8729 - val_loss: 0.3677 - val_accuracy: 0.8488\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.2901 - accuracy: 0.8731 - val_loss: 0.3899 - val_accuracy: 0.8435\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 38s 359ms/step - loss: 0.2505 - accuracy: 0.9001 - val_loss: 0.4064 - val_accuracy: 0.8196\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 38s 356ms/step - loss: 0.2371 - accuracy: 0.9025 - val_loss: 0.4805 - val_accuracy: 0.7772\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 38s 355ms/step - loss: 0.2135 - accuracy: 0.9134 - val_loss: 0.4158 - val_accuracy: 0.8196\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 38s 354ms/step - loss: 0.1908 - accuracy: 0.9196 - val_loss: 0.4351 - val_accuracy: 0.8064\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 38s 358ms/step - loss: 0.1657 - accuracy: 0.9372 - val_loss: 0.5429 - val_accuracy: 0.7745\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.1332 - accuracy: 0.9371 - val_loss: 0.5599 - val_accuracy: 0.7878\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 38s 358ms/step - loss: 0.1011 - accuracy: 0.9662 - val_loss: 0.6659 - val_accuracy: 0.7878\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 38s 358ms/step - loss: 0.0882 - accuracy: 0.9643 - val_loss: 0.6095 - val_accuracy: 0.8170\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 38s 357ms/step - loss: 0.0798 - accuracy: 0.9688 - val_loss: 0.6491 - val_accuracy: 0.8249\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 84.8806381225586\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 60s 458ms/step - loss: 0.6347 - accuracy: 0.6337 - val_loss: 0.5618 - val_accuracy: 0.6976\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 44s 407ms/step - loss: 0.5139 - accuracy: 0.7450 - val_loss: 0.4796 - val_accuracy: 0.7692\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 43s 398ms/step - loss: 0.4241 - accuracy: 0.7922 - val_loss: 0.4552 - val_accuracy: 0.7825\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 42s 394ms/step - loss: 0.3722 - accuracy: 0.8416 - val_loss: 0.4722 - val_accuracy: 0.7639\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 42s 392ms/step - loss: 0.3182 - accuracy: 0.8704 - val_loss: 0.4966 - val_accuracy: 0.7533\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.3095 - accuracy: 0.8649 - val_loss: 0.4993 - val_accuracy: 0.7533\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.2588 - accuracy: 0.8896 - val_loss: 0.6197 - val_accuracy: 0.7294\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 42s 390ms/step - loss: 0.2552 - accuracy: 0.8958 - val_loss: 0.6162 - val_accuracy: 0.7507\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 42s 391ms/step - loss: 0.2077 - accuracy: 0.9196 - val_loss: 0.6298 - val_accuracy: 0.7533\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 0.2040 - accuracy: 0.9142 - val_loss: 0.7205 - val_accuracy: 0.7454\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 42s 390ms/step - loss: 0.1662 - accuracy: 0.9344 - val_loss: 0.7857 - val_accuracy: 0.7401\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 0.1475 - accuracy: 0.9466 - val_loss: 0.9047 - val_accuracy: 0.7347\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 41s 387ms/step - loss: 0.1025 - accuracy: 0.9643 - val_loss: 1.0146 - val_accuracy: 0.7268\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  78.835976  79.100531  80.423278  79.365081  84.656084  78.249335   \n",
      "\n",
      "        acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.575598  80.636603  84.880638  78.249335  80.397246  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_2(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>78.835976</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>79.365081</td>\n",
       "      <td>84.656084</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>84.880638</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>80.397246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  78.835976  79.100531  80.423278  79.365081  84.656084  78.249335   \n",
       "\n",
       "        acc7       acc8       acc9      acc10        AVG  \n",
       "0  79.575598  80.636603  84.880638  78.249335  80.397246  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('GRU_CR_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "#         tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Bidirectional((tf.keras.layers.GRU(64))),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Propagate X through a Dense layer with 1 unit\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_45 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_45 (Bidirectio (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 440,673\n",
      "Trainable params: 440,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 80s 642ms/step - loss: 0.6326 - accuracy: 0.6375 - val_loss: 0.4725 - val_accuracy: 0.7725\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 62s 575ms/step - loss: 0.3715 - accuracy: 0.8356 - val_loss: 0.4138 - val_accuracy: 0.7989\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 62s 584ms/step - loss: 0.1893 - accuracy: 0.9380 - val_loss: 0.5095 - val_accuracy: 0.8069\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 62s 581ms/step - loss: 0.0864 - accuracy: 0.9733 - val_loss: 0.6016 - val_accuracy: 0.7698\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 62s 583ms/step - loss: 0.0642 - accuracy: 0.9823 - val_loss: 0.7925 - val_accuracy: 0.7884\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 62s 582ms/step - loss: 0.0376 - accuracy: 0.9898 - val_loss: 0.9291 - val_accuracy: 0.7910\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 62s 583ms/step - loss: 0.0172 - accuracy: 0.9934 - val_loss: 0.9857 - val_accuracy: 0.8016\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 62s 583ms/step - loss: 0.0072 - accuracy: 0.9982 - val_loss: 1.1589 - val_accuracy: 0.7910\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 63s 586ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 1.1326 - val_accuracy: 0.7910\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 63s 586ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 1.3054 - val_accuracy: 0.7910\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 62s 583ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 1.1801 - val_accuracy: 0.7884\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 63s 585ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 1.1491 - val_accuracy: 0.7672\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 62s 580ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 1.3048 - val_accuracy: 0.7778\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 86s 708ms/step - loss: 0.6113 - accuracy: 0.6619 - val_loss: 0.4480 - val_accuracy: 0.7857\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 74s 695ms/step - loss: 0.3415 - accuracy: 0.8494 - val_loss: 0.4448 - val_accuracy: 0.8016\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 74s 694ms/step - loss: 0.2096 - accuracy: 0.9231 - val_loss: 0.4844 - val_accuracy: 0.8201\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 73s 686ms/step - loss: 0.1123 - accuracy: 0.9602 - val_loss: 0.6512 - val_accuracy: 0.7831\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0578 - accuracy: 0.9844 - val_loss: 0.7606 - val_accuracy: 0.8016\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 73s 685ms/step - loss: 0.0385 - accuracy: 0.9885 - val_loss: 0.9620 - val_accuracy: 0.7698\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 74s 687ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 1.0321 - val_accuracy: 0.7831\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 73s 684ms/step - loss: 0.0202 - accuracy: 0.9948 - val_loss: 1.0929 - val_accuracy: 0.7778\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 73s 681ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.9989 - val_accuracy: 0.7778\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 73s 685ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 1.2092 - val_accuracy: 0.7778\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 73s 680ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 1.3268 - val_accuracy: 0.7751\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 1.3633 - val_accuracy: 0.7804\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 73s 683ms/step - loss: 0.0014 - accuracy: 0.9994 - val_loss: 1.4262 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 82.0105791091919\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 100s 789ms/step - loss: 0.6290 - accuracy: 0.6277 - val_loss: 0.3870 - val_accuracy: 0.8307\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 80s 744ms/step - loss: 0.3557 - accuracy: 0.8424 - val_loss: 0.3722 - val_accuracy: 0.8307\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 81s 753ms/step - loss: 0.2033 - accuracy: 0.9191 - val_loss: 0.3233 - val_accuracy: 0.8624\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 81s 754ms/step - loss: 0.1105 - accuracy: 0.9612 - val_loss: 0.3677 - val_accuracy: 0.8439\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 80s 748ms/step - loss: 0.0620 - accuracy: 0.9804 - val_loss: 0.4288 - val_accuracy: 0.8386\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 81s 756ms/step - loss: 0.0396 - accuracy: 0.9886 - val_loss: 0.5090 - val_accuracy: 0.8095\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 81s 756ms/step - loss: 0.0185 - accuracy: 0.9951 - val_loss: 0.5697 - val_accuracy: 0.8148\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 80s 750ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.6544 - val_accuracy: 0.8069\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 80s 752ms/step - loss: 0.0079 - accuracy: 0.9990 - val_loss: 0.6693 - val_accuracy: 0.8122\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 80s 751ms/step - loss: 0.0051 - accuracy: 0.9991 - val_loss: 0.6977 - val_accuracy: 0.8228\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 81s 755ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.7557 - val_accuracy: 0.8175\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 80s 749ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.8486 - val_accuracy: 0.8307\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 79s 743ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.8843 - val_accuracy: 0.8228\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.24338507652283\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 108s 907ms/step - loss: 0.6212 - accuracy: 0.6505 - val_loss: 0.4612 - val_accuracy: 0.7778\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 89s 832ms/step - loss: 0.3560 - accuracy: 0.8430 - val_loss: 0.3660 - val_accuracy: 0.8333\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 80s 750ms/step - loss: 0.1829 - accuracy: 0.9391 - val_loss: 0.3953 - val_accuracy: 0.8307\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 80s 747ms/step - loss: 0.1111 - accuracy: 0.9663 - val_loss: 0.4578 - val_accuracy: 0.8280\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 80s 747ms/step - loss: 0.0549 - accuracy: 0.9780 - val_loss: 0.5052 - val_accuracy: 0.8228\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 79s 741ms/step - loss: 0.0287 - accuracy: 0.9948 - val_loss: 0.6631 - val_accuracy: 0.8228\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 84s 781ms/step - loss: 0.0150 - accuracy: 0.9953 - val_loss: 0.8094 - val_accuracy: 0.8307\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 82s 769ms/step - loss: 0.0082 - accuracy: 0.9988 - val_loss: 0.8035 - val_accuracy: 0.8307\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 82s 769ms/step - loss: 0.0075 - accuracy: 0.9982 - val_loss: 0.8358 - val_accuracy: 0.8360\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 83s 772ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.9031 - val_accuracy: 0.8095\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 83s 772ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 0.7009 - val_accuracy: 0.8413\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 82s 770ms/step - loss: 0.0066 - accuracy: 0.9989 - val_loss: 0.8573 - val_accuracy: 0.8307\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 82s 768ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.9652 - val_accuracy: 0.8333\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 82s 769ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 1.0033 - val_accuracy: 0.8386\n",
      "Epoch 15/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 82s 767ms/step - loss: 0.0012 - accuracy: 0.9992 - val_loss: 1.0675 - val_accuracy: 0.8280\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 83s 775ms/step - loss: 0.0015 - accuracy: 0.9993 - val_loss: 1.1205 - val_accuracy: 0.8307\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 82s 765ms/step - loss: 0.0015 - accuracy: 0.9991 - val_loss: 1.1570 - val_accuracy: 0.8307\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 82s 763ms/step - loss: 0.0022 - accuracy: 0.9985 - val_loss: 1.1898 - val_accuracy: 0.8307\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 81s 761ms/step - loss: 0.0014 - accuracy: 0.9989 - val_loss: 1.2075 - val_accuracy: 0.8333\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 81s 760ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 1.2189 - val_accuracy: 0.8333\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 82s 765ms/step - loss: 0.0017 - accuracy: 0.9990 - val_loss: 1.2346 - val_accuracy: 0.8333\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 84.1269850730896\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 75s 602ms/step - loss: 0.6320 - accuracy: 0.6357 - val_loss: 0.4848 - val_accuracy: 0.7566\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 58s 541ms/step - loss: 0.3711 - accuracy: 0.8315 - val_loss: 0.4293 - val_accuracy: 0.8042\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 53s 493ms/step - loss: 0.1847 - accuracy: 0.9312 - val_loss: 0.4737 - val_accuracy: 0.8042\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 52s 485ms/step - loss: 0.1091 - accuracy: 0.9683 - val_loss: 0.5287 - val_accuracy: 0.7778\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 52s 482ms/step - loss: 0.0602 - accuracy: 0.9833 - val_loss: 0.7393 - val_accuracy: 0.7460\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 51s 479ms/step - loss: 0.0489 - accuracy: 0.9837 - val_loss: 0.8069 - val_accuracy: 0.7778\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 51s 478ms/step - loss: 0.0194 - accuracy: 0.9951 - val_loss: 0.8412 - val_accuracy: 0.7698\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 51s 481ms/step - loss: 0.0115 - accuracy: 0.9960 - val_loss: 0.9722 - val_accuracy: 0.7937\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 52s 482ms/step - loss: 0.0121 - accuracy: 0.9959 - val_loss: 1.0061 - val_accuracy: 0.7566\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 51s 480ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 1.1989 - val_accuracy: 0.7698\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 51s 479ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 1.2712 - val_accuracy: 0.7725\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 51s 480ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.3361 - val_accuracy: 0.7725\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 56s 418ms/step - loss: 0.6325 - accuracy: 0.6435 - val_loss: 0.4617 - val_accuracy: 0.7613\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 37s 343ms/step - loss: 0.3497 - accuracy: 0.8517 - val_loss: 0.3697 - val_accuracy: 0.8223\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 36s 340ms/step - loss: 0.1837 - accuracy: 0.9353 - val_loss: 0.4547 - val_accuracy: 0.7984\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 36s 340ms/step - loss: 0.1195 - accuracy: 0.9569 - val_loss: 0.5457 - val_accuracy: 0.8011\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 36s 340ms/step - loss: 0.0611 - accuracy: 0.9781 - val_loss: 0.5691 - val_accuracy: 0.8064\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 37s 342ms/step - loss: 0.0232 - accuracy: 0.9930 - val_loss: 0.6662 - val_accuracy: 0.7984\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 36s 340ms/step - loss: 0.0157 - accuracy: 0.9967 - val_loss: 0.8585 - val_accuracy: 0.8090\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 37s 341ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 0.9012 - val_accuracy: 0.8090\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 37s 342ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 0.9931 - val_accuracy: 0.7905\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 37s 342ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 1.0933 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 36s 341ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 1.1451 - val_accuracy: 0.8037\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 36s 340ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 1.1840 - val_accuracy: 0.8011\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 97s 774ms/step - loss: 0.6102 - accuracy: 0.6661 - val_loss: 0.4767 - val_accuracy: 0.7719\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 79s 742ms/step - loss: 0.3534 - accuracy: 0.8421 - val_loss: 0.4545 - val_accuracy: 0.7931\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 80s 743ms/step - loss: 0.2038 - accuracy: 0.9278 - val_loss: 0.5605 - val_accuracy: 0.7692\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 79s 739ms/step - loss: 0.1069 - accuracy: 0.9668 - val_loss: 0.6726 - val_accuracy: 0.7639\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 79s 740ms/step - loss: 0.0457 - accuracy: 0.9887 - val_loss: 0.8781 - val_accuracy: 0.7533\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 79s 738ms/step - loss: 0.0280 - accuracy: 0.9925 - val_loss: 1.2071 - val_accuracy: 0.7321\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 79s 738ms/step - loss: 0.0215 - accuracy: 0.9930 - val_loss: 1.2417 - val_accuracy: 0.7294\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 79s 737ms/step - loss: 0.0081 - accuracy: 0.9974 - val_loss: 1.5858 - val_accuracy: 0.7347\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 79s 737ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 1.6437 - val_accuracy: 0.7347\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 79s 740ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.7609 - val_accuracy: 0.7321\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 79s 738ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.8872 - val_accuracy: 0.7321\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 79s 739ms/step - loss: 0.0017 - accuracy: 0.9985 - val_loss: 2.0080 - val_accuracy: 0.7188\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 98s 814ms/step - loss: 0.6304 - accuracy: 0.6261 - val_loss: 0.5241 - val_accuracy: 0.7374\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 79s 739ms/step - loss: 0.3694 - accuracy: 0.8328 - val_loss: 0.5960 - val_accuracy: 0.7401\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 74s 690ms/step - loss: 0.1883 - accuracy: 0.9267 - val_loss: 0.8623 - val_accuracy: 0.7215\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 74s 691ms/step - loss: 0.0999 - accuracy: 0.9676 - val_loss: 0.8410 - val_accuracy: 0.7321\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 74s 689ms/step - loss: 0.0461 - accuracy: 0.9887 - val_loss: 0.9580 - val_accuracy: 0.7454\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 74s 689ms/step - loss: 0.0271 - accuracy: 0.9922 - val_loss: 1.2926 - val_accuracy: 0.7427\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 74s 687ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 1.5319 - val_accuracy: 0.7241\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 1.7766 - val_accuracy: 0.7454\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 73s 685ms/step - loss: 0.0140 - accuracy: 0.9952 - val_loss: 1.6553 - val_accuracy: 0.7427\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 74s 687ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 1.8586 - val_accuracy: 0.7241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "107/107 [==============================] - 73s 686ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 1.7103 - val_accuracy: 0.7427\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0073 - accuracy: 0.9982 - val_loss: 1.7315 - val_accuracy: 0.7401\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 1.9313 - val_accuracy: 0.7427\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 73s 681ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 2.0014 - val_accuracy: 0.7454\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 74s 690ms/step - loss: 0.0017 - accuracy: 0.9987 - val_loss: 2.0810 - val_accuracy: 0.7401\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 74.53581094741821\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 95s 781ms/step - loss: 0.6237 - accuracy: 0.6493 - val_loss: 0.4844 - val_accuracy: 0.7586\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 66s 612ms/step - loss: 0.3622 - accuracy: 0.8394 - val_loss: 0.4883 - val_accuracy: 0.7772\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 58s 538ms/step - loss: 0.2038 - accuracy: 0.9247 - val_loss: 0.5082 - val_accuracy: 0.7984\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 57s 535ms/step - loss: 0.0994 - accuracy: 0.9691 - val_loss: 0.6240 - val_accuracy: 0.8064\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 57s 530ms/step - loss: 0.0592 - accuracy: 0.9833 - val_loss: 0.6062 - val_accuracy: 0.8090\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 56s 527ms/step - loss: 0.0265 - accuracy: 0.9922 - val_loss: 0.8122 - val_accuracy: 0.7798\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 56s 520ms/step - loss: 0.0362 - accuracy: 0.9914 - val_loss: 1.0096 - val_accuracy: 0.7905\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 56s 520ms/step - loss: 0.0103 - accuracy: 0.9962 - val_loss: 0.9616 - val_accuracy: 0.7851\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 56s 520ms/step - loss: 0.0057 - accuracy: 0.9982 - val_loss: 1.1263 - val_accuracy: 0.7931\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 56s 520ms/step - loss: 0.0037 - accuracy: 0.9982 - val_loss: 1.2491 - val_accuracy: 0.7905\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.2839 - val_accuracy: 0.7878\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 1.3412 - val_accuracy: 0.7878\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.0016 - accuracy: 0.9990 - val_loss: 1.3722 - val_accuracy: 0.7825\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 56s 524ms/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 1.4283 - val_accuracy: 0.7825\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.0011 - accuracy: 0.9994 - val_loss: 1.4613 - val_accuracy: 0.7825\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 69s 544ms/step - loss: 0.6212 - accuracy: 0.6402 - val_loss: 0.6593 - val_accuracy: 0.7003\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 52s 490ms/step - loss: 0.3502 - accuracy: 0.8501 - val_loss: 0.4850 - val_accuracy: 0.7958\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 55s 516ms/step - loss: 0.1948 - accuracy: 0.9278 - val_loss: 0.6710 - val_accuracy: 0.7533\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.1053 - accuracy: 0.9635 - val_loss: 0.7654 - val_accuracy: 0.7639\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 55s 518ms/step - loss: 0.0627 - accuracy: 0.9802 - val_loss: 0.8831 - val_accuracy: 0.7719\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 55s 517ms/step - loss: 0.0265 - accuracy: 0.9938 - val_loss: 0.9938 - val_accuracy: 0.7639\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 56s 526ms/step - loss: 0.0270 - accuracy: 0.9906 - val_loss: 1.1877 - val_accuracy: 0.7586\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 55s 519ms/step - loss: 0.0133 - accuracy: 0.9961 - val_loss: 1.2452 - val_accuracy: 0.7692\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 56s 523ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 1.3811 - val_accuracy: 0.7719\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 1.5452 - val_accuracy: 0.7745\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 1.6969 - val_accuracy: 0.7798\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 56s 519ms/step - loss: 0.0017 - accuracy: 0.9989 - val_loss: 1.8093 - val_accuracy: 0.7745\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  76.719576  79.894179  78.571427  82.804233  81.216931  81.697613   \n",
      "\n",
      "        acc7       acc8       acc9     acc10        AVG  \n",
      "0  77.453583  79.045093  82.493371  81.43236  80.132837  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_3(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.687833</td>\n",
       "      <td>82.010579</td>\n",
       "      <td>86.243385</td>\n",
       "      <td>84.126985</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>82.228118</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>74.535811</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>81.004379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  80.687833  82.010579  86.243385  84.126985  80.423278  82.228118   \n",
       "\n",
       "        acc7       acc8       acc9      acc10        AVG  \n",
       "0  79.310346  74.535811  80.901855  79.575598  81.004379  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('GRU_CR_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
