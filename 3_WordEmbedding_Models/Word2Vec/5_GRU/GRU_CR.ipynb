{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using GRU model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaknesses are minor the feel and layout of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many of our disney movies do n 't play on this...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player has a problem with dual layer dvd 's su...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know the saying is you get what you pay for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will never purchase apex again .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>so far , the anti spam feature seems to be ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>i did not have any of the installation problem...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>their products have been great and have saved ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     weaknesses are minor the feel and layout of th...      0  train\n",
       "1     many of our disney movies do n 't play on this...      0  train\n",
       "2     player has a problem with dual layer dvd 's su...      0  train\n",
       "3     i know the saying is you get what you pay for ...      0  train\n",
       "4                      will never purchase apex again .      0  train\n",
       "...                                                 ...    ...    ...\n",
       "3770  so far , the anti spam feature seems to be ver...      1  train\n",
       "3771  i downloaded a trial version of computer assoc...      1  train\n",
       "3772  i did not have any of the installation problem...      1  train\n",
       "3773  their products have been great and have saved ...      1  train\n",
       "3774                                                         1  train\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/CR/CR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3775 entries, 0 to 3774\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3775 non-null   object\n",
      " 1   label     3775 non-null   int32 \n",
      " 2   split     3775 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 73.9+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2407</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          1368   1368\n",
       "1          2407   2407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  will never purchase apex again .\n",
      "Into a sequence of int: [72, 194, 285, 207, 286]\n",
      "Into a padded sequence: [ 72 194 285 207 286   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "and 3\n",
      "i 4\n",
      "it 5\n",
      "to 6\n",
      "a 7\n",
      "is 8\n",
      "of 9\n",
      "this 10\n",
      "5336\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "<img src=\"model.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "#         tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Bidirectional((tf.keras.layers.GRU(64))),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Propagate X through a Dense layer with 1 unit\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 440,673\n",
      "Trainable params: 440,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 43s 309ms/step - loss: 0.6296 - accuracy: 0.6404 - val_loss: 0.4986 - val_accuracy: 0.7513\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 24s 229ms/step - loss: 0.2904 - accuracy: 0.8794 - val_loss: 0.4936 - val_accuracy: 0.7672\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.1148 - accuracy: 0.9613 - val_loss: 0.5883 - val_accuracy: 0.7487\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.0466 - accuracy: 0.9847 - val_loss: 0.6880 - val_accuracy: 0.7619\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.8613 - val_accuracy: 0.7381\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 22s 201ms/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 1.0451 - val_accuracy: 0.7593\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.0040 - accuracy: 0.9986 - val_loss: 1.2537 - val_accuracy: 0.7513\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 1.1701 - val_accuracy: 0.7487\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 1.3299 - val_accuracy: 0.7407\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.0055 - accuracy: 0.9985 - val_loss: 1.5681 - val_accuracy: 0.7381\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.0028 - accuracy: 0.9974 - val_loss: 1.6954 - val_accuracy: 0.7407\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 9.2867e-04 - accuracy: 0.9995 - val_loss: 1.7912 - val_accuracy: 0.7407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Training 2: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 32s 204ms/step - loss: 0.6190 - accuracy: 0.6587 - val_loss: 0.4415 - val_accuracy: 0.7989\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 17s 162ms/step - loss: 0.2923 - accuracy: 0.8905 - val_loss: 0.4515 - val_accuracy: 0.7751\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.1284 - accuracy: 0.9611 - val_loss: 0.5211 - val_accuracy: 0.7857\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0534 - accuracy: 0.9868 - val_loss: 0.6666 - val_accuracy: 0.7804\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.0239 - accuracy: 0.9923 - val_loss: 0.8450 - val_accuracy: 0.7857\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.9504 - val_accuracy: 0.7884\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0133 - accuracy: 0.9948 - val_loss: 1.0475 - val_accuracy: 0.7751\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 1.1982 - val_accuracy: 0.7593\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0029 - accuracy: 0.9984 - val_loss: 1.2937 - val_accuracy: 0.7725\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.4011 - val_accuracy: 0.7672\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 16s 145ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 1.4512 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Training 3: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 79s 616ms/step - loss: 0.6336 - accuracy: 0.6359 - val_loss: 0.4578 - val_accuracy: 0.7751\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.2939 - accuracy: 0.8792 - val_loss: 0.4663 - val_accuracy: 0.7857\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 63s 586ms/step - loss: 0.1274 - accuracy: 0.9605 - val_loss: 0.5844 - val_accuracy: 0.7725\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 63s 591ms/step - loss: 0.0547 - accuracy: 0.9863 - val_loss: 0.7783 - val_accuracy: 0.7646\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.0268 - accuracy: 0.9919 - val_loss: 0.9939 - val_accuracy: 0.7593\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 63s 588ms/step - loss: 0.0139 - accuracy: 0.9970 - val_loss: 1.1034 - val_accuracy: 0.7593\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.0116 - accuracy: 0.9968 - val_loss: 1.1587 - val_accuracy: 0.7778\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 63s 587ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 1.3302 - val_accuracy: 0.7434\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 63s 585ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.4329 - val_accuracy: 0.7646\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 63s 589ms/step - loss: 0.0010 - accuracy: 0.9993 - val_loss: 1.5455 - val_accuracy: 0.7698\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 63s 588ms/step - loss: 0.0019 - accuracy: 0.9986 - val_loss: 1.6190 - val_accuracy: 0.7698\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 64s 596ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.6839 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.57142686843872\n",
      "Training 4: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 83s 671ms/step - loss: 0.6298 - accuracy: 0.6438 - val_loss: 0.4223 - val_accuracy: 0.8148\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 68s 640ms/step - loss: 0.2950 - accuracy: 0.8904 - val_loss: 0.4085 - val_accuracy: 0.8280\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 64s 598ms/step - loss: 0.1340 - accuracy: 0.9581 - val_loss: 0.5217 - val_accuracy: 0.8122\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 64s 598ms/step - loss: 0.0559 - accuracy: 0.9820 - val_loss: 0.5972 - val_accuracy: 0.7963\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 63s 592ms/step - loss: 0.0471 - accuracy: 0.9850 - val_loss: 0.7249 - val_accuracy: 0.7937\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 63s 589ms/step - loss: 0.0199 - accuracy: 0.9971 - val_loss: 0.7942 - val_accuracy: 0.7910\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 64s 596ms/step - loss: 0.0085 - accuracy: 0.9977 - val_loss: 0.8650 - val_accuracy: 0.7910\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 64s 594ms/step - loss: 0.0060 - accuracy: 0.9996 - val_loss: 0.8907 - val_accuracy: 0.7804\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 1.0569 - val_accuracy: 0.7910\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.1376 - val_accuracy: 0.7989\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 1.2140 - val_accuracy: 0.7884\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 63s 593ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.2542 - val_accuracy: 0.7910\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.80423283576965\n",
      "Training 5: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 58s 438ms/step - loss: 0.6388 - accuracy: 0.6151 - val_loss: 0.4527 - val_accuracy: 0.7725\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 41s 385ms/step - loss: 0.3098 - accuracy: 0.8694 - val_loss: 0.4149 - val_accuracy: 0.8122\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.1297 - accuracy: 0.9543 - val_loss: 0.4942 - val_accuracy: 0.7857\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0635 - accuracy: 0.9829 - val_loss: 0.5914 - val_accuracy: 0.7884\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0252 - accuracy: 0.9930 - val_loss: 0.8111 - val_accuracy: 0.7725\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 36s 333ms/step - loss: 0.0158 - accuracy: 0.9957 - val_loss: 0.9364 - val_accuracy: 0.7698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "107/107 [==============================] - 36s 333ms/step - loss: 0.0135 - accuracy: 0.9962 - val_loss: 0.9987 - val_accuracy: 0.7804\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 36s 332ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.1415 - val_accuracy: 0.7804\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0027 - accuracy: 0.9986 - val_loss: 1.2575 - val_accuracy: 0.7857\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0020 - accuracy: 0.9984 - val_loss: 1.2993 - val_accuracy: 0.7751\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 35s 328ms/step - loss: 0.0020 - accuracy: 0.9983 - val_loss: 1.3994 - val_accuracy: 0.7778\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 35s 330ms/step - loss: 0.0014 - accuracy: 0.9991 - val_loss: 1.4575 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Training 6: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 41s 292ms/step - loss: 0.6241 - accuracy: 0.6480 - val_loss: 0.4593 - val_accuracy: 0.7639\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 26s 246ms/step - loss: 0.2725 - accuracy: 0.8996 - val_loss: 0.4489 - val_accuracy: 0.8170\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 0.1200 - accuracy: 0.9581 - val_loss: 0.5913 - val_accuracy: 0.8064\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0626 - accuracy: 0.9802 - val_loss: 0.7950 - val_accuracy: 0.7984\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0294 - accuracy: 0.9916 - val_loss: 0.9397 - val_accuracy: 0.7931\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0100 - accuracy: 0.9979 - val_loss: 1.0385 - val_accuracy: 0.7984\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 1.0404 - val_accuracy: 0.8011\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 1.2376 - val_accuracy: 0.7851\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.0083 - accuracy: 0.9975 - val_loss: 1.3866 - val_accuracy: 0.7798\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 27s 249ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.9862 - val_accuracy: 0.7878\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 27s 250ms/step - loss: 0.0101 - accuracy: 0.9959 - val_loss: 1.3433 - val_accuracy: 0.7560\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 27s 251ms/step - loss: 0.0056 - accuracy: 0.9979 - val_loss: 1.1628 - val_accuracy: 0.7772\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Training 7: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 51s 378ms/step - loss: 0.6289 - accuracy: 0.6365 - val_loss: 0.4440 - val_accuracy: 0.7745\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 39s 366ms/step - loss: 0.2883 - accuracy: 0.8851 - val_loss: 0.4712 - val_accuracy: 0.7719\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 41s 383ms/step - loss: 0.1251 - accuracy: 0.9594 - val_loss: 0.6416 - val_accuracy: 0.7639\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 41s 382ms/step - loss: 0.0620 - accuracy: 0.9804 - val_loss: 0.7890 - val_accuracy: 0.7480\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 41s 385ms/step - loss: 0.0261 - accuracy: 0.9945 - val_loss: 0.9578 - val_accuracy: 0.7480\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 45s 423ms/step - loss: 0.0162 - accuracy: 0.9950 - val_loss: 1.0668 - val_accuracy: 0.7613\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 73s 687ms/step - loss: 0.0093 - accuracy: 0.9979 - val_loss: 1.2892 - val_accuracy: 0.7507\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 73s 686ms/step - loss: 0.0061 - accuracy: 0.9974 - val_loss: 1.4442 - val_accuracy: 0.7533\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 74s 693ms/step - loss: 0.0033 - accuracy: 0.9981 - val_loss: 1.4690 - val_accuracy: 0.7374\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 1.7214 - val_accuracy: 0.7533\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 74s 694ms/step - loss: 0.0019 - accuracy: 0.9993 - val_loss: 1.6448 - val_accuracy: 0.7480\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 77.45358347892761\n",
      "Training 8: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 88s 728ms/step - loss: 0.6287 - accuracy: 0.6396 - val_loss: 0.4594 - val_accuracy: 0.7851\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 74s 688ms/step - loss: 0.2751 - accuracy: 0.8982 - val_loss: 0.4934 - val_accuracy: 0.7772\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 73s 684ms/step - loss: 0.1310 - accuracy: 0.9563 - val_loss: 0.6380 - val_accuracy: 0.7905\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 73s 685ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.7229 - val_accuracy: 0.7798\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 73s 683ms/step - loss: 0.0249 - accuracy: 0.9936 - val_loss: 0.9703 - val_accuracy: 0.7560\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 74s 694ms/step - loss: 0.0130 - accuracy: 0.9959 - val_loss: 1.1489 - val_accuracy: 0.7586\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 1.0146 - val_accuracy: 0.7533\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 1.2082 - val_accuracy: 0.7613\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 74s 692ms/step - loss: 0.0094 - accuracy: 0.9972 - val_loss: 1.4499 - val_accuracy: 0.7586\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 74s 695ms/step - loss: 0.0110 - accuracy: 0.9965 - val_loss: 1.2231 - val_accuracy: 0.7560\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 74s 693ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.1156 - val_accuracy: 0.7454\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 74s 695ms/step - loss: 0.0126 - accuracy: 0.9957 - val_loss: 1.1657 - val_accuracy: 0.7507\n",
      "Epoch 13/30\n",
      "107/107 [==============================] - 74s 696ms/step - loss: 0.0052 - accuracy: 0.9990 - val_loss: 1.4421 - val_accuracy: 0.7560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Training 9: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 98s 818ms/step - loss: 0.6246 - accuracy: 0.6500 - val_loss: 0.3954 - val_accuracy: 0.8223\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 89s 830ms/step - loss: 0.2925 - accuracy: 0.8908 - val_loss: 0.3832 - val_accuracy: 0.8249\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 88s 822ms/step - loss: 0.1376 - accuracy: 0.9574 - val_loss: 0.4778 - val_accuracy: 0.8170\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 87s 814ms/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.6666 - val_accuracy: 0.7825\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 86s 809ms/step - loss: 0.0324 - accuracy: 0.9875 - val_loss: 0.7384 - val_accuracy: 0.7905\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 86s 805ms/step - loss: 0.0170 - accuracy: 0.9959 - val_loss: 0.9594 - val_accuracy: 0.7931\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 86s 805ms/step - loss: 0.0079 - accuracy: 0.9975 - val_loss: 0.9591 - val_accuracy: 0.7905\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 1.1568 - val_accuracy: 0.7931\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.1579 - val_accuracy: 0.7958\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 86s 802ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 1.2415 - val_accuracy: 0.8011\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 86s 802ms/step - loss: 0.0023 - accuracy: 0.9974 - val_loss: 1.2908 - val_accuracy: 0.8011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "107/107 [==============================] - 86s 800ms/step - loss: 7.1514e-04 - accuracy: 0.9997 - val_loss: 1.3317 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.49337077140808\n",
      "Training 10: \n",
      "Epoch 1/30\n",
      "107/107 [==============================] - 105s 883ms/step - loss: 0.6272 - accuracy: 0.6474 - val_loss: 0.4421 - val_accuracy: 0.7878\n",
      "Epoch 2/30\n",
      "107/107 [==============================] - 72s 673ms/step - loss: 0.2698 - accuracy: 0.8879 - val_loss: 0.4446 - val_accuracy: 0.8143\n",
      "Epoch 3/30\n",
      "107/107 [==============================] - 63s 589ms/step - loss: 0.1214 - accuracy: 0.9597 - val_loss: 0.5284 - val_accuracy: 0.7825\n",
      "Epoch 4/30\n",
      "107/107 [==============================] - 62s 578ms/step - loss: 0.0701 - accuracy: 0.9792 - val_loss: 0.7685 - val_accuracy: 0.7905\n",
      "Epoch 5/30\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.9923 - val_accuracy: 0.7798\n",
      "Epoch 6/30\n",
      "107/107 [==============================] - 61s 575ms/step - loss: 0.0154 - accuracy: 0.9962 - val_loss: 1.2048 - val_accuracy: 0.7878\n",
      "Epoch 7/30\n",
      "107/107 [==============================] - 62s 579ms/step - loss: 0.0085 - accuracy: 0.9986 - val_loss: 1.4466 - val_accuracy: 0.7401\n",
      "Epoch 8/30\n",
      "107/107 [==============================] - 62s 578ms/step - loss: 0.0117 - accuracy: 0.9956 - val_loss: 1.3172 - val_accuracy: 0.7745\n",
      "Epoch 9/30\n",
      "107/107 [==============================] - 61s 573ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 1.5097 - val_accuracy: 0.7639\n",
      "Epoch 10/30\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0029 - accuracy: 0.9988 - val_loss: 1.3565 - val_accuracy: 0.7560\n",
      "Epoch 11/30\n",
      "107/107 [==============================] - 61s 571ms/step - loss: 0.0055 - accuracy: 0.9997 - val_loss: 1.4394 - val_accuracy: 0.7533\n",
      "Epoch 12/30\n",
      "107/107 [==============================] - 61s 573ms/step - loss: 0.0074 - accuracy: 0.9967 - val_loss: 1.3746 - val_accuracy: 0.7533\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  76.719576  79.894179  78.571427  82.804233  81.216931  81.697613   \n",
      "\n",
      "        acc7       acc8       acc9     acc10        AVG  \n",
      "0  77.453583  79.045093  82.493371  81.43236  80.132837  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model(input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=30, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.719576</td>\n",
       "      <td>79.894179</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>82.804233</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>77.453583</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>82.493371</td>\n",
       "      <td>81.43236</td>\n",
       "      <td>80.132837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  76.719576  79.894179  78.571427  82.804233  81.216931  81.697613   \n",
       "\n",
       "        acc7       acc8       acc9     acc10        AVG  \n",
       "0  77.453583  79.045093  82.493371  81.43236  80.132837  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('GRU_CR.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5046 words present from 5336 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb_mean:  -0.003527845\n",
      "emb_std:  0.13315111\n"
     ]
    }
   ],
   "source": [
    "emb_mean = word2vec.vectors.mean()\n",
    "emb_std = word2vec.vectors.std()\n",
    "print('emb_mean: ', emb_mean)\n",
    "print('emb_std: ', emb_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index, emb_mean, emb_std):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    np.random.seed(2021)\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    # initialize the matrix with generic normal distribution values\n",
    "    embed_matrix = np.random.normal(emb_mean, emb_std, (vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.get_vector(word)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19468211,  0.08648376, -0.05924511, ..., -0.16683994,\n",
       "        -0.09975549, -0.08595189],\n",
       "       [-0.13509196, -0.07441947,  0.15388953, ..., -0.05400787,\n",
       "        -0.13156594, -0.05996158],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i, emb_mean, emb_std)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "#         tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Bidirectional((tf.keras.layers.GRU(64))),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Propagate X through a Dense layer with 1 unit\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 440,673\n",
      "Trainable params: 140,673\n",
      "Non-trainable params: 300,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 23s 130ms/step - loss: 0.6216 - accuracy: 0.6516 - val_loss: 0.4822 - val_accuracy: 0.7619\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.4281 - accuracy: 0.8025 - val_loss: 0.4350 - val_accuracy: 0.7857\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 11s 104ms/step - loss: 0.3969 - accuracy: 0.8141 - val_loss: 0.4190 - val_accuracy: 0.8228\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 11s 102ms/step - loss: 0.3511 - accuracy: 0.8461 - val_loss: 0.4552 - val_accuracy: 0.7672\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 11s 103ms/step - loss: 0.3240 - accuracy: 0.8625 - val_loss: 0.4263 - val_accuracy: 0.8122\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.3100 - accuracy: 0.8589 - val_loss: 0.4015 - val_accuracy: 0.8201\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 12s 108ms/step - loss: 0.2719 - accuracy: 0.8830 - val_loss: 0.4462 - val_accuracy: 0.7989\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.2340 - accuracy: 0.9009 - val_loss: 0.4340 - val_accuracy: 0.8254\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 12s 109ms/step - loss: 0.2264 - accuracy: 0.9056 - val_loss: 0.4431 - val_accuracy: 0.8122\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 12s 110ms/step - loss: 0.1793 - accuracy: 0.9264 - val_loss: 0.4685 - val_accuracy: 0.8069\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.1642 - accuracy: 0.9362 - val_loss: 0.4993 - val_accuracy: 0.8175\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 11s 104ms/step - loss: 0.1072 - accuracy: 0.9650 - val_loss: 0.5474 - val_accuracy: 0.8042\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 11s 107ms/step - loss: 0.1196 - accuracy: 0.9513 - val_loss: 0.6058 - val_accuracy: 0.8175\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.0797 - accuracy: 0.9745 - val_loss: 0.6996 - val_accuracy: 0.8122\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.0459 - accuracy: 0.9865 - val_loss: 0.7975 - val_accuracy: 0.8042\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 11s 103ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.9362 - val_accuracy: 0.7857\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 11s 103ms/step - loss: 0.0691 - accuracy: 0.9722 - val_loss: 0.7463 - val_accuracy: 0.8228\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 12s 109ms/step - loss: 0.0222 - accuracy: 0.9970 - val_loss: 0.9342 - val_accuracy: 0.7989\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 21s 117ms/step - loss: 0.6251 - accuracy: 0.6403 - val_loss: 0.4672 - val_accuracy: 0.7725\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 10s 90ms/step - loss: 0.4345 - accuracy: 0.8008 - val_loss: 0.4178 - val_accuracy: 0.8016\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.3963 - accuracy: 0.8148 - val_loss: 0.4084 - val_accuracy: 0.8016\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.3592 - accuracy: 0.8405 - val_loss: 0.4051 - val_accuracy: 0.8016\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 10s 92ms/step - loss: 0.3187 - accuracy: 0.8655 - val_loss: 0.4071 - val_accuracy: 0.8069\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 10s 90ms/step - loss: 0.2925 - accuracy: 0.8746 - val_loss: 0.4092 - val_accuracy: 0.7989\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 10s 89ms/step - loss: 0.2631 - accuracy: 0.8913 - val_loss: 0.4201 - val_accuracy: 0.7963\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 10s 89ms/step - loss: 0.2261 - accuracy: 0.9068 - val_loss: 0.4188 - val_accuracy: 0.8042\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.2176 - accuracy: 0.9159 - val_loss: 0.4688 - val_accuracy: 0.8095\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 10s 90ms/step - loss: 0.1741 - accuracy: 0.9313 - val_loss: 0.4949 - val_accuracy: 0.7910\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 10s 90ms/step - loss: 0.1280 - accuracy: 0.9532 - val_loss: 0.5234 - val_accuracy: 0.7989\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 10s 89ms/step - loss: 0.1238 - accuracy: 0.9587 - val_loss: 0.5856 - val_accuracy: 0.7804\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.1202 - accuracy: 0.9576 - val_loss: 0.6805 - val_accuracy: 0.7910\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 9s 88ms/step - loss: 0.0758 - accuracy: 0.9767 - val_loss: 0.6616 - val_accuracy: 0.7831\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 9s 86ms/step - loss: 0.0532 - accuracy: 0.9848 - val_loss: 0.7614 - val_accuracy: 0.7831\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 9s 86ms/step - loss: 0.0460 - accuracy: 0.9888 - val_loss: 0.7750 - val_accuracy: 0.7910\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 9s 87ms/step - loss: 0.0267 - accuracy: 0.9947 - val_loss: 0.7870 - val_accuracy: 0.7778\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 9s 87ms/step - loss: 0.0264 - accuracy: 0.9946 - val_loss: 1.0122 - val_accuracy: 0.7963\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 9s 86ms/step - loss: 0.0456 - accuracy: 0.9860 - val_loss: 0.8482 - val_accuracy: 0.7884\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 39s 272ms/step - loss: 0.6098 - accuracy: 0.6699 - val_loss: 0.4714 - val_accuracy: 0.7698\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 25s 229ms/step - loss: 0.4200 - accuracy: 0.8077 - val_loss: 0.4524 - val_accuracy: 0.7672\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 19s 180ms/step - loss: 0.3849 - accuracy: 0.8295 - val_loss: 0.4590 - val_accuracy: 0.7778\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 19s 179ms/step - loss: 0.3397 - accuracy: 0.8483 - val_loss: 0.4099 - val_accuracy: 0.8122\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 19s 174ms/step - loss: 0.3310 - accuracy: 0.8539 - val_loss: 0.4258 - val_accuracy: 0.7989\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 18s 164ms/step - loss: 0.3167 - accuracy: 0.8602 - val_loss: 0.4587 - val_accuracy: 0.7778\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 18s 167ms/step - loss: 0.2626 - accuracy: 0.8906 - val_loss: 0.4315 - val_accuracy: 0.7989\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 18s 164ms/step - loss: 0.2556 - accuracy: 0.8947 - val_loss: 0.4883 - val_accuracy: 0.8069\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 17s 160ms/step - loss: 0.2160 - accuracy: 0.9051 - val_loss: 0.4625 - val_accuracy: 0.8016\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 17s 162ms/step - loss: 0.1794 - accuracy: 0.9323 - val_loss: 0.5309 - val_accuracy: 0.7989\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 17s 163ms/step - loss: 0.1614 - accuracy: 0.9353 - val_loss: 0.5138 - val_accuracy: 0.7937\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 17s 161ms/step - loss: 0.1213 - accuracy: 0.9570 - val_loss: 0.5490 - val_accuracy: 0.8122\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 17s 161ms/step - loss: 0.1093 - accuracy: 0.9637 - val_loss: 0.5822 - val_accuracy: 0.8148\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 17s 162ms/step - loss: 0.0812 - accuracy: 0.9722 - val_loss: 0.6505 - val_accuracy: 0.8095\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 17s 163ms/step - loss: 0.0545 - accuracy: 0.9854 - val_loss: 0.6822 - val_accuracy: 0.8069\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 17s 163ms/step - loss: 0.0438 - accuracy: 0.9889 - val_loss: 0.6382 - val_accuracy: 0.8228\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 17s 161ms/step - loss: 0.0343 - accuracy: 0.9920 - val_loss: 0.7605 - val_accuracy: 0.8042\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 17s 161ms/step - loss: 0.0272 - accuracy: 0.9935 - val_loss: 0.8489 - val_accuracy: 0.8095\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 17s 158ms/step - loss: 0.0225 - accuracy: 0.9948 - val_loss: 0.8241 - val_accuracy: 0.8042\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.0225 - accuracy: 0.9960 - val_loss: 0.7608 - val_accuracy: 0.8122\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 16s 149ms/step - loss: 0.0114 - accuracy: 0.9968 - val_loss: 0.8741 - val_accuracy: 0.8175\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.9145 - val_accuracy: 0.8148\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 16s 150ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.9549 - val_accuracy: 0.8175\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0071 - accuracy: 0.9978 - val_loss: 0.9521 - val_accuracy: 0.7857\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0220 - accuracy: 0.9949 - val_loss: 0.9611 - val_accuracy: 0.7884\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 16s 151ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.9015 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 82.27513432502747\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 29s 183ms/step - loss: 0.6171 - accuracy: 0.6554 - val_loss: 0.5014 - val_accuracy: 0.7222\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 17s 160ms/step - loss: 0.4379 - accuracy: 0.7964 - val_loss: 0.4468 - val_accuracy: 0.8069\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.3654 - accuracy: 0.8354 - val_loss: 0.4333 - val_accuracy: 0.8016\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.3638 - accuracy: 0.8357 - val_loss: 0.4644 - val_accuracy: 0.7698\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 0.3360 - accuracy: 0.8521 - val_loss: 0.4333 - val_accuracy: 0.8095\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 17s 156ms/step - loss: 0.2954 - accuracy: 0.8706 - val_loss: 0.4300 - val_accuracy: 0.8148\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 17s 157ms/step - loss: 0.2792 - accuracy: 0.8834 - val_loss: 0.4342 - val_accuracy: 0.8095\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.2415 - accuracy: 0.9006 - val_loss: 0.4324 - val_accuracy: 0.8280\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.2143 - accuracy: 0.9059 - val_loss: 0.4664 - val_accuracy: 0.8042\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.1714 - accuracy: 0.9418 - val_loss: 0.4787 - val_accuracy: 0.8254\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.1514 - accuracy: 0.9421 - val_loss: 0.4891 - val_accuracy: 0.8201\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.1108 - accuracy: 0.9598 - val_loss: 0.5762 - val_accuracy: 0.7937\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 16s 150ms/step - loss: 0.0969 - accuracy: 0.9624 - val_loss: 0.5925 - val_accuracy: 0.8148\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.0744 - accuracy: 0.9754 - val_loss: 0.6071 - val_accuracy: 0.8228\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0480 - accuracy: 0.9868 - val_loss: 0.6860 - val_accuracy: 0.8307\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.0431 - accuracy: 0.9864 - val_loss: 0.7014 - val_accuracy: 0.8254\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0267 - accuracy: 0.9934 - val_loss: 0.7253 - val_accuracy: 0.8333\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0167 - accuracy: 0.9973 - val_loss: 0.7933 - val_accuracy: 0.8360\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.0181 - accuracy: 0.9972 - val_loss: 0.8384 - val_accuracy: 0.8148\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.0156 - accuracy: 0.9961 - val_loss: 0.8633 - val_accuracy: 0.8254\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 17s 154ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.8218 - val_accuracy: 0.8333\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.0090 - accuracy: 0.9990 - val_loss: 0.9162 - val_accuracy: 0.8333\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.9484 - val_accuracy: 0.8360\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.9877 - val_accuracy: 0.8280\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0039 - accuracy: 0.9986 - val_loss: 0.9367 - val_accuracy: 0.8095\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 16s 151ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 1.0013 - val_accuracy: 0.8095\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 16s 152ms/step - loss: 0.0051 - accuracy: 0.9977 - val_loss: 1.0239 - val_accuracy: 0.8069\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.0253 - accuracy: 0.9913 - val_loss: 0.8568 - val_accuracy: 0.8280\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 83.59788656234741\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 23s 129ms/step - loss: 0.6173 - accuracy: 0.6399 - val_loss: 0.4811 - val_accuracy: 0.7593\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 10s 96ms/step - loss: 0.4363 - accuracy: 0.7996 - val_loss: 0.4467 - val_accuracy: 0.7804\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 10s 94ms/step - loss: 0.3719 - accuracy: 0.8378 - val_loss: 0.4370 - val_accuracy: 0.7831\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.3468 - accuracy: 0.8519 - val_loss: 0.4259 - val_accuracy: 0.7857\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.3343 - accuracy: 0.8474 - val_loss: 0.4492 - val_accuracy: 0.7910\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 10s 92ms/step - loss: 0.3081 - accuracy: 0.8702 - val_loss: 0.4226 - val_accuracy: 0.7910\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.2805 - accuracy: 0.8742 - val_loss: 0.4818 - val_accuracy: 0.7857\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.2618 - accuracy: 0.8893 - val_loss: 0.4584 - val_accuracy: 0.8148\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 10s 92ms/step - loss: 0.2156 - accuracy: 0.9225 - val_loss: 0.4562 - val_accuracy: 0.8016\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.1950 - accuracy: 0.9245 - val_loss: 0.4617 - val_accuracy: 0.8069\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 10s 94ms/step - loss: 0.1580 - accuracy: 0.9403 - val_loss: 0.5627 - val_accuracy: 0.7963\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.1341 - accuracy: 0.9468 - val_loss: 0.5931 - val_accuracy: 0.7831\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.1018 - accuracy: 0.9659 - val_loss: 0.6474 - val_accuracy: 0.7751\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.0825 - accuracy: 0.9729 - val_loss: 0.7085 - val_accuracy: 0.7725\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.0529 - accuracy: 0.9885 - val_loss: 0.8512 - val_accuracy: 0.7778\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 10s 93ms/step - loss: 0.0473 - accuracy: 0.9893 - val_loss: 0.7465 - val_accuracy: 0.7778\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 10s 91ms/step - loss: 0.0297 - accuracy: 0.9909 - val_loss: 0.9152 - val_accuracy: 0.7884\n",
      "Epoch 18/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 10s 92ms/step - loss: 0.1213 - accuracy: 0.9546 - val_loss: 0.7870 - val_accuracy: 0.7989\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 20s 102ms/step - loss: 0.6286 - accuracy: 0.6449 - val_loss: 0.4579 - val_accuracy: 0.7905\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 8s 76ms/step - loss: 0.4512 - accuracy: 0.7884 - val_loss: 0.4196 - val_accuracy: 0.8143\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.3809 - accuracy: 0.8337 - val_loss: 0.4002 - val_accuracy: 0.8276\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.3748 - accuracy: 0.8347 - val_loss: 0.3802 - val_accuracy: 0.8090\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 8s 73ms/step - loss: 0.3310 - accuracy: 0.8404 - val_loss: 0.3734 - val_accuracy: 0.8249\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.3102 - accuracy: 0.8695 - val_loss: 0.3836 - val_accuracy: 0.8117\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.2702 - accuracy: 0.8821 - val_loss: 0.4214 - val_accuracy: 0.8117\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 8s 74ms/step - loss: 0.2516 - accuracy: 0.8975 - val_loss: 0.3952 - val_accuracy: 0.8223\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 8s 77ms/step - loss: 0.2252 - accuracy: 0.9073 - val_loss: 0.4023 - val_accuracy: 0.8064\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 8s 75ms/step - loss: 0.1904 - accuracy: 0.9257 - val_loss: 0.3973 - val_accuracy: 0.8170\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 8s 73ms/step - loss: 0.1709 - accuracy: 0.9335 - val_loss: 0.5392 - val_accuracy: 0.7905\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 8s 72ms/step - loss: 0.1482 - accuracy: 0.9391 - val_loss: 0.4620 - val_accuracy: 0.8143\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 8s 73ms/step - loss: 0.1087 - accuracy: 0.9581 - val_loss: 0.4704 - val_accuracy: 0.8223\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 82.75862336158752\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 53s 414ms/step - loss: 0.6247 - accuracy: 0.6404 - val_loss: 0.4891 - val_accuracy: 0.7480\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 37s 346ms/step - loss: 0.4287 - accuracy: 0.7924 - val_loss: 0.4150 - val_accuracy: 0.8011\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 28s 265ms/step - loss: 0.4026 - accuracy: 0.8254 - val_loss: 0.3982 - val_accuracy: 0.8011\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 28s 262ms/step - loss: 0.3504 - accuracy: 0.8505 - val_loss: 0.3839 - val_accuracy: 0.8170\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 28s 259ms/step - loss: 0.3188 - accuracy: 0.8561 - val_loss: 0.3894 - val_accuracy: 0.8170\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.3010 - accuracy: 0.8729 - val_loss: 0.3907 - val_accuracy: 0.8276\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.2720 - accuracy: 0.8854 - val_loss: 0.4175 - val_accuracy: 0.8302\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 28s 257ms/step - loss: 0.2431 - accuracy: 0.8981 - val_loss: 0.4781 - val_accuracy: 0.7586\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 28s 257ms/step - loss: 0.2187 - accuracy: 0.9077 - val_loss: 0.4887 - val_accuracy: 0.7851\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.1981 - accuracy: 0.9111 - val_loss: 0.4279 - val_accuracy: 0.8302\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.1659 - accuracy: 0.9288 - val_loss: 0.4657 - val_accuracy: 0.8408\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 27s 257ms/step - loss: 0.1284 - accuracy: 0.9530 - val_loss: 0.4565 - val_accuracy: 0.8223\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 28s 257ms/step - loss: 0.1074 - accuracy: 0.9647 - val_loss: 0.5003 - val_accuracy: 0.8143\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 27s 256ms/step - loss: 0.0957 - accuracy: 0.9670 - val_loss: 0.4793 - val_accuracy: 0.8594\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.0597 - accuracy: 0.9836 - val_loss: 0.5982 - val_accuracy: 0.8143\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 28s 257ms/step - loss: 0.0476 - accuracy: 0.9883 - val_loss: 0.6576 - val_accuracy: 0.8117\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 27s 257ms/step - loss: 0.0413 - accuracy: 0.9903 - val_loss: 0.6778 - val_accuracy: 0.8196\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 27s 257ms/step - loss: 0.0256 - accuracy: 0.9934 - val_loss: 0.6245 - val_accuracy: 0.8408\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 27s 257ms/step - loss: 0.0201 - accuracy: 0.9968 - val_loss: 0.6724 - val_accuracy: 0.8196\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.0175 - accuracy: 0.9972 - val_loss: 0.6575 - val_accuracy: 0.8276\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 28s 258ms/step - loss: 0.0108 - accuracy: 0.9990 - val_loss: 0.6884 - val_accuracy: 0.8249\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 28s 257ms/step - loss: 0.0179 - accuracy: 0.9968 - val_loss: 0.7402 - val_accuracy: 0.8223\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 27s 256ms/step - loss: 0.0164 - accuracy: 0.9953 - val_loss: 0.7669 - val_accuracy: 0.8462\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 27s 257ms/step - loss: 0.0441 - accuracy: 0.9879 - val_loss: 0.7055 - val_accuracy: 0.8302\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 85.94164252281189\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 36s 248ms/step - loss: 0.6215 - accuracy: 0.6372 - val_loss: 0.5003 - val_accuracy: 0.7454\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.4285 - accuracy: 0.8058 - val_loss: 0.4488 - val_accuracy: 0.7958\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 20s 186ms/step - loss: 0.3781 - accuracy: 0.8308 - val_loss: 0.4206 - val_accuracy: 0.7984\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.3489 - accuracy: 0.8496 - val_loss: 0.4192 - val_accuracy: 0.8011\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 19s 179ms/step - loss: 0.3380 - accuracy: 0.8563 - val_loss: 0.4338 - val_accuracy: 0.7931\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 19s 180ms/step - loss: 0.2773 - accuracy: 0.8838 - val_loss: 0.4231 - val_accuracy: 0.8011\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.2529 - accuracy: 0.8942 - val_loss: 0.4398 - val_accuracy: 0.7984\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 19s 181ms/step - loss: 0.2296 - accuracy: 0.9035 - val_loss: 0.4677 - val_accuracy: 0.8090\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.2139 - accuracy: 0.9059 - val_loss: 0.4624 - val_accuracy: 0.8037\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.1590 - accuracy: 0.9414 - val_loss: 0.5293 - val_accuracy: 0.8223\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 20s 183ms/step - loss: 0.1243 - accuracy: 0.9509 - val_loss: 0.5403 - val_accuracy: 0.7878\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.1084 - accuracy: 0.9640 - val_loss: 0.5620 - val_accuracy: 0.8090\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.0785 - accuracy: 0.9760 - val_loss: 0.5800 - val_accuracy: 0.8223\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.0616 - accuracy: 0.9832 - val_loss: 0.7258 - val_accuracy: 0.7931\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 20s 185ms/step - loss: 0.0549 - accuracy: 0.9795 - val_loss: 0.7022 - val_accuracy: 0.8037\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.0364 - accuracy: 0.9905 - val_loss: 0.9913 - val_accuracy: 0.7347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/40\n",
      "107/107 [==============================] - 20s 185ms/step - loss: 0.0560 - accuracy: 0.9830 - val_loss: 0.8272 - val_accuracy: 0.8037\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 20s 185ms/step - loss: 0.0170 - accuracy: 0.9961 - val_loss: 0.8570 - val_accuracy: 0.8037\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 20s 184ms/step - loss: 0.0114 - accuracy: 0.9987 - val_loss: 0.8107 - val_accuracy: 0.7878\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 20s 185ms/step - loss: 0.0155 - accuracy: 0.9954 - val_loss: 0.9236 - val_accuracy: 0.8170\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 28s 188ms/step - loss: 0.6296 - accuracy: 0.6427 - val_loss: 0.4873 - val_accuracy: 0.7507\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 17s 159ms/step - loss: 0.4426 - accuracy: 0.7957 - val_loss: 0.4376 - val_accuracy: 0.7825\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 16s 153ms/step - loss: 0.3851 - accuracy: 0.8373 - val_loss: 0.4231 - val_accuracy: 0.7878\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 16s 154ms/step - loss: 0.3517 - accuracy: 0.8575 - val_loss: 0.4373 - val_accuracy: 0.7905\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 17s 155ms/step - loss: 0.3174 - accuracy: 0.8646 - val_loss: 0.4294 - val_accuracy: 0.7772\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 16s 151ms/step - loss: 0.3055 - accuracy: 0.8671 - val_loss: 0.4155 - val_accuracy: 0.7984\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 16s 148ms/step - loss: 0.2686 - accuracy: 0.8892 - val_loss: 0.4244 - val_accuracy: 0.8064\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 16s 148ms/step - loss: 0.2323 - accuracy: 0.9065 - val_loss: 0.4393 - val_accuracy: 0.7798\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.2347 - accuracy: 0.9012 - val_loss: 0.4543 - val_accuracy: 0.7745\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.2015 - accuracy: 0.9232 - val_loss: 0.5239 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 16s 146ms/step - loss: 0.1701 - accuracy: 0.9305 - val_loss: 0.5549 - val_accuracy: 0.8011\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 16s 145ms/step - loss: 0.1162 - accuracy: 0.9577 - val_loss: 0.5960 - val_accuracy: 0.7984\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 15s 144ms/step - loss: 0.1140 - accuracy: 0.9590 - val_loss: 0.6489 - val_accuracy: 0.7825\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0795 - accuracy: 0.9709 - val_loss: 0.6626 - val_accuracy: 0.7772\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 15s 144ms/step - loss: 0.0540 - accuracy: 0.9855 - val_loss: 0.7515 - val_accuracy: 0.7958\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 15s 144ms/step - loss: 0.0420 - accuracy: 0.9843 - val_loss: 0.8107 - val_accuracy: 0.7958\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 15s 145ms/step - loss: 0.0268 - accuracy: 0.9936 - val_loss: 0.9307 - val_accuracy: 0.7905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 25s 157ms/step - loss: 0.6219 - accuracy: 0.6468 - val_loss: 0.4673 - val_accuracy: 0.7533\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 11s 104ms/step - loss: 0.4443 - accuracy: 0.7948 - val_loss: 0.4407 - val_accuracy: 0.7931\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 11s 105ms/step - loss: 0.3854 - accuracy: 0.8358 - val_loss: 0.4243 - val_accuracy: 0.7958\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 11s 106ms/step - loss: 0.3349 - accuracy: 0.8459 - val_loss: 0.4393 - val_accuracy: 0.7878\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 11s 104ms/step - loss: 0.3033 - accuracy: 0.8691 - val_loss: 0.4627 - val_accuracy: 0.7958\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 11s 104ms/step - loss: 0.3192 - accuracy: 0.8541 - val_loss: 0.4574 - val_accuracy: 0.7878\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 11s 104ms/step - loss: 0.2704 - accuracy: 0.8890 - val_loss: 0.5091 - val_accuracy: 0.7745\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 11s 103ms/step - loss: 0.2244 - accuracy: 0.9112 - val_loss: 0.4611 - val_accuracy: 0.8011\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 11s 103ms/step - loss: 0.2103 - accuracy: 0.9166 - val_loss: 0.4894 - val_accuracy: 0.8037\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 11s 102ms/step - loss: 0.1764 - accuracy: 0.9322 - val_loss: 0.4911 - val_accuracy: 0.7905\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 11s 105ms/step - loss: 0.1387 - accuracy: 0.9506 - val_loss: 0.5433 - val_accuracy: 0.7931\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 11s 107ms/step - loss: 0.1094 - accuracy: 0.9580 - val_loss: 0.6381 - val_accuracy: 0.7905\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 16s 151ms/step - loss: 0.0771 - accuracy: 0.9753 - val_loss: 0.6141 - val_accuracy: 0.8011\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 44s 414ms/step - loss: 0.0592 - accuracy: 0.9820 - val_loss: 0.6543 - val_accuracy: 0.7958\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.0494 - accuracy: 0.9846 - val_loss: 0.7307 - val_accuracy: 0.7905\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 44s 414ms/step - loss: 0.0467 - accuracy: 0.9840 - val_loss: 0.8281 - val_accuracy: 0.7905\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 44s 416ms/step - loss: 0.0327 - accuracy: 0.9916 - val_loss: 0.9596 - val_accuracy: 0.7745\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.0211 - accuracy: 0.9938 - val_loss: 0.9117 - val_accuracy: 0.8064\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.0102 - accuracy: 0.9980 - val_loss: 0.9892 - val_accuracy: 0.7772\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.0235 - accuracy: 0.9941 - val_loss: 1.0539 - val_accuracy: 0.7958\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 45s 420ms/step - loss: 0.0157 - accuracy: 0.9952 - val_loss: 0.9534 - val_accuracy: 0.7825\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 44s 415ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.9711 - val_accuracy: 0.8064\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 44s 411ms/step - loss: 0.0074 - accuracy: 0.9989 - val_loss: 0.9098 - val_accuracy: 0.8170\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.0160 - accuracy: 0.9947 - val_loss: 0.8447 - val_accuracy: 0.8196\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.0305 - accuracy: 0.9910 - val_loss: 0.9141 - val_accuracy: 0.8064\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 44s 410ms/step - loss: 0.0070 - accuracy: 0.9986 - val_loss: 0.9721 - val_accuracy: 0.8117\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 1.0823 - val_accuracy: 0.8011\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 1.0531 - val_accuracy: 0.8037\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 44s 408ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 1.1210 - val_accuracy: 0.8011\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 44s 412ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 1.2026 - val_accuracy: 0.7958\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 43s 406ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 1.1707 - val_accuracy: 0.8037\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.1950 - val_accuracy: 0.8037\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 44s 410ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.2248 - val_accuracy: 0.7958\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 43s 407ms/step - loss: 0.0033 - accuracy: 0.9984 - val_loss: 1.2268 - val_accuracy: 0.8064\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00034: early stopping\n",
      "Test Accuracy: 81.9628655910492\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  82.539684  80.952382  82.275134  83.597887  81.481481  82.758623   \n",
      "\n",
      "        acc7       acc8       acc9      acc10        AVG  \n",
      "0  85.941643  82.228118  80.636603  81.962866  82.437442  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_2(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>82.539684</td>\n",
       "      <td>80.952382</td>\n",
       "      <td>82.275134</td>\n",
       "      <td>83.597887</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>82.758623</td>\n",
       "      <td>85.941643</td>\n",
       "      <td>82.228118</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>81.962866</td>\n",
       "      <td>82.437442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  82.539684  80.952382  82.275134  83.597887  81.481481  82.758623   \n",
       "\n",
       "        acc7       acc8       acc9      acc10        AVG  \n",
       "0  85.941643  82.228118  80.636603  81.962866  82.437442  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('GRU_CR_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "#         tf.keras.layers.LSTM(units=128, return_sequences=True),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Bidirectional((tf.keras.layers.GRU(64))),\n",
    "#         tf.keras.layers.Dropout(0.5),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Propagate X through a Dense layer with 1 unit\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_11 (Bidirectio (None, 128)               140544    \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 440,673\n",
      "Trainable params: 440,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 90s 753ms/step - loss: 0.6115 - accuracy: 0.6444 - val_loss: 0.4574 - val_accuracy: 0.7804\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 74s 693ms/step - loss: 0.3246 - accuracy: 0.8693 - val_loss: 0.3896 - val_accuracy: 0.8175\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 67s 627ms/step - loss: 0.1684 - accuracy: 0.9418 - val_loss: 0.4605 - val_accuracy: 0.7884\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 67s 627ms/step - loss: 0.1044 - accuracy: 0.9639 - val_loss: 0.4980 - val_accuracy: 0.8122\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 66s 619ms/step - loss: 0.0544 - accuracy: 0.9842 - val_loss: 0.5611 - val_accuracy: 0.8175\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 66s 621ms/step - loss: 0.0232 - accuracy: 0.9957 - val_loss: 0.7273 - val_accuracy: 0.7937\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 66s 616ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 0.8970 - val_accuracy: 0.7989\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 66s 614ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.9934 - val_accuracy: 0.7910\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 66s 614ms/step - loss: 0.0027 - accuracy: 0.9990 - val_loss: 1.0648 - val_accuracy: 0.7857\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 65s 604ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 1.2426 - val_accuracy: 0.7910\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 65s 605ms/step - loss: 0.0018 - accuracy: 0.9984 - val_loss: 1.3130 - val_accuracy: 0.7857\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 65s 609ms/step - loss: 7.7663e-04 - accuracy: 0.9995 - val_loss: 1.3697 - val_accuracy: 0.7937\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 73s 603ms/step - loss: 0.6059 - accuracy: 0.6589 - val_loss: 0.4660 - val_accuracy: 0.7831\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 61s 568ms/step - loss: 0.3156 - accuracy: 0.8740 - val_loss: 0.4216 - val_accuracy: 0.7989\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 53s 495ms/step - loss: 0.1737 - accuracy: 0.9419 - val_loss: 0.4801 - val_accuracy: 0.8148\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 52s 483ms/step - loss: 0.0869 - accuracy: 0.9729 - val_loss: 0.6584 - val_accuracy: 0.8122\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 52s 483ms/step - loss: 0.0522 - accuracy: 0.9831 - val_loss: 0.6601 - val_accuracy: 0.8069\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 52s 483ms/step - loss: 0.0221 - accuracy: 0.9942 - val_loss: 0.8385 - val_accuracy: 0.8042\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 52s 488ms/step - loss: 0.0116 - accuracy: 0.9975 - val_loss: 0.9336 - val_accuracy: 0.7989\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 52s 482ms/step - loss: 0.0104 - accuracy: 0.9976 - val_loss: 1.1652 - val_accuracy: 0.7989\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 51s 481ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 1.1973 - val_accuracy: 0.8016\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 52s 483ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.2753 - val_accuracy: 0.8042\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 52s 482ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 1.3546 - val_accuracy: 0.7989\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 51s 480ms/step - loss: 7.8113e-04 - accuracy: 1.0000 - val_loss: 1.4084 - val_accuracy: 0.8069\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 52s 485ms/step - loss: 9.4550e-04 - accuracy: 0.9994 - val_loss: 1.4608 - val_accuracy: 0.7884\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 52s 406ms/step - loss: 0.6166 - accuracy: 0.6356 - val_loss: 0.4192 - val_accuracy: 0.8201\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 37s 343ms/step - loss: 0.3081 - accuracy: 0.8703 - val_loss: 0.3719 - val_accuracy: 0.8307\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 32s 302ms/step - loss: 0.1597 - accuracy: 0.9436 - val_loss: 0.4243 - val_accuracy: 0.7963\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 33s 306ms/step - loss: 0.0941 - accuracy: 0.9638 - val_loss: 0.6444 - val_accuracy: 0.8175\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.0562 - accuracy: 0.9829 - val_loss: 0.5805 - val_accuracy: 0.7989\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 33s 308ms/step - loss: 0.0203 - accuracy: 0.9960 - val_loss: 0.6796 - val_accuracy: 0.7989\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 33s 308ms/step - loss: 0.0162 - accuracy: 0.9960 - val_loss: 0.8739 - val_accuracy: 0.7989\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.0124 - accuracy: 0.9948 - val_loss: 1.0620 - val_accuracy: 0.8069\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.0163 - accuracy: 0.9956 - val_loss: 1.0272 - val_accuracy: 0.7963\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 33s 309ms/step - loss: 0.0080 - accuracy: 0.9977 - val_loss: 1.0365 - val_accuracy: 0.7910\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.0034 - accuracy: 0.9986 - val_loss: 1.2096 - val_accuracy: 0.8095\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 33s 310ms/step - loss: 0.0024 - accuracy: 0.9987 - val_loss: 1.2359 - val_accuracy: 0.8095\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 83.06878209114075\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 49s 383ms/step - loss: 0.6150 - accuracy: 0.6544 - val_loss: 0.3917 - val_accuracy: 0.8254\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 69s 645ms/step - loss: 0.3301 - accuracy: 0.8666 - val_loss: 0.4463 - val_accuracy: 0.7910\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 69s 647ms/step - loss: 0.1805 - accuracy: 0.9317 - val_loss: 0.3986 - val_accuracy: 0.8122\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 69s 648ms/step - loss: 0.0907 - accuracy: 0.9710 - val_loss: 0.5537 - val_accuracy: 0.7937\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 69s 648ms/step - loss: 0.0473 - accuracy: 0.9852 - val_loss: 0.6937 - val_accuracy: 0.8095\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 69s 641ms/step - loss: 0.0232 - accuracy: 0.9949 - val_loss: 0.6058 - val_accuracy: 0.8095\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 68s 637ms/step - loss: 0.0099 - accuracy: 0.9974 - val_loss: 0.7879 - val_accuracy: 0.8016\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 69s 647ms/step - loss: 0.0046 - accuracy: 0.9997 - val_loss: 1.0207 - val_accuracy: 0.7857\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 68s 639ms/step - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.8338 - val_accuracy: 0.7725\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 68s 636ms/step - loss: 0.0167 - accuracy: 0.9955 - val_loss: 0.8193 - val_accuracy: 0.7884\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 69s 644ms/step - loss: 0.0366 - accuracy: 0.9859 - val_loss: 0.8343 - val_accuracy: 0.8042\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 91s 775ms/step - loss: 0.6109 - accuracy: 0.6629 - val_loss: 0.4948 - val_accuracy: 0.7804\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 72s 676ms/step - loss: 0.3166 - accuracy: 0.8661 - val_loss: 0.4264 - val_accuracy: 0.8254\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 62s 583ms/step - loss: 0.1700 - accuracy: 0.9441 - val_loss: 0.4798 - val_accuracy: 0.8148\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 60s 564ms/step - loss: 0.0814 - accuracy: 0.9775 - val_loss: 0.5603 - val_accuracy: 0.8016\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 60s 558ms/step - loss: 0.0386 - accuracy: 0.9904 - val_loss: 0.6656 - val_accuracy: 0.7884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/40\n",
      "107/107 [==============================] - 60s 559ms/step - loss: 0.0190 - accuracy: 0.9951 - val_loss: 0.7961 - val_accuracy: 0.7751\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 60s 559ms/step - loss: 0.0444 - accuracy: 0.9854 - val_loss: 0.9255 - val_accuracy: 0.7804\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 60s 558ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.9975 - val_accuracy: 0.7751\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 60s 561ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 1.0577 - val_accuracy: 0.7672\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 60s 565ms/step - loss: 0.0023 - accuracy: 0.9989 - val_loss: 1.1856 - val_accuracy: 0.7857\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 60s 561ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.2427 - val_accuracy: 0.7857\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 59s 554ms/step - loss: 0.0021 - accuracy: 0.9986 - val_loss: 1.2414 - val_accuracy: 0.7804\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 75s 615ms/step - loss: 0.6166 - accuracy: 0.6499 - val_loss: 0.4576 - val_accuracy: 0.7745\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 52s 488ms/step - loss: 0.3090 - accuracy: 0.8700 - val_loss: 0.4223 - val_accuracy: 0.8143\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 49s 455ms/step - loss: 0.1771 - accuracy: 0.9337 - val_loss: 0.4417 - val_accuracy: 0.8276\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 44s 414ms/step - loss: 0.0890 - accuracy: 0.9689 - val_loss: 0.5576 - val_accuracy: 0.8223\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 44s 413ms/step - loss: 0.0536 - accuracy: 0.9819 - val_loss: 0.6590 - val_accuracy: 0.8090\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 46s 434ms/step - loss: 0.0220 - accuracy: 0.9948 - val_loss: 0.8922 - val_accuracy: 0.8143\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 46s 434ms/step - loss: 0.0146 - accuracy: 0.9958 - val_loss: 0.9910 - val_accuracy: 0.8037\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 45s 417ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 1.0278 - val_accuracy: 0.8011\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 44s 409ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 1.1776 - val_accuracy: 0.8011\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 46s 433ms/step - loss: 0.0032 - accuracy: 0.9993 - val_loss: 1.1640 - val_accuracy: 0.8011\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 47s 441ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 1.2966 - val_accuracy: 0.7984\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 47s 441ms/step - loss: 0.0011 - accuracy: 0.9996 - val_loss: 1.3720 - val_accuracy: 0.7984\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 47s 438ms/step - loss: 8.6345e-04 - accuracy: 0.9995 - val_loss: 1.4038 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 82.75862336158752\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 57s 453ms/step - loss: 0.6160 - accuracy: 0.6510 - val_loss: 0.4194 - val_accuracy: 0.7905\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 41s 382ms/step - loss: 0.3110 - accuracy: 0.8807 - val_loss: 0.4054 - val_accuracy: 0.7984\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 36s 339ms/step - loss: 0.1554 - accuracy: 0.9473 - val_loss: 0.5584 - val_accuracy: 0.7931\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 36s 338ms/step - loss: 0.0937 - accuracy: 0.9672 - val_loss: 0.6948 - val_accuracy: 0.7772\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 37s 344ms/step - loss: 0.0473 - accuracy: 0.9835 - val_loss: 0.7631 - val_accuracy: 0.7878\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 37s 347ms/step - loss: 0.0230 - accuracy: 0.9909 - val_loss: 0.8201 - val_accuracy: 0.7905\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 36s 339ms/step - loss: 0.0123 - accuracy: 0.9979 - val_loss: 0.9295 - val_accuracy: 0.7878\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 37s 341ms/step - loss: 0.0124 - accuracy: 0.9959 - val_loss: 1.1351 - val_accuracy: 0.7905\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 37s 349ms/step - loss: 0.0086 - accuracy: 0.9975 - val_loss: 1.1070 - val_accuracy: 0.7905\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 39s 368ms/step - loss: 0.0022 - accuracy: 0.9991 - val_loss: 1.2169 - val_accuracy: 0.7878\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 40s 370ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.3484 - val_accuracy: 0.7851\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 40s 369ms/step - loss: 0.0012 - accuracy: 0.9993 - val_loss: 1.4680 - val_accuracy: 0.7798\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 49s 380ms/step - loss: 0.6040 - accuracy: 0.6631 - val_loss: 0.4377 - val_accuracy: 0.7772\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 37s 347ms/step - loss: 0.3083 - accuracy: 0.8784 - val_loss: 0.4235 - val_accuracy: 0.7958\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 40s 378ms/step - loss: 0.1731 - accuracy: 0.9308 - val_loss: 0.4821 - val_accuracy: 0.7878\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 41s 381ms/step - loss: 0.1003 - accuracy: 0.9709 - val_loss: 0.6471 - val_accuracy: 0.7931\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 41s 380ms/step - loss: 0.0441 - accuracy: 0.9854 - val_loss: 0.7832 - val_accuracy: 0.8011\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 44s 408ms/step - loss: 0.0237 - accuracy: 0.9946 - val_loss: 0.8578 - val_accuracy: 0.7825\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 41s 384ms/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.9689 - val_accuracy: 0.7984\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 41s 384ms/step - loss: 0.0066 - accuracy: 0.9979 - val_loss: 0.9436 - val_accuracy: 0.7984\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 41s 385ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.9630 - val_accuracy: 0.7958\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 41s 384ms/step - loss: 0.0043 - accuracy: 0.9977 - val_loss: 1.1339 - val_accuracy: 0.7958\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 44s 416ms/step - loss: 0.0054 - accuracy: 0.9982 - val_loss: 1.0920 - val_accuracy: 0.7931\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 70s 658ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.3235 - val_accuracy: 0.7825\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 71s 660ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 1.2883 - val_accuracy: 0.7851\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 71s 660ms/step - loss: 7.9315e-04 - accuracy: 0.9997 - val_loss: 1.3566 - val_accuracy: 0.7851\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 69s 646ms/step - loss: 9.0165e-04 - accuracy: 0.9995 - val_loss: 1.4160 - val_accuracy: 0.7905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 72s 589ms/step - loss: 0.6067 - accuracy: 0.6567 - val_loss: 0.4449 - val_accuracy: 0.7825\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 62s 582ms/step - loss: 0.3235 - accuracy: 0.8649 - val_loss: 0.4280 - val_accuracy: 0.8037\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 56s 521ms/step - loss: 0.1743 - accuracy: 0.9375 - val_loss: 0.4566 - val_accuracy: 0.8064\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 56s 520ms/step - loss: 0.0865 - accuracy: 0.9749 - val_loss: 0.5909 - val_accuracy: 0.7851\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 58s 542ms/step - loss: 0.0430 - accuracy: 0.9855 - val_loss: 0.7469 - val_accuracy: 0.7666\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 60s 559ms/step - loss: 0.0274 - accuracy: 0.9923 - val_loss: 0.8098 - val_accuracy: 0.8037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/40\n",
      "107/107 [==============================] - 60s 561ms/step - loss: 0.0090 - accuracy: 0.9981 - val_loss: 0.8892 - val_accuracy: 0.7958\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.9594 - val_accuracy: 0.7984\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 54s 503ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 1.0789 - val_accuracy: 0.8011\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 58s 538ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 1.0204 - val_accuracy: 0.7984\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 59s 554ms/step - loss: 0.0069 - accuracy: 0.9976 - val_loss: 1.1307 - val_accuracy: 0.7878\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 58s 538ms/step - loss: 0.0109 - accuracy: 0.9961 - val_loss: 1.0269 - val_accuracy: 0.8037\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 55s 514ms/step - loss: 0.0084 - accuracy: 0.9968 - val_loss: 1.1066 - val_accuracy: 0.8037\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "107/107 [==============================] - 95s 811ms/step - loss: 0.6115 - accuracy: 0.6628 - val_loss: 0.4287 - val_accuracy: 0.7958\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 73s 681ms/step - loss: 0.3123 - accuracy: 0.8686 - val_loss: 0.4099 - val_accuracy: 0.8090\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 71s 661ms/step - loss: 0.1587 - accuracy: 0.9395 - val_loss: 0.4919 - val_accuracy: 0.8011\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 71s 659ms/step - loss: 0.0828 - accuracy: 0.9743 - val_loss: 0.7207 - val_accuracy: 0.7931\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 66s 615ms/step - loss: 0.0588 - accuracy: 0.9776 - val_loss: 0.8638 - val_accuracy: 0.7984\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 66s 617ms/step - loss: 0.0221 - accuracy: 0.9926 - val_loss: 0.9356 - val_accuracy: 0.7851\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 70s 654ms/step - loss: 0.0102 - accuracy: 0.9972 - val_loss: 1.0337 - val_accuracy: 0.7878\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 69s 647ms/step - loss: 0.0087 - accuracy: 0.9983 - val_loss: 1.2124 - val_accuracy: 0.7931\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 68s 631ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 1.3067 - val_accuracy: 0.7825\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 65s 609ms/step - loss: 0.0032 - accuracy: 0.9983 - val_loss: 1.4211 - val_accuracy: 0.7878\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 67s 622ms/step - loss: 0.0332 - accuracy: 0.9879 - val_loss: 1.0040 - val_accuracy: 0.8064\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 67s 625ms/step - loss: 0.0170 - accuracy: 0.9947 - val_loss: 1.0523 - val_accuracy: 0.8011\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "\n",
      "       acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
      "0  81.74603  81.481481  83.068782  82.539684  82.539684  82.758623  79.840851   \n",
      "\n",
      "        acc8       acc9      acc10       AVG  \n",
      "0  80.106103  80.636603  80.901855  81.56197  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "emb_mean = emb_mean\n",
    "emb_std = emb_std\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index, emb_mean, emb_std)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_3(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record3)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81.74603</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>83.068782</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>82.758623</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>81.56197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  81.74603  81.481481  83.068782  82.539684  82.539684  82.758623  79.840851   \n",
       "\n",
       "        acc8       acc9      acc10       AVG  \n",
       "0  80.106103  80.636603  80.901855  81.56197  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('GRU_CR_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
