{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classification with MPQA Dataset\n",
    "<hr>\n",
    "\n",
    "The __modus operandi__ for text classification is to use __word embedding__ for representing words and a Convolutional neural network to learn how to discriminate documents on classification problems. \n",
    "\n",
    "__Yoav Goldberg__ commented in _A Primer on Neural Network Models for Natural Language Processing, 2015._ :\n",
    "> _The non-linearity of the network, as well as the ability to easily integrate pre-trained\n",
    "word embeddings, often lead to superior classification accuracy._\n",
    "\n",
    "He also commented in _Neural Network Methods for Natural Language Processing, 2017_ :\n",
    "> ... _the CNN is in essence a feature-extracting architecture. ... . The CNNs layer's responsibility is to extract meaningful sub-structures that are useful for the overall prediction task at hand._\n",
    "\n",
    "We will build a text classification model using CNN model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 1,2, 3, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2) constraint: 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10606, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complaining</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing to support</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desperately needs</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many years of decay</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no quick fix</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>urged</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>hope</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10606 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label  split\n",
       "0              complaining      0  train\n",
       "1       failing to support      0  train\n",
       "2        desperately needs      0  train\n",
       "3      many years of decay      0  train\n",
       "4             no quick fix      0  train\n",
       "...                    ...    ...    ...\n",
       "10601                urged      1  train\n",
       "10602       strictly abide      1  train\n",
       "10603                 hope      1  train\n",
       "10604       strictly abide      1  train\n",
       "10605                           1  train\n",
       "\n",
       "[10606 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/MPQA/MPQA.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10606 entries, 0 to 10605\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10606 non-null  object\n",
      " 1   label     10606 non-null  int32 \n",
      " 2   split     10606 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 207.3+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7294</td>\n",
       "      <td>7294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3312</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          7294   7294\n",
       "1          3312   3312"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complaining'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  a very complicated process\n",
      "Into a sequence of int: [5, 44, 946, 581]\n",
      "Into a padded sequence: [  5  44 946 581   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "print(\"Example of sentence: \", sentences[8])\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[8])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "of 3\n",
      "to 4\n",
      "a 5\n",
      "and 6\n",
      "not 7\n",
      "is 8\n",
      "in 9\n",
      "be 10\n",
      "6236\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "A __standard model__ for document classification is to use (quoted from __Jason Brownlee__, the author of [machinelearningmastery.com](https://machinelearningmastery.com)):\n",
    ">- Word Embedding: A distributed representation of words where different words that have a similar meaning (based on their usage) also have a similar representation.\n",
    ">- Convolutional Model: A feature extraction model that learns to extract salient features from documents represented using a word embedding.\n",
    ">- Fully Connected Model: The interpretation of extracted features in terms of a predictive output.\n",
    "\n",
    "\n",
    "Therefore, the model is comprised of the following elements:\n",
    "- __Input layer__ that defines the length of input sequences.\n",
    "- __Embedding layer__ set to the size of the vocabulary and 100-dimensional real-valued representations.\n",
    "- __Conv1D layer__ with 32 filters and a kernel size set to the number of words to read at once.\n",
    "- __MaxPooling1D layer__ to consolidate the output from the convolutional layer.\n",
    "- __Flatten layer__ to reduce the three-dimensional output to two dimensional for concatenation.\n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 3, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2): 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "We will perform the best parameter using __grid search__ and 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "Now, we will build Convolutional Neural Network (CNN) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "The model takes inspiration from `CNN for Sentence Classification` by *Yoon Kim*.\n",
    "\n",
    "Now, we will define our CNN model as follows:\n",
    "- One Conv layer with 100 filters, kernel size 5, and relu activation function;\n",
    "- One MaxPool layer with pool size = 2;\n",
    "- One Dropout layer after flattened;\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)\n",
    "\n",
    "**Note**: \n",
    "- The whole purpose of dropout layers is to tackle the problem of over-fitting and to introduce generalization to the model. Hence it is advisable to keep dropout parameter near 0.5 in hidden layers. \n",
    "- https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          1870800   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,009,921\n",
      "Trainable params: 2,009,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "191/191 - 12s - loss: 0.5715 - accuracy: 0.7051 - val_loss: 0.4476 - val_accuracy: 0.8435\n",
      "Epoch 2/15\n",
      "191/191 - 6s - loss: 0.3333 - accuracy: 0.8698 - val_loss: 0.4152 - val_accuracy: 0.8549\n",
      "Epoch 3/15\n",
      "191/191 - 6s - loss: 0.2107 - accuracy: 0.9331 - val_loss: 0.4450 - val_accuracy: 0.8483\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1787 - accuracy: 0.9459 - val_loss: 0.5061 - val_accuracy: 0.8435\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1517 - accuracy: 0.9537 - val_loss: 0.5590 - val_accuracy: 0.8530\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1390 - accuracy: 0.9577 - val_loss: 0.5864 - val_accuracy: 0.8464\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1331 - accuracy: 0.9580 - val_loss: 0.6178 - val_accuracy: 0.8464\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5902 - accuracy: 0.6865 - val_loss: 0.4577 - val_accuracy: 0.7936\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3521 - accuracy: 0.8749 - val_loss: 0.3611 - val_accuracy: 0.8379\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2231 - accuracy: 0.9219 - val_loss: 0.3746 - val_accuracy: 0.8285\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1833 - accuracy: 0.9350 - val_loss: 0.4187 - val_accuracy: 0.8238\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1524 - accuracy: 0.9402 - val_loss: 0.4697 - val_accuracy: 0.8586\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1359 - accuracy: 0.9480 - val_loss: 0.5402 - val_accuracy: 0.8181\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1269 - accuracy: 0.9542 - val_loss: 0.5797 - val_accuracy: 0.8464\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.1181 - accuracy: 0.9565 - val_loss: 0.6196 - val_accuracy: 0.8511\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.1055 - accuracy: 0.9595 - val_loss: 0.6530 - val_accuracy: 0.8501\n",
      "Epoch 10/15\n",
      "191/191 - 7s - loss: 0.0965 - accuracy: 0.9611 - val_loss: 0.7379 - val_accuracy: 0.8483\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.6006 - accuracy: 0.6913 - val_loss: 0.4548 - val_accuracy: 0.8294\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3715 - accuracy: 0.8500 - val_loss: 0.3504 - val_accuracy: 0.8690\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2401 - accuracy: 0.9209 - val_loss: 0.3524 - val_accuracy: 0.8699\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1942 - accuracy: 0.9380 - val_loss: 0.3910 - val_accuracy: 0.8596\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1645 - accuracy: 0.9486 - val_loss: 0.4181 - val_accuracy: 0.8643\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1435 - accuracy: 0.9530 - val_loss: 0.5117 - val_accuracy: 0.8633\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1330 - accuracy: 0.9576 - val_loss: 0.5073 - val_accuracy: 0.8586\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.1239 - accuracy: 0.9581 - val_loss: 0.5570 - val_accuracy: 0.8558\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.99340224266052\n",
      "Epoch 1/15\n",
      "191/191 - 8s - loss: 0.5864 - accuracy: 0.7021 - val_loss: 0.4552 - val_accuracy: 0.8322\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3609 - accuracy: 0.8520 - val_loss: 0.3612 - val_accuracy: 0.8596\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2317 - accuracy: 0.9019 - val_loss: 0.4108 - val_accuracy: 0.8549\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1968 - accuracy: 0.9171 - val_loss: 0.4450 - val_accuracy: 0.8049\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1615 - accuracy: 0.9402 - val_loss: 0.5180 - val_accuracy: 0.8369\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1363 - accuracy: 0.9467 - val_loss: 0.5720 - val_accuracy: 0.8285\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1273 - accuracy: 0.9504 - val_loss: 0.6804 - val_accuracy: 0.8303\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.95664501190186\n",
      "Epoch 1/15\n",
      "191/191 - 8s - loss: 0.5907 - accuracy: 0.6916 - val_loss: 0.4614 - val_accuracy: 0.8322\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3579 - accuracy: 0.8634 - val_loss: 0.3542 - val_accuracy: 0.8662\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2229 - accuracy: 0.9261 - val_loss: 0.3848 - val_accuracy: 0.8633\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1815 - accuracy: 0.9392 - val_loss: 0.4518 - val_accuracy: 0.8558\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1553 - accuracy: 0.9463 - val_loss: 0.4702 - val_accuracy: 0.8624\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1362 - accuracy: 0.9542 - val_loss: 0.5335 - val_accuracy: 0.8539\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1279 - accuracy: 0.9556 - val_loss: 0.5444 - val_accuracy: 0.8520\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "Epoch 1/15\n",
      "191/191 - 8s - loss: 0.5723 - accuracy: 0.6932 - val_loss: 0.4680 - val_accuracy: 0.8181\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3516 - accuracy: 0.8695 - val_loss: 0.4017 - val_accuracy: 0.8483\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2408 - accuracy: 0.9251 - val_loss: 0.4451 - val_accuracy: 0.8058\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1817 - accuracy: 0.9405 - val_loss: 0.5223 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1535 - accuracy: 0.9467 - val_loss: 0.5984 - val_accuracy: 0.8464\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1322 - accuracy: 0.9531 - val_loss: 0.6716 - val_accuracy: 0.8266\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1160 - accuracy: 0.9565 - val_loss: 0.7325 - val_accuracy: 0.8322\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.82563495635986\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5998 - accuracy: 0.7002 - val_loss: 0.4449 - val_accuracy: 0.8519\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3628 - accuracy: 0.8736 - val_loss: 0.3285 - val_accuracy: 0.8764\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2558 - accuracy: 0.9192 - val_loss: 0.3398 - val_accuracy: 0.8726\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.2188 - accuracy: 0.9348 - val_loss: 0.3757 - val_accuracy: 0.8679\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1923 - accuracy: 0.9371 - val_loss: 0.4261 - val_accuracy: 0.8689\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1674 - accuracy: 0.9514 - val_loss: 0.4506 - val_accuracy: 0.8651\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1523 - accuracy: 0.9545 - val_loss: 0.4553 - val_accuracy: 0.8689\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.64150738716125\n",
      "Epoch 1/15\n",
      "191/191 - 8s - loss: 0.5974 - accuracy: 0.6867 - val_loss: 0.4940 - val_accuracy: 0.8038\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3667 - accuracy: 0.8574 - val_loss: 0.4256 - val_accuracy: 0.8425\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2316 - accuracy: 0.9232 - val_loss: 0.4637 - val_accuracy: 0.8066\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1862 - accuracy: 0.9342 - val_loss: 0.5053 - val_accuracy: 0.8491\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1659 - accuracy: 0.9415 - val_loss: 0.5583 - val_accuracy: 0.8547\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1455 - accuracy: 0.9471 - val_loss: 0.5943 - val_accuracy: 0.8557\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1366 - accuracy: 0.9486 - val_loss: 0.6523 - val_accuracy: 0.8585\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.1226 - accuracy: 0.9522 - val_loss: 0.7147 - val_accuracy: 0.8566\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.1181 - accuracy: 0.9572 - val_loss: 0.7630 - val_accuracy: 0.8566\n",
      "Epoch 10/15\n",
      "191/191 - 7s - loss: 0.1002 - accuracy: 0.9646 - val_loss: 0.8988 - val_accuracy: 0.8557\n",
      "Epoch 11/15\n",
      "191/191 - 7s - loss: 0.0930 - accuracy: 0.9679 - val_loss: 0.9507 - val_accuracy: 0.8547\n",
      "Epoch 12/15\n",
      "191/191 - 7s - loss: 0.0911 - accuracy: 0.9702 - val_loss: 0.9647 - val_accuracy: 0.8500\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 85.84905862808228\n",
      "Epoch 1/15\n",
      "191/191 - 8s - loss: 0.5912 - accuracy: 0.6868 - val_loss: 0.4666 - val_accuracy: 0.7075\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3653 - accuracy: 0.8474 - val_loss: 0.3229 - val_accuracy: 0.8802\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2191 - accuracy: 0.9246 - val_loss: 0.3597 - val_accuracy: 0.8745\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1797 - accuracy: 0.9343 - val_loss: 0.3671 - val_accuracy: 0.8755\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1581 - accuracy: 0.9385 - val_loss: 0.3964 - val_accuracy: 0.8802\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1380 - accuracy: 0.9463 - val_loss: 0.4266 - val_accuracy: 0.8670\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1335 - accuracy: 0.9498 - val_loss: 0.4822 - val_accuracy: 0.8660\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.01887035369873\n",
      "Epoch 1/15\n",
      "191/191 - 8s - loss: 0.6219 - accuracy: 0.6873 - val_loss: 0.5207 - val_accuracy: 0.6745\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.4104 - accuracy: 0.8284 - val_loss: 0.3595 - val_accuracy: 0.8547\n",
      "Epoch 3/15\n",
      "191/191 - 11s - loss: 0.2541 - accuracy: 0.9301 - val_loss: 0.3622 - val_accuracy: 0.8651\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.2082 - accuracy: 0.9427 - val_loss: 0.4042 - val_accuracy: 0.8575\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1782 - accuracy: 0.9510 - val_loss: 0.4418 - val_accuracy: 0.8585\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1566 - accuracy: 0.9574 - val_loss: 0.5155 - val_accuracy: 0.8453\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1425 - accuracy: 0.9614 - val_loss: 0.5399 - val_accuracy: 0.8462\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.1327 - accuracy: 0.9616 - val_loss: 0.5727 - val_accuracy: 0.8443\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.50943636894226\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "\n",
      "        acc6       acc7       acc8      acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.01887  86.509436  86.375874  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5788 - accuracy: 0.7081 - val_loss: 0.4396 - val_accuracy: 0.8388\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3297 - accuracy: 0.8668 - val_loss: 0.3784 - val_accuracy: 0.8558\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2112 - accuracy: 0.9229 - val_loss: 0.4435 - val_accuracy: 0.8445\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1694 - accuracy: 0.9411 - val_loss: 0.4844 - val_accuracy: 0.8511\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1365 - accuracy: 0.9536 - val_loss: 0.5472 - val_accuracy: 0.8567\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1259 - accuracy: 0.9540 - val_loss: 0.5976 - val_accuracy: 0.8520\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.1088 - accuracy: 0.9618 - val_loss: 0.6975 - val_accuracy: 0.8388\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0839 - accuracy: 0.9682 - val_loss: 0.8105 - val_accuracy: 0.8398\n",
      "Epoch 9/15\n",
      "191/191 - 10s - loss: 0.0831 - accuracy: 0.9653 - val_loss: 0.8046 - val_accuracy: 0.8332\n",
      "Epoch 10/15\n",
      "191/191 - 9s - loss: 0.0809 - accuracy: 0.9653 - val_loss: 0.8901 - val_accuracy: 0.8407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 85.67389249801636\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6006 - accuracy: 0.6950 - val_loss: 0.4648 - val_accuracy: 0.7747\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3720 - accuracy: 0.8671 - val_loss: 0.3650 - val_accuracy: 0.8558\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2406 - accuracy: 0.9323 - val_loss: 0.3873 - val_accuracy: 0.8615\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1941 - accuracy: 0.9476 - val_loss: 0.4188 - val_accuracy: 0.8511\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1599 - accuracy: 0.9554 - val_loss: 0.4971 - val_accuracy: 0.7992\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1375 - accuracy: 0.9619 - val_loss: 0.5590 - val_accuracy: 0.8021\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.1276 - accuracy: 0.9650 - val_loss: 0.5822 - val_accuracy: 0.8087\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.1107 - accuracy: 0.9683 - val_loss: 0.6212 - val_accuracy: 0.8087\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.14514470100403\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6274 - accuracy: 0.6823 - val_loss: 0.5062 - val_accuracy: 0.7003\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.4169 - accuracy: 0.8145 - val_loss: 0.3602 - val_accuracy: 0.8596\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2717 - accuracy: 0.9081 - val_loss: 0.3892 - val_accuracy: 0.8539\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.2129 - accuracy: 0.9405 - val_loss: 0.4236 - val_accuracy: 0.8520\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1766 - accuracy: 0.9532 - val_loss: 0.4651 - val_accuracy: 0.8511\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1551 - accuracy: 0.9583 - val_loss: 0.5653 - val_accuracy: 0.8530\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1362 - accuracy: 0.9627 - val_loss: 0.5658 - val_accuracy: 0.8473\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.95664501190186\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5897 - accuracy: 0.6876 - val_loss: 0.4503 - val_accuracy: 0.8294\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3437 - accuracy: 0.8710 - val_loss: 0.3427 - val_accuracy: 0.8605\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2198 - accuracy: 0.9247 - val_loss: 0.3624 - val_accuracy: 0.8520\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1727 - accuracy: 0.9400 - val_loss: 0.4215 - val_accuracy: 0.8530\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1433 - accuracy: 0.9450 - val_loss: 0.4774 - val_accuracy: 0.8586\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1177 - accuracy: 0.9568 - val_loss: 0.5616 - val_accuracy: 0.8417\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1077 - accuracy: 0.9592 - val_loss: 0.5934 - val_accuracy: 0.8577\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.05089783668518\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.6082 - accuracy: 0.6837 - val_loss: 0.4908 - val_accuracy: 0.6975\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3858 - accuracy: 0.8454 - val_loss: 0.3684 - val_accuracy: 0.8596\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2501 - accuracy: 0.9311 - val_loss: 0.3889 - val_accuracy: 0.8530\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.2031 - accuracy: 0.9435 - val_loss: 0.4415 - val_accuracy: 0.8558\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1636 - accuracy: 0.9541 - val_loss: 0.4940 - val_accuracy: 0.8454\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1469 - accuracy: 0.9596 - val_loss: 0.5626 - val_accuracy: 0.8492\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1334 - accuracy: 0.9629 - val_loss: 0.6028 - val_accuracy: 0.8473\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.95664501190186\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6084 - accuracy: 0.6927 - val_loss: 0.4919 - val_accuracy: 0.8049\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3704 - accuracy: 0.8647 - val_loss: 0.4152 - val_accuracy: 0.8313\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2182 - accuracy: 0.9371 - val_loss: 0.4994 - val_accuracy: 0.8143\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1761 - accuracy: 0.9498 - val_loss: 0.5060 - val_accuracy: 0.8228\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1370 - accuracy: 0.9606 - val_loss: 0.6109 - val_accuracy: 0.8115\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1196 - accuracy: 0.9650 - val_loss: 0.6450 - val_accuracy: 0.8181\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1104 - accuracy: 0.9652 - val_loss: 0.7215 - val_accuracy: 0.8200\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.12912583351135\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.6095 - accuracy: 0.6842 - val_loss: 0.4929 - val_accuracy: 0.6915\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3848 - accuracy: 0.8610 - val_loss: 0.3724 - val_accuracy: 0.8594\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2407 - accuracy: 0.9359 - val_loss: 0.3934 - val_accuracy: 0.8415\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1915 - accuracy: 0.9502 - val_loss: 0.4306 - val_accuracy: 0.8472\n",
      "Epoch 5/15\n",
      "191/191 - 11s - loss: 0.1618 - accuracy: 0.9621 - val_loss: 0.4961 - val_accuracy: 0.8481\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1374 - accuracy: 0.9640 - val_loss: 0.5235 - val_accuracy: 0.8406\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1207 - accuracy: 0.9696 - val_loss: 0.6100 - val_accuracy: 0.8349\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.94339489936829\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5867 - accuracy: 0.6943 - val_loss: 0.4158 - val_accuracy: 0.8500\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3374 - accuracy: 0.8732 - val_loss: 0.3368 - val_accuracy: 0.8774\n",
      "Epoch 3/15\n",
      "191/191 - 12s - loss: 0.2047 - accuracy: 0.9369 - val_loss: 0.3930 - val_accuracy: 0.8538\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1634 - accuracy: 0.9524 - val_loss: 0.4497 - val_accuracy: 0.8443\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1340 - accuracy: 0.9606 - val_loss: 0.4758 - val_accuracy: 0.8443\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1176 - accuracy: 0.9632 - val_loss: 0.5175 - val_accuracy: 0.8349\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0997 - accuracy: 0.9695 - val_loss: 0.5796 - val_accuracy: 0.8377\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.73584961891174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5795 - accuracy: 0.7132 - val_loss: 0.4173 - val_accuracy: 0.8519\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3426 - accuracy: 0.8757 - val_loss: 0.3596 - val_accuracy: 0.8708\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2087 - accuracy: 0.9321 - val_loss: 0.3973 - val_accuracy: 0.8575\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1678 - accuracy: 0.9463 - val_loss: 0.4674 - val_accuracy: 0.8594\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1385 - accuracy: 0.9550 - val_loss: 0.5085 - val_accuracy: 0.8623\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1165 - accuracy: 0.9580 - val_loss: 0.5853 - val_accuracy: 0.8557\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1015 - accuracy: 0.9642 - val_loss: 0.6634 - val_accuracy: 0.8453\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.07547187805176\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.5824 - accuracy: 0.7064 - val_loss: 0.4451 - val_accuracy: 0.8274\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3427 - accuracy: 0.8553 - val_loss: 0.3901 - val_accuracy: 0.8057\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2274 - accuracy: 0.9268 - val_loss: 0.4410 - val_accuracy: 0.8075\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1721 - accuracy: 0.9425 - val_loss: 0.4452 - val_accuracy: 0.8340\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1474 - accuracy: 0.9500 - val_loss: 0.5756 - val_accuracy: 0.8038\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1158 - accuracy: 0.9567 - val_loss: 0.5845 - val_accuracy: 0.8047\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1065 - accuracy: 0.9613 - val_loss: 0.6572 - val_accuracy: 0.8274\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0971 - accuracy: 0.9600 - val_loss: 0.6978 - val_accuracy: 0.7962\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.0817 - accuracy: 0.9677 - val_loss: 0.7584 - val_accuracy: 0.8330\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.39622616767883\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 12s - loss: 0.5802 - accuracy: 0.7039 - val_loss: 0.4369 - val_accuracy: 0.8351\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3345 - accuracy: 0.8684 - val_loss: 0.3568 - val_accuracy: 0.8633\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.1983 - accuracy: 0.9312 - val_loss: 0.4141 - val_accuracy: 0.8586\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1513 - accuracy: 0.9494 - val_loss: 0.4569 - val_accuracy: 0.8501\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1187 - accuracy: 0.9546 - val_loss: 0.5096 - val_accuracy: 0.8501\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1020 - accuracy: 0.9617 - val_loss: 0.6279 - val_accuracy: 0.8558\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0934 - accuracy: 0.9647 - val_loss: 0.6475 - val_accuracy: 0.8388\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.33365035057068\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5980 - accuracy: 0.6926 - val_loss: 0.4877 - val_accuracy: 0.8087\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3689 - accuracy: 0.8403 - val_loss: 0.4008 - val_accuracy: 0.8407\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2184 - accuracy: 0.9246 - val_loss: 0.4613 - val_accuracy: 0.8021\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1673 - accuracy: 0.9358 - val_loss: 0.5176 - val_accuracy: 0.7964\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1383 - accuracy: 0.9449 - val_loss: 0.5937 - val_accuracy: 0.7992\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1174 - accuracy: 0.9518 - val_loss: 0.6490 - val_accuracy: 0.7983\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.1047 - accuracy: 0.9563 - val_loss: 0.7148 - val_accuracy: 0.8322\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.0716302394867\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5865 - accuracy: 0.7057 - val_loss: 0.4269 - val_accuracy: 0.8106\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3352 - accuracy: 0.8754 - val_loss: 0.3695 - val_accuracy: 0.8586\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2095 - accuracy: 0.9273 - val_loss: 0.4094 - val_accuracy: 0.8407\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1545 - accuracy: 0.9523 - val_loss: 0.4972 - val_accuracy: 0.8464\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1209 - accuracy: 0.9579 - val_loss: 0.5892 - val_accuracy: 0.8049\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.1031 - accuracy: 0.9627 - val_loss: 0.6323 - val_accuracy: 0.8049\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0951 - accuracy: 0.9639 - val_loss: 0.7201 - val_accuracy: 0.8077\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5915 - accuracy: 0.6996 - val_loss: 0.4552 - val_accuracy: 0.8238\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3520 - accuracy: 0.8749 - val_loss: 0.3861 - val_accuracy: 0.8445\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2058 - accuracy: 0.9394 - val_loss: 0.4159 - val_accuracy: 0.8483\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1589 - accuracy: 0.9560 - val_loss: 0.5021 - val_accuracy: 0.8369\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1268 - accuracy: 0.9629 - val_loss: 0.5883 - val_accuracy: 0.8388\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1012 - accuracy: 0.9672 - val_loss: 0.6719 - val_accuracy: 0.8360\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0979 - accuracy: 0.9700 - val_loss: 0.7480 - val_accuracy: 0.8294\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0838 - accuracy: 0.9733 - val_loss: 0.8513 - val_accuracy: 0.8275\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.82563495635986\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5869 - accuracy: 0.7001 - val_loss: 0.4220 - val_accuracy: 0.8313\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3472 - accuracy: 0.8619 - val_loss: 0.3428 - val_accuracy: 0.8549\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2150 - accuracy: 0.9366 - val_loss: 0.3851 - val_accuracy: 0.8577\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1703 - accuracy: 0.9557 - val_loss: 0.4278 - val_accuracy: 0.8511\n",
      "Epoch 5/15\n",
      "191/191 - 11s - loss: 0.1389 - accuracy: 0.9630 - val_loss: 0.4818 - val_accuracy: 0.8492\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.1195 - accuracy: 0.9691 - val_loss: 0.5713 - val_accuracy: 0.8501\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.1028 - accuracy: 0.9722 - val_loss: 0.6232 - val_accuracy: 0.8511\n",
      "Epoch 8/15\n",
      "191/191 - 10s - loss: 0.0992 - accuracy: 0.9748 - val_loss: 0.6725 - val_accuracy: 0.8351\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.76814532279968\n",
      "Epoch 1/15\n",
      "191/191 - 12s - loss: 0.5789 - accuracy: 0.6931 - val_loss: 0.4863 - val_accuracy: 0.7851\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3368 - accuracy: 0.8785 - val_loss: 0.4062 - val_accuracy: 0.8341\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2122 - accuracy: 0.9388 - val_loss: 0.4496 - val_accuracy: 0.7983\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1677 - accuracy: 0.9558 - val_loss: 0.5223 - val_accuracy: 0.8426\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1268 - accuracy: 0.9625 - val_loss: 0.6188 - val_accuracy: 0.8181\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1071 - accuracy: 0.9679 - val_loss: 0.6610 - val_accuracy: 0.8181\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0920 - accuracy: 0.9708 - val_loss: 0.7329 - val_accuracy: 0.7861\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0829 - accuracy: 0.9729 - val_loss: 0.8213 - val_accuracy: 0.7879\n",
      "Epoch 9/15\n",
      "191/191 - 9s - loss: 0.0765 - accuracy: 0.9735 - val_loss: 0.8482 - val_accuracy: 0.8341\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 84.26012992858887\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5916 - accuracy: 0.7009 - val_loss: 0.4394 - val_accuracy: 0.8406\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3470 - accuracy: 0.8539 - val_loss: 0.3232 - val_accuracy: 0.8887\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2062 - accuracy: 0.9364 - val_loss: 0.3490 - val_accuracy: 0.8849\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1550 - accuracy: 0.9511 - val_loss: 0.4110 - val_accuracy: 0.8764\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1292 - accuracy: 0.9607 - val_loss: 0.4583 - val_accuracy: 0.8783\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1099 - accuracy: 0.9643 - val_loss: 0.5019 - val_accuracy: 0.8717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0950 - accuracy: 0.9697 - val_loss: 0.5684 - val_accuracy: 0.8736\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 88.86792659759521\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5950 - accuracy: 0.6976 - val_loss: 0.4756 - val_accuracy: 0.8113\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3548 - accuracy: 0.8498 - val_loss: 0.4107 - val_accuracy: 0.8009\n",
      "Epoch 3/15\n",
      "191/191 - 11s - loss: 0.2177 - accuracy: 0.9279 - val_loss: 0.4689 - val_accuracy: 0.7943\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1593 - accuracy: 0.9470 - val_loss: 0.5767 - val_accuracy: 0.7840\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1354 - accuracy: 0.9556 - val_loss: 0.6309 - val_accuracy: 0.7764\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1166 - accuracy: 0.9596 - val_loss: 0.6562 - val_accuracy: 0.7877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.13207817077637\n",
      "Epoch 1/15\n",
      "191/191 - 14s - loss: 0.6138 - accuracy: 0.6867 - val_loss: 0.4837 - val_accuracy: 0.8236\n",
      "Epoch 2/15\n",
      "191/191 - 12s - loss: 0.3757 - accuracy: 0.8672 - val_loss: 0.3631 - val_accuracy: 0.8538\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2353 - accuracy: 0.9383 - val_loss: 0.4075 - val_accuracy: 0.8500\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1807 - accuracy: 0.9554 - val_loss: 0.4459 - val_accuracy: 0.8519\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1462 - accuracy: 0.9635 - val_loss: 0.5068 - val_accuracy: 0.8330\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1279 - accuracy: 0.9669 - val_loss: 0.6303 - val_accuracy: 0.8302\n",
      "Epoch 7/15\n",
      "191/191 - 11s - loss: 0.1170 - accuracy: 0.9707 - val_loss: 0.6426 - val_accuracy: 0.8179\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.37735939025879\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5937 - accuracy: 0.6889 - val_loss: 0.4536 - val_accuracy: 0.8415\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3563 - accuracy: 0.8694 - val_loss: 0.3773 - val_accuracy: 0.8491\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2175 - accuracy: 0.9340 - val_loss: 0.4631 - val_accuracy: 0.8434\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1709 - accuracy: 0.9514 - val_loss: 0.5007 - val_accuracy: 0.8528\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1300 - accuracy: 0.9623 - val_loss: 0.5875 - val_accuracy: 0.8472\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1098 - accuracy: 0.9676 - val_loss: 0.6774 - val_accuracy: 0.8472\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0939 - accuracy: 0.9707 - val_loss: 0.6761 - val_accuracy: 0.8406\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0864 - accuracy: 0.9735 - val_loss: 0.9145 - val_accuracy: 0.8415\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0806 - accuracy: 0.9742 - val_loss: 0.9153 - val_accuracy: 0.8462\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.2830171585083\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 14s - loss: 0.5923 - accuracy: 0.7009 - val_loss: 0.4535 - val_accuracy: 0.8285\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3378 - accuracy: 0.8779 - val_loss: 0.3655 - val_accuracy: 0.8596\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2058 - accuracy: 0.9317 - val_loss: 0.4318 - val_accuracy: 0.8473\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1537 - accuracy: 0.9476 - val_loss: 0.4740 - val_accuracy: 0.8549\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1199 - accuracy: 0.9587 - val_loss: 0.5201 - val_accuracy: 0.8652\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0992 - accuracy: 0.9646 - val_loss: 0.6256 - val_accuracy: 0.8483\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0876 - accuracy: 0.9677 - val_loss: 0.7261 - val_accuracy: 0.8492\n",
      "Epoch 8/15\n",
      "191/191 - 10s - loss: 0.0876 - accuracy: 0.9668 - val_loss: 0.7050 - val_accuracy: 0.8435\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0782 - accuracy: 0.9669 - val_loss: 0.8056 - val_accuracy: 0.8162\n",
      "Epoch 10/15\n",
      "191/191 - 10s - loss: 0.0716 - accuracy: 0.9685 - val_loss: 0.8633 - val_accuracy: 0.8577\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 86.52215003967285\n",
      "Epoch 1/15\n",
      "191/191 - 12s - loss: 0.5906 - accuracy: 0.6888 - val_loss: 0.4773 - val_accuracy: 0.7587\n",
      "Epoch 2/15\n",
      "191/191 - 13s - loss: 0.3536 - accuracy: 0.8529 - val_loss: 0.3746 - val_accuracy: 0.8586\n",
      "Epoch 3/15\n",
      "191/191 - 12s - loss: 0.1996 - accuracy: 0.9326 - val_loss: 0.4534 - val_accuracy: 0.8539\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1557 - accuracy: 0.9500 - val_loss: 0.5173 - val_accuracy: 0.8530\n",
      "Epoch 5/15\n",
      "191/191 - 11s - loss: 0.1222 - accuracy: 0.9580 - val_loss: 0.6282 - val_accuracy: 0.8483\n",
      "Epoch 6/15\n",
      "191/191 - 10s - loss: 0.1005 - accuracy: 0.9611 - val_loss: 0.7144 - val_accuracy: 0.8435\n",
      "Epoch 7/15\n",
      "191/191 - 13s - loss: 0.0920 - accuracy: 0.9629 - val_loss: 0.7136 - val_accuracy: 0.8369\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Epoch 1/15\n",
      "191/191 - 14s - loss: 0.5971 - accuracy: 0.6982 - val_loss: 0.4304 - val_accuracy: 0.8238\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3573 - accuracy: 0.8531 - val_loss: 0.3375 - val_accuracy: 0.8662\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2189 - accuracy: 0.9146 - val_loss: 0.3882 - val_accuracy: 0.8558\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1647 - accuracy: 0.9252 - val_loss: 0.4288 - val_accuracy: 0.8615\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1300 - accuracy: 0.9519 - val_loss: 0.4700 - val_accuracy: 0.8615\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.1036 - accuracy: 0.9657 - val_loss: 0.5160 - val_accuracy: 0.8605\n",
      "Epoch 7/15\n",
      "191/191 - 11s - loss: 0.0910 - accuracy: 0.9654 - val_loss: 0.5745 - val_accuracy: 0.8605\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.5973 - accuracy: 0.6967 - val_loss: 0.4423 - val_accuracy: 0.8285\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3553 - accuracy: 0.8629 - val_loss: 0.3769 - val_accuracy: 0.8435\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2122 - accuracy: 0.9272 - val_loss: 0.3976 - val_accuracy: 0.8511\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1519 - accuracy: 0.9460 - val_loss: 0.4997 - val_accuracy: 0.8473\n",
      "Epoch 5/15\n",
      "191/191 - 13s - loss: 0.1162 - accuracy: 0.9619 - val_loss: 0.5473 - val_accuracy: 0.8398\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.1030 - accuracy: 0.9629 - val_loss: 0.6676 - val_accuracy: 0.8360\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0875 - accuracy: 0.9662 - val_loss: 0.7185 - val_accuracy: 0.8313\n",
      "Epoch 8/15\n",
      "191/191 - 10s - loss: 0.0816 - accuracy: 0.9705 - val_loss: 0.7701 - val_accuracy: 0.8049\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.10838747024536\n",
      "Epoch 1/15\n",
      "191/191 - 15s - loss: 0.5886 - accuracy: 0.6999 - val_loss: 0.4788 - val_accuracy: 0.7484\n",
      "Epoch 2/15\n",
      "191/191 - 12s - loss: 0.3440 - accuracy: 0.8527 - val_loss: 0.3587 - val_accuracy: 0.8501\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2099 - accuracy: 0.9356 - val_loss: 0.4191 - val_accuracy: 0.8539\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1505 - accuracy: 0.9500 - val_loss: 0.4560 - val_accuracy: 0.8473\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1242 - accuracy: 0.9599 - val_loss: 0.5681 - val_accuracy: 0.8435\n",
      "Epoch 6/15\n",
      "191/191 - 10s - loss: 0.1094 - accuracy: 0.9617 - val_loss: 0.5823 - val_accuracy: 0.8332\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0881 - accuracy: 0.9633 - val_loss: 0.7290 - val_accuracy: 0.8379\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0791 - accuracy: 0.9686 - val_loss: 0.7801 - val_accuracy: 0.8369\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.39113998413086\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6049 - accuracy: 0.6915 - val_loss: 0.4407 - val_accuracy: 0.8369\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3759 - accuracy: 0.8272 - val_loss: 0.3470 - val_accuracy: 0.8699\n",
      "Epoch 3/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191/191 - 9s - loss: 0.2496 - accuracy: 0.8770 - val_loss: 0.3522 - val_accuracy: 0.8728\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.2137 - accuracy: 0.8983 - val_loss: 0.3822 - val_accuracy: 0.8586\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1672 - accuracy: 0.9252 - val_loss: 0.4353 - val_accuracy: 0.8605\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1339 - accuracy: 0.9417 - val_loss: 0.6284 - val_accuracy: 0.8351\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.1132 - accuracy: 0.9629 - val_loss: 0.6229 - val_accuracy: 0.8134\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0980 - accuracy: 0.9661 - val_loss: 0.6948 - val_accuracy: 0.8407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.27615475654602\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.6056 - accuracy: 0.6889 - val_loss: 0.5134 - val_accuracy: 0.6613\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3700 - accuracy: 0.8467 - val_loss: 0.3830 - val_accuracy: 0.8462\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2254 - accuracy: 0.9298 - val_loss: 0.4095 - val_accuracy: 0.8453\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1575 - accuracy: 0.9555 - val_loss: 0.4939 - val_accuracy: 0.8443\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1330 - accuracy: 0.9623 - val_loss: 0.5275 - val_accuracy: 0.8358\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1153 - accuracy: 0.9680 - val_loss: 0.6259 - val_accuracy: 0.8292\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0967 - accuracy: 0.9713 - val_loss: 0.7211 - val_accuracy: 0.7925\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.62263941764832\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6124 - accuracy: 0.6872 - val_loss: 0.4590 - val_accuracy: 0.8264\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3694 - accuracy: 0.8563 - val_loss: 0.3433 - val_accuracy: 0.8708\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2270 - accuracy: 0.9299 - val_loss: 0.3749 - val_accuracy: 0.8689\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1701 - accuracy: 0.9503 - val_loss: 0.4365 - val_accuracy: 0.8547\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1398 - accuracy: 0.9579 - val_loss: 0.4915 - val_accuracy: 0.8528\n",
      "Epoch 6/15\n",
      "191/191 - 10s - loss: 0.1141 - accuracy: 0.9653 - val_loss: 0.6079 - val_accuracy: 0.8472\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0986 - accuracy: 0.9714 - val_loss: 0.6591 - val_accuracy: 0.8462\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.07547187805176\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.6114 - accuracy: 0.6835 - val_loss: 0.4796 - val_accuracy: 0.6972\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3878 - accuracy: 0.8484 - val_loss: 0.3681 - val_accuracy: 0.8443\n",
      "Epoch 3/15\n",
      "191/191 - 10s - loss: 0.2563 - accuracy: 0.9070 - val_loss: 0.3885 - val_accuracy: 0.8462\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.2054 - accuracy: 0.9358 - val_loss: 0.4429 - val_accuracy: 0.8425\n",
      "Epoch 5/15\n",
      "191/191 - 11s - loss: 0.1606 - accuracy: 0.9563 - val_loss: 0.5222 - val_accuracy: 0.8406\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.1322 - accuracy: 0.9645 - val_loss: 0.6175 - val_accuracy: 0.8425\n",
      "Epoch 7/15\n",
      "191/191 - 11s - loss: 0.1160 - accuracy: 0.9705 - val_loss: 0.6755 - val_accuracy: 0.8443\n",
      "Epoch 8/15\n",
      "191/191 - 11s - loss: 0.1067 - accuracy: 0.9728 - val_loss: 0.6943 - val_accuracy: 0.8406\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.62263941764832\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.6164 - accuracy: 0.6860 - val_loss: 0.4893 - val_accuracy: 0.6821\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.3918 - accuracy: 0.8555 - val_loss: 0.3629 - val_accuracy: 0.8519\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2505 - accuracy: 0.9248 - val_loss: 0.3691 - val_accuracy: 0.8632\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1956 - accuracy: 0.9413 - val_loss: 0.4184 - val_accuracy: 0.8311\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1616 - accuracy: 0.9600 - val_loss: 0.5331 - val_accuracy: 0.8462\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1303 - accuracy: 0.9689 - val_loss: 0.5027 - val_accuracy: 0.8528\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1139 - accuracy: 0.9716 - val_loss: 0.5506 - val_accuracy: 0.8528\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.1051 - accuracy: 0.9750 - val_loss: 0.6440 - val_accuracy: 0.8406\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.32075190544128\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 16s - loss: 0.6111 - accuracy: 0.6917 - val_loss: 0.5071 - val_accuracy: 0.7955\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3551 - accuracy: 0.8674 - val_loss: 0.3901 - val_accuracy: 0.8379\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2153 - accuracy: 0.9282 - val_loss: 0.4279 - val_accuracy: 0.8426\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1552 - accuracy: 0.9430 - val_loss: 0.4676 - val_accuracy: 0.7936\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1237 - accuracy: 0.9504 - val_loss: 0.5200 - val_accuracy: 0.8417\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1028 - accuracy: 0.9563 - val_loss: 0.6987 - val_accuracy: 0.7936\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0957 - accuracy: 0.9614 - val_loss: 0.7276 - val_accuracy: 0.7851\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0833 - accuracy: 0.9671 - val_loss: 0.8289 - val_accuracy: 0.7889\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.26012992858887\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.6285 - accuracy: 0.6857 - val_loss: 0.5300 - val_accuracy: 0.6814\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.4159 - accuracy: 0.8170 - val_loss: 0.3597 - val_accuracy: 0.8586\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2394 - accuracy: 0.9200 - val_loss: 0.4072 - val_accuracy: 0.8492\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1781 - accuracy: 0.9488 - val_loss: 0.4582 - val_accuracy: 0.8501\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1367 - accuracy: 0.9573 - val_loss: 0.5160 - val_accuracy: 0.8473\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1235 - accuracy: 0.9630 - val_loss: 0.5756 - val_accuracy: 0.8464\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1033 - accuracy: 0.9648 - val_loss: 0.6683 - val_accuracy: 0.8209\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.6312 - accuracy: 0.6827 - val_loss: 0.5023 - val_accuracy: 0.7615\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.4286 - accuracy: 0.8460 - val_loss: 0.3295 - val_accuracy: 0.8728\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2863 - accuracy: 0.9327 - val_loss: 0.3211 - val_accuracy: 0.8699\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.2156 - accuracy: 0.9539 - val_loss: 0.3443 - val_accuracy: 0.8680\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1716 - accuracy: 0.9663 - val_loss: 0.3670 - val_accuracy: 0.8652\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1455 - accuracy: 0.9693 - val_loss: 0.4321 - val_accuracy: 0.8426\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1284 - accuracy: 0.9729 - val_loss: 0.4821 - val_accuracy: 0.8652\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.27615475654602\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.6089 - accuracy: 0.6859 - val_loss: 0.4740 - val_accuracy: 0.7766\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3674 - accuracy: 0.8696 - val_loss: 0.3753 - val_accuracy: 0.8124\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2160 - accuracy: 0.9360 - val_loss: 0.4964 - val_accuracy: 0.7936\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1649 - accuracy: 0.9518 - val_loss: 0.4442 - val_accuracy: 0.8633\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1273 - accuracy: 0.9643 - val_loss: 0.5424 - val_accuracy: 0.8106\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1114 - accuracy: 0.9692 - val_loss: 0.6310 - val_accuracy: 0.8030\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0890 - accuracy: 0.9736 - val_loss: 0.6959 - val_accuracy: 0.8435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0827 - accuracy: 0.9746 - val_loss: 0.7902 - val_accuracy: 0.8002\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0849 - accuracy: 0.9727 - val_loss: 0.7253 - val_accuracy: 0.8388\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 86.33365035057068\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5994 - accuracy: 0.6908 - val_loss: 0.4577 - val_accuracy: 0.8473\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3672 - accuracy: 0.8356 - val_loss: 0.3643 - val_accuracy: 0.8680\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2102 - accuracy: 0.9332 - val_loss: 0.3930 - val_accuracy: 0.8596\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1539 - accuracy: 0.9576 - val_loss: 0.4313 - val_accuracy: 0.8567\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1230 - accuracy: 0.9627 - val_loss: 0.5155 - val_accuracy: 0.8549\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1001 - accuracy: 0.9696 - val_loss: 0.6146 - val_accuracy: 0.8068\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0877 - accuracy: 0.9711 - val_loss: 0.7082 - val_accuracy: 0.8558\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.80490255355835\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5933 - accuracy: 0.6902 - val_loss: 0.4583 - val_accuracy: 0.8200\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3392 - accuracy: 0.8729 - val_loss: 0.4046 - val_accuracy: 0.8454\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1945 - accuracy: 0.9411 - val_loss: 0.4767 - val_accuracy: 0.8388\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1437 - accuracy: 0.9562 - val_loss: 0.5654 - val_accuracy: 0.8200\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1170 - accuracy: 0.9654 - val_loss: 0.6556 - val_accuracy: 0.7983\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0989 - accuracy: 0.9705 - val_loss: 0.7101 - val_accuracy: 0.8200\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0917 - accuracy: 0.9710 - val_loss: 0.8377 - val_accuracy: 0.8172\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.54288244247437\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.6091 - accuracy: 0.6912 - val_loss: 0.4811 - val_accuracy: 0.7943\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.3639 - accuracy: 0.8630 - val_loss: 0.4032 - val_accuracy: 0.8509\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2194 - accuracy: 0.9321 - val_loss: 0.4622 - val_accuracy: 0.8094\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1633 - accuracy: 0.9511 - val_loss: 0.5386 - val_accuracy: 0.8387\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1279 - accuracy: 0.9654 - val_loss: 0.6599 - val_accuracy: 0.8226\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1096 - accuracy: 0.9707 - val_loss: 0.7343 - val_accuracy: 0.8198\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0949 - accuracy: 0.9694 - val_loss: 0.7407 - val_accuracy: 0.8208\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.0943386554718\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.6038 - accuracy: 0.6930 - val_loss: 0.4666 - val_accuracy: 0.8170\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3630 - accuracy: 0.8673 - val_loss: 0.3690 - val_accuracy: 0.8632\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2203 - accuracy: 0.9285 - val_loss: 0.4509 - val_accuracy: 0.8566\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1675 - accuracy: 0.9507 - val_loss: 0.4864 - val_accuracy: 0.8528\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1335 - accuracy: 0.9598 - val_loss: 0.5840 - val_accuracy: 0.8500\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1109 - accuracy: 0.9685 - val_loss: 0.6479 - val_accuracy: 0.8557\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0973 - accuracy: 0.9729 - val_loss: 0.7593 - val_accuracy: 0.8462\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.32075190544128\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.6095 - accuracy: 0.6836 - val_loss: 0.4764 - val_accuracy: 0.7047\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3764 - accuracy: 0.8433 - val_loss: 0.3499 - val_accuracy: 0.8566\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2287 - accuracy: 0.9356 - val_loss: 0.3737 - val_accuracy: 0.8547\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1619 - accuracy: 0.9555 - val_loss: 0.4199 - val_accuracy: 0.8557\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1331 - accuracy: 0.9632 - val_loss: 0.4410 - val_accuracy: 0.8566\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1066 - accuracy: 0.9685 - val_loss: 0.5635 - val_accuracy: 0.8547\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0952 - accuracy: 0.9721 - val_loss: 0.6179 - val_accuracy: 0.8453\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5932 - accuracy: 0.6874 - val_loss: 0.4750 - val_accuracy: 0.6849\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3579 - accuracy: 0.8546 - val_loss: 0.3866 - val_accuracy: 0.8528\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2082 - accuracy: 0.9384 - val_loss: 0.4272 - val_accuracy: 0.8462\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1528 - accuracy: 0.9538 - val_loss: 0.4869 - val_accuracy: 0.8170\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1217 - accuracy: 0.9619 - val_loss: 0.5620 - val_accuracy: 0.8387\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1027 - accuracy: 0.9677 - val_loss: 0.6074 - val_accuracy: 0.8472\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0898 - accuracy: 0.9710 - val_loss: 0.6703 - val_accuracy: 0.8302\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.2830171585083\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4       relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4  84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 15s - loss: 0.6072 - accuracy: 0.6885 - val_loss: 0.5235 - val_accuracy: 0.6664\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3986 - accuracy: 0.8166 - val_loss: 0.4125 - val_accuracy: 0.8351\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2387 - accuracy: 0.9083 - val_loss: 0.4308 - val_accuracy: 0.8407\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1790 - accuracy: 0.9376 - val_loss: 0.5018 - val_accuracy: 0.8360\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1310 - accuracy: 0.9554 - val_loss: 0.5848 - val_accuracy: 0.8454\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1165 - accuracy: 0.9652 - val_loss: 0.6718 - val_accuracy: 0.8275\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0958 - accuracy: 0.9712 - val_loss: 0.7791 - val_accuracy: 0.8256\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0843 - accuracy: 0.9728 - val_loss: 0.8755 - val_accuracy: 0.8294\n",
      "Epoch 9/15\n",
      "191/191 - 9s - loss: 0.0788 - accuracy: 0.9746 - val_loss: 0.8593 - val_accuracy: 0.8294\n",
      "Epoch 10/15\n",
      "191/191 - 9s - loss: 0.0776 - accuracy: 0.9767 - val_loss: 0.9961 - val_accuracy: 0.8285\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 84.54288244247437\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5995 - accuracy: 0.6863 - val_loss: 0.4933 - val_accuracy: 0.6909\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3660 - accuracy: 0.8444 - val_loss: 0.4075 - val_accuracy: 0.7955\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2182 - accuracy: 0.9364 - val_loss: 0.4388 - val_accuracy: 0.8030\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1578 - accuracy: 0.9584 - val_loss: 0.4972 - val_accuracy: 0.8068\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1338 - accuracy: 0.9669 - val_loss: 0.5926 - val_accuracy: 0.8058\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1126 - accuracy: 0.9701 - val_loss: 0.6346 - val_accuracy: 0.8068\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.1037 - accuracy: 0.9722 - val_loss: 0.7362 - val_accuracy: 0.8011\n",
      "Epoch 8/15\n",
      "191/191 - 10s - loss: 0.0983 - accuracy: 0.9719 - val_loss: 0.8000 - val_accuracy: 0.7955\n",
      "Epoch 9/15\n",
      "191/191 - 9s - loss: 0.0876 - accuracy: 0.9761 - val_loss: 0.8771 - val_accuracy: 0.7926\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 80.6786060333252\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6090 - accuracy: 0.6935 - val_loss: 0.5094 - val_accuracy: 0.8058\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3720 - accuracy: 0.8373 - val_loss: 0.4046 - val_accuracy: 0.8407\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2212 - accuracy: 0.9141 - val_loss: 0.4670 - val_accuracy: 0.7917\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1566 - accuracy: 0.9301 - val_loss: 0.4954 - val_accuracy: 0.8351\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1354 - accuracy: 0.9451 - val_loss: 0.5613 - val_accuracy: 0.8266\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1044 - accuracy: 0.9535 - val_loss: 0.7394 - val_accuracy: 0.8219\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0932 - accuracy: 0.9586 - val_loss: 0.7349 - val_accuracy: 0.8275\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.0716302394867\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6044 - accuracy: 0.6856 - val_loss: 0.4603 - val_accuracy: 0.7022\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3899 - accuracy: 0.8142 - val_loss: 0.3665 - val_accuracy: 0.8652\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2291 - accuracy: 0.9258 - val_loss: 0.4005 - val_accuracy: 0.8520\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1533 - accuracy: 0.9455 - val_loss: 0.4803 - val_accuracy: 0.8407\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1160 - accuracy: 0.9565 - val_loss: 0.5448 - val_accuracy: 0.8435\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0929 - accuracy: 0.9626 - val_loss: 0.6399 - val_accuracy: 0.8351\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0892 - accuracy: 0.9627 - val_loss: 0.6748 - val_accuracy: 0.8445\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.52215003967285\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6152 - accuracy: 0.6911 - val_loss: 0.4684 - val_accuracy: 0.7597\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3844 - accuracy: 0.8445 - val_loss: 0.3656 - val_accuracy: 0.8586\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2247 - accuracy: 0.9072 - val_loss: 0.4013 - val_accuracy: 0.8162\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1690 - accuracy: 0.9241 - val_loss: 0.4570 - val_accuracy: 0.8435\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1336 - accuracy: 0.9395 - val_loss: 0.6101 - val_accuracy: 0.8426\n",
      "Epoch 6/15\n",
      "191/191 - 10s - loss: 0.1093 - accuracy: 0.9519 - val_loss: 0.6369 - val_accuracy: 0.8454\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0916 - accuracy: 0.9579 - val_loss: 0.7117 - val_accuracy: 0.8520\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6307 - accuracy: 0.6831 - val_loss: 0.5371 - val_accuracy: 0.7078\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.4414 - accuracy: 0.7761 - val_loss: 0.3658 - val_accuracy: 0.8369\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2345 - accuracy: 0.9213 - val_loss: 0.4918 - val_accuracy: 0.8143\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1781 - accuracy: 0.9394 - val_loss: 0.4540 - val_accuracy: 0.8134\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1385 - accuracy: 0.9471 - val_loss: 0.4918 - val_accuracy: 0.8200\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1152 - accuracy: 0.9546 - val_loss: 0.5719 - val_accuracy: 0.8106\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.1043 - accuracy: 0.9566 - val_loss: 0.6005 - val_accuracy: 0.8172\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.69462490081787\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.6088 - accuracy: 0.6863 - val_loss: 0.4758 - val_accuracy: 0.7764\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3841 - accuracy: 0.8285 - val_loss: 0.3545 - val_accuracy: 0.8670\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2540 - accuracy: 0.8773 - val_loss: 0.3903 - val_accuracy: 0.8274\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.2120 - accuracy: 0.9030 - val_loss: 0.4000 - val_accuracy: 0.8698\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1745 - accuracy: 0.9290 - val_loss: 0.4748 - val_accuracy: 0.8670\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1570 - accuracy: 0.9309 - val_loss: 0.5336 - val_accuracy: 0.8274\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.1274 - accuracy: 0.9256 - val_loss: 0.6333 - val_accuracy: 0.8443\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.1004 - accuracy: 0.9434 - val_loss: 0.7662 - val_accuracy: 0.8104\n",
      "Epoch 9/15\n",
      "191/191 - 10s - loss: 0.0892 - accuracy: 0.9712 - val_loss: 0.7675 - val_accuracy: 0.8491\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 86.98112964630127\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6034 - accuracy: 0.6878 - val_loss: 0.4571 - val_accuracy: 0.6821\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3769 - accuracy: 0.8269 - val_loss: 0.3431 - val_accuracy: 0.8745\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2165 - accuracy: 0.9382 - val_loss: 0.3662 - val_accuracy: 0.8764\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1653 - accuracy: 0.9581 - val_loss: 0.4364 - val_accuracy: 0.8736\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1367 - accuracy: 0.9655 - val_loss: 0.4847 - val_accuracy: 0.8406\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1108 - accuracy: 0.9702 - val_loss: 0.5216 - val_accuracy: 0.8340\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0998 - accuracy: 0.9727 - val_loss: 0.6032 - val_accuracy: 0.8755\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0940 - accuracy: 0.9720 - val_loss: 0.6465 - val_accuracy: 0.8679\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.64150738716125\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.6332 - accuracy: 0.6852 - val_loss: 0.5660 - val_accuracy: 0.6594\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.4458 - accuracy: 0.7854 - val_loss: 0.4188 - val_accuracy: 0.8151\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.2561 - accuracy: 0.9253 - val_loss: 0.4494 - val_accuracy: 0.8179\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1907 - accuracy: 0.9508 - val_loss: 0.4847 - val_accuracy: 0.8255\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1574 - accuracy: 0.9595 - val_loss: 0.6042 - val_accuracy: 0.7858\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1251 - accuracy: 0.9688 - val_loss: 0.7494 - val_accuracy: 0.7849\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.1093 - accuracy: 0.9718 - val_loss: 0.8078 - val_accuracy: 0.7849\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0958 - accuracy: 0.9755 - val_loss: 0.8286 - val_accuracy: 0.8160\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0934 - accuracy: 0.9750 - val_loss: 0.9296 - val_accuracy: 0.7783\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 82.54716992378235\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.6193 - accuracy: 0.6825 - val_loss: 0.4887 - val_accuracy: 0.7038\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.3758 - accuracy: 0.8555 - val_loss: 0.3639 - val_accuracy: 0.8500\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.2216 - accuracy: 0.9249 - val_loss: 0.4063 - val_accuracy: 0.8170\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1615 - accuracy: 0.9436 - val_loss: 0.5045 - val_accuracy: 0.8453\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1245 - accuracy: 0.9557 - val_loss: 0.5501 - val_accuracy: 0.8406\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.1016 - accuracy: 0.9677 - val_loss: 0.6394 - val_accuracy: 0.8094\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0936 - accuracy: 0.9669 - val_loss: 0.6922 - val_accuracy: 0.8368\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4       relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5       relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4  84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5  83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5590 - accuracy: 0.7276 - val_loss: 0.4054 - val_accuracy: 0.8238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2964 - accuracy: 0.9010 - val_loss: 0.3925 - val_accuracy: 0.8379\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1903 - accuracy: 0.9459 - val_loss: 0.4217 - val_accuracy: 0.8417\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1554 - accuracy: 0.9540 - val_loss: 0.4242 - val_accuracy: 0.8511\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1352 - accuracy: 0.9604 - val_loss: 0.4668 - val_accuracy: 0.8417\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1228 - accuracy: 0.9628 - val_loss: 0.4638 - val_accuracy: 0.8464\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1052 - accuracy: 0.9689 - val_loss: 0.5371 - val_accuracy: 0.8322\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0978 - accuracy: 0.9721 - val_loss: 0.5047 - val_accuracy: 0.8539\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.0903 - accuracy: 0.9737 - val_loss: 0.5596 - val_accuracy: 0.8445\n",
      "Epoch 10/15\n",
      "191/191 - 7s - loss: 0.0879 - accuracy: 0.9733 - val_loss: 0.5584 - val_accuracy: 0.8473\n",
      "Epoch 11/15\n",
      "191/191 - 7s - loss: 0.0821 - accuracy: 0.9739 - val_loss: 0.5751 - val_accuracy: 0.8379\n",
      "Epoch 12/15\n",
      "191/191 - 7s - loss: 0.0779 - accuracy: 0.9758 - val_loss: 0.6112 - val_accuracy: 0.8369\n",
      "Epoch 13/15\n",
      "191/191 - 7s - loss: 0.0770 - accuracy: 0.9751 - val_loss: 0.6275 - val_accuracy: 0.8294\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.39113998413086\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5534 - accuracy: 0.7305 - val_loss: 0.4109 - val_accuracy: 0.8106\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2927 - accuracy: 0.9036 - val_loss: 0.4204 - val_accuracy: 0.8379\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1808 - accuracy: 0.9438 - val_loss: 0.4809 - val_accuracy: 0.8322\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1455 - accuracy: 0.9550 - val_loss: 0.5049 - val_accuracy: 0.7964\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1155 - accuracy: 0.9626 - val_loss: 0.5466 - val_accuracy: 0.8011\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1036 - accuracy: 0.9655 - val_loss: 0.5627 - val_accuracy: 0.7983\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0912 - accuracy: 0.9694 - val_loss: 0.5907 - val_accuracy: 0.8021\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.7888777256012\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5646 - accuracy: 0.7322 - val_loss: 0.4219 - val_accuracy: 0.8303\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3054 - accuracy: 0.8977 - val_loss: 0.3742 - val_accuracy: 0.8549\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2042 - accuracy: 0.9385 - val_loss: 0.3918 - val_accuracy: 0.8492\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1586 - accuracy: 0.9540 - val_loss: 0.4194 - val_accuracy: 0.8247\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1375 - accuracy: 0.9603 - val_loss: 0.4302 - val_accuracy: 0.8520\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1157 - accuracy: 0.9649 - val_loss: 0.4683 - val_accuracy: 0.8228\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1057 - accuracy: 0.9678 - val_loss: 0.4772 - val_accuracy: 0.8549\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5551 - accuracy: 0.7327 - val_loss: 0.3881 - val_accuracy: 0.8379\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2995 - accuracy: 0.8981 - val_loss: 0.3554 - val_accuracy: 0.8690\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1907 - accuracy: 0.9434 - val_loss: 0.3796 - val_accuracy: 0.8605\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1544 - accuracy: 0.9526 - val_loss: 0.3967 - val_accuracy: 0.8605\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1321 - accuracy: 0.9596 - val_loss: 0.4175 - val_accuracy: 0.8530\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1121 - accuracy: 0.9663 - val_loss: 0.4435 - val_accuracy: 0.8577\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0965 - accuracy: 0.9726 - val_loss: 0.4832 - val_accuracy: 0.8633\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.8991494178772\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5562 - accuracy: 0.7338 - val_loss: 0.3638 - val_accuracy: 0.8530\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2924 - accuracy: 0.9003 - val_loss: 0.3327 - val_accuracy: 0.8699\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1882 - accuracy: 0.9431 - val_loss: 0.3482 - val_accuracy: 0.8756\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1583 - accuracy: 0.9514 - val_loss: 0.3687 - val_accuracy: 0.8652\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1328 - accuracy: 0.9605 - val_loss: 0.3826 - val_accuracy: 0.8652\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1178 - accuracy: 0.9653 - val_loss: 0.4309 - val_accuracy: 0.8501\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1026 - accuracy: 0.9682 - val_loss: 0.4240 - val_accuracy: 0.8671\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0886 - accuracy: 0.9733 - val_loss: 0.4784 - val_accuracy: 0.8539\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.55890727043152\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5456 - accuracy: 0.7401 - val_loss: 0.3974 - val_accuracy: 0.8369\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2924 - accuracy: 0.8994 - val_loss: 0.3874 - val_accuracy: 0.8511\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1801 - accuracy: 0.9431 - val_loss: 0.4319 - val_accuracy: 0.8473\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1423 - accuracy: 0.9542 - val_loss: 0.4652 - val_accuracy: 0.8483\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1226 - accuracy: 0.9617 - val_loss: 0.4931 - val_accuracy: 0.8426\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1027 - accuracy: 0.9666 - val_loss: 0.5357 - val_accuracy: 0.8398\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0903 - accuracy: 0.9691 - val_loss: 0.5663 - val_accuracy: 0.8426\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.10838747024536\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5666 - accuracy: 0.7344 - val_loss: 0.3806 - val_accuracy: 0.8425\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2997 - accuracy: 0.8996 - val_loss: 0.3440 - val_accuracy: 0.8698\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1929 - accuracy: 0.9432 - val_loss: 0.3896 - val_accuracy: 0.8321\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1606 - accuracy: 0.9557 - val_loss: 0.4181 - val_accuracy: 0.8321\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1378 - accuracy: 0.9612 - val_loss: 0.4479 - val_accuracy: 0.8264\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1206 - accuracy: 0.9657 - val_loss: 0.4734 - val_accuracy: 0.8311\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1091 - accuracy: 0.9691 - val_loss: 0.4809 - val_accuracy: 0.8642\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.98112964630127\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5642 - accuracy: 0.7308 - val_loss: 0.4475 - val_accuracy: 0.7840\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3008 - accuracy: 0.9034 - val_loss: 0.4489 - val_accuracy: 0.8038\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.2003 - accuracy: 0.9419 - val_loss: 0.4925 - val_accuracy: 0.8094\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1633 - accuracy: 0.9537 - val_loss: 0.4890 - val_accuracy: 0.8132\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1396 - accuracy: 0.9603 - val_loss: 0.5391 - val_accuracy: 0.8066\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1210 - accuracy: 0.9666 - val_loss: 0.5330 - val_accuracy: 0.8047\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.1132 - accuracy: 0.9684 - val_loss: 0.5617 - val_accuracy: 0.8057\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.1026 - accuracy: 0.9706 - val_loss: 0.5829 - val_accuracy: 0.7981\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.0999 - accuracy: 0.9714 - val_loss: 0.6195 - val_accuracy: 0.7925\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.32075667381287\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5530 - accuracy: 0.7371 - val_loss: 0.4167 - val_accuracy: 0.8264\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2888 - accuracy: 0.8989 - val_loss: 0.3896 - val_accuracy: 0.8208\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1854 - accuracy: 0.9424 - val_loss: 0.4262 - val_accuracy: 0.8170\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1490 - accuracy: 0.9560 - val_loss: 0.4422 - val_accuracy: 0.8170\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1218 - accuracy: 0.9629 - val_loss: 0.4763 - val_accuracy: 0.8245\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1065 - accuracy: 0.9665 - val_loss: 0.5065 - val_accuracy: 0.8151\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 82.64151215553284\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5547 - accuracy: 0.7375 - val_loss: 0.4073 - val_accuracy: 0.8377\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2943 - accuracy: 0.8996 - val_loss: 0.3753 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1842 - accuracy: 0.9422 - val_loss: 0.4148 - val_accuracy: 0.8226\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1497 - accuracy: 0.9534 - val_loss: 0.4563 - val_accuracy: 0.8160\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1281 - accuracy: 0.9606 - val_loss: 0.4586 - val_accuracy: 0.8283\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1106 - accuracy: 0.9662 - val_loss: 0.5040 - val_accuracy: 0.8170\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 83.77358317375183\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4       relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5       relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "6       tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4  84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5  83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "6  85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5513 - accuracy: 0.7395 - val_loss: 0.4110 - val_accuracy: 0.8351\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2814 - accuracy: 0.9010 - val_loss: 0.4025 - val_accuracy: 0.8011\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1766 - accuracy: 0.9476 - val_loss: 0.4463 - val_accuracy: 0.8360\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1369 - accuracy: 0.9620 - val_loss: 0.5140 - val_accuracy: 0.7861\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1098 - accuracy: 0.9688 - val_loss: 0.5026 - val_accuracy: 0.8398\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.0971 - accuracy: 0.9730 - val_loss: 0.5183 - val_accuracy: 0.8351\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0860 - accuracy: 0.9748 - val_loss: 0.5587 - val_accuracy: 0.8360\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0770 - accuracy: 0.9775 - val_loss: 0.6346 - val_accuracy: 0.8219\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.0696 - accuracy: 0.9775 - val_loss: 0.6753 - val_accuracy: 0.7785\n",
      "Epoch 10/15\n",
      "191/191 - 7s - loss: 0.0653 - accuracy: 0.9805 - val_loss: 0.6824 - val_accuracy: 0.7832\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 83.97737741470337\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5536 - accuracy: 0.7370 - val_loss: 0.3858 - val_accuracy: 0.8247\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2835 - accuracy: 0.9051 - val_loss: 0.3478 - val_accuracy: 0.8567\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1781 - accuracy: 0.9445 - val_loss: 0.3737 - val_accuracy: 0.8473\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1345 - accuracy: 0.9577 - val_loss: 0.4017 - val_accuracy: 0.8539\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1069 - accuracy: 0.9680 - val_loss: 0.4643 - val_accuracy: 0.8426\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.0884 - accuracy: 0.9717 - val_loss: 0.4781 - val_accuracy: 0.8445\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0800 - accuracy: 0.9741 - val_loss: 0.5169 - val_accuracy: 0.8351\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.67389249801636\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5533 - accuracy: 0.7368 - val_loss: 0.3878 - val_accuracy: 0.8332\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2844 - accuracy: 0.9035 - val_loss: 0.3789 - val_accuracy: 0.8511\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1715 - accuracy: 0.9492 - val_loss: 0.4109 - val_accuracy: 0.8520\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1303 - accuracy: 0.9610 - val_loss: 0.4493 - val_accuracy: 0.8483\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.0995 - accuracy: 0.9687 - val_loss: 0.4872 - val_accuracy: 0.8530\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.0924 - accuracy: 0.9716 - val_loss: 0.5153 - val_accuracy: 0.8473\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0834 - accuracy: 0.9736 - val_loss: 0.5579 - val_accuracy: 0.8435\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0684 - accuracy: 0.9774 - val_loss: 0.5707 - val_accuracy: 0.8483\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0674 - accuracy: 0.9778 - val_loss: 0.5842 - val_accuracy: 0.8426\n",
      "Epoch 10/15\n",
      "191/191 - 8s - loss: 0.0616 - accuracy: 0.9814 - val_loss: 0.6222 - val_accuracy: 0.8426\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 85.29688715934753\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5708 - accuracy: 0.7255 - val_loss: 0.3959 - val_accuracy: 0.8473\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2995 - accuracy: 0.9017 - val_loss: 0.3819 - val_accuracy: 0.8492\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1922 - accuracy: 0.9464 - val_loss: 0.3909 - val_accuracy: 0.8577\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1478 - accuracy: 0.9608 - val_loss: 0.4225 - val_accuracy: 0.8539\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1243 - accuracy: 0.9676 - val_loss: 0.4479 - val_accuracy: 0.8483\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1056 - accuracy: 0.9712 - val_loss: 0.5170 - val_accuracy: 0.8238\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0979 - accuracy: 0.9726 - val_loss: 0.5224 - val_accuracy: 0.8483\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0890 - accuracy: 0.9738 - val_loss: 0.5386 - val_accuracy: 0.8435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.76814532279968\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5525 - accuracy: 0.7343 - val_loss: 0.3774 - val_accuracy: 0.8567\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2895 - accuracy: 0.9031 - val_loss: 0.3536 - val_accuracy: 0.8662\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1816 - accuracy: 0.9469 - val_loss: 0.3807 - val_accuracy: 0.8577\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1417 - accuracy: 0.9586 - val_loss: 0.4186 - val_accuracy: 0.8549\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1129 - accuracy: 0.9674 - val_loss: 0.4712 - val_accuracy: 0.8492\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.0964 - accuracy: 0.9720 - val_loss: 0.4841 - val_accuracy: 0.8417\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0842 - accuracy: 0.9766 - val_loss: 0.5312 - val_accuracy: 0.8068\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5532 - accuracy: 0.7388 - val_loss: 0.4002 - val_accuracy: 0.8398\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2945 - accuracy: 0.9060 - val_loss: 0.3953 - val_accuracy: 0.8464\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1784 - accuracy: 0.9480 - val_loss: 0.4543 - val_accuracy: 0.8407\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1343 - accuracy: 0.9635 - val_loss: 0.4831 - val_accuracy: 0.8435\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1131 - accuracy: 0.9679 - val_loss: 0.5046 - val_accuracy: 0.8445\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1012 - accuracy: 0.9697 - val_loss: 0.5775 - val_accuracy: 0.8049\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0892 - accuracy: 0.9732 - val_loss: 0.5845 - val_accuracy: 0.8426\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.63713526725769\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.5717 - accuracy: 0.7225 - val_loss: 0.3910 - val_accuracy: 0.8340\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3050 - accuracy: 0.8959 - val_loss: 0.3483 - val_accuracy: 0.8660\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1883 - accuracy: 0.9469 - val_loss: 0.3599 - val_accuracy: 0.8849\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1429 - accuracy: 0.9592 - val_loss: 0.3975 - val_accuracy: 0.8783\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1197 - accuracy: 0.9666 - val_loss: 0.4285 - val_accuracy: 0.8755\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1014 - accuracy: 0.9712 - val_loss: 0.4730 - val_accuracy: 0.8632\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0893 - accuracy: 0.9748 - val_loss: 0.4747 - val_accuracy: 0.8632\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0793 - accuracy: 0.9763 - val_loss: 0.5170 - val_accuracy: 0.8613\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.49056363105774\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5560 - accuracy: 0.7373 - val_loss: 0.3865 - val_accuracy: 0.8491\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2947 - accuracy: 0.9021 - val_loss: 0.3623 - val_accuracy: 0.8651\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1821 - accuracy: 0.9452 - val_loss: 0.3936 - val_accuracy: 0.8453\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1439 - accuracy: 0.9614 - val_loss: 0.4341 - val_accuracy: 0.8481\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1177 - accuracy: 0.9669 - val_loss: 0.4636 - val_accuracy: 0.8462\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1017 - accuracy: 0.9716 - val_loss: 0.5090 - val_accuracy: 0.8481\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0904 - accuracy: 0.9731 - val_loss: 0.5291 - val_accuracy: 0.8453\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.50943636894226\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5636 - accuracy: 0.7362 - val_loss: 0.4125 - val_accuracy: 0.8292\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.3043 - accuracy: 0.9011 - val_loss: 0.3900 - val_accuracy: 0.8481\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1841 - accuracy: 0.9492 - val_loss: 0.4227 - val_accuracy: 0.8425\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1446 - accuracy: 0.9582 - val_loss: 0.4275 - val_accuracy: 0.8547\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1209 - accuracy: 0.9668 - val_loss: 0.4792 - val_accuracy: 0.8434\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.1055 - accuracy: 0.9702 - val_loss: 0.4856 - val_accuracy: 0.8377\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.5143 - val_accuracy: 0.8387\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0866 - accuracy: 0.9760 - val_loss: 0.5368 - val_accuracy: 0.8453\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.0813 - accuracy: 0.9764 - val_loss: 0.5969 - val_accuracy: 0.8321\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.4716956615448\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5591 - accuracy: 0.7344 - val_loss: 0.3916 - val_accuracy: 0.8358\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2907 - accuracy: 0.9030 - val_loss: 0.3647 - val_accuracy: 0.8198\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1769 - accuracy: 0.9480 - val_loss: 0.4299 - val_accuracy: 0.8132\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1360 - accuracy: 0.9622 - val_loss: 0.4587 - val_accuracy: 0.8094\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1096 - accuracy: 0.9687 - val_loss: 0.4769 - val_accuracy: 0.8274\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.0959 - accuracy: 0.9728 - val_loss: 0.5179 - val_accuracy: 0.8113\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 83.58490467071533\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4       relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5       relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "6       tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
      "7       tanh       2  83.977377  85.673892  85.296887  85.768145  86.616397   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4  84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5  83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "6  85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
      "7  84.637135  88.490564  86.509436  85.471696  83.584905  85.602643  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5674 - accuracy: 0.7277 - val_loss: 0.3832 - val_accuracy: 0.8454\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2988 - accuracy: 0.9005 - val_loss: 0.3476 - val_accuracy: 0.8662\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1759 - accuracy: 0.9497 - val_loss: 0.3852 - val_accuracy: 0.8605\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1386 - accuracy: 0.9640 - val_loss: 0.4155 - val_accuracy: 0.8624\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1225 - accuracy: 0.9662 - val_loss: 0.4354 - val_accuracy: 0.8586\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.1014 - accuracy: 0.9716 - val_loss: 0.4824 - val_accuracy: 0.8435\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0866 - accuracy: 0.9764 - val_loss: 0.4961 - val_accuracy: 0.8483\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5666 - accuracy: 0.7250 - val_loss: 0.3751 - val_accuracy: 0.8501\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2916 - accuracy: 0.9005 - val_loss: 0.3360 - val_accuracy: 0.8624\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1786 - accuracy: 0.9488 - val_loss: 0.3731 - val_accuracy: 0.8577\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1260 - accuracy: 0.9643 - val_loss: 0.4129 - val_accuracy: 0.8492\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1014 - accuracy: 0.9699 - val_loss: 0.4755 - val_accuracy: 0.8407\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0936 - accuracy: 0.9738 - val_loss: 0.4821 - val_accuracy: 0.8473\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0755 - accuracy: 0.9764 - val_loss: 0.5156 - val_accuracy: 0.8407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.23939752578735\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5638 - accuracy: 0.7288 - val_loss: 0.4098 - val_accuracy: 0.8341\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2809 - accuracy: 0.9065 - val_loss: 0.4025 - val_accuracy: 0.8577\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1701 - accuracy: 0.9510 - val_loss: 0.4360 - val_accuracy: 0.8520\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1229 - accuracy: 0.9661 - val_loss: 0.4884 - val_accuracy: 0.8483\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0999 - accuracy: 0.9713 - val_loss: 0.5456 - val_accuracy: 0.8454\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0821 - accuracy: 0.9759 - val_loss: 0.5831 - val_accuracy: 0.8417\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0758 - accuracy: 0.9777 - val_loss: 0.6220 - val_accuracy: 0.8445\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.76814532279968\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5625 - accuracy: 0.7273 - val_loss: 0.3865 - val_accuracy: 0.8464\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2837 - accuracy: 0.9099 - val_loss: 0.3651 - val_accuracy: 0.8567\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1700 - accuracy: 0.9506 - val_loss: 0.3920 - val_accuracy: 0.8530\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1204 - accuracy: 0.9668 - val_loss: 0.4422 - val_accuracy: 0.8577\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1032 - accuracy: 0.9709 - val_loss: 0.4935 - val_accuracy: 0.8407\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0857 - accuracy: 0.9739 - val_loss: 0.5267 - val_accuracy: 0.8398\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0770 - accuracy: 0.9772 - val_loss: 0.5568 - val_accuracy: 0.8096\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0687 - accuracy: 0.9801 - val_loss: 0.5718 - val_accuracy: 0.8473\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0692 - accuracy: 0.9798 - val_loss: 0.5977 - val_accuracy: 0.8115\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.76814532279968\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5736 - accuracy: 0.7245 - val_loss: 0.4232 - val_accuracy: 0.7964\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3031 - accuracy: 0.8987 - val_loss: 0.3819 - val_accuracy: 0.8143\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1815 - accuracy: 0.9486 - val_loss: 0.4089 - val_accuracy: 0.8492\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1333 - accuracy: 0.9648 - val_loss: 0.4865 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1098 - accuracy: 0.9705 - val_loss: 0.4985 - val_accuracy: 0.8040\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0985 - accuracy: 0.9715 - val_loss: 0.5289 - val_accuracy: 0.8049\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0840 - accuracy: 0.9766 - val_loss: 0.5733 - val_accuracy: 0.8011\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0757 - accuracy: 0.9779 - val_loss: 0.5966 - val_accuracy: 0.8002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.91988778114319\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5662 - accuracy: 0.7290 - val_loss: 0.3848 - val_accuracy: 0.8360\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2967 - accuracy: 0.9024 - val_loss: 0.3337 - val_accuracy: 0.8671\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1708 - accuracy: 0.9499 - val_loss: 0.3639 - val_accuracy: 0.8435\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1266 - accuracy: 0.9629 - val_loss: 0.4507 - val_accuracy: 0.8153\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1018 - accuracy: 0.9692 - val_loss: 0.4703 - val_accuracy: 0.8473\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0842 - accuracy: 0.9746 - val_loss: 0.5587 - val_accuracy: 0.8369\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0816 - accuracy: 0.9754 - val_loss: 0.5459 - val_accuracy: 0.8153\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.71064972877502\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5675 - accuracy: 0.7260 - val_loss: 0.3967 - val_accuracy: 0.8349\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2890 - accuracy: 0.9009 - val_loss: 0.3688 - val_accuracy: 0.8491\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1721 - accuracy: 0.9514 - val_loss: 0.4267 - val_accuracy: 0.8443\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1283 - accuracy: 0.9629 - val_loss: 0.4752 - val_accuracy: 0.8311\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1038 - accuracy: 0.9701 - val_loss: 0.4965 - val_accuracy: 0.8425\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0848 - accuracy: 0.9749 - val_loss: 0.5567 - val_accuracy: 0.8264\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0733 - accuracy: 0.9779 - val_loss: 0.6325 - val_accuracy: 0.8198\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.9056601524353\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5600 - accuracy: 0.7304 - val_loss: 0.3947 - val_accuracy: 0.8292\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2814 - accuracy: 0.9072 - val_loss: 0.4029 - val_accuracy: 0.8104\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1593 - accuracy: 0.9515 - val_loss: 0.4720 - val_accuracy: 0.8292\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1195 - accuracy: 0.9674 - val_loss: 0.5009 - val_accuracy: 0.8075\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.0997 - accuracy: 0.9701 - val_loss: 0.5335 - val_accuracy: 0.8132\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0781 - accuracy: 0.9767 - val_loss: 0.6286 - val_accuracy: 0.8113\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 82.92452692985535\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5680 - accuracy: 0.7271 - val_loss: 0.4064 - val_accuracy: 0.8434\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2920 - accuracy: 0.9010 - val_loss: 0.4082 - val_accuracy: 0.8132\n",
      "Epoch 3/15\n",
      "191/191 - 7s - loss: 0.1656 - accuracy: 0.9525 - val_loss: 0.4633 - val_accuracy: 0.8151\n",
      "Epoch 4/15\n",
      "191/191 - 7s - loss: 0.1195 - accuracy: 0.9667 - val_loss: 0.4987 - val_accuracy: 0.8415\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1016 - accuracy: 0.9721 - val_loss: 0.4995 - val_accuracy: 0.8491\n",
      "Epoch 6/15\n",
      "191/191 - 7s - loss: 0.0781 - accuracy: 0.9762 - val_loss: 0.5625 - val_accuracy: 0.8415\n",
      "Epoch 7/15\n",
      "191/191 - 7s - loss: 0.0737 - accuracy: 0.9782 - val_loss: 0.5949 - val_accuracy: 0.8368\n",
      "Epoch 8/15\n",
      "191/191 - 7s - loss: 0.0714 - accuracy: 0.9784 - val_loss: 0.6041 - val_accuracy: 0.8368\n",
      "Epoch 9/15\n",
      "191/191 - 7s - loss: 0.0584 - accuracy: 0.9828 - val_loss: 0.6004 - val_accuracy: 0.8472\n",
      "Epoch 10/15\n",
      "191/191 - 7s - loss: 0.0583 - accuracy: 0.9812 - val_loss: 0.6815 - val_accuracy: 0.8028\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 84.9056601524353\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5558 - accuracy: 0.7312 - val_loss: 0.3988 - val_accuracy: 0.8387\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2807 - accuracy: 0.9066 - val_loss: 0.3863 - val_accuracy: 0.8575\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1670 - accuracy: 0.9514 - val_loss: 0.4139 - val_accuracy: 0.8528\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1203 - accuracy: 0.9657 - val_loss: 0.4780 - val_accuracy: 0.8443\n",
      "Epoch 5/15\n",
      "191/191 - 7s - loss: 0.1003 - accuracy: 0.9711 - val_loss: 0.5045 - val_accuracy: 0.8453\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0831 - accuracy: 0.9735 - val_loss: 0.5568 - val_accuracy: 0.8274\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0712 - accuracy: 0.9776 - val_loss: 0.5862 - val_accuracy: 0.8491\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.75471639633179\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4       relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5       relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "6       tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
      "7       tanh       2  83.977377  85.673892  85.296887  85.768145  86.616397   \n",
      "8       tanh       3  86.616397  86.239398  85.768145  85.768145  84.919888   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4  84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5  83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "6  85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
      "7  84.637135  88.490564  86.509436  85.471696  83.584905  85.602643  \n",
      "8  86.710650  84.905660  82.924527  84.905660  85.754716  85.451319  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5662 - accuracy: 0.7256 - val_loss: 0.4042 - val_accuracy: 0.8360\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2818 - accuracy: 0.9040 - val_loss: 0.3880 - val_accuracy: 0.8303\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1541 - accuracy: 0.9558 - val_loss: 0.4331 - val_accuracy: 0.8294\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1076 - accuracy: 0.9688 - val_loss: 0.4842 - val_accuracy: 0.8435\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0852 - accuracy: 0.9750 - val_loss: 0.5595 - val_accuracy: 0.8172\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0766 - accuracy: 0.9788 - val_loss: 0.6014 - val_accuracy: 0.8087\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0657 - accuracy: 0.9800 - val_loss: 0.6824 - val_accuracy: 0.8002\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0667 - accuracy: 0.9790 - val_loss: 0.6446 - val_accuracy: 0.8266\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0586 - accuracy: 0.9806 - val_loss: 0.6959 - val_accuracy: 0.8021\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 84.35438275337219\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5723 - accuracy: 0.7238 - val_loss: 0.3831 - val_accuracy: 0.8530\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2947 - accuracy: 0.8977 - val_loss: 0.3941 - val_accuracy: 0.8473\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1677 - accuracy: 0.9515 - val_loss: 0.4412 - val_accuracy: 0.8454\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1254 - accuracy: 0.9654 - val_loss: 0.5119 - val_accuracy: 0.8058\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1026 - accuracy: 0.9739 - val_loss: 0.5310 - val_accuracy: 0.8445\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0895 - accuracy: 0.9745 - val_loss: 0.5569 - val_accuracy: 0.8445\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 85.29688715934753\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5780 - accuracy: 0.7186 - val_loss: 0.3995 - val_accuracy: 0.8501\n",
      "Epoch 2/15\n",
      "191/191 - 7s - loss: 0.2981 - accuracy: 0.9017 - val_loss: 0.3539 - val_accuracy: 0.8690\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1762 - accuracy: 0.9499 - val_loss: 0.4188 - val_accuracy: 0.7945\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1312 - accuracy: 0.9650 - val_loss: 0.4333 - val_accuracy: 0.8633\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1073 - accuracy: 0.9706 - val_loss: 0.4755 - val_accuracy: 0.8483\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0883 - accuracy: 0.9748 - val_loss: 0.4885 - val_accuracy: 0.8435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0797 - accuracy: 0.9760 - val_loss: 0.5263 - val_accuracy: 0.8530\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.8991494178772\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5713 - accuracy: 0.7221 - val_loss: 0.3984 - val_accuracy: 0.8238\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2891 - accuracy: 0.9046 - val_loss: 0.3641 - val_accuracy: 0.8624\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1770 - accuracy: 0.9517 - val_loss: 0.4073 - val_accuracy: 0.8483\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1312 - accuracy: 0.9635 - val_loss: 0.4621 - val_accuracy: 0.8332\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1035 - accuracy: 0.9717 - val_loss: 0.5072 - val_accuracy: 0.8068\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0905 - accuracy: 0.9755 - val_loss: 0.5216 - val_accuracy: 0.8294\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0820 - accuracy: 0.9763 - val_loss: 0.5289 - val_accuracy: 0.8473\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.23939752578735\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5673 - accuracy: 0.7287 - val_loss: 0.4273 - val_accuracy: 0.8172\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2898 - accuracy: 0.9038 - val_loss: 0.4013 - val_accuracy: 0.8153\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1670 - accuracy: 0.9524 - val_loss: 0.4665 - val_accuracy: 0.8068\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1243 - accuracy: 0.9661 - val_loss: 0.5402 - val_accuracy: 0.8049\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0982 - accuracy: 0.9718 - val_loss: 0.5304 - val_accuracy: 0.8143\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0846 - accuracy: 0.9753 - val_loss: 0.6197 - val_accuracy: 0.8049\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.71536326408386\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5595 - accuracy: 0.7287 - val_loss: 0.3940 - val_accuracy: 0.8369\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2888 - accuracy: 0.9061 - val_loss: 0.3827 - val_accuracy: 0.8256\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1727 - accuracy: 0.9506 - val_loss: 0.4016 - val_accuracy: 0.8549\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1279 - accuracy: 0.9631 - val_loss: 0.4599 - val_accuracy: 0.8454\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1009 - accuracy: 0.9711 - val_loss: 0.5013 - val_accuracy: 0.8407\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0860 - accuracy: 0.9736 - val_loss: 0.5393 - val_accuracy: 0.8435\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0757 - accuracy: 0.9787 - val_loss: 0.5711 - val_accuracy: 0.8407\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0761 - accuracy: 0.9787 - val_loss: 0.5828 - val_accuracy: 0.8407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5678 - accuracy: 0.7251 - val_loss: 0.3781 - val_accuracy: 0.8528\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2854 - accuracy: 0.9082 - val_loss: 0.3616 - val_accuracy: 0.8613\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1652 - accuracy: 0.9530 - val_loss: 0.4191 - val_accuracy: 0.8462\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1257 - accuracy: 0.9654 - val_loss: 0.4623 - val_accuracy: 0.8151\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1014 - accuracy: 0.9716 - val_loss: 0.4968 - val_accuracy: 0.8396\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.0877 - accuracy: 0.9751 - val_loss: 0.5227 - val_accuracy: 0.8425\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0746 - accuracy: 0.9767 - val_loss: 0.6090 - val_accuracy: 0.7943\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.13207340240479\n",
      "Epoch 1/15\n",
      "191/191 - 13s - loss: 0.5653 - accuracy: 0.7287 - val_loss: 0.3977 - val_accuracy: 0.8500\n",
      "Epoch 2/15\n",
      "191/191 - 12s - loss: 0.2882 - accuracy: 0.9056 - val_loss: 0.4055 - val_accuracy: 0.8094\n",
      "Epoch 3/15\n",
      "191/191 - 12s - loss: 0.1671 - accuracy: 0.9506 - val_loss: 0.4569 - val_accuracy: 0.8075\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1168 - accuracy: 0.9674 - val_loss: 0.4927 - val_accuracy: 0.8047\n",
      "Epoch 5/15\n",
      "191/191 - 12s - loss: 0.0965 - accuracy: 0.9719 - val_loss: 0.5931 - val_accuracy: 0.8038\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.0881 - accuracy: 0.9746 - val_loss: 0.5942 - val_accuracy: 0.8094\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.5612 - accuracy: 0.7298 - val_loss: 0.4251 - val_accuracy: 0.8245\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.2865 - accuracy: 0.9036 - val_loss: 0.3926 - val_accuracy: 0.8519\n",
      "Epoch 3/15\n",
      "191/191 - 11s - loss: 0.1655 - accuracy: 0.9512 - val_loss: 0.4764 - val_accuracy: 0.8123\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1183 - accuracy: 0.9662 - val_loss: 0.4967 - val_accuracy: 0.8387\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.0942 - accuracy: 0.9749 - val_loss: 0.5438 - val_accuracy: 0.8094\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0867 - accuracy: 0.9751 - val_loss: 0.5725 - val_accuracy: 0.8311\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0699 - accuracy: 0.9810 - val_loss: 0.6094 - val_accuracy: 0.8396\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.18868088722229\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5740 - accuracy: 0.7235 - val_loss: 0.3791 - val_accuracy: 0.8519\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2948 - accuracy: 0.9031 - val_loss: 0.3379 - val_accuracy: 0.8717\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1751 - accuracy: 0.9535 - val_loss: 0.4020 - val_accuracy: 0.8160\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1316 - accuracy: 0.9655 - val_loss: 0.4051 - val_accuracy: 0.8632\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1084 - accuracy: 0.9686 - val_loss: 0.4516 - val_accuracy: 0.8642\n",
      "Epoch 6/15\n",
      "191/191 - 10s - loss: 0.0947 - accuracy: 0.9737 - val_loss: 0.5022 - val_accuracy: 0.8170\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0813 - accuracy: 0.9750 - val_loss: 0.5331 - val_accuracy: 0.8132\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.16981410980225\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1       relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2       relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3       relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4       relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5       relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "6       tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
      "7       tanh       2  83.977377  85.673892  85.296887  85.768145  86.616397   \n",
      "8       tanh       3  86.616397  86.239398  85.768145  85.768145  84.919888   \n",
      "9       tanh       4  84.354383  85.296887  86.899149  86.239398  81.715363   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1  83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2  84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3  87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4  84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5  83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "6  85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
      "7  84.637135  88.490564  86.509436  85.471696  83.584905  85.602643  \n",
      "8  86.710650  84.905660  82.924527  84.905660  85.754716  85.451319  \n",
      "9  85.485393  86.132073  85.000002  85.188681  87.169814  85.348114  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5706 - accuracy: 0.7238 - val_loss: 0.3997 - val_accuracy: 0.8115\n",
      "Epoch 2/15\n",
      "191/191 - 11s - loss: 0.2806 - accuracy: 0.9052 - val_loss: 0.3824 - val_accuracy: 0.8256\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.1468 - accuracy: 0.9552 - val_loss: 0.4517 - val_accuracy: 0.8266\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1112 - accuracy: 0.9650 - val_loss: 0.5056 - val_accuracy: 0.8172\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.0845 - accuracy: 0.9739 - val_loss: 0.5086 - val_accuracy: 0.8134\n",
      "Epoch 6/15\n",
      "191/191 - 10s - loss: 0.0733 - accuracy: 0.9774 - val_loss: 0.5528 - val_accuracy: 0.8200\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0620 - accuracy: 0.9786 - val_loss: 0.5963 - val_accuracy: 0.8247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "191/191 - 11s - loss: 0.0607 - accuracy: 0.9795 - val_loss: 0.5990 - val_accuracy: 0.8294\n",
      "Epoch 9/15\n",
      "191/191 - 9s - loss: 0.0564 - accuracy: 0.9805 - val_loss: 0.6204 - val_accuracy: 0.8228\n",
      "Epoch 10/15\n",
      "191/191 - 10s - loss: 0.0597 - accuracy: 0.9806 - val_loss: 0.6378 - val_accuracy: 0.8238\n",
      "Epoch 11/15\n",
      "191/191 - 10s - loss: 0.0568 - accuracy: 0.9822 - val_loss: 0.6164 - val_accuracy: 0.8567\n",
      "Epoch 12/15\n",
      "191/191 - 10s - loss: 0.0556 - accuracy: 0.9794 - val_loss: 0.6754 - val_accuracy: 0.8153\n",
      "Epoch 13/15\n",
      "191/191 - 9s - loss: 0.0543 - accuracy: 0.9805 - val_loss: 0.6718 - val_accuracy: 0.8106\n",
      "Epoch 14/15\n",
      "191/191 - 12s - loss: 0.0486 - accuracy: 0.9838 - val_loss: 0.6473 - val_accuracy: 0.8454\n",
      "Epoch 15/15\n",
      "191/191 - 8s - loss: 0.0498 - accuracy: 0.9829 - val_loss: 0.6701 - val_accuracy: 0.8030\n",
      "Test Accuracy: 80.30160069465637\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.5691 - accuracy: 0.7188 - val_loss: 0.4266 - val_accuracy: 0.8322\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.2822 - accuracy: 0.9098 - val_loss: 0.4349 - val_accuracy: 0.8360\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.1565 - accuracy: 0.9551 - val_loss: 0.4970 - val_accuracy: 0.8275\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1146 - accuracy: 0.9698 - val_loss: 0.5460 - val_accuracy: 0.8172\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.0985 - accuracy: 0.9720 - val_loss: 0.6167 - val_accuracy: 0.8190\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0809 - accuracy: 0.9750 - val_loss: 0.6403 - val_accuracy: 0.8190\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0753 - accuracy: 0.9778 - val_loss: 0.6707 - val_accuracy: 0.8153\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.60037803649902\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5753 - accuracy: 0.7185 - val_loss: 0.3905 - val_accuracy: 0.8624\n",
      "Epoch 2/15\n",
      "191/191 - 10s - loss: 0.2955 - accuracy: 0.9017 - val_loss: 0.3372 - val_accuracy: 0.8746\n",
      "Epoch 3/15\n",
      "191/191 - 11s - loss: 0.1690 - accuracy: 0.9522 - val_loss: 0.3803 - val_accuracy: 0.8671\n",
      "Epoch 4/15\n",
      "191/191 - 10s - loss: 0.1269 - accuracy: 0.9660 - val_loss: 0.4269 - val_accuracy: 0.8577\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.1034 - accuracy: 0.9711 - val_loss: 0.4412 - val_accuracy: 0.8662\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.0920 - accuracy: 0.9729 - val_loss: 0.4833 - val_accuracy: 0.8624\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0855 - accuracy: 0.9750 - val_loss: 0.4841 - val_accuracy: 0.8718\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.4646544456482\n",
      "Epoch 1/15\n",
      "191/191 - 11s - loss: 0.5728 - accuracy: 0.7248 - val_loss: 0.3988 - val_accuracy: 0.8407\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2861 - accuracy: 0.9068 - val_loss: 0.3919 - val_accuracy: 0.8247\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.1684 - accuracy: 0.9528 - val_loss: 0.4333 - val_accuracy: 0.8520\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1217 - accuracy: 0.9689 - val_loss: 0.5093 - val_accuracy: 0.8379\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.0950 - accuracy: 0.9732 - val_loss: 0.5184 - val_accuracy: 0.8398\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.0844 - accuracy: 0.9754 - val_loss: 0.5639 - val_accuracy: 0.8379\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0783 - accuracy: 0.9777 - val_loss: 0.6167 - val_accuracy: 0.8294\n",
      "Epoch 8/15\n",
      "191/191 - 10s - loss: 0.0705 - accuracy: 0.9782 - val_loss: 0.6625 - val_accuracy: 0.8190\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.20264029502869\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5733 - accuracy: 0.7210 - val_loss: 0.4007 - val_accuracy: 0.8332\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.2962 - accuracy: 0.9027 - val_loss: 0.3508 - val_accuracy: 0.8680\n",
      "Epoch 3/15\n",
      "191/191 - 11s - loss: 0.1662 - accuracy: 0.9516 - val_loss: 0.3882 - val_accuracy: 0.8341\n",
      "Epoch 4/15\n",
      "191/191 - 11s - loss: 0.1216 - accuracy: 0.9668 - val_loss: 0.4349 - val_accuracy: 0.8501\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.0959 - accuracy: 0.9717 - val_loss: 0.4470 - val_accuracy: 0.8558\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0772 - accuracy: 0.9763 - val_loss: 0.4784 - val_accuracy: 0.8586\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0732 - accuracy: 0.9773 - val_loss: 0.5273 - val_accuracy: 0.8501\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.80490255355835\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5808 - accuracy: 0.7099 - val_loss: 0.4118 - val_accuracy: 0.8445\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.2971 - accuracy: 0.9005 - val_loss: 0.3681 - val_accuracy: 0.8615\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.1693 - accuracy: 0.9539 - val_loss: 0.4330 - val_accuracy: 0.8360\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1194 - accuracy: 0.9667 - val_loss: 0.4855 - val_accuracy: 0.8049\n",
      "Epoch 5/15\n",
      "191/191 - 10s - loss: 0.0976 - accuracy: 0.9718 - val_loss: 0.5219 - val_accuracy: 0.8030\n",
      "Epoch 6/15\n",
      "191/191 - 11s - loss: 0.0866 - accuracy: 0.9756 - val_loss: 0.5985 - val_accuracy: 0.8162\n",
      "Epoch 7/15\n",
      "191/191 - 11s - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.6009 - val_accuracy: 0.7851\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.14514470100403\n",
      "Epoch 1/15\n",
      "191/191 - 14s - loss: 0.5662 - accuracy: 0.7247 - val_loss: 0.4164 - val_accuracy: 0.8245\n",
      "Epoch 2/15\n",
      "191/191 - 13s - loss: 0.2877 - accuracy: 0.9032 - val_loss: 0.4063 - val_accuracy: 0.8151\n",
      "Epoch 3/15\n",
      "191/191 - 13s - loss: 0.1589 - accuracy: 0.9561 - val_loss: 0.4789 - val_accuracy: 0.8047\n",
      "Epoch 4/15\n",
      "191/191 - 12s - loss: 0.1177 - accuracy: 0.9668 - val_loss: 0.5005 - val_accuracy: 0.8132\n",
      "Epoch 5/15\n",
      "191/191 - 13s - loss: 0.0879 - accuracy: 0.9749 - val_loss: 0.5569 - val_accuracy: 0.8302\n",
      "Epoch 6/15\n",
      "191/191 - 13s - loss: 0.0792 - accuracy: 0.9772 - val_loss: 0.6044 - val_accuracy: 0.8028\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0692 - accuracy: 0.9779 - val_loss: 0.6179 - val_accuracy: 0.8066\n",
      "Epoch 8/15\n",
      "191/191 - 11s - loss: 0.0627 - accuracy: 0.9799 - val_loss: 0.6898 - val_accuracy: 0.7953\n",
      "Epoch 9/15\n",
      "191/191 - 13s - loss: 0.0575 - accuracy: 0.9802 - val_loss: 0.7003 - val_accuracy: 0.8000\n",
      "Epoch 10/15\n",
      "191/191 - 12s - loss: 0.0571 - accuracy: 0.9809 - val_loss: 0.7267 - val_accuracy: 0.7972\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 83.01886916160583\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5692 - accuracy: 0.7218 - val_loss: 0.4017 - val_accuracy: 0.8396\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.2923 - accuracy: 0.9071 - val_loss: 0.3553 - val_accuracy: 0.8302\n",
      "Epoch 3/15\n",
      "191/191 - 9s - loss: 0.1693 - accuracy: 0.9539 - val_loss: 0.3989 - val_accuracy: 0.8528\n",
      "Epoch 4/15\n",
      "191/191 - 9s - loss: 0.1267 - accuracy: 0.9672 - val_loss: 0.4778 - val_accuracy: 0.8085\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.0971 - accuracy: 0.9728 - val_loss: 0.4939 - val_accuracy: 0.8198\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0865 - accuracy: 0.9770 - val_loss: 0.5270 - val_accuracy: 0.8500\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0760 - accuracy: 0.9771 - val_loss: 0.5852 - val_accuracy: 0.7934\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0710 - accuracy: 0.9804 - val_loss: 0.6203 - val_accuracy: 0.8217\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.2830171585083\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5665 - accuracy: 0.7304 - val_loss: 0.3735 - val_accuracy: 0.8519\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2845 - accuracy: 0.9055 - val_loss: 0.3576 - val_accuracy: 0.8679\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1770 - accuracy: 0.9515 - val_loss: 0.3971 - val_accuracy: 0.8094\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1321 - accuracy: 0.9633 - val_loss: 0.4746 - val_accuracy: 0.7934\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1074 - accuracy: 0.9711 - val_loss: 0.4842 - val_accuracy: 0.8481\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0947 - accuracy: 0.9737 - val_loss: 0.5254 - val_accuracy: 0.7962\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0876 - accuracy: 0.9755 - val_loss: 0.5663 - val_accuracy: 0.8377\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.79245114326477\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5682 - accuracy: 0.7270 - val_loss: 0.3982 - val_accuracy: 0.8396\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2830 - accuracy: 0.9060 - val_loss: 0.4064 - val_accuracy: 0.8104\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1669 - accuracy: 0.9536 - val_loss: 0.4191 - val_accuracy: 0.8274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1208 - accuracy: 0.9671 - val_loss: 0.4694 - val_accuracy: 0.8132\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0972 - accuracy: 0.9728 - val_loss: 0.5513 - val_accuracy: 0.8038\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0846 - accuracy: 0.9776 - val_loss: 0.5648 - val_accuracy: 0.8000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 83.96226167678833\n",
      "\n",
      "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0        relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1        relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2        relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3        relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4        relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5        relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "6        tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
      "7        tanh       2  83.977377  85.673892  85.296887  85.768145  86.616397   \n",
      "8        tanh       3  86.616397  86.239398  85.768145  85.768145  84.919888   \n",
      "9        tanh       4  84.354383  85.296887  86.899149  86.239398  81.715363   \n",
      "10       tanh       5  80.301601  83.600378  87.464654  85.202640  86.804903   \n",
      "\n",
      "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0   84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1   83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2   84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3   87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4   84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5   83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "6   85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
      "7   84.637135  88.490564  86.509436  85.471696  83.584905  85.602643  \n",
      "8   86.710650  84.905660  82.924527  84.905660  85.754716  85.451319  \n",
      "9   85.485393  86.132073  85.000002  85.188681  87.169814  85.348114  \n",
      "10  86.145145  83.018869  85.283017  86.792451  83.962262  84.857592  \n",
      "\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5639 - accuracy: 0.7277 - val_loss: 0.4178 - val_accuracy: 0.8313\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2789 - accuracy: 0.9111 - val_loss: 0.3881 - val_accuracy: 0.8398\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1539 - accuracy: 0.9564 - val_loss: 0.4226 - val_accuracy: 0.8332\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1085 - accuracy: 0.9675 - val_loss: 0.4663 - val_accuracy: 0.8369\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0849 - accuracy: 0.9738 - val_loss: 0.5206 - val_accuracy: 0.8238\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0727 - accuracy: 0.9764 - val_loss: 0.5678 - val_accuracy: 0.8256\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0683 - accuracy: 0.9776 - val_loss: 0.5964 - val_accuracy: 0.8228\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.97737741470337\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5689 - accuracy: 0.7155 - val_loss: 0.3844 - val_accuracy: 0.8464\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2800 - accuracy: 0.9055 - val_loss: 0.3615 - val_accuracy: 0.8539\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1527 - accuracy: 0.9558 - val_loss: 0.4130 - val_accuracy: 0.8247\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1098 - accuracy: 0.9666 - val_loss: 0.4909 - val_accuracy: 0.8200\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0825 - accuracy: 0.9748 - val_loss: 0.5301 - val_accuracy: 0.8209\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0723 - accuracy: 0.9784 - val_loss: 0.6157 - val_accuracy: 0.8040\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0671 - accuracy: 0.9775 - val_loss: 0.5796 - val_accuracy: 0.8445\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.39113998413086\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5803 - accuracy: 0.7141 - val_loss: 0.3943 - val_accuracy: 0.8417\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3048 - accuracy: 0.9018 - val_loss: 0.3610 - val_accuracy: 0.8624\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1813 - accuracy: 0.9479 - val_loss: 0.3924 - val_accuracy: 0.8351\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1288 - accuracy: 0.9663 - val_loss: 0.4544 - val_accuracy: 0.8501\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.1060 - accuracy: 0.9716 - val_loss: 0.4691 - val_accuracy: 0.8294\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0897 - accuracy: 0.9752 - val_loss: 0.5251 - val_accuracy: 0.8426\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0814 - accuracy: 0.9763 - val_loss: 0.5145 - val_accuracy: 0.8483\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.23939752578735\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5705 - accuracy: 0.7236 - val_loss: 0.4201 - val_accuracy: 0.8379\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2828 - accuracy: 0.9081 - val_loss: 0.3742 - val_accuracy: 0.8549\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1654 - accuracy: 0.9537 - val_loss: 0.4340 - val_accuracy: 0.8275\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1156 - accuracy: 0.9654 - val_loss: 0.4752 - val_accuracy: 0.8219\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0935 - accuracy: 0.9731 - val_loss: 0.5198 - val_accuracy: 0.8143\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0815 - accuracy: 0.9752 - val_loss: 0.5540 - val_accuracy: 0.8577\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0720 - accuracy: 0.9789 - val_loss: 0.5857 - val_accuracy: 0.8153\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0642 - accuracy: 0.9807 - val_loss: 0.6188 - val_accuracy: 0.8134\n",
      "Epoch 9/15\n",
      "191/191 - 8s - loss: 0.0628 - accuracy: 0.9808 - val_loss: 0.6965 - val_accuracy: 0.8040\n",
      "Epoch 10/15\n",
      "191/191 - 8s - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.7317 - val_accuracy: 0.7983\n",
      "Epoch 11/15\n",
      "191/191 - 8s - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.6766 - val_accuracy: 0.8049\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 85.76814532279968\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5726 - accuracy: 0.7237 - val_loss: 0.4147 - val_accuracy: 0.8464\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2841 - accuracy: 0.9039 - val_loss: 0.3776 - val_accuracy: 0.8558\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1559 - accuracy: 0.9543 - val_loss: 0.4638 - val_accuracy: 0.8087\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1130 - accuracy: 0.9676 - val_loss: 0.5120 - val_accuracy: 0.8058\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0940 - accuracy: 0.9738 - val_loss: 0.5319 - val_accuracy: 0.8483\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0775 - accuracy: 0.9772 - val_loss: 0.5969 - val_accuracy: 0.8332\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0710 - accuracy: 0.9790 - val_loss: 0.6336 - val_accuracy: 0.8011\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.57963967323303\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5715 - accuracy: 0.7247 - val_loss: 0.4039 - val_accuracy: 0.8332\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2894 - accuracy: 0.9032 - val_loss: 0.3761 - val_accuracy: 0.8209\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1611 - accuracy: 0.9529 - val_loss: 0.4082 - val_accuracy: 0.8549\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1152 - accuracy: 0.9687 - val_loss: 0.4714 - val_accuracy: 0.8106\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0910 - accuracy: 0.9750 - val_loss: 0.5198 - val_accuracy: 0.8162\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0807 - accuracy: 0.9761 - val_loss: 0.5640 - val_accuracy: 0.8134\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0704 - accuracy: 0.9782 - val_loss: 0.6286 - val_accuracy: 0.7992\n",
      "Epoch 8/15\n",
      "191/191 - 8s - loss: 0.0704 - accuracy: 0.9787 - val_loss: 0.6233 - val_accuracy: 0.8275\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5680 - accuracy: 0.7225 - val_loss: 0.3988 - val_accuracy: 0.8462\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2800 - accuracy: 0.9084 - val_loss: 0.3687 - val_accuracy: 0.8594\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1619 - accuracy: 0.9513 - val_loss: 0.4534 - val_accuracy: 0.8425\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1157 - accuracy: 0.9669 - val_loss: 0.4780 - val_accuracy: 0.8406\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0897 - accuracy: 0.9727 - val_loss: 0.5148 - val_accuracy: 0.8377\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0787 - accuracy: 0.9771 - val_loss: 0.5329 - val_accuracy: 0.8094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0742 - accuracy: 0.9773 - val_loss: 0.5734 - val_accuracy: 0.8292\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.94339489936829\n",
      "Epoch 1/15\n",
      "191/191 - 9s - loss: 0.5788 - accuracy: 0.7187 - val_loss: 0.4064 - val_accuracy: 0.8472\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.2947 - accuracy: 0.9045 - val_loss: 0.3850 - val_accuracy: 0.8179\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1715 - accuracy: 0.9540 - val_loss: 0.4311 - val_accuracy: 0.8142\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1317 - accuracy: 0.9666 - val_loss: 0.4440 - val_accuracy: 0.8566\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.1110 - accuracy: 0.9695 - val_loss: 0.5196 - val_accuracy: 0.8075\n",
      "Epoch 6/15\n",
      "191/191 - 8s - loss: 0.0969 - accuracy: 0.9738 - val_loss: 0.5448 - val_accuracy: 0.8132\n",
      "Epoch 7/15\n",
      "191/191 - 8s - loss: 0.0868 - accuracy: 0.9755 - val_loss: 0.5472 - val_accuracy: 0.8160\n",
      "Epoch 8/15\n",
      "191/191 - 9s - loss: 0.0753 - accuracy: 0.9783 - val_loss: 0.5871 - val_accuracy: 0.8085\n",
      "Epoch 9/15\n",
      "191/191 - 9s - loss: 0.0700 - accuracy: 0.9794 - val_loss: 0.6109 - val_accuracy: 0.8377\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5797 - accuracy: 0.7154 - val_loss: 0.4229 - val_accuracy: 0.8113\n",
      "Epoch 2/15\n",
      "191/191 - 8s - loss: 0.3018 - accuracy: 0.8981 - val_loss: 0.3835 - val_accuracy: 0.8538\n",
      "Epoch 3/15\n",
      "191/191 - 8s - loss: 0.1738 - accuracy: 0.9508 - val_loss: 0.4378 - val_accuracy: 0.8396\n",
      "Epoch 4/15\n",
      "191/191 - 8s - loss: 0.1253 - accuracy: 0.9656 - val_loss: 0.4944 - val_accuracy: 0.8340\n",
      "Epoch 5/15\n",
      "191/191 - 8s - loss: 0.0975 - accuracy: 0.9733 - val_loss: 0.5542 - val_accuracy: 0.8264\n",
      "Epoch 6/15\n",
      "191/191 - 9s - loss: 0.0826 - accuracy: 0.9778 - val_loss: 0.5691 - val_accuracy: 0.7906\n",
      "Epoch 7/15\n",
      "191/191 - 9s - loss: 0.0760 - accuracy: 0.9770 - val_loss: 0.6134 - val_accuracy: 0.8330\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.37735939025879\n",
      "Epoch 1/15\n",
      "191/191 - 10s - loss: 0.5766 - accuracy: 0.7187 - val_loss: 0.3774 - val_accuracy: 0.8443\n",
      "Epoch 2/15\n",
      "191/191 - 9s - loss: 0.2983 - accuracy: 0.8972 - val_loss: 0.3311 - val_accuracy: 0.8679\n",
      "Epoch 3/15\n",
      "191/191 - 11s - loss: 0.1650 - accuracy: 0.9529 - val_loss: 0.4128 - val_accuracy: 0.8557\n",
      "Epoch 4/15\n",
      "191/191 - 11s - loss: 0.1221 - accuracy: 0.9658 - val_loss: 0.4338 - val_accuracy: 0.8179\n",
      "Epoch 5/15\n",
      "191/191 - 9s - loss: 0.0975 - accuracy: 0.9714 - val_loss: 0.4750 - val_accuracy: 0.8453\n",
      "Epoch 6/15\n",
      "191/191 - 12s - loss: 0.0810 - accuracy: 0.9757 - val_loss: 0.5177 - val_accuracy: 0.8396\n",
      "Epoch 7/15\n",
      "191/191 - 10s - loss: 0.0696 - accuracy: 0.9790 - val_loss: 0.5503 - val_accuracy: 0.8028\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.79245114326477\n",
      "\n",
      "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0        relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
      "1        relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
      "2        relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
      "3        relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
      "4        relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
      "5        relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
      "6        tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
      "7        tanh       2  83.977377  85.673892  85.296887  85.768145  86.616397   \n",
      "8        tanh       3  86.616397  86.239398  85.768145  85.768145  84.919888   \n",
      "9        tanh       4  84.354383  85.296887  86.899149  86.239398  81.715363   \n",
      "10       tanh       5  80.301601  83.600378  87.464654  85.202640  86.804903   \n",
      "11       tanh       6  83.977377  85.391140  86.239398  85.768145  85.579640   \n",
      "\n",
      "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0   84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
      "1   83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
      "2   84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
      "3   87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
      "4   84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
      "5   83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  \n",
      "6   85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
      "7   84.637135  88.490564  86.509436  85.471696  83.584905  85.602643  \n",
      "8   86.710650  84.905660  82.924527  84.905660  85.754716  85.451319  \n",
      "9   85.485393  86.132073  85.000002  85.188681  87.169814  85.348114  \n",
      "10  86.145145  83.018869  85.283017  86.792451  83.962262  84.857592  \n",
      "11  85.485393  85.943395  85.660380  85.377359  86.792451  85.621468  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu', 'tanh']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "\n",
    "            # Define the input shape\n",
    "            model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=15, verbose=2, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record = record.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>86.993402</td>\n",
       "      <td>85.956645</td>\n",
       "      <td>86.616397</td>\n",
       "      <td>84.825635</td>\n",
       "      <td>87.641507</td>\n",
       "      <td>85.849059</td>\n",
       "      <td>88.018870</td>\n",
       "      <td>86.509436</td>\n",
       "      <td>86.375874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>86.522150</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>86.616397</td>\n",
       "      <td>85.108387</td>\n",
       "      <td>85.391140</td>\n",
       "      <td>87.276155</td>\n",
       "      <td>84.622639</td>\n",
       "      <td>87.075472</td>\n",
       "      <td>84.622639</td>\n",
       "      <td>86.320752</td>\n",
       "      <td>85.941812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>84.260130</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>87.276155</td>\n",
       "      <td>86.333650</td>\n",
       "      <td>86.804903</td>\n",
       "      <td>84.542882</td>\n",
       "      <td>85.094339</td>\n",
       "      <td>86.320752</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>85.283017</td>\n",
       "      <td>85.743860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>85.673892</td>\n",
       "      <td>86.145145</td>\n",
       "      <td>85.956645</td>\n",
       "      <td>86.050898</td>\n",
       "      <td>85.956645</td>\n",
       "      <td>83.129126</td>\n",
       "      <td>85.943395</td>\n",
       "      <td>87.735850</td>\n",
       "      <td>87.075472</td>\n",
       "      <td>83.396226</td>\n",
       "      <td>85.706329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>83.977377</td>\n",
       "      <td>85.391140</td>\n",
       "      <td>86.239398</td>\n",
       "      <td>85.768145</td>\n",
       "      <td>85.579640</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>85.943395</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>85.377359</td>\n",
       "      <td>86.792451</td>\n",
       "      <td>85.621468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>83.977377</td>\n",
       "      <td>85.673892</td>\n",
       "      <td>85.296887</td>\n",
       "      <td>85.768145</td>\n",
       "      <td>86.616397</td>\n",
       "      <td>84.637135</td>\n",
       "      <td>88.490564</td>\n",
       "      <td>86.509436</td>\n",
       "      <td>85.471696</td>\n",
       "      <td>83.584905</td>\n",
       "      <td>85.602643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>86.616397</td>\n",
       "      <td>86.239398</td>\n",
       "      <td>85.768145</td>\n",
       "      <td>85.768145</td>\n",
       "      <td>84.919888</td>\n",
       "      <td>86.710650</td>\n",
       "      <td>84.905660</td>\n",
       "      <td>82.924527</td>\n",
       "      <td>84.905660</td>\n",
       "      <td>85.754716</td>\n",
       "      <td>85.451319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>84.354383</td>\n",
       "      <td>85.296887</td>\n",
       "      <td>86.899149</td>\n",
       "      <td>86.239398</td>\n",
       "      <td>81.715363</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>86.132073</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>85.188681</td>\n",
       "      <td>87.169814</td>\n",
       "      <td>85.348114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>86.333650</td>\n",
       "      <td>84.071630</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>84.825635</td>\n",
       "      <td>85.768145</td>\n",
       "      <td>84.260130</td>\n",
       "      <td>88.867927</td>\n",
       "      <td>81.132078</td>\n",
       "      <td>85.377359</td>\n",
       "      <td>85.283017</td>\n",
       "      <td>85.178196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>85.391140</td>\n",
       "      <td>83.788878</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>86.899149</td>\n",
       "      <td>87.558907</td>\n",
       "      <td>85.108387</td>\n",
       "      <td>86.981130</td>\n",
       "      <td>81.320757</td>\n",
       "      <td>82.641512</td>\n",
       "      <td>83.773583</td>\n",
       "      <td>84.894884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>5</td>\n",
       "      <td>80.301601</td>\n",
       "      <td>83.600378</td>\n",
       "      <td>87.464654</td>\n",
       "      <td>85.202640</td>\n",
       "      <td>86.804903</td>\n",
       "      <td>86.145145</td>\n",
       "      <td>83.018869</td>\n",
       "      <td>85.283017</td>\n",
       "      <td>86.792451</td>\n",
       "      <td>83.962262</td>\n",
       "      <td>84.857592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>84.542882</td>\n",
       "      <td>80.678606</td>\n",
       "      <td>84.071630</td>\n",
       "      <td>86.522150</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>83.694625</td>\n",
       "      <td>86.981130</td>\n",
       "      <td>87.641507</td>\n",
       "      <td>82.547170</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>84.754210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "0        relu       1  85.485393  85.862392  86.993402  85.956645  86.616397   \n",
       "3        relu       4  86.522150  85.862392  86.616397  85.108387  85.391140   \n",
       "4        relu       5  84.260130  85.862392  87.276155  86.333650  86.804903   \n",
       "1        relu       2  85.673892  86.145145  85.956645  86.050898  85.956645   \n",
       "11       tanh       6  83.977377  85.391140  86.239398  85.768145  85.579640   \n",
       "7        tanh       2  83.977377  85.673892  85.296887  85.768145  86.616397   \n",
       "8        tanh       3  86.616397  86.239398  85.768145  85.768145  84.919888   \n",
       "9        tanh       4  84.354383  85.296887  86.899149  86.239398  81.715363   \n",
       "2        relu       3  86.333650  84.071630  85.862392  84.825635  85.768145   \n",
       "6        tanh       1  85.391140  83.788878  85.485393  86.899149  87.558907   \n",
       "10       tanh       5  80.301601  83.600378  87.464654  85.202640  86.804903   \n",
       "5        relu       6  84.542882  80.678606  84.071630  86.522150  85.862392   \n",
       "\n",
       "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "0   84.825635  87.641507  85.849059  88.018870  86.509436  86.375874  \n",
       "3   87.276155  84.622639  87.075472  84.622639  86.320752  85.941812  \n",
       "4   84.542882  85.094339  86.320752  85.660380  85.283017  85.743860  \n",
       "1   83.129126  85.943395  87.735850  87.075472  83.396226  85.706329  \n",
       "11  85.485393  85.943395  85.660380  85.377359  86.792451  85.621468  \n",
       "7   84.637135  88.490564  86.509436  85.471696  83.584905  85.602643  \n",
       "8   86.710650  84.905660  82.924527  84.905660  85.754716  85.451319  \n",
       "9   85.485393  86.132073  85.000002  85.188681  87.169814  85.348114  \n",
       "2   84.260130  88.867927  81.132078  85.377359  85.283017  85.178196  \n",
       "6   85.108387  86.981130  81.320757  82.641512  83.773583  84.894884  \n",
       "10  86.145145  83.018869  85.283017  86.792451  83.962262  84.857592  \n",
       "5   83.694625  86.981130  87.641507  82.547170  85.000002  84.754210  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>86.375874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>85.621468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AVG\n",
       "Activation           \n",
       "relu        86.375874\n",
       "tanh        85.621468"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_MPQA.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6083 words present from 6236 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    \n",
    "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
    "            \n",
    "        # initialize the unknown word with standard normal distribution values\n",
    "        else:\n",
    "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.55148904,  0.57902778, -0.11133335, ...,  0.74881703,\n",
       "         1.93214372,  1.15349156],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(filters = 100, kernel_size = 3, activation='relu', \n",
    "                 input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_121 (Embedding)    (None, 100, 300)          1768800   \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_121 (Flatten)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_242 (Dropout)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_243 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,907,921\n",
      "Trainable params: 139,121\n",
      "Non-trainable params: 1,768,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(vocab_size, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.84165978431702\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 88.31291198730469\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 86.52215003967285\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 87.55890727043152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 88.87841701507568\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.4716956615448\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 87.35849261283875\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 87.64150738716125\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 88.96226286888123\n",
      "\n",
      "  Activation Filters      acc1       acc2      acc3       acc4       acc5  \\\n",
      "0       relu       1  87.84166  88.312912  86.52215  87.558907  85.485393   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10       AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.40334  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.23939752578735\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 86.14514470100403\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 88.12441229820251\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.37040758132935\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.52686357498169\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.75471639633179\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 88.67924809455872\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.69811367988586\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.01887035369873\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 77.5683343410492\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 78.13383340835571\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 84.26012992858887\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.49010634422302\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 85.95664501190186\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 86.71064972877502\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 86.50943636894226\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 83.86792540550232\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 77.73584723472595\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.52686357498169\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 87.37040758132935\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 88.12441229820251\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 84.44863557815552\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 81.80961608886719\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 83.97737741470337\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 76.41509175300598\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 87.73584961891174\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 83.86792540550232\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 86.32075190544128\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
      "3       relu       4  81.526864  87.370408  88.124412  84.448636  81.809616   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  \n",
      "3  83.977377  76.415092  87.735850  83.867925  86.320752  84.159693  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.05089783668518\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 82.28086829185486\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 85.67389249801636\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.67389249801636\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 84.35438275337219\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 83.12912583351135\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 85.37735939025879\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.37735939025879\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.45282888412476\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
      "3       relu       4  81.526864  87.370408  88.124412  84.448636  81.809616   \n",
      "4       relu       5  86.050898  82.280868  85.673892  85.673892  84.354383   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  \n",
      "3  83.977377  76.415092  87.735850  83.867925  86.320752  84.159693  \n",
      "4  83.129126  85.377359  85.377359  87.452829  85.000002  85.037061  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 85.39113998413086\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.57963967323303\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 86.8991494178772\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 85.29688715934753\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.32233905792236\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 86.99340224266052\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 86.60377264022827\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 75.84905624389648\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 76.79245471954346\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.2830171585083\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
      "3       relu       4  81.526864  87.370408  88.124412  84.448636  81.809616   \n",
      "4       relu       5  86.050898  82.280868  85.673892  85.673892  84.354383   \n",
      "5       relu       6  85.391140  85.579640  86.899149  85.296887  78.322339   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  \n",
      "3  83.977377  76.415092  87.735850  83.867925  86.320752  84.159693  \n",
      "4  83.129126  85.377359  85.377359  87.452829  85.000002  85.037061  \n",
      "5  86.993402  86.603773  75.849056  76.792455  85.283017  83.301086  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 84.26012992858887\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.77285289764404\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 86.05089783668518\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 86.52215003967285\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.29688715934753\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 83.7888777256012\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.18868088722229\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 85.18868088722229\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 88.01887035369873\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
      "3       relu       4  81.526864  87.370408  88.124412  84.448636  81.809616   \n",
      "4       relu       5  86.050898  82.280868  85.673892  85.673892  84.354383   \n",
      "5       relu       6  85.391140  85.579640  86.899149  85.296887  78.322339   \n",
      "6       relu       7  84.260130  80.772853  86.050898  86.522150  85.296887   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  \n",
      "3  83.977377  76.415092  87.735850  83.867925  86.320752  84.159693  \n",
      "4  83.129126  85.377359  85.377359  87.452829  85.000002  85.037061  \n",
      "5  86.993402  86.603773  75.849056  76.792455  85.283017  83.301086  \n",
      "6  83.788878  85.000002  85.188681  85.188681  88.018870  85.008803  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 86.05089783668518\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 87.55890727043152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 86.05089783668518\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.68991732597351\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 82.54716992378235\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 86.50943636894226\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.62263941764832\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
      "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
      "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
      "3       relu       4  81.526864  87.370408  88.124412  84.448636  81.809616   \n",
      "4       relu       5  86.050898  82.280868  85.673892  85.673892  84.354383   \n",
      "5       relu       6  85.391140  85.579640  86.899149  85.296887  78.322339   \n",
      "6       relu       7  84.260130  80.772853  86.050898  86.522150  85.296887   \n",
      "7       relu       8  85.862392  86.050898  87.558907  85.485393  86.050898   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
      "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
      "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  \n",
      "3  83.977377  76.415092  87.735850  83.867925  86.320752  84.159693  \n",
      "4  83.129126  85.377359  85.377359  87.452829  85.000002  85.037061  \n",
      "5  86.993402  86.603773  75.849056  76.792455  85.283017  83.301086  \n",
      "6  83.788878  85.000002  85.188681  85.188681  88.018870  85.008803  \n",
      "7  88.689917  85.660380  82.547170  86.509436  84.622639  85.903803  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "            \n",
    "            \n",
    "            emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "            \n",
    "            # Define the input shape\n",
    "            model = define_model_2(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                 max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=30, verbose=0, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record2 = record2.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record2)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>87.841660</td>\n",
       "      <td>88.312912</td>\n",
       "      <td>86.522150</td>\n",
       "      <td>87.558907</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>88.878417</td>\n",
       "      <td>85.471696</td>\n",
       "      <td>87.358493</td>\n",
       "      <td>87.641507</td>\n",
       "      <td>88.962263</td>\n",
       "      <td>87.403340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>86.239398</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>86.145145</td>\n",
       "      <td>88.124412</td>\n",
       "      <td>87.370408</td>\n",
       "      <td>81.526864</td>\n",
       "      <td>85.754716</td>\n",
       "      <td>88.679248</td>\n",
       "      <td>81.698114</td>\n",
       "      <td>88.018870</td>\n",
       "      <td>85.904257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>86.050898</td>\n",
       "      <td>87.558907</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>86.050898</td>\n",
       "      <td>88.689917</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>82.547170</td>\n",
       "      <td>86.509436</td>\n",
       "      <td>84.622639</td>\n",
       "      <td>85.903803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>86.050898</td>\n",
       "      <td>82.280868</td>\n",
       "      <td>85.673892</td>\n",
       "      <td>85.673892</td>\n",
       "      <td>84.354383</td>\n",
       "      <td>83.129126</td>\n",
       "      <td>85.377359</td>\n",
       "      <td>85.377359</td>\n",
       "      <td>87.452829</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>85.037061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>84.260130</td>\n",
       "      <td>80.772853</td>\n",
       "      <td>86.050898</td>\n",
       "      <td>86.522150</td>\n",
       "      <td>85.296887</td>\n",
       "      <td>83.788878</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>85.188681</td>\n",
       "      <td>85.188681</td>\n",
       "      <td>88.018870</td>\n",
       "      <td>85.008803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>81.526864</td>\n",
       "      <td>87.370408</td>\n",
       "      <td>88.124412</td>\n",
       "      <td>84.448636</td>\n",
       "      <td>81.809616</td>\n",
       "      <td>83.977377</td>\n",
       "      <td>76.415092</td>\n",
       "      <td>87.735850</td>\n",
       "      <td>83.867925</td>\n",
       "      <td>86.320752</td>\n",
       "      <td>84.159693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>85.391140</td>\n",
       "      <td>85.579640</td>\n",
       "      <td>86.899149</td>\n",
       "      <td>85.296887</td>\n",
       "      <td>78.322339</td>\n",
       "      <td>86.993402</td>\n",
       "      <td>86.603773</td>\n",
       "      <td>75.849056</td>\n",
       "      <td>76.792455</td>\n",
       "      <td>85.283017</td>\n",
       "      <td>83.301086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>77.568334</td>\n",
       "      <td>78.133833</td>\n",
       "      <td>84.260130</td>\n",
       "      <td>80.490106</td>\n",
       "      <td>85.956645</td>\n",
       "      <td>86.710650</td>\n",
       "      <td>86.509436</td>\n",
       "      <td>83.867925</td>\n",
       "      <td>77.735847</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>82.689329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "0       relu       1  87.841660  88.312912  86.522150  87.558907  85.485393   \n",
       "1       relu       2  86.239398  85.485393  86.145145  88.124412  87.370408   \n",
       "7       relu       8  85.862392  86.050898  87.558907  85.485393  86.050898   \n",
       "4       relu       5  86.050898  82.280868  85.673892  85.673892  84.354383   \n",
       "6       relu       7  84.260130  80.772853  86.050898  86.522150  85.296887   \n",
       "3       relu       4  81.526864  87.370408  88.124412  84.448636  81.809616   \n",
       "5       relu       6  85.391140  85.579640  86.899149  85.296887  78.322339   \n",
       "2       relu       3  77.568334  78.133833  84.260130  80.490106  85.956645   \n",
       "\n",
       "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "0  88.878417  85.471696  87.358493  87.641507  88.962263  87.403340  \n",
       "1  81.526864  85.754716  88.679248  81.698114  88.018870  85.904257  \n",
       "7  88.689917  85.660380  82.547170  86.509436  84.622639  85.903803  \n",
       "4  83.129126  85.377359  85.377359  87.452829  85.000002  85.037061  \n",
       "6  83.788878  85.000002  85.188681  85.188681  88.018870  85.008803  \n",
       "3  83.977377  76.415092  87.735850  83.867925  86.320752  84.159693  \n",
       "5  86.993402  86.603773  75.849056  76.792455  85.283017  83.301086  \n",
       "2  86.710650  86.509436  83.867925  77.735847  85.660380  82.689329  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>87.40334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AVG\n",
       "Activation          \n",
       "relu        87.40334"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_MPQA_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(filters = 100, kernel_size = 3, activation='relu', \n",
    "                 input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_202 (Embedding)    (None, 100, 300)          1772100   \n",
      "_________________________________________________________________\n",
      "conv1d_202 (Conv1D)          (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_202 (MaxPoolin (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_202 (Flatten)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_404 (Dropout)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_405 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,911,221\n",
      "Trainable params: 1,911,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(vocab_size, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.99811577796936\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.23939752578735\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 83.31762552261353\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.42789721488953\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 88.31291198730469\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.65316009521484\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.22641444206238\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.73584961891174\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.16981410980225\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "\n",
      "       acc6       acc7      acc8       acc9      acc10        AVG  \n",
      "0  87.65316  81.226414  87.73585  87.169814  85.000002  85.508119  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 85.48539280891418\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 75.30631422996521\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 83.7888777256012\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 86.80490255355835\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 88.68991732597351\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 83.69462490081787\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 80.94339370727539\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 85.75471639633179\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.5283031463623\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 87.07547187805176\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.93590664863586\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 87.74740695953369\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 78.79359126091003\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.8991494178772\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 83.12912583351135\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.95664501190186\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.84905862808228\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.13207340240479\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.26415038108826\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.60377264022827\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 87.1819019317627\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.20735383033752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 88.12441229820251\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.80961608886719\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 87.84165978431702\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 82.75212049484253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 87.26415038108826\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.41509294509888\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 86.69811487197876\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
      "3       relu       4  87.181902  80.207354  88.124412  81.809616  87.841660   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
      "3  82.752120  85.660380  87.264150  81.415093  86.698115  84.895480  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.43261075019836\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.84165978431702\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.24411106109619\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.43261075019836\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.57963967323303\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.22641563415527\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.84905862808228\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 86.79245114326477\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
      "3       relu       4  87.181902  80.207354  88.124412  81.809616  87.841660   \n",
      "4       relu       5  81.432611  87.841660  81.244111  81.432611  86.616397   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
      "3  82.752120  85.660380  87.264150  81.415093  86.698115  84.895480  \n",
      "4  85.579640  86.226416  85.849059  86.792451  85.660380  84.867533  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 87.37040758132935\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 87.84165978431702\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 78.22808623313904\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 88.21865916252136\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.62111043930054\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.37040758132935\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.56603789329529\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.22641563415527\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 87.16981410980225\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
      "3       relu       4  87.181902  80.207354  88.124412  81.809616  87.841660   \n",
      "4       relu       5  81.432611  87.841660  81.244111  81.432611  86.616397   \n",
      "5       relu       6  87.370408  87.841660  78.228086  88.218659  81.621110   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
      "3  82.752120  85.660380  87.264150  81.415093  86.698115  84.895480  \n",
      "4  85.579640  86.226416  85.849059  86.792451  85.660380  84.867533  \n",
      "5  87.370408  85.566038  86.226416  87.169814  85.660380  85.527298  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.58435320854187\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 87.08765506744385\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.29688715934753\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.58435320854187\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.52686357498169\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 83.2233726978302\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 83.67924690246582\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 83.01886916160583\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.41509294509888\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 82.45282769203186\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
      "3       relu       4  87.181902  80.207354  88.124412  81.809616  87.841660   \n",
      "4       relu       5  81.432611  87.841660  81.244111  81.432611  86.616397   \n",
      "5       relu       6  87.370408  87.841660  78.228086  88.218659  81.621110   \n",
      "6       relu       7  80.584353  87.087655  85.296887  80.584353  81.526864   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
      "3  82.752120  85.660380  87.264150  81.415093  86.698115  84.895480  \n",
      "4  85.579640  86.226416  85.849059  86.792451  85.660380  84.867533  \n",
      "5  87.370408  85.566038  86.226416  87.169814  85.660380  85.527298  \n",
      "6  83.223373  83.679247  83.018869  81.415093  82.452828  82.886952  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.46936798095703\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.84165978431702\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 87.1819019317627\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 87.4646544456482\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.71064972877502\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 86.05089783668518\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 86.03773713111877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 82.16981291770935\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 87.26415038108826\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.39622616767883\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
      "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
      "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
      "3       relu       4  87.181902  80.207354  88.124412  81.809616  87.841660   \n",
      "4       relu       5  81.432611  87.841660  81.244111  81.432611  86.616397   \n",
      "5       relu       6  87.370408  87.841660  78.228086  88.218659  81.621110   \n",
      "6       relu       7  80.584353  87.087655  85.296887  80.584353  81.526864   \n",
      "7       relu       8  82.469368  87.841660  87.181902  87.464654  86.710650   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
      "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
      "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
      "3  82.752120  85.660380  87.264150  81.415093  86.698115  84.895480  \n",
      "4  85.579640  86.226416  85.849059  86.792451  85.660380  84.867533  \n",
      "5  87.370408  85.566038  86.226416  87.169814  85.660380  85.527298  \n",
      "6  83.223373  83.679247  83.018869  81.415093  82.452828  82.886952  \n",
      "7  86.050898  86.037737  82.169813  87.264150  83.396226  85.658706  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "            \n",
    "            \n",
    "            emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "            \n",
    "            # Define the input shape\n",
    "            model = define_model_3(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                 max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=20, verbose=0, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record3 = record3.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record3)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>82.469368</td>\n",
       "      <td>87.841660</td>\n",
       "      <td>87.181902</td>\n",
       "      <td>87.464654</td>\n",
       "      <td>86.710650</td>\n",
       "      <td>86.050898</td>\n",
       "      <td>86.037737</td>\n",
       "      <td>82.169813</td>\n",
       "      <td>87.264150</td>\n",
       "      <td>83.396226</td>\n",
       "      <td>85.658706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>87.935907</td>\n",
       "      <td>87.747407</td>\n",
       "      <td>78.793591</td>\n",
       "      <td>86.899149</td>\n",
       "      <td>83.129126</td>\n",
       "      <td>85.956645</td>\n",
       "      <td>85.849059</td>\n",
       "      <td>86.132073</td>\n",
       "      <td>87.264150</td>\n",
       "      <td>86.603773</td>\n",
       "      <td>85.631088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>87.370408</td>\n",
       "      <td>87.841660</td>\n",
       "      <td>78.228086</td>\n",
       "      <td>88.218659</td>\n",
       "      <td>81.621110</td>\n",
       "      <td>87.370408</td>\n",
       "      <td>85.566038</td>\n",
       "      <td>86.226416</td>\n",
       "      <td>87.169814</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>85.527298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>81.998116</td>\n",
       "      <td>86.239398</td>\n",
       "      <td>83.317626</td>\n",
       "      <td>86.427897</td>\n",
       "      <td>88.312912</td>\n",
       "      <td>87.653160</td>\n",
       "      <td>81.226414</td>\n",
       "      <td>87.735850</td>\n",
       "      <td>87.169814</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>85.508119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>87.181902</td>\n",
       "      <td>80.207354</td>\n",
       "      <td>88.124412</td>\n",
       "      <td>81.809616</td>\n",
       "      <td>87.841660</td>\n",
       "      <td>82.752120</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>87.264150</td>\n",
       "      <td>81.415093</td>\n",
       "      <td>86.698115</td>\n",
       "      <td>84.895480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>81.432611</td>\n",
       "      <td>87.841660</td>\n",
       "      <td>81.244111</td>\n",
       "      <td>81.432611</td>\n",
       "      <td>86.616397</td>\n",
       "      <td>85.579640</td>\n",
       "      <td>86.226416</td>\n",
       "      <td>85.849059</td>\n",
       "      <td>86.792451</td>\n",
       "      <td>85.660380</td>\n",
       "      <td>84.867533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>85.485393</td>\n",
       "      <td>75.306314</td>\n",
       "      <td>83.788878</td>\n",
       "      <td>86.804903</td>\n",
       "      <td>88.689917</td>\n",
       "      <td>83.694625</td>\n",
       "      <td>80.943394</td>\n",
       "      <td>85.754716</td>\n",
       "      <td>84.528303</td>\n",
       "      <td>87.075472</td>\n",
       "      <td>84.207191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>80.584353</td>\n",
       "      <td>87.087655</td>\n",
       "      <td>85.296887</td>\n",
       "      <td>80.584353</td>\n",
       "      <td>81.526864</td>\n",
       "      <td>83.223373</td>\n",
       "      <td>83.679247</td>\n",
       "      <td>83.018869</td>\n",
       "      <td>81.415093</td>\n",
       "      <td>82.452828</td>\n",
       "      <td>82.886952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "7       relu       8  82.469368  87.841660  87.181902  87.464654  86.710650   \n",
       "2       relu       3  87.935907  87.747407  78.793591  86.899149  83.129126   \n",
       "5       relu       6  87.370408  87.841660  78.228086  88.218659  81.621110   \n",
       "0       relu       1  81.998116  86.239398  83.317626  86.427897  88.312912   \n",
       "3       relu       4  87.181902  80.207354  88.124412  81.809616  87.841660   \n",
       "4       relu       5  81.432611  87.841660  81.244111  81.432611  86.616397   \n",
       "1       relu       2  85.485393  75.306314  83.788878  86.804903  88.689917   \n",
       "6       relu       7  80.584353  87.087655  85.296887  80.584353  81.526864   \n",
       "\n",
       "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "7  86.050898  86.037737  82.169813  87.264150  83.396226  85.658706  \n",
       "2  85.956645  85.849059  86.132073  87.264150  86.603773  85.631088  \n",
       "5  87.370408  85.566038  86.226416  87.169814  85.660380  85.527298  \n",
       "0  87.653160  81.226414  87.735850  87.169814  85.000002  85.508119  \n",
       "3  82.752120  85.660380  87.264150  81.415093  86.698115  84.895480  \n",
       "4  85.579640  86.226416  85.849059  86.792451  85.660380  84.867533  \n",
       "1  83.694625  80.943394  85.754716  84.528303  87.075472  84.207191  \n",
       "6  83.223373  83.679247  83.018869  81.415093  82.452828  82.886952  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_MPQA_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
