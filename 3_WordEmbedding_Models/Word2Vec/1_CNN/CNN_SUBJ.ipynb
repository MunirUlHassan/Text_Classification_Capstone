{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classification with MPQA Dataset\n",
    "<hr>\n",
    "\n",
    "The __modus operandi__ for text classification is to use __word embedding__ for representing words and a Convolutional neural network to learn how to discriminate documents on classification problems. \n",
    "\n",
    "__Yoav Goldberg__ commented in _A Primer on Neural Network Models for Natural Language Processing, 2015._ :\n",
    "> _The non-linearity of the network, as well as the ability to easily integrate pre-trained\n",
    "word embeddings, often lead to superior classification accuracy._\n",
    "\n",
    "He also commented in _Neural Network Methods for Natural Language Processing, 2017_ :\n",
    "> ... _the CNN is in essence a feature-extracting architecture. ... . The CNNs layer's responsibility is to extract meaningful sub-structures that are useful for the overall prediction task at hand._\n",
    "\n",
    "We will build a text classification model using CNN model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 1,2, 3, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2) constraint: 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>smart and alert , thirteen conversations about...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color , musical bounce and warm seas lapping o...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is not a mass market entertainment but an u...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a light hearted french film about the spiritua...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my wife is an actress has its moments in looki...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>in the end , they discover that balance in lif...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>a counterfeit 1000 tomin bank note is passed i...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>enter the beautiful and mysterious secret agen...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>after listening to a missionary from china spe...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>looking for a short cut to fame , glass concoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     smart and alert , thirteen conversations about...      0  train\n",
       "1     color , musical bounce and warm seas lapping o...      0  train\n",
       "2     it is not a mass market entertainment but an u...      0  train\n",
       "3     a light hearted french film about the spiritua...      0  train\n",
       "4     my wife is an actress has its moments in looki...      0  train\n",
       "...                                                 ...    ...    ...\n",
       "9995  in the end , they discover that balance in lif...      1  train\n",
       "9996  a counterfeit 1000 tomin bank note is passed i...      1  train\n",
       "9997  enter the beautiful and mysterious secret agen...      1  train\n",
       "9998  after listening to a missionary from china spe...      1  train\n",
       "9999  looking for a short cut to fame , glass concoc...      1  train\n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/SUBJ/SUBJ.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10000 non-null  object\n",
      " 1   label     10000 non-null  int32 \n",
      " 2   split     10000 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 195.4+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5000</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          5000   5000\n",
       "1          5000   5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smart and alert , thirteen conversations about one thing is a small gem .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  my wife is an actress has its moments in looking at the comic effects of jealousy . in the end , though , it is only mildly amusing when it could have been so much more .\n",
      "Into a sequence of int: [336, 208, 8, 16, 921, 25, 29, 312, 7, 313, 32, 2, 488, 551, 5, 3203, 7, 2, 129, 194, 10, 8, 60, 2330, 716, 39, 10, 128, 43, 82, 54, 81, 45]\n",
      "Into a padded sequence: [ 336  208    8   16  921   25   29  312    7  313   32    2  488  551\n",
      "    5 3203    7    2  129  194   10    8   60 2330  716   39   10  128\n",
      "   43   82   54   81   45    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "a 3\n",
      "and 4\n",
      "of 5\n",
      "to 6\n",
      "in 7\n",
      "is 8\n",
      "'s 9\n",
      "it 10\n",
      "21324\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "A __standard model__ for document classification is to use (quoted from __Jason Brownlee__, the author of [machinelearningmastery.com](https://machinelearningmastery.com)):\n",
    ">- Word Embedding: A distributed representation of words where different words that have a similar meaning (based on their usage) also have a similar representation.\n",
    ">- Convolutional Model: A feature extraction model that learns to extract salient features from documents represented using a word embedding.\n",
    ">- Fully Connected Model: The interpretation of extracted features in terms of a predictive output.\n",
    "\n",
    "\n",
    "Therefore, the model is comprised of the following elements:\n",
    "- __Input layer__ that defines the length of input sequences.\n",
    "- __Embedding layer__ set to the size of the vocabulary and 100-dimensional real-valued representations.\n",
    "- __Conv1D layer__ with 32 filters and a kernel size set to the number of words to read at once.\n",
    "- __MaxPooling1D layer__ to consolidate the output from the convolutional layer.\n",
    "- __Flatten layer__ to reduce the three-dimensional output to two dimensional for concatenation.\n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 3, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2): 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "We will perform the best parameter using __grid search__ and 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "Now, we will build Convolutional Neural Network (CNN) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "The model takes inspiration from `CNN for Sentence Classification` by *Yoon Kim*.\n",
    "\n",
    "Now, we will define our CNN model as follows:\n",
    "- One Conv layer with 100 filters, kernel size 5, and relu activation function;\n",
    "- One MaxPool layer with pool size = 2;\n",
    "- One Dropout layer after flattened;\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)\n",
    "\n",
    "**Note**: \n",
    "- The whole purpose of dropout layers is to tackle the problem of over-fitting and to introduce generalization to the model. Hence it is advisable to keep dropout parameter near 0.5 in hidden layers. \n",
    "- https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          6397200   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,536,321\n",
      "Trainable params: 6,536,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.6851 - accuracy: 0.5187 - val_loss: 0.5145 - val_accuracy: 0.8610\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.3089 - accuracy: 0.8681 - val_loss: 0.2200 - val_accuracy: 0.9140\n",
      "Epoch 3/15\n",
      "180/180 - 17s - loss: 0.1218 - accuracy: 0.9559 - val_loss: 0.2579 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0689 - accuracy: 0.9776 - val_loss: 0.3511 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0463 - accuracy: 0.9864 - val_loss: 0.4157 - val_accuracy: 0.9040\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0361 - accuracy: 0.9904 - val_loss: 0.4922 - val_accuracy: 0.9000\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0322 - accuracy: 0.9892 - val_loss: 0.6074 - val_accuracy: 0.9090\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5219 - accuracy: 0.7141 - val_loss: 0.2361 - val_accuracy: 0.9030\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2007 - accuracy: 0.9270 - val_loss: 0.2013 - val_accuracy: 0.9260\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0898 - accuracy: 0.9667 - val_loss: 0.2615 - val_accuracy: 0.9150\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0507 - accuracy: 0.9738 - val_loss: 0.2977 - val_accuracy: 0.9210\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0404 - accuracy: 0.9782 - val_loss: 0.3662 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0343 - accuracy: 0.9789 - val_loss: 0.3868 - val_accuracy: 0.9200\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0283 - accuracy: 0.9844 - val_loss: 0.4538 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.59999990463257\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5607 - accuracy: 0.6548 - val_loss: 0.2709 - val_accuracy: 0.9020\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2392 - accuracy: 0.9279 - val_loss: 0.2236 - val_accuracy: 0.9210\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1326 - accuracy: 0.9738 - val_loss: 0.2422 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0965 - accuracy: 0.9876 - val_loss: 0.2817 - val_accuracy: 0.9070\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0782 - accuracy: 0.9911 - val_loss: 0.3634 - val_accuracy: 0.9000\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0679 - accuracy: 0.9943 - val_loss: 0.3912 - val_accuracy: 0.9020\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0575 - accuracy: 0.9954 - val_loss: 0.4885 - val_accuracy: 0.8960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.10000038146973\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5807 - accuracy: 0.6702 - val_loss: 0.2805 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2619 - accuracy: 0.9102 - val_loss: 0.2152 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.2562 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0810 - accuracy: 0.9749 - val_loss: 0.3106 - val_accuracy: 0.9100\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0620 - accuracy: 0.9798 - val_loss: 0.3634 - val_accuracy: 0.9040\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0558 - accuracy: 0.9836 - val_loss: 0.4309 - val_accuracy: 0.9050\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0539 - accuracy: 0.9824 - val_loss: 0.4229 - val_accuracy: 0.9030\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0501 - accuracy: 0.9830 - val_loss: 0.5444 - val_accuracy: 0.8990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5514 - accuracy: 0.6896 - val_loss: 0.2685 - val_accuracy: 0.8950\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2012 - accuracy: 0.9306 - val_loss: 0.2103 - val_accuracy: 0.9220\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0822 - accuracy: 0.9780 - val_loss: 0.2575 - val_accuracy: 0.9150\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0491 - accuracy: 0.9872 - val_loss: 0.3303 - val_accuracy: 0.9140\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0376 - accuracy: 0.9893 - val_loss: 0.4195 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.4569 - val_accuracy: 0.9090\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0281 - accuracy: 0.9914 - val_loss: 0.5330 - val_accuracy: 0.9060\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.1999990940094\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5847 - accuracy: 0.6773 - val_loss: 0.3013 - val_accuracy: 0.9050\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2894 - accuracy: 0.9276 - val_loss: 0.2215 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1920 - accuracy: 0.9761 - val_loss: 0.2406 - val_accuracy: 0.9230\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.1477 - accuracy: 0.9879 - val_loss: 0.2690 - val_accuracy: 0.9180\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.1178 - accuracy: 0.9930 - val_loss: 0.3549 - val_accuracy: 0.9100\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.1030 - accuracy: 0.9953 - val_loss: 0.3659 - val_accuracy: 0.9230\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0880 - accuracy: 0.9954 - val_loss: 0.4195 - val_accuracy: 0.9150\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0814 - accuracy: 0.9950 - val_loss: 0.5111 - val_accuracy: 0.9110\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.6038 - accuracy: 0.6171 - val_loss: 0.2668 - val_accuracy: 0.9070\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2704 - accuracy: 0.8788 - val_loss: 0.2021 - val_accuracy: 0.9290\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1165 - accuracy: 0.9504 - val_loss: 0.2420 - val_accuracy: 0.9290\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0735 - accuracy: 0.9603 - val_loss: 0.3059 - val_accuracy: 0.9210\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0608 - accuracy: 0.9668 - val_loss: 0.3683 - val_accuracy: 0.9120\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0542 - accuracy: 0.9682 - val_loss: 0.4547 - val_accuracy: 0.9040\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0500 - accuracy: 0.9683 - val_loss: 0.4612 - val_accuracy: 0.9090\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.90000200271606\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.6932 - accuracy: 0.4923 - val_loss: 0.6932 - val_accuracy: 0.4970\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.6043 - accuracy: 0.5950 - val_loss: 0.2849 - val_accuracy: 0.8940\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.2806 - accuracy: 0.8888 - val_loss: 0.2214 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.1612 - accuracy: 0.9577 - val_loss: 0.2285 - val_accuracy: 0.9170\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0904 - accuracy: 0.9728 - val_loss: 0.3187 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0662 - accuracy: 0.9782 - val_loss: 0.3550 - val_accuracy: 0.9020\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0580 - accuracy: 0.9806 - val_loss: 0.4436 - val_accuracy: 0.9130\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0496 - accuracy: 0.9848 - val_loss: 0.4887 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 18s - loss: 0.5672 - accuracy: 0.6693 - val_loss: 0.2742 - val_accuracy: 0.8960\n",
      "Epoch 2/15\n",
      "180/180 - 17s - loss: 0.2485 - accuracy: 0.8906 - val_loss: 0.2274 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0996 - accuracy: 0.9499 - val_loss: 0.2535 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0642 - accuracy: 0.9622 - val_loss: 0.3164 - val_accuracy: 0.9130\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0442 - accuracy: 0.9816 - val_loss: 0.3822 - val_accuracy: 0.9110\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0390 - accuracy: 0.9837 - val_loss: 0.4350 - val_accuracy: 0.8970\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0391 - accuracy: 0.9813 - val_loss: 0.4917 - val_accuracy: 0.9050\n",
      "Epoch 8/15\n",
      "180/180 - 17s - loss: 0.0334 - accuracy: 0.9861 - val_loss: 0.5404 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5863 - accuracy: 0.6301 - val_loss: 0.2777 - val_accuracy: 0.8970\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2447 - accuracy: 0.9059 - val_loss: 0.2543 - val_accuracy: 0.9020\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1099 - accuracy: 0.9509 - val_loss: 0.3405 - val_accuracy: 0.8940\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0623 - accuracy: 0.9633 - val_loss: 0.4157 - val_accuracy: 0.8960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0494 - accuracy: 0.9768 - val_loss: 0.5339 - val_accuracy: 0.8960\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0427 - accuracy: 0.9814 - val_loss: 0.5424 - val_accuracy: 0.8960\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0345 - accuracy: 0.9829 - val_loss: 0.6695 - val_accuracy: 0.9030\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0350 - accuracy: 0.9840 - val_loss: 0.6754 - val_accuracy: 0.8950\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0327 - accuracy: 0.9836 - val_loss: 0.6963 - val_accuracy: 0.8960\n",
      "Epoch 10/15\n",
      "180/180 - 18s - loss: 0.0343 - accuracy: 0.9828 - val_loss: 0.7160 - val_accuracy: 0.8970\n",
      "Epoch 11/15\n",
      "180/180 - 18s - loss: 0.0319 - accuracy: 0.9847 - val_loss: 0.7615 - val_accuracy: 0.8920\n",
      "Epoch 12/15\n",
      "180/180 - 18s - loss: 0.0308 - accuracy: 0.9844 - val_loss: 0.8657 - val_accuracy: 0.8970\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 90.2999997138977\n",
      "\n",
      "  Activation Filters       acc1  acc2  acc3  acc4       acc5       acc6  \\\n",
      "0       relu       1  91.399997  92.6  92.1  91.7  92.199999  92.299998   \n",
      "\n",
      "        acc7  acc8       acc9  acc10    AVG  \n",
      "0  92.900002  91.7  91.600001   90.3  91.88  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5176 - accuracy: 0.7151 - val_loss: 0.2465 - val_accuracy: 0.8940\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2091 - accuracy: 0.9203 - val_loss: 0.2396 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.1037 - accuracy: 0.9699 - val_loss: 0.3092 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0721 - accuracy: 0.9803 - val_loss: 0.3579 - val_accuracy: 0.9070\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0635 - accuracy: 0.9791 - val_loss: 0.4142 - val_accuracy: 0.9030\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0543 - accuracy: 0.9847 - val_loss: 0.4620 - val_accuracy: 0.8980\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0528 - accuracy: 0.9824 - val_loss: 0.5589 - val_accuracy: 0.8960\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0432 - accuracy: 0.9874 - val_loss: 0.6278 - val_accuracy: 0.8920\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 90.89999794960022\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5416 - accuracy: 0.6918 - val_loss: 0.2511 - val_accuracy: 0.9020\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2013 - accuracy: 0.9376 - val_loss: 0.2034 - val_accuracy: 0.9200\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0912 - accuracy: 0.9809 - val_loss: 0.2825 - val_accuracy: 0.9140\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0632 - accuracy: 0.9893 - val_loss: 0.3274 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0469 - accuracy: 0.9932 - val_loss: 0.4389 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0444 - accuracy: 0.9946 - val_loss: 0.4103 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0391 - accuracy: 0.9937 - val_loss: 0.5386 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.00000166893005\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.6062 - accuracy: 0.6143 - val_loss: 0.3060 - val_accuracy: 0.8860\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2805 - accuracy: 0.8816 - val_loss: 0.2394 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.1527 - accuracy: 0.9673 - val_loss: 0.2643 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.1039 - accuracy: 0.9843 - val_loss: 0.2694 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0817 - accuracy: 0.9891 - val_loss: 0.3621 - val_accuracy: 0.9150\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0700 - accuracy: 0.9912 - val_loss: 0.4137 - val_accuracy: 0.9080\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0609 - accuracy: 0.9924 - val_loss: 0.4263 - val_accuracy: 0.9090\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0558 - accuracy: 0.9927 - val_loss: 0.5284 - val_accuracy: 0.9050\n",
      "Epoch 9/15\n",
      "180/180 - 19s - loss: 0.0543 - accuracy: 0.9913 - val_loss: 0.4895 - val_accuracy: 0.9040\n",
      "Epoch 10/15\n",
      "180/180 - 19s - loss: 0.0516 - accuracy: 0.9917 - val_loss: 0.5820 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.6020 - accuracy: 0.6276 - val_loss: 0.3091 - val_accuracy: 0.8910\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2509 - accuracy: 0.9181 - val_loss: 0.2053 - val_accuracy: 0.9240\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1123 - accuracy: 0.9702 - val_loss: 0.2315 - val_accuracy: 0.9180\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0688 - accuracy: 0.9879 - val_loss: 0.2987 - val_accuracy: 0.9200\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0521 - accuracy: 0.9924 - val_loss: 0.3763 - val_accuracy: 0.9170\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0415 - accuracy: 0.9942 - val_loss: 0.4021 - val_accuracy: 0.9160\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0420 - accuracy: 0.9942 - val_loss: 0.4297 - val_accuracy: 0.9110\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5562 - accuracy: 0.6794 - val_loss: 0.2634 - val_accuracy: 0.9040\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2527 - accuracy: 0.9188 - val_loss: 0.2178 - val_accuracy: 0.9100\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.1356 - accuracy: 0.9717 - val_loss: 0.2628 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0977 - accuracy: 0.9846 - val_loss: 0.3127 - val_accuracy: 0.9140\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0793 - accuracy: 0.9880 - val_loss: 0.3245 - val_accuracy: 0.9120\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0709 - accuracy: 0.9891 - val_loss: 0.3940 - val_accuracy: 0.9080\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0585 - accuracy: 0.9920 - val_loss: 0.4212 - val_accuracy: 0.9050\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0588 - accuracy: 0.9906 - val_loss: 0.4094 - val_accuracy: 0.9090\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5320 - accuracy: 0.6972 - val_loss: 0.2308 - val_accuracy: 0.9140\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1972 - accuracy: 0.9254 - val_loss: 0.2051 - val_accuracy: 0.9160\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0857 - accuracy: 0.9706 - val_loss: 0.2995 - val_accuracy: 0.9060\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0489 - accuracy: 0.9797 - val_loss: 0.4061 - val_accuracy: 0.9030\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0465 - accuracy: 0.9791 - val_loss: 0.4165 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0391 - accuracy: 0.9814 - val_loss: 0.4948 - val_accuracy: 0.9080\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0271 - accuracy: 0.9832 - val_loss: 0.5815 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5848 - accuracy: 0.6460 - val_loss: 0.2774 - val_accuracy: 0.9010\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.2489 - accuracy: 0.8831 - val_loss: 0.2198 - val_accuracy: 0.9130\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.1040 - accuracy: 0.9598 - val_loss: 0.2704 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0546 - accuracy: 0.9851 - val_loss: 0.3838 - val_accuracy: 0.8990\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0352 - accuracy: 0.9901 - val_loss: 0.4885 - val_accuracy: 0.9040\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.5406 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0280 - accuracy: 0.9909 - val_loss: 0.6213 - val_accuracy: 0.8990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.6387 - accuracy: 0.5757 - val_loss: 0.3134 - val_accuracy: 0.8670\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2896 - accuracy: 0.8913 - val_loss: 0.2004 - val_accuracy: 0.9270\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.1512 - accuracy: 0.9702 - val_loss: 0.1931 - val_accuracy: 0.9220\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0982 - accuracy: 0.9883 - val_loss: 0.2761 - val_accuracy: 0.9170\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0770 - accuracy: 0.9918 - val_loss: 0.3052 - val_accuracy: 0.9190\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0657 - accuracy: 0.9949 - val_loss: 0.3742 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0598 - accuracy: 0.9936 - val_loss: 0.3801 - val_accuracy: 0.9150\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.69999861717224\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5901 - accuracy: 0.6478 - val_loss: 0.3184 - val_accuracy: 0.8930\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.3255 - accuracy: 0.9028 - val_loss: 0.2560 - val_accuracy: 0.9210\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.1935 - accuracy: 0.9436 - val_loss: 0.2204 - val_accuracy: 0.9230\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.1227 - accuracy: 0.9606 - val_loss: 0.2648 - val_accuracy: 0.9150\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.1036 - accuracy: 0.9644 - val_loss: 0.3502 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0958 - accuracy: 0.9670 - val_loss: 0.3776 - val_accuracy: 0.9040\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0964 - accuracy: 0.9633 - val_loss: 0.3954 - val_accuracy: 0.9140\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0934 - accuracy: 0.9644 - val_loss: 0.3929 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5481 - accuracy: 0.6852 - val_loss: 0.2307 - val_accuracy: 0.9100\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1931 - accuracy: 0.9274 - val_loss: 0.2039 - val_accuracy: 0.9160\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0780 - accuracy: 0.9694 - val_loss: 0.2828 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0451 - accuracy: 0.9796 - val_loss: 0.3311 - val_accuracy: 0.9100\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0315 - accuracy: 0.9819 - val_loss: 0.4144 - val_accuracy: 0.9120\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0318 - accuracy: 0.9820 - val_loss: 0.4028 - val_accuracy: 0.9170\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0247 - accuracy: 0.9850 - val_loss: 0.5541 - val_accuracy: 0.9030\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0281 - accuracy: 0.9817 - val_loss: 0.5366 - val_accuracy: 0.9200\n",
      "Epoch 9/15\n",
      "180/180 - 19s - loss: 0.0262 - accuracy: 0.9826 - val_loss: 0.5923 - val_accuracy: 0.9090\n",
      "Epoch 10/15\n",
      "180/180 - 19s - loss: 0.0270 - accuracy: 0.9830 - val_loss: 0.6180 - val_accuracy: 0.9060\n",
      "Epoch 11/15\n",
      "180/180 - 19s - loss: 0.0279 - accuracy: 0.9817 - val_loss: 0.6136 - val_accuracy: 0.9130\n",
      "Epoch 12/15\n",
      "180/180 - 19s - loss: 0.0232 - accuracy: 0.9839 - val_loss: 0.6920 - val_accuracy: 0.9040\n",
      "Epoch 13/15\n",
      "180/180 - 19s - loss: 0.0227 - accuracy: 0.9833 - val_loss: 0.7284 - val_accuracy: 0.9060\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 92.00000166893005\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5455 - accuracy: 0.6797 - val_loss: 0.2433 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1972 - accuracy: 0.9312 - val_loss: 0.2216 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0878 - accuracy: 0.9670 - val_loss: 0.2672 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0547 - accuracy: 0.9783 - val_loss: 0.3593 - val_accuracy: 0.9160\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0435 - accuracy: 0.9821 - val_loss: 0.4502 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0391 - accuracy: 0.9823 - val_loss: 0.5092 - val_accuracy: 0.9070\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0305 - accuracy: 0.9829 - val_loss: 0.6627 - val_accuracy: 0.9090\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0288 - accuracy: 0.9811 - val_loss: 0.5974 - val_accuracy: 0.8960\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0238 - accuracy: 0.9852 - val_loss: 0.6121 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5655 - accuracy: 0.6516 - val_loss: 0.2598 - val_accuracy: 0.8950\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.2421 - accuracy: 0.9047 - val_loss: 0.2106 - val_accuracy: 0.9180\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0995 - accuracy: 0.9640 - val_loss: 0.2846 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0549 - accuracy: 0.9774 - val_loss: 0.3595 - val_accuracy: 0.9080\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0500 - accuracy: 0.9793 - val_loss: 0.3418 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0377 - accuracy: 0.9846 - val_loss: 0.4444 - val_accuracy: 0.9110\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0362 - accuracy: 0.9820 - val_loss: 0.4768 - val_accuracy: 0.9210\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0289 - accuracy: 0.9848 - val_loss: 0.5613 - val_accuracy: 0.9100\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0255 - accuracy: 0.9820 - val_loss: 0.6404 - val_accuracy: 0.9020\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0212 - accuracy: 0.9850 - val_loss: 0.7515 - val_accuracy: 0.8920\n",
      "Epoch 11/15\n",
      "180/180 - 20s - loss: 0.0225 - accuracy: 0.9848 - val_loss: 0.7514 - val_accuracy: 0.9010\n",
      "Epoch 12/15\n",
      "180/180 - 21s - loss: 0.0240 - accuracy: 0.9850 - val_loss: 0.7661 - val_accuracy: 0.8960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 92.10000038146973\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.6116 - accuracy: 0.6106 - val_loss: 0.2786 - val_accuracy: 0.8930\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.2225 - accuracy: 0.9138 - val_loss: 0.2218 - val_accuracy: 0.9150\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0886 - accuracy: 0.9668 - val_loss: 0.2707 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0531 - accuracy: 0.9789 - val_loss: 0.3540 - val_accuracy: 0.9050\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0434 - accuracy: 0.9808 - val_loss: 0.4436 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0363 - accuracy: 0.9843 - val_loss: 0.5799 - val_accuracy: 0.8930\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0362 - accuracy: 0.9828 - val_loss: 0.5549 - val_accuracy: 0.9010\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5421 - accuracy: 0.6752 - val_loss: 0.2594 - val_accuracy: 0.8960\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1932 - accuracy: 0.9374 - val_loss: 0.2643 - val_accuracy: 0.8980\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0785 - accuracy: 0.9779 - val_loss: 0.2944 - val_accuracy: 0.9130\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0426 - accuracy: 0.9873 - val_loss: 0.4035 - val_accuracy: 0.9190\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.5792 - val_accuracy: 0.9000\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0284 - accuracy: 0.9914 - val_loss: 0.5841 - val_accuracy: 0.9070\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0265 - accuracy: 0.9919 - val_loss: 0.6712 - val_accuracy: 0.9050\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0272 - accuracy: 0.9919 - val_loss: 0.6863 - val_accuracy: 0.9080\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0247 - accuracy: 0.9903 - val_loss: 0.7146 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.5594 - accuracy: 0.6597 - val_loss: 0.2897 - val_accuracy: 0.8810\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.2176 - accuracy: 0.8901 - val_loss: 0.2637 - val_accuracy: 0.9050\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.1082 - accuracy: 0.9504 - val_loss: 0.3608 - val_accuracy: 0.8880\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0631 - accuracy: 0.9659 - val_loss: 0.4355 - val_accuracy: 0.8950\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0518 - accuracy: 0.9683 - val_loss: 0.4820 - val_accuracy: 0.8880\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0487 - accuracy: 0.9701 - val_loss: 0.5661 - val_accuracy: 0.8890\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0487 - accuracy: 0.9646 - val_loss: 0.5815 - val_accuracy: 0.8860\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.49999713897705\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4905 - accuracy: 0.7340 - val_loss: 0.2208 - val_accuracy: 0.9070\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1748 - accuracy: 0.9356 - val_loss: 0.2060 - val_accuracy: 0.9260\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0687 - accuracy: 0.9737 - val_loss: 0.2979 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0409 - accuracy: 0.9791 - val_loss: 0.3701 - val_accuracy: 0.9060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0334 - accuracy: 0.9816 - val_loss: 0.4313 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0295 - accuracy: 0.9832 - val_loss: 0.4829 - val_accuracy: 0.9130\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0285 - accuracy: 0.9812 - val_loss: 0.5717 - val_accuracy: 0.9060\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.59999990463257\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5733 - accuracy: 0.6467 - val_loss: 0.2467 - val_accuracy: 0.9000\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.2482 - accuracy: 0.9192 - val_loss: 0.1988 - val_accuracy: 0.9230\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.1184 - accuracy: 0.9672 - val_loss: 0.2618 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0715 - accuracy: 0.9804 - val_loss: 0.3669 - val_accuracy: 0.9120\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0603 - accuracy: 0.9827 - val_loss: 0.4044 - val_accuracy: 0.9090\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0529 - accuracy: 0.9842 - val_loss: 0.4491 - val_accuracy: 0.9100\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0504 - accuracy: 0.9821 - val_loss: 0.5093 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5393 - accuracy: 0.6734 - val_loss: 0.2551 - val_accuracy: 0.8920\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.2488 - accuracy: 0.9058 - val_loss: 0.2226 - val_accuracy: 0.9110\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.1434 - accuracy: 0.9656 - val_loss: 0.2534 - val_accuracy: 0.9240\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0957 - accuracy: 0.9849 - val_loss: 0.3859 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0816 - accuracy: 0.9878 - val_loss: 0.4230 - val_accuracy: 0.9110\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0698 - accuracy: 0.9898 - val_loss: 0.4568 - val_accuracy: 0.9140\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0592 - accuracy: 0.9913 - val_loss: 0.5596 - val_accuracy: 0.9150\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0577 - accuracy: 0.9916 - val_loss: 0.5531 - val_accuracy: 0.9120\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5844 - accuracy: 0.6272 - val_loss: 0.2567 - val_accuracy: 0.8950\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.2156 - accuracy: 0.9244 - val_loss: 0.2083 - val_accuracy: 0.9250\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0802 - accuracy: 0.9753 - val_loss: 0.2892 - val_accuracy: 0.9150\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0496 - accuracy: 0.9862 - val_loss: 0.3531 - val_accuracy: 0.9140\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0374 - accuracy: 0.9887 - val_loss: 0.4221 - val_accuracy: 0.9090\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0326 - accuracy: 0.9888 - val_loss: 0.4751 - val_accuracy: 0.9050\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.5383 - val_accuracy: 0.9030\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5363 - accuracy: 0.6866 - val_loss: 0.2278 - val_accuracy: 0.9110\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1990 - accuracy: 0.9210 - val_loss: 0.1975 - val_accuracy: 0.9310\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0852 - accuracy: 0.9698 - val_loss: 0.2615 - val_accuracy: 0.9270\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0533 - accuracy: 0.9787 - val_loss: 0.4013 - val_accuracy: 0.9200\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0434 - accuracy: 0.9812 - val_loss: 0.4569 - val_accuracy: 0.9180\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0370 - accuracy: 0.9838 - val_loss: 0.5021 - val_accuracy: 0.9240\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0352 - accuracy: 0.9836 - val_loss: 0.5646 - val_accuracy: 0.9120\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 93.09999942779541\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.05  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.6086 - accuracy: 0.5973 - val_loss: 0.2808 - val_accuracy: 0.9020\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.3340 - accuracy: 0.9063 - val_loss: 0.2244 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.2019 - accuracy: 0.9699 - val_loss: 0.2257 - val_accuracy: 0.9130\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.1492 - accuracy: 0.9877 - val_loss: 0.3433 - val_accuracy: 0.9040\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.1174 - accuracy: 0.9940 - val_loss: 0.3194 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.1011 - accuracy: 0.9964 - val_loss: 0.4136 - val_accuracy: 0.9040\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0861 - accuracy: 0.9976 - val_loss: 0.5344 - val_accuracy: 0.9010\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0766 - accuracy: 0.9973 - val_loss: 0.4193 - val_accuracy: 0.9000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.6933 - accuracy: 0.4938 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.6932 - accuracy: 0.4868 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.6932 - accuracy: 0.4914 - val_loss: 0.6931 - val_accuracy: 0.4990\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.6932 - accuracy: 0.4972 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.6932 - accuracy: 0.4986 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.6932 - accuracy: 0.4999 - val_loss: 0.6931 - val_accuracy: 0.5010\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.6932 - accuracy: 0.4974 - val_loss: 0.6932 - val_accuracy: 0.4990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 50.09999871253967\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5203 - accuracy: 0.7142 - val_loss: 0.2452 - val_accuracy: 0.8880\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1964 - accuracy: 0.9198 - val_loss: 0.2214 - val_accuracy: 0.9090\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0786 - accuracy: 0.9608 - val_loss: 0.2785 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0534 - accuracy: 0.9737 - val_loss: 0.3435 - val_accuracy: 0.9190\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0404 - accuracy: 0.9831 - val_loss: 0.3975 - val_accuracy: 0.9220\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0400 - accuracy: 0.9814 - val_loss: 0.4206 - val_accuracy: 0.9200\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0333 - accuracy: 0.9830 - val_loss: 0.4910 - val_accuracy: 0.9220\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0356 - accuracy: 0.9817 - val_loss: 0.4928 - val_accuracy: 0.9150\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0363 - accuracy: 0.9831 - val_loss: 0.4723 - val_accuracy: 0.9060\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0371 - accuracy: 0.9809 - val_loss: 0.5126 - val_accuracy: 0.9140\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 92.1999990940094\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5384 - accuracy: 0.6804 - val_loss: 0.2368 - val_accuracy: 0.9120\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1982 - accuracy: 0.9304 - val_loss: 0.2105 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0841 - accuracy: 0.9720 - val_loss: 0.3141 - val_accuracy: 0.9110\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0552 - accuracy: 0.9760 - val_loss: 0.3883 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0426 - accuracy: 0.9816 - val_loss: 0.4433 - val_accuracy: 0.9040\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0376 - accuracy: 0.9816 - val_loss: 0.5700 - val_accuracy: 0.9070\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0334 - accuracy: 0.9821 - val_loss: 0.6306 - val_accuracy: 0.9040\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5129 - accuracy: 0.7301 - val_loss: 0.2495 - val_accuracy: 0.8970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.2021 - accuracy: 0.9343 - val_loss: 0.2348 - val_accuracy: 0.9040\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0988 - accuracy: 0.9680 - val_loss: 0.3252 - val_accuracy: 0.9030\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0709 - accuracy: 0.9799 - val_loss: 0.4325 - val_accuracy: 0.9020\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0584 - accuracy: 0.9822 - val_loss: 0.5256 - val_accuracy: 0.8930\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0511 - accuracy: 0.9820 - val_loss: 0.5402 - val_accuracy: 0.8960\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0502 - accuracy: 0.9842 - val_loss: 0.4944 - val_accuracy: 0.9050\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0522 - accuracy: 0.9827 - val_loss: 0.6147 - val_accuracy: 0.8920\n",
      "Epoch 9/15\n",
      "180/180 - 19s - loss: 0.0471 - accuracy: 0.9842 - val_loss: 0.7574 - val_accuracy: 0.8840\n",
      "Epoch 10/15\n",
      "180/180 - 19s - loss: 0.0503 - accuracy: 0.9818 - val_loss: 0.6477 - val_accuracy: 0.8990\n",
      "Epoch 11/15\n",
      "180/180 - 19s - loss: 0.0472 - accuracy: 0.9828 - val_loss: 0.6203 - val_accuracy: 0.9020\n",
      "Epoch 12/15\n",
      "180/180 - 19s - loss: 0.0436 - accuracy: 0.9836 - val_loss: 0.8965 - val_accuracy: 0.8770\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 90.49999713897705\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5635 - accuracy: 0.6573 - val_loss: 0.2712 - val_accuracy: 0.8880\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.2152 - accuracy: 0.9226 - val_loss: 0.2582 - val_accuracy: 0.9040\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0979 - accuracy: 0.9779 - val_loss: 0.3130 - val_accuracy: 0.9030\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0535 - accuracy: 0.9918 - val_loss: 0.4223 - val_accuracy: 0.9060\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0509 - accuracy: 0.9933 - val_loss: 0.5183 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0390 - accuracy: 0.9947 - val_loss: 0.5657 - val_accuracy: 0.8980\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0394 - accuracy: 0.9956 - val_loss: 0.6690 - val_accuracy: 0.8990\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0324 - accuracy: 0.9958 - val_loss: 0.7345 - val_accuracy: 0.9050\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0357 - accuracy: 0.9946 - val_loss: 0.7322 - val_accuracy: 0.9010\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0277 - accuracy: 0.9963 - val_loss: 0.9319 - val_accuracy: 0.9010\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.6145 - accuracy: 0.6286 - val_loss: 0.3116 - val_accuracy: 0.8950\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.3253 - accuracy: 0.9084 - val_loss: 0.2199 - val_accuracy: 0.9210\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.2119 - accuracy: 0.9613 - val_loss: 0.2337 - val_accuracy: 0.9190\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.1516 - accuracy: 0.9830 - val_loss: 0.2583 - val_accuracy: 0.9290\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.1246 - accuracy: 0.9861 - val_loss: 0.2806 - val_accuracy: 0.9290\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.1091 - accuracy: 0.9891 - val_loss: 0.2778 - val_accuracy: 0.9180\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0967 - accuracy: 0.9907 - val_loss: 0.3998 - val_accuracy: 0.9130\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0867 - accuracy: 0.9914 - val_loss: 0.4076 - val_accuracy: 0.9220\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0792 - accuracy: 0.9918 - val_loss: 0.4698 - val_accuracy: 0.9150\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.90000200271606\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5263 - accuracy: 0.7060 - val_loss: 0.2423 - val_accuracy: 0.9030\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.2073 - accuracy: 0.9337 - val_loss: 0.2030 - val_accuracy: 0.9250\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.1054 - accuracy: 0.9684 - val_loss: 0.2288 - val_accuracy: 0.9200\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0710 - accuracy: 0.9803 - val_loss: 0.3212 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0521 - accuracy: 0.9824 - val_loss: 0.3671 - val_accuracy: 0.9150\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0511 - accuracy: 0.9834 - val_loss: 0.4394 - val_accuracy: 0.9100\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0488 - accuracy: 0.9849 - val_loss: 0.4857 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.6342 - accuracy: 0.5913 - val_loss: 0.3163 - val_accuracy: 0.8730\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.2546 - accuracy: 0.8948 - val_loss: 0.2316 - val_accuracy: 0.9030\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.1129 - accuracy: 0.9518 - val_loss: 0.2646 - val_accuracy: 0.9110\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0566 - accuracy: 0.9773 - val_loss: 0.4105 - val_accuracy: 0.9000\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0382 - accuracy: 0.9832 - val_loss: 0.5123 - val_accuracy: 0.8970\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0373 - accuracy: 0.9819 - val_loss: 0.5702 - val_accuracy: 0.8990\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0373 - accuracy: 0.9828 - val_loss: 0.6266 - val_accuracy: 0.8970\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0310 - accuracy: 0.9849 - val_loss: 0.6686 - val_accuracy: 0.9010\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4965 - accuracy: 0.7316 - val_loss: 0.2878 - val_accuracy: 0.8910\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1776 - accuracy: 0.9368 - val_loss: 0.2667 - val_accuracy: 0.8970\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0799 - accuracy: 0.9712 - val_loss: 0.3738 - val_accuracy: 0.8880\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0421 - accuracy: 0.9792 - val_loss: 0.4902 - val_accuracy: 0.8910\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0300 - accuracy: 0.9829 - val_loss: 0.6690 - val_accuracy: 0.8940\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0272 - accuracy: 0.9826 - val_loss: 0.6878 - val_accuracy: 0.8960\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0253 - accuracy: 0.9833 - val_loss: 0.7556 - val_accuracy: 0.8830\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 89.70000147819519\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.05  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.30  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5532 - accuracy: 0.6686 - val_loss: 0.2541 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1951 - accuracy: 0.9249 - val_loss: 0.2264 - val_accuracy: 0.9090\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0733 - accuracy: 0.9669 - val_loss: 0.3092 - val_accuracy: 0.9050\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0406 - accuracy: 0.9782 - val_loss: 0.3788 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0309 - accuracy: 0.9817 - val_loss: 0.4814 - val_accuracy: 0.9030\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0269 - accuracy: 0.9828 - val_loss: 0.6016 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0255 - accuracy: 0.9830 - val_loss: 0.6450 - val_accuracy: 0.8960\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0248 - accuracy: 0.9820 - val_loss: 0.6435 - val_accuracy: 0.9040\n",
      "Epoch 9/15\n",
      "180/180 - 22s - loss: 0.0216 - accuracy: 0.9856 - val_loss: 0.7453 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4924 - accuracy: 0.7319 - val_loss: 0.2323 - val_accuracy: 0.8970\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1930 - accuracy: 0.9270 - val_loss: 0.2066 - val_accuracy: 0.9170\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0815 - accuracy: 0.9703 - val_loss: 0.2689 - val_accuracy: 0.9190\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0471 - accuracy: 0.9818 - val_loss: 0.3910 - val_accuracy: 0.9170\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0437 - accuracy: 0.9801 - val_loss: 0.4148 - val_accuracy: 0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0370 - accuracy: 0.9823 - val_loss: 0.4644 - val_accuracy: 0.9190\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0340 - accuracy: 0.9820 - val_loss: 0.4882 - val_accuracy: 0.9140\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0348 - accuracy: 0.9837 - val_loss: 0.5206 - val_accuracy: 0.9180\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.5649 - accuracy: 0.6627 - val_loss: 0.2548 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.2030 - accuracy: 0.9241 - val_loss: 0.2402 - val_accuracy: 0.9030\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0740 - accuracy: 0.9693 - val_loss: 0.3439 - val_accuracy: 0.8990\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0404 - accuracy: 0.9803 - val_loss: 0.4170 - val_accuracy: 0.9080\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0292 - accuracy: 0.9822 - val_loss: 0.4997 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0269 - accuracy: 0.9819 - val_loss: 0.5569 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0253 - accuracy: 0.9850 - val_loss: 0.6682 - val_accuracy: 0.9040\n",
      "Epoch 8/15\n",
      "180/180 - 22s - loss: 0.0227 - accuracy: 0.9834 - val_loss: 0.6965 - val_accuracy: 0.9060\n",
      "Epoch 9/15\n",
      "180/180 - 22s - loss: 0.0252 - accuracy: 0.9829 - val_loss: 0.8073 - val_accuracy: 0.8970\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.5692 - accuracy: 0.6766 - val_loss: 0.3029 - val_accuracy: 0.8760\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.2479 - accuracy: 0.9257 - val_loss: 0.2280 - val_accuracy: 0.9030\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.1316 - accuracy: 0.9781 - val_loss: 0.2490 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0897 - accuracy: 0.9904 - val_loss: 0.3206 - val_accuracy: 0.9150\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0710 - accuracy: 0.9941 - val_loss: 0.4353 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0626 - accuracy: 0.9963 - val_loss: 0.5326 - val_accuracy: 0.9080\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0564 - accuracy: 0.9949 - val_loss: 0.5614 - val_accuracy: 0.9100\n",
      "Epoch 8/15\n",
      "180/180 - 22s - loss: 0.0559 - accuracy: 0.9940 - val_loss: 0.4832 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5167 - accuracy: 0.7178 - val_loss: 0.2414 - val_accuracy: 0.9010\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1945 - accuracy: 0.9271 - val_loss: 0.1994 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0793 - accuracy: 0.9676 - val_loss: 0.2433 - val_accuracy: 0.9270\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0409 - accuracy: 0.9787 - val_loss: 0.3646 - val_accuracy: 0.9160\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0296 - accuracy: 0.9824 - val_loss: 0.4656 - val_accuracy: 0.9180\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0308 - accuracy: 0.9807 - val_loss: 0.5462 - val_accuracy: 0.9220\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0279 - accuracy: 0.9827 - val_loss: 0.5315 - val_accuracy: 0.9190\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0272 - accuracy: 0.9831 - val_loss: 0.5449 - val_accuracy: 0.9240\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.69999861717224\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5365 - accuracy: 0.6843 - val_loss: 0.2472 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1982 - accuracy: 0.9283 - val_loss: 0.1979 - val_accuracy: 0.9250\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0869 - accuracy: 0.9690 - val_loss: 0.2457 - val_accuracy: 0.9200\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.3263 - val_accuracy: 0.9210\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0348 - accuracy: 0.9904 - val_loss: 0.4020 - val_accuracy: 0.9240\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0279 - accuracy: 0.9924 - val_loss: 0.4815 - val_accuracy: 0.9170\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0306 - accuracy: 0.9893 - val_loss: 0.5106 - val_accuracy: 0.9170\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.5486 - accuracy: 0.6663 - val_loss: 0.2356 - val_accuracy: 0.9020\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1993 - accuracy: 0.9282 - val_loss: 0.2204 - val_accuracy: 0.9090\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0767 - accuracy: 0.9808 - val_loss: 0.2914 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0447 - accuracy: 0.9853 - val_loss: 0.4106 - val_accuracy: 0.9120\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0294 - accuracy: 0.9922 - val_loss: 0.4833 - val_accuracy: 0.9150\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0306 - accuracy: 0.9923 - val_loss: 0.5662 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0312 - accuracy: 0.9896 - val_loss: 0.5669 - val_accuracy: 0.9130\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0311 - accuracy: 0.9910 - val_loss: 0.6675 - val_accuracy: 0.8990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.5017 - accuracy: 0.7158 - val_loss: 0.2569 - val_accuracy: 0.8980\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.1917 - accuracy: 0.9401 - val_loss: 0.2650 - val_accuracy: 0.8960\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0898 - accuracy: 0.9809 - val_loss: 0.3473 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0562 - accuracy: 0.9919 - val_loss: 0.4932 - val_accuracy: 0.9020\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0478 - accuracy: 0.9947 - val_loss: 0.5934 - val_accuracy: 0.8920\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0378 - accuracy: 0.9958 - val_loss: 0.6933 - val_accuracy: 0.8920\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0328 - accuracy: 0.9963 - val_loss: 0.7115 - val_accuracy: 0.9050\n",
      "Epoch 8/15\n",
      "180/180 - 22s - loss: 0.0313 - accuracy: 0.9966 - val_loss: 0.7753 - val_accuracy: 0.8960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 90.89999794960022\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.6540 - accuracy: 0.5502 - val_loss: 0.3285 - val_accuracy: 0.8650\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.2961 - accuracy: 0.8480 - val_loss: 0.2156 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.1414 - accuracy: 0.9357 - val_loss: 0.2275 - val_accuracy: 0.9110\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0932 - accuracy: 0.9620 - val_loss: 0.3050 - val_accuracy: 0.9040\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0822 - accuracy: 0.9634 - val_loss: 0.3630 - val_accuracy: 0.8960\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0646 - accuracy: 0.9708 - val_loss: 0.4556 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0661 - accuracy: 0.9687 - val_loss: 0.4729 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.20000004768372\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.5988 - accuracy: 0.6504 - val_loss: 0.2719 - val_accuracy: 0.8800\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.2337 - accuracy: 0.9163 - val_loss: 0.2038 - val_accuracy: 0.9180\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0933 - accuracy: 0.9684 - val_loss: 0.2471 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0565 - accuracy: 0.9776 - val_loss: 0.3292 - val_accuracy: 0.9080\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0396 - accuracy: 0.9837 - val_loss: 0.4421 - val_accuracy: 0.9020\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0390 - accuracy: 0.9804 - val_loss: 0.4751 - val_accuracy: 0.9050\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0336 - accuracy: 0.9843 - val_loss: 0.5330 - val_accuracy: 0.8970\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4       relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.05  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.30  \n",
      "4  92.500001  91.700000  90.899998  91.200000  91.799998  91.63  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.6937 - accuracy: 0.4878 - val_loss: 0.6931 - val_accuracy: 0.4950\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.5847 - accuracy: 0.6250 - val_loss: 0.2772 - val_accuracy: 0.8890\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.2366 - accuracy: 0.9028 - val_loss: 0.2009 - val_accuracy: 0.9280\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.1028 - accuracy: 0.9514 - val_loss: 0.2505 - val_accuracy: 0.9240\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0615 - accuracy: 0.9673 - val_loss: 0.3287 - val_accuracy: 0.9260\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0545 - accuracy: 0.9640 - val_loss: 0.4179 - val_accuracy: 0.9220\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0473 - accuracy: 0.9690 - val_loss: 0.4360 - val_accuracy: 0.9190\n",
      "Epoch 8/15\n",
      "180/180 - 23s - loss: 0.0457 - accuracy: 0.9681 - val_loss: 0.4998 - val_accuracy: 0.9150\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.79999732971191\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.6845 - accuracy: 0.5297 - val_loss: 0.4950 - val_accuracy: 0.8370\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.3297 - accuracy: 0.8410 - val_loss: 0.2079 - val_accuracy: 0.9160\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.1185 - accuracy: 0.9528 - val_loss: 0.2327 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0595 - accuracy: 0.9781 - val_loss: 0.3007 - val_accuracy: 0.9050\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0417 - accuracy: 0.9821 - val_loss: 0.4472 - val_accuracy: 0.9070\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0372 - accuracy: 0.9831 - val_loss: 0.5235 - val_accuracy: 0.9110\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0341 - accuracy: 0.9839 - val_loss: 0.6213 - val_accuracy: 0.8970\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.5703 - accuracy: 0.6736 - val_loss: 0.2809 - val_accuracy: 0.8910\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.2183 - accuracy: 0.9204 - val_loss: 0.2336 - val_accuracy: 0.9090\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.1021 - accuracy: 0.9708 - val_loss: 0.2968 - val_accuracy: 0.9050\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0677 - accuracy: 0.9781 - val_loss: 0.3851 - val_accuracy: 0.8970\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0544 - accuracy: 0.9837 - val_loss: 0.4742 - val_accuracy: 0.8880\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0431 - accuracy: 0.9898 - val_loss: 0.6694 - val_accuracy: 0.8920\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0427 - accuracy: 0.9914 - val_loss: 0.5586 - val_accuracy: 0.8910\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.89999794960022\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.5661 - accuracy: 0.6441 - val_loss: 0.2584 - val_accuracy: 0.8850\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.2277 - accuracy: 0.9074 - val_loss: 0.2012 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.1004 - accuracy: 0.9514 - val_loss: 0.3856 - val_accuracy: 0.8820\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0629 - accuracy: 0.9653 - val_loss: 0.3608 - val_accuracy: 0.9080\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0502 - accuracy: 0.9669 - val_loss: 0.4378 - val_accuracy: 0.9160\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0417 - accuracy: 0.9702 - val_loss: 0.5148 - val_accuracy: 0.9180\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0451 - accuracy: 0.9711 - val_loss: 0.5654 - val_accuracy: 0.9090\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.6120 - accuracy: 0.5986 - val_loss: 0.3011 - val_accuracy: 0.8860\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.2512 - accuracy: 0.8893 - val_loss: 0.2252 - val_accuracy: 0.9170\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.1062 - accuracy: 0.9758 - val_loss: 0.2862 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0647 - accuracy: 0.9899 - val_loss: 0.3986 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0467 - accuracy: 0.9941 - val_loss: 0.5897 - val_accuracy: 0.9070\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0404 - accuracy: 0.9951 - val_loss: 0.5318 - val_accuracy: 0.9090\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0364 - accuracy: 0.9964 - val_loss: 0.5935 - val_accuracy: 0.9130\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.5211 - accuracy: 0.6893 - val_loss: 0.2230 - val_accuracy: 0.9180\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1881 - accuracy: 0.9297 - val_loss: 0.1848 - val_accuracy: 0.9310\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0710 - accuracy: 0.9727 - val_loss: 0.2801 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0397 - accuracy: 0.9822 - val_loss: 0.4018 - val_accuracy: 0.9070\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0303 - accuracy: 0.9824 - val_loss: 0.4685 - val_accuracy: 0.9200\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0248 - accuracy: 0.9836 - val_loss: 0.5570 - val_accuracy: 0.9170\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0233 - accuracy: 0.9856 - val_loss: 0.5854 - val_accuracy: 0.9190\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 93.09999942779541\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.5409 - accuracy: 0.6712 - val_loss: 0.2598 - val_accuracy: 0.8890\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.2053 - accuracy: 0.9279 - val_loss: 0.2167 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0825 - accuracy: 0.9714 - val_loss: 0.2876 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0491 - accuracy: 0.9823 - val_loss: 0.3667 - val_accuracy: 0.9070\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0408 - accuracy: 0.9807 - val_loss: 0.4595 - val_accuracy: 0.8980\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0382 - accuracy: 0.9820 - val_loss: 0.4421 - val_accuracy: 0.9130\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0385 - accuracy: 0.9802 - val_loss: 0.5162 - val_accuracy: 0.9100\n",
      "Epoch 8/15\n",
      "180/180 - 23s - loss: 0.0320 - accuracy: 0.9830 - val_loss: 0.5632 - val_accuracy: 0.9150\n",
      "Epoch 9/15\n",
      "180/180 - 23s - loss: 0.0354 - accuracy: 0.9848 - val_loss: 0.5567 - val_accuracy: 0.9050\n",
      "Epoch 10/15\n",
      "180/180 - 23s - loss: 0.0375 - accuracy: 0.9826 - val_loss: 0.5151 - val_accuracy: 0.9190\n",
      "Epoch 11/15\n",
      "180/180 - 23s - loss: 0.0353 - accuracy: 0.9839 - val_loss: 0.5907 - val_accuracy: 0.9110\n",
      "Epoch 12/15\n",
      "180/180 - 23s - loss: 0.0304 - accuracy: 0.9850 - val_loss: 0.7063 - val_accuracy: 0.9090\n",
      "Epoch 13/15\n",
      "180/180 - 23s - loss: 0.0298 - accuracy: 0.9863 - val_loss: 0.7617 - val_accuracy: 0.9050\n",
      "Epoch 14/15\n",
      "180/180 - 23s - loss: 0.0317 - accuracy: 0.9840 - val_loss: 0.7791 - val_accuracy: 0.9010\n",
      "Epoch 15/15\n",
      "180/180 - 23s - loss: 0.0295 - accuracy: 0.9857 - val_loss: 0.8121 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.5194 - accuracy: 0.6994 - val_loss: 0.2453 - val_accuracy: 0.9030\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1885 - accuracy: 0.9161 - val_loss: 0.2210 - val_accuracy: 0.9110\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0746 - accuracy: 0.9592 - val_loss: 0.2968 - val_accuracy: 0.9070\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0486 - accuracy: 0.9758 - val_loss: 0.4766 - val_accuracy: 0.8990\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0416 - accuracy: 0.9819 - val_loss: 0.4937 - val_accuracy: 0.9000\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0378 - accuracy: 0.9831 - val_loss: 0.5777 - val_accuracy: 0.9050\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0388 - accuracy: 0.9829 - val_loss: 0.7200 - val_accuracy: 0.8860\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.5613 - accuracy: 0.6720 - val_loss: 0.2904 - val_accuracy: 0.8670\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.2131 - accuracy: 0.9321 - val_loss: 0.2379 - val_accuracy: 0.9030\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0958 - accuracy: 0.9784 - val_loss: 0.3114 - val_accuracy: 0.8980\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0576 - accuracy: 0.9902 - val_loss: 0.5108 - val_accuracy: 0.9020\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0434 - accuracy: 0.9934 - val_loss: 0.5159 - val_accuracy: 0.8970\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0390 - accuracy: 0.9947 - val_loss: 0.6119 - val_accuracy: 0.8900\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0324 - accuracy: 0.9968 - val_loss: 0.6831 - val_accuracy: 0.8860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.2999997138977\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.5470 - accuracy: 0.6933 - val_loss: 0.2382 - val_accuracy: 0.9060\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.2033 - accuracy: 0.9369 - val_loss: 0.2041 - val_accuracy: 0.9160\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0893 - accuracy: 0.9803 - val_loss: 0.3330 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0577 - accuracy: 0.9863 - val_loss: 0.3892 - val_accuracy: 0.9080\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0528 - accuracy: 0.9878 - val_loss: 0.4483 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0430 - accuracy: 0.9917 - val_loss: 0.4932 - val_accuracy: 0.9140\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0419 - accuracy: 0.9910 - val_loss: 0.5322 - val_accuracy: 0.9120\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4       relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5       relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.05  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.30  \n",
      "4  92.500001  91.700000  90.899998  91.200000  91.799998  91.63  \n",
      "5  93.099999  91.900003  91.100001  90.300000  91.600001  91.69  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4483 - accuracy: 0.7784 - val_loss: 0.2044 - val_accuracy: 0.9120\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1358 - accuracy: 0.9582 - val_loss: 0.2068 - val_accuracy: 0.9160\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0505 - accuracy: 0.9912 - val_loss: 0.2404 - val_accuracy: 0.9180\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2833 - val_accuracy: 0.9150\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0137 - accuracy: 0.9988 - val_loss: 0.3071 - val_accuracy: 0.9110\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0122 - accuracy: 0.9992 - val_loss: 0.3518 - val_accuracy: 0.9170\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0096 - accuracy: 0.9987 - val_loss: 0.3451 - val_accuracy: 0.9170\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0076 - accuracy: 0.9994 - val_loss: 0.3812 - val_accuracy: 0.9230\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0067 - accuracy: 0.9993 - val_loss: 0.4022 - val_accuracy: 0.9160\n",
      "Epoch 10/15\n",
      "180/180 - 18s - loss: 0.0126 - accuracy: 0.9977 - val_loss: 0.4122 - val_accuracy: 0.9210\n",
      "Epoch 11/15\n",
      "180/180 - 18s - loss: 0.0093 - accuracy: 0.9983 - val_loss: 0.4524 - val_accuracy: 0.9060\n",
      "Epoch 12/15\n",
      "180/180 - 18s - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.4355 - val_accuracy: 0.9100\n",
      "Epoch 13/15\n",
      "180/180 - 18s - loss: 0.0067 - accuracy: 0.9986 - val_loss: 0.4741 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4585 - accuracy: 0.7713 - val_loss: 0.2272 - val_accuracy: 0.9110\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1278 - accuracy: 0.9601 - val_loss: 0.2177 - val_accuracy: 0.9220\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0453 - accuracy: 0.9908 - val_loss: 0.2543 - val_accuracy: 0.9190\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0205 - accuracy: 0.9978 - val_loss: 0.2533 - val_accuracy: 0.9210\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0133 - accuracy: 0.9989 - val_loss: 0.3025 - val_accuracy: 0.9240\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0105 - accuracy: 0.9989 - val_loss: 0.3497 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0093 - accuracy: 0.9987 - val_loss: 0.3315 - val_accuracy: 0.9150\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.3965 - val_accuracy: 0.9090\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0078 - accuracy: 0.9991 - val_loss: 0.4264 - val_accuracy: 0.9130\n",
      "Epoch 10/15\n",
      "180/180 - 18s - loss: 0.0090 - accuracy: 0.9983 - val_loss: 0.4080 - val_accuracy: 0.9120\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4651 - accuracy: 0.7704 - val_loss: 0.2450 - val_accuracy: 0.8870\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1425 - accuracy: 0.9606 - val_loss: 0.2499 - val_accuracy: 0.8970\n",
      "Epoch 3/15\n",
      "180/180 - 17s - loss: 0.0451 - accuracy: 0.9919 - val_loss: 0.3243 - val_accuracy: 0.8960\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0204 - accuracy: 0.9982 - val_loss: 0.3816 - val_accuracy: 0.8960\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.4026 - val_accuracy: 0.8930\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0113 - accuracy: 0.9987 - val_loss: 0.4707 - val_accuracy: 0.8870\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0098 - accuracy: 0.9988 - val_loss: 0.4592 - val_accuracy: 0.8920\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 89.70000147819519\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4587 - accuracy: 0.7654 - val_loss: 0.2380 - val_accuracy: 0.9040\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1387 - accuracy: 0.9589 - val_loss: 0.2420 - val_accuracy: 0.9020\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0459 - accuracy: 0.9919 - val_loss: 0.2878 - val_accuracy: 0.9040\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0232 - accuracy: 0.9967 - val_loss: 0.3288 - val_accuracy: 0.9040\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0134 - accuracy: 0.9987 - val_loss: 0.3677 - val_accuracy: 0.9070\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0120 - accuracy: 0.9989 - val_loss: 0.3857 - val_accuracy: 0.9190\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0092 - accuracy: 0.9990 - val_loss: 0.4314 - val_accuracy: 0.9030\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.4514 - val_accuracy: 0.9080\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.4689 - val_accuracy: 0.9100\n",
      "Epoch 10/15\n",
      "180/180 - 17s - loss: 0.0064 - accuracy: 0.9992 - val_loss: 0.4932 - val_accuracy: 0.9080\n",
      "Epoch 11/15\n",
      "180/180 - 17s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.5186 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4639 - accuracy: 0.7567 - val_loss: 0.2086 - val_accuracy: 0.9260\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1358 - accuracy: 0.9581 - val_loss: 0.2146 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0430 - accuracy: 0.9926 - val_loss: 0.2196 - val_accuracy: 0.9270\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0218 - accuracy: 0.9972 - val_loss: 0.2524 - val_accuracy: 0.9180\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0157 - accuracy: 0.9978 - val_loss: 0.2772 - val_accuracy: 0.9190\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0118 - accuracy: 0.9981 - val_loss: 0.3251 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0087 - accuracy: 0.9990 - val_loss: 0.3421 - val_accuracy: 0.9120\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.3369 - val_accuracy: 0.9180\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.69999861717224\n",
      "Epoch 1/15\n",
      "180/180 - 18s - loss: 0.4601 - accuracy: 0.7651 - val_loss: 0.2394 - val_accuracy: 0.9070\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1348 - accuracy: 0.9578 - val_loss: 0.2510 - val_accuracy: 0.9130\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0416 - accuracy: 0.9920 - val_loss: 0.2977 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0201 - accuracy: 0.9976 - val_loss: 0.3369 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0145 - accuracy: 0.9982 - val_loss: 0.3673 - val_accuracy: 0.9100\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.4252 - val_accuracy: 0.8980\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0090 - accuracy: 0.9991 - val_loss: 0.4183 - val_accuracy: 0.9040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Epoch 1/15\n",
      "180/180 - 18s - loss: 0.4597 - accuracy: 0.7736 - val_loss: 0.2387 - val_accuracy: 0.9040\n",
      "Epoch 2/15\n",
      "180/180 - 17s - loss: 0.1402 - accuracy: 0.9613 - val_loss: 0.2420 - val_accuracy: 0.8990\n",
      "Epoch 3/15\n",
      "180/180 - 17s - loss: 0.0483 - accuracy: 0.9919 - val_loss: 0.2829 - val_accuracy: 0.8950\n",
      "Epoch 4/15\n",
      "180/180 - 17s - loss: 0.0257 - accuracy: 0.9974 - val_loss: 0.3681 - val_accuracy: 0.8890\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0158 - accuracy: 0.9987 - val_loss: 0.3991 - val_accuracy: 0.8920\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0123 - accuracy: 0.9987 - val_loss: 0.4161 - val_accuracy: 0.8960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 90.39999842643738\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4511 - accuracy: 0.7718 - val_loss: 0.2474 - val_accuracy: 0.8980\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1370 - accuracy: 0.9586 - val_loss: 0.2078 - val_accuracy: 0.9260\n",
      "Epoch 3/15\n",
      "180/180 - 17s - loss: 0.0462 - accuracy: 0.9910 - val_loss: 0.2454 - val_accuracy: 0.9180\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0222 - accuracy: 0.9971 - val_loss: 0.2816 - val_accuracy: 0.9200\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0139 - accuracy: 0.9984 - val_loss: 0.3135 - val_accuracy: 0.9200\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0101 - accuracy: 0.9986 - val_loss: 0.3427 - val_accuracy: 0.9220\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.3689 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.59999990463257\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4604 - accuracy: 0.7706 - val_loss: 0.2313 - val_accuracy: 0.9170\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1348 - accuracy: 0.9613 - val_loss: 0.2124 - val_accuracy: 0.9250\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0463 - accuracy: 0.9921 - val_loss: 0.2481 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0250 - accuracy: 0.9962 - val_loss: 0.3026 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 17s - loss: 0.0148 - accuracy: 0.9984 - val_loss: 0.3373 - val_accuracy: 0.9070\n",
      "Epoch 6/15\n",
      "180/180 - 17s - loss: 0.0098 - accuracy: 0.9993 - val_loss: 0.3633 - val_accuracy: 0.9120\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0078 - accuracy: 0.9994 - val_loss: 0.3864 - val_accuracy: 0.9130\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "Epoch 1/15\n",
      "180/180 - 18s - loss: 0.4580 - accuracy: 0.7650 - val_loss: 0.2043 - val_accuracy: 0.9180\n",
      "Epoch 2/15\n",
      "180/180 - 18s - loss: 0.1395 - accuracy: 0.9557 - val_loss: 0.1809 - val_accuracy: 0.9330\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0445 - accuracy: 0.9923 - val_loss: 0.1928 - val_accuracy: 0.9380\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0208 - accuracy: 0.9972 - val_loss: 0.2262 - val_accuracy: 0.9290\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0130 - accuracy: 0.9989 - val_loss: 0.2342 - val_accuracy: 0.9340\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0107 - accuracy: 0.9990 - val_loss: 0.2813 - val_accuracy: 0.9310\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0108 - accuracy: 0.9982 - val_loss: 0.3334 - val_accuracy: 0.9240\n",
      "Epoch 8/15\n",
      "180/180 - 17s - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.3410 - val_accuracy: 0.9170\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 93.80000233650208\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4       relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5       relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "6       tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.05  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.30  \n",
      "4  92.500001  91.700000  90.899998  91.200000  91.799998  91.63  \n",
      "5  93.099999  91.900003  91.100001  90.300000  91.600001  91.69  \n",
      "6  91.299999  90.399998  92.600000  92.500001  93.800002  91.96  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4573 - accuracy: 0.7727 - val_loss: 0.2274 - val_accuracy: 0.9090\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1463 - accuracy: 0.9578 - val_loss: 0.2130 - val_accuracy: 0.9100\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0537 - accuracy: 0.9897 - val_loss: 0.2503 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0264 - accuracy: 0.9973 - val_loss: 0.2923 - val_accuracy: 0.9170\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0168 - accuracy: 0.9986 - val_loss: 0.3310 - val_accuracy: 0.9130\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0143 - accuracy: 0.9988 - val_loss: 0.3693 - val_accuracy: 0.9100\n",
      "Epoch 7/15\n",
      "180/180 - 17s - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.3999 - val_accuracy: 0.9070\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0097 - accuracy: 0.9993 - val_loss: 0.4134 - val_accuracy: 0.9070\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0093 - accuracy: 0.9982 - val_loss: 0.4877 - val_accuracy: 0.8960\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4611 - accuracy: 0.7651 - val_loss: 0.2674 - val_accuracy: 0.8910\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1543 - accuracy: 0.9550 - val_loss: 0.2333 - val_accuracy: 0.9110\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0610 - accuracy: 0.9902 - val_loss: 0.2666 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0313 - accuracy: 0.9963 - val_loss: 0.3082 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0184 - accuracy: 0.9988 - val_loss: 0.3402 - val_accuracy: 0.9060\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0127 - accuracy: 0.9991 - val_loss: 0.3735 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0105 - accuracy: 0.9992 - val_loss: 0.3963 - val_accuracy: 0.9060\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4518 - accuracy: 0.7740 - val_loss: 0.2307 - val_accuracy: 0.9050\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1393 - accuracy: 0.9570 - val_loss: 0.2274 - val_accuracy: 0.9090\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0459 - accuracy: 0.9932 - val_loss: 0.2752 - val_accuracy: 0.9030\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0213 - accuracy: 0.9982 - val_loss: 0.3088 - val_accuracy: 0.9060\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0123 - accuracy: 0.9989 - val_loss: 0.3365 - val_accuracy: 0.9090\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0099 - accuracy: 0.9989 - val_loss: 0.3856 - val_accuracy: 0.9030\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0083 - accuracy: 0.9997 - val_loss: 0.4054 - val_accuracy: 0.9040\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.89999794960022\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4437 - accuracy: 0.7757 - val_loss: 0.2221 - val_accuracy: 0.9190\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1383 - accuracy: 0.9572 - val_loss: 0.2188 - val_accuracy: 0.9150\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0448 - accuracy: 0.9916 - val_loss: 0.2634 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0203 - accuracy: 0.9982 - val_loss: 0.3264 - val_accuracy: 0.9020\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0130 - accuracy: 0.9989 - val_loss: 0.3451 - val_accuracy: 0.9100\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.3847 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4531 - accuracy: 0.7734 - val_loss: 0.2265 - val_accuracy: 0.9100\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1400 - accuracy: 0.9556 - val_loss: 0.2268 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0442 - accuracy: 0.9918 - val_loss: 0.2797 - val_accuracy: 0.9130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0196 - accuracy: 0.9979 - val_loss: 0.3267 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0141 - accuracy: 0.9984 - val_loss: 0.3442 - val_accuracy: 0.9100\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0126 - accuracy: 0.9981 - val_loss: 0.3841 - val_accuracy: 0.9090\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0086 - accuracy: 0.9988 - val_loss: 0.3949 - val_accuracy: 0.9110\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0068 - accuracy: 0.9992 - val_loss: 0.4282 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4551 - accuracy: 0.7651 - val_loss: 0.2094 - val_accuracy: 0.9130\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1343 - accuracy: 0.9569 - val_loss: 0.1855 - val_accuracy: 0.9310\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0433 - accuracy: 0.9928 - val_loss: 0.2203 - val_accuracy: 0.9250\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0207 - accuracy: 0.9973 - val_loss: 0.2528 - val_accuracy: 0.9180\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0139 - accuracy: 0.9987 - val_loss: 0.2744 - val_accuracy: 0.9230\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0100 - accuracy: 0.9984 - val_loss: 0.3063 - val_accuracy: 0.9250\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0106 - accuracy: 0.9986 - val_loss: 0.3234 - val_accuracy: 0.9230\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 93.09999942779541\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4560 - accuracy: 0.7641 - val_loss: 0.2694 - val_accuracy: 0.9010\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1415 - accuracy: 0.9583 - val_loss: 0.2455 - val_accuracy: 0.9170\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0520 - accuracy: 0.9912 - val_loss: 0.2759 - val_accuracy: 0.9190\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0224 - accuracy: 0.9983 - val_loss: 0.3088 - val_accuracy: 0.9230\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0143 - accuracy: 0.9990 - val_loss: 0.3402 - val_accuracy: 0.9220\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.3654 - val_accuracy: 0.9220\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0091 - accuracy: 0.9988 - val_loss: 0.3917 - val_accuracy: 0.9200\n",
      "Epoch 8/15\n",
      "180/180 - 18s - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.4151 - val_accuracy: 0.9230\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.4396 - val_accuracy: 0.9190\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4411 - accuracy: 0.7734 - val_loss: 0.2224 - val_accuracy: 0.9040\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1348 - accuracy: 0.9577 - val_loss: 0.2211 - val_accuracy: 0.9130\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0420 - accuracy: 0.9918 - val_loss: 0.2707 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0196 - accuracy: 0.9978 - val_loss: 0.3111 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0118 - accuracy: 0.9988 - val_loss: 0.3602 - val_accuracy: 0.9030\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.4011 - val_accuracy: 0.8980\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0071 - accuracy: 0.9994 - val_loss: 0.4111 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Epoch 1/15\n",
      "180/180 - 19s - loss: 0.4436 - accuracy: 0.7711 - val_loss: 0.2366 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1336 - accuracy: 0.9584 - val_loss: 0.2425 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0429 - accuracy: 0.9923 - val_loss: 0.2778 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0191 - accuracy: 0.9974 - val_loss: 0.3249 - val_accuracy: 0.9070\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0118 - accuracy: 0.9992 - val_loss: 0.3599 - val_accuracy: 0.9100\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0092 - accuracy: 0.9996 - val_loss: 0.3949 - val_accuracy: 0.9120\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.4236 - val_accuracy: 0.9110\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.4488 - val_accuracy: 0.9080\n",
      "Epoch 9/15\n",
      "180/180 - 18s - loss: 0.0059 - accuracy: 0.9996 - val_loss: 0.4763 - val_accuracy: 0.9090\n",
      "Epoch 10/15\n",
      "180/180 - 18s - loss: 0.0062 - accuracy: 0.9989 - val_loss: 0.4928 - val_accuracy: 0.9080\n",
      "Epoch 11/15\n",
      "180/180 - 18s - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.5148 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.20000004768372\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4538 - accuracy: 0.7696 - val_loss: 0.2321 - val_accuracy: 0.9060\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1367 - accuracy: 0.9588 - val_loss: 0.2063 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0471 - accuracy: 0.9924 - val_loss: 0.2518 - val_accuracy: 0.9140\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0228 - accuracy: 0.9977 - val_loss: 0.2807 - val_accuracy: 0.9160\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0141 - accuracy: 0.9987 - val_loss: 0.3148 - val_accuracy: 0.9180\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0101 - accuracy: 0.9993 - val_loss: 0.3610 - val_accuracy: 0.9140\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0078 - accuracy: 0.9997 - val_loss: 0.3859 - val_accuracy: 0.9140\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4       relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5       relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "6       tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
      "7       tanh       2  91.700000  91.100001  90.899998  91.900003  91.299999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10    AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.88  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.83  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.05  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.30  \n",
      "4  92.500001  91.700000  90.899998  91.200000  91.799998  91.63  \n",
      "5  93.099999  91.900003  91.100001  90.300000  91.600001  91.69  \n",
      "6  91.299999  90.399998  92.600000  92.500001  93.800002  91.96  \n",
      "7  93.099999  92.299998  91.299999  91.200000  91.900003  91.67  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4498 - accuracy: 0.7707 - val_loss: 0.2326 - val_accuracy: 0.9100\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1493 - accuracy: 0.9567 - val_loss: 0.2517 - val_accuracy: 0.9030\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0578 - accuracy: 0.9891 - val_loss: 0.2786 - val_accuracy: 0.9150\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0352 - accuracy: 0.9946 - val_loss: 0.3188 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0216 - accuracy: 0.9974 - val_loss: 0.4317 - val_accuracy: 0.8920\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0166 - accuracy: 0.9978 - val_loss: 0.4187 - val_accuracy: 0.9010\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0131 - accuracy: 0.9986 - val_loss: 0.4401 - val_accuracy: 0.9000\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0093 - accuracy: 0.9991 - val_loss: 0.4980 - val_accuracy: 0.8980\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4280 - accuracy: 0.7830 - val_loss: 0.2203 - val_accuracy: 0.9140\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1185 - accuracy: 0.9636 - val_loss: 0.2211 - val_accuracy: 0.9160\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0352 - accuracy: 0.9951 - val_loss: 0.2685 - val_accuracy: 0.9200\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0153 - accuracy: 0.9990 - val_loss: 0.3155 - val_accuracy: 0.9160\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0096 - accuracy: 0.9997 - val_loss: 0.3447 - val_accuracy: 0.9140\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0071 - accuracy: 0.9996 - val_loss: 0.3814 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 19s - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.4085 - val_accuracy: 0.9170\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0053 - accuracy: 0.9996 - val_loss: 0.4302 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.00000166893005\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4504 - accuracy: 0.7726 - val_loss: 0.2239 - val_accuracy: 0.9060\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1355 - accuracy: 0.9581 - val_loss: 0.2339 - val_accuracy: 0.9130\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0456 - accuracy: 0.9920 - val_loss: 0.3012 - val_accuracy: 0.8990\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0206 - accuracy: 0.9981 - val_loss: 0.3508 - val_accuracy: 0.8980\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0127 - accuracy: 0.9993 - val_loss: 0.3480 - val_accuracy: 0.9090\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0102 - accuracy: 0.9989 - val_loss: 0.3945 - val_accuracy: 0.9040\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0087 - accuracy: 0.9996 - val_loss: 0.4249 - val_accuracy: 0.9010\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4367 - accuracy: 0.7763 - val_loss: 0.2180 - val_accuracy: 0.9050\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1385 - accuracy: 0.9566 - val_loss: 0.2031 - val_accuracy: 0.9170\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0458 - accuracy: 0.9917 - val_loss: 0.2219 - val_accuracy: 0.9240\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0197 - accuracy: 0.9981 - val_loss: 0.2617 - val_accuracy: 0.9210\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0120 - accuracy: 0.9984 - val_loss: 0.2718 - val_accuracy: 0.9270\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0091 - accuracy: 0.9997 - val_loss: 0.3026 - val_accuracy: 0.9260\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0077 - accuracy: 0.9998 - val_loss: 0.3216 - val_accuracy: 0.9260\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.3394 - val_accuracy: 0.9300\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.3586 - val_accuracy: 0.9280\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0053 - accuracy: 0.9993 - val_loss: 0.3759 - val_accuracy: 0.9290\n",
      "Epoch 11/15\n",
      "180/180 - 20s - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.3865 - val_accuracy: 0.9240\n",
      "Epoch 12/15\n",
      "180/180 - 20s - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.4644 - val_accuracy: 0.9130\n",
      "Epoch 13/15\n",
      "180/180 - 20s - loss: 0.0455 - accuracy: 0.9877 - val_loss: 0.4533 - val_accuracy: 0.9020\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 93.00000071525574\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4493 - accuracy: 0.7643 - val_loss: 0.2575 - val_accuracy: 0.8950\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1354 - accuracy: 0.9599 - val_loss: 0.2658 - val_accuracy: 0.9020\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0445 - accuracy: 0.9932 - val_loss: 0.3469 - val_accuracy: 0.8850\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0243 - accuracy: 0.9967 - val_loss: 0.4050 - val_accuracy: 0.8880\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0136 - accuracy: 0.9992 - val_loss: 0.3953 - val_accuracy: 0.9030\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0138 - accuracy: 0.9979 - val_loss: 0.4663 - val_accuracy: 0.8980\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0120 - accuracy: 0.9980 - val_loss: 0.5376 - val_accuracy: 0.8880\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0103 - accuracy: 0.9983 - val_loss: 0.5156 - val_accuracy: 0.9010\n",
      "Epoch 9/15\n",
      "180/180 - 19s - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.5463 - val_accuracy: 0.8900\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0065 - accuracy: 0.9993 - val_loss: 0.6013 - val_accuracy: 0.8880\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.2999997138977\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4534 - accuracy: 0.7741 - val_loss: 0.2512 - val_accuracy: 0.9100\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1451 - accuracy: 0.9604 - val_loss: 0.2346 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 18s - loss: 0.0536 - accuracy: 0.9917 - val_loss: 0.2764 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 18s - loss: 0.0291 - accuracy: 0.9967 - val_loss: 0.3302 - val_accuracy: 0.9040\n",
      "Epoch 5/15\n",
      "180/180 - 18s - loss: 0.0204 - accuracy: 0.9973 - val_loss: 0.3727 - val_accuracy: 0.8980\n",
      "Epoch 6/15\n",
      "180/180 - 18s - loss: 0.0164 - accuracy: 0.9986 - val_loss: 0.3807 - val_accuracy: 0.9080\n",
      "Epoch 7/15\n",
      "180/180 - 18s - loss: 0.0111 - accuracy: 0.9990 - val_loss: 0.3949 - val_accuracy: 0.9100\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4667 - accuracy: 0.7553 - val_loss: 0.2259 - val_accuracy: 0.9170\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1543 - accuracy: 0.9552 - val_loss: 0.2112 - val_accuracy: 0.9230\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0634 - accuracy: 0.9896 - val_loss: 0.2262 - val_accuracy: 0.9190\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0379 - accuracy: 0.9949 - val_loss: 0.2400 - val_accuracy: 0.9220\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0230 - accuracy: 0.9973 - val_loss: 0.2819 - val_accuracy: 0.9150\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0154 - accuracy: 0.9987 - val_loss: 0.2837 - val_accuracy: 0.9270\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0110 - accuracy: 0.9996 - val_loss: 0.3155 - val_accuracy: 0.9230\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0105 - accuracy: 0.9993 - val_loss: 0.3300 - val_accuracy: 0.9240\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.3447 - val_accuracy: 0.9250\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0078 - accuracy: 0.9992 - val_loss: 0.3545 - val_accuracy: 0.9260\n",
      "Epoch 11/15\n",
      "180/180 - 20s - loss: 0.0080 - accuracy: 0.9996 - val_loss: 0.3717 - val_accuracy: 0.9270\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 92.69999861717224\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4468 - accuracy: 0.7688 - val_loss: 0.2365 - val_accuracy: 0.9030\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1280 - accuracy: 0.9609 - val_loss: 0.2140 - val_accuracy: 0.9110\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0399 - accuracy: 0.9919 - val_loss: 0.2708 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0198 - accuracy: 0.9977 - val_loss: 0.3043 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0138 - accuracy: 0.9990 - val_loss: 0.3342 - val_accuracy: 0.9140\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0098 - accuracy: 0.9990 - val_loss: 0.3591 - val_accuracy: 0.9160\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0091 - accuracy: 0.9986 - val_loss: 0.4005 - val_accuracy: 0.9100\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0083 - accuracy: 0.9990 - val_loss: 0.4543 - val_accuracy: 0.9070\n",
      "Epoch 9/15\n",
      "180/180 - 19s - loss: 0.0167 - accuracy: 0.9968 - val_loss: 0.5049 - val_accuracy: 0.8960\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0156 - accuracy: 0.9960 - val_loss: 0.4729 - val_accuracy: 0.8960\n",
      "Epoch 11/15\n",
      "180/180 - 20s - loss: 0.0116 - accuracy: 0.9967 - val_loss: 0.5879 - val_accuracy: 0.8860\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4569 - accuracy: 0.7648 - val_loss: 0.2325 - val_accuracy: 0.9130\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1551 - accuracy: 0.9562 - val_loss: 0.2326 - val_accuracy: 0.9060\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0583 - accuracy: 0.9897 - val_loss: 0.2843 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0295 - accuracy: 0.9968 - val_loss: 0.2938 - val_accuracy: 0.9130\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0184 - accuracy: 0.9986 - val_loss: 0.3255 - val_accuracy: 0.9120\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0122 - accuracy: 0.9997 - val_loss: 0.3348 - val_accuracy: 0.9190\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0098 - accuracy: 0.9996 - val_loss: 0.3507 - val_accuracy: 0.9220\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0084 - accuracy: 0.9994 - val_loss: 0.3704 - val_accuracy: 0.9220\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0077 - accuracy: 0.9994 - val_loss: 0.3889 - val_accuracy: 0.9220\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0060 - accuracy: 0.9994 - val_loss: 0.4109 - val_accuracy: 0.9210\n",
      "Epoch 11/15\n",
      "180/180 - 20s - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.4216 - val_accuracy: 0.9200\n",
      "Epoch 12/15\n",
      "180/180 - 20s - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.4337 - val_accuracy: 0.9220\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 92.1999990940094\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4624 - accuracy: 0.7603 - val_loss: 0.2487 - val_accuracy: 0.9060\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1517 - accuracy: 0.9576 - val_loss: 0.2494 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0612 - accuracy: 0.9893 - val_loss: 0.2864 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0322 - accuracy: 0.9970 - val_loss: 0.3203 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0210 - accuracy: 0.9980 - val_loss: 0.3917 - val_accuracy: 0.8970\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.3946 - val_accuracy: 0.9060\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0114 - accuracy: 0.9993 - val_loss: 0.4193 - val_accuracy: 0.9040\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.4608 - val_accuracy: 0.9060\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0078 - accuracy: 0.9996 - val_loss: 0.4894 - val_accuracy: 0.9040\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4       relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5       relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "6       tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
      "7       tanh       2  91.700000  91.100001  90.899998  91.900003  91.299999   \n",
      "8       tanh       3  91.500002  92.000002  91.299999  93.000001  90.300000   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.880000  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.830000  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.050000  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.300000  \n",
      "4  92.500001  91.700000  90.899998  91.200000  91.799998  91.630000  \n",
      "5  93.099999  91.900003  91.100001  90.300000  91.600001  91.690000  \n",
      "6  91.299999  90.399998  92.600000  92.500001  93.800002  91.960000  \n",
      "7  93.099999  92.299998  91.299999  91.200000  91.900003  91.670000  \n",
      "8  91.900003  92.699999  91.600001  92.199999  91.100001  91.760001  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4289 - accuracy: 0.7831 - val_loss: 0.2216 - val_accuracy: 0.9070\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1304 - accuracy: 0.9631 - val_loss: 0.2118 - val_accuracy: 0.9180\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0456 - accuracy: 0.9922 - val_loss: 0.2991 - val_accuracy: 0.8960\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0246 - accuracy: 0.9966 - val_loss: 0.3542 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0170 - accuracy: 0.9978 - val_loss: 0.3775 - val_accuracy: 0.9110\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0134 - accuracy: 0.9984 - val_loss: 0.3880 - val_accuracy: 0.9190\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.4557 - val_accuracy: 0.9030\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0066 - accuracy: 0.9996 - val_loss: 0.4894 - val_accuracy: 0.9090\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.5544 - val_accuracy: 0.9010\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0046 - accuracy: 0.9999 - val_loss: 0.5525 - val_accuracy: 0.9010\n",
      "Epoch 11/15\n",
      "180/180 - 21s - loss: 0.0042 - accuracy: 0.9998 - val_loss: 0.5832 - val_accuracy: 0.9000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4335 - accuracy: 0.7791 - val_loss: 0.2700 - val_accuracy: 0.8850\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1351 - accuracy: 0.9621 - val_loss: 0.2586 - val_accuracy: 0.9010\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0531 - accuracy: 0.9900 - val_loss: 0.3184 - val_accuracy: 0.8880\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0262 - accuracy: 0.9973 - val_loss: 0.3480 - val_accuracy: 0.8970\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0155 - accuracy: 0.9990 - val_loss: 0.3757 - val_accuracy: 0.9070\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0111 - accuracy: 0.9991 - val_loss: 0.4073 - val_accuracy: 0.9040\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0099 - accuracy: 0.9994 - val_loss: 0.4253 - val_accuracy: 0.9040\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0069 - accuracy: 0.9993 - val_loss: 0.4716 - val_accuracy: 0.9050\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.4999 - val_accuracy: 0.8980\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.5193 - val_accuracy: 0.9000\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.70000052452087\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4441 - accuracy: 0.7703 - val_loss: 0.2550 - val_accuracy: 0.8980\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1472 - accuracy: 0.9592 - val_loss: 0.2426 - val_accuracy: 0.9060\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0565 - accuracy: 0.9912 - val_loss: 0.3035 - val_accuracy: 0.8990\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0277 - accuracy: 0.9969 - val_loss: 0.3512 - val_accuracy: 0.8990\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0199 - accuracy: 0.9981 - val_loss: 0.4379 - val_accuracy: 0.8860\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0138 - accuracy: 0.9990 - val_loss: 0.4105 - val_accuracy: 0.9000\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0109 - accuracy: 0.9994 - val_loss: 0.4291 - val_accuracy: 0.9020\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.6000018119812\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4333 - accuracy: 0.7874 - val_loss: 0.2424 - val_accuracy: 0.9020\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1402 - accuracy: 0.9606 - val_loss: 0.2123 - val_accuracy: 0.9150\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0530 - accuracy: 0.9907 - val_loss: 0.2451 - val_accuracy: 0.9180\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0258 - accuracy: 0.9963 - val_loss: 0.2641 - val_accuracy: 0.9250\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0163 - accuracy: 0.9988 - val_loss: 0.3043 - val_accuracy: 0.9170\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0115 - accuracy: 0.9992 - val_loss: 0.3203 - val_accuracy: 0.9210\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0093 - accuracy: 0.9989 - val_loss: 0.3419 - val_accuracy: 0.9200\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0084 - accuracy: 0.9996 - val_loss: 0.3624 - val_accuracy: 0.9200\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0074 - accuracy: 0.9993 - val_loss: 0.3802 - val_accuracy: 0.9190\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4277 - accuracy: 0.7879 - val_loss: 0.2186 - val_accuracy: 0.9140\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1277 - accuracy: 0.9622 - val_loss: 0.2336 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0476 - accuracy: 0.9914 - val_loss: 0.2597 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0222 - accuracy: 0.9979 - val_loss: 0.2987 - val_accuracy: 0.9150\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0141 - accuracy: 0.9991 - val_loss: 0.3296 - val_accuracy: 0.9170\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0102 - accuracy: 0.9993 - val_loss: 0.3581 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0092 - accuracy: 0.9993 - val_loss: 0.3697 - val_accuracy: 0.9140\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0062 - accuracy: 0.9996 - val_loss: 0.3846 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4497 - accuracy: 0.7712 - val_loss: 0.2632 - val_accuracy: 0.8970\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1331 - accuracy: 0.9609 - val_loss: 0.2525 - val_accuracy: 0.9020\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0446 - accuracy: 0.9936 - val_loss: 0.3312 - val_accuracy: 0.9010\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0202 - accuracy: 0.9981 - val_loss: 0.3963 - val_accuracy: 0.8910\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0120 - accuracy: 0.9994 - val_loss: 0.4311 - val_accuracy: 0.8920\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 - 20s - loss: 0.0093 - accuracy: 0.9996 - val_loss: 0.4734 - val_accuracy: 0.8900\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.5084 - val_accuracy: 0.8900\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.20000100135803\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4336 - accuracy: 0.7779 - val_loss: 0.2322 - val_accuracy: 0.9110\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1306 - accuracy: 0.9628 - val_loss: 0.2167 - val_accuracy: 0.9130\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0414 - accuracy: 0.9936 - val_loss: 0.2599 - val_accuracy: 0.9210\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0198 - accuracy: 0.9978 - val_loss: 0.3441 - val_accuracy: 0.9050\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0142 - accuracy: 0.9988 - val_loss: 0.3309 - val_accuracy: 0.9150\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0105 - accuracy: 0.9991 - val_loss: 0.4047 - val_accuracy: 0.9080\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.4137 - val_accuracy: 0.9100\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0071 - accuracy: 0.9993 - val_loss: 0.4346 - val_accuracy: 0.9120\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.10000038146973\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4406 - accuracy: 0.7812 - val_loss: 0.2364 - val_accuracy: 0.9070\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1334 - accuracy: 0.9601 - val_loss: 0.2579 - val_accuracy: 0.8990\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0448 - accuracy: 0.9931 - val_loss: 0.2925 - val_accuracy: 0.9060\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0221 - accuracy: 0.9973 - val_loss: 0.3579 - val_accuracy: 0.9010\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0138 - accuracy: 0.9990 - val_loss: 0.3936 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0097 - accuracy: 0.9994 - val_loss: 0.4179 - val_accuracy: 0.9060\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.4289 - val_accuracy: 0.9030\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0074 - accuracy: 0.9996 - val_loss: 0.4457 - val_accuracy: 0.9050\n",
      "Epoch 9/15\n",
      "180/180 - 20s - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.4635 - val_accuracy: 0.9080\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.4814 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.2203 - val_accuracy: 0.9140\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1520 - accuracy: 0.9557 - val_loss: 0.2055 - val_accuracy: 0.9230\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0579 - accuracy: 0.9909 - val_loss: 0.2399 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0277 - accuracy: 0.9968 - val_loss: 0.2870 - val_accuracy: 0.9190\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0174 - accuracy: 0.9984 - val_loss: 0.3109 - val_accuracy: 0.9160\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0138 - accuracy: 0.9990 - val_loss: 0.3224 - val_accuracy: 0.9240\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0132 - accuracy: 0.9987 - val_loss: 0.3451 - val_accuracy: 0.9220\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0082 - accuracy: 0.9993 - val_loss: 0.3551 - val_accuracy: 0.9250\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.3710 - val_accuracy: 0.9320\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0065 - accuracy: 0.9994 - val_loss: 0.3936 - val_accuracy: 0.9290\n",
      "Epoch 11/15\n",
      "180/180 - 21s - loss: 0.0056 - accuracy: 0.9996 - val_loss: 0.4093 - val_accuracy: 0.9280\n",
      "Epoch 12/15\n",
      "180/180 - 20s - loss: 0.0043 - accuracy: 0.9997 - val_loss: 0.4246 - val_accuracy: 0.9290\n",
      "Epoch 13/15\n",
      "180/180 - 20s - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.4390 - val_accuracy: 0.9310\n",
      "Epoch 14/15\n",
      "180/180 - 20s - loss: 0.0045 - accuracy: 0.9998 - val_loss: 0.4551 - val_accuracy: 0.9290\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 93.19999814033508\n",
      "Epoch 1/15\n",
      "180/180 - 20s - loss: 0.4351 - accuracy: 0.7843 - val_loss: 0.2339 - val_accuracy: 0.9000\n",
      "Epoch 2/15\n",
      "180/180 - 19s - loss: 0.1406 - accuracy: 0.9598 - val_loss: 0.2123 - val_accuracy: 0.9150\n",
      "Epoch 3/15\n",
      "180/180 - 19s - loss: 0.0542 - accuracy: 0.9896 - val_loss: 0.2520 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 19s - loss: 0.0295 - accuracy: 0.9958 - val_loss: 0.2817 - val_accuracy: 0.9140\n",
      "Epoch 5/15\n",
      "180/180 - 19s - loss: 0.0157 - accuracy: 0.9984 - val_loss: 0.3687 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 19s - loss: 0.0136 - accuracy: 0.9986 - val_loss: 0.3622 - val_accuracy: 0.9150\n",
      "Epoch 7/15\n",
      "180/180 - 19s - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.3680 - val_accuracy: 0.9210\n",
      "Epoch 8/15\n",
      "180/180 - 19s - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.3814 - val_accuracy: 0.9170\n",
      "Epoch 9/15\n",
      "180/180 - 19s - loss: 0.0066 - accuracy: 0.9992 - val_loss: 0.3962 - val_accuracy: 0.9160\n",
      "Epoch 10/15\n",
      "180/180 - 19s - loss: 0.0075 - accuracy: 0.9991 - val_loss: 0.4697 - val_accuracy: 0.9020\n",
      "Epoch 11/15\n",
      "180/180 - 19s - loss: 0.0249 - accuracy: 0.9940 - val_loss: 0.5411 - val_accuracy: 0.8870\n",
      "Epoch 12/15\n",
      "180/180 - 19s - loss: 0.0301 - accuracy: 0.9930 - val_loss: 0.4526 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 92.10000038146973\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1       relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2       relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3       relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4       relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5       relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "6       tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
      "7       tanh       2  91.700000  91.100001  90.899998  91.900003  91.299999   \n",
      "8       tanh       3  91.500002  92.000002  91.299999  93.000001  90.300000   \n",
      "9       tanh       4  91.900003  90.700001  90.600002  92.500001  91.700000   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  92.299998  92.900002  91.700000  91.600001  90.300000  91.880000  \n",
      "1  91.600001  91.299999  92.699999  92.299998  92.000002  91.830000  \n",
      "2  92.600000  92.299998  92.400002  92.500001  93.099999  92.050000  \n",
      "3  90.799999  92.900002  92.500001  91.100001  89.700001  87.300000  \n",
      "4  92.500001  91.700000  90.899998  91.200000  91.799998  91.630000  \n",
      "5  93.099999  91.900003  91.100001  90.300000  91.600001  91.690000  \n",
      "6  91.299999  90.399998  92.600000  92.500001  93.800002  91.960000  \n",
      "7  93.099999  92.299998  91.299999  91.200000  91.900003  91.670000  \n",
      "8  91.900003  92.699999  91.600001  92.199999  91.100001  91.760001  \n",
      "9  90.200001  92.100000  90.799999  93.199998  92.100000  91.580001  \n",
      "\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4420 - accuracy: 0.7753 - val_loss: 0.2261 - val_accuracy: 0.9180\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.1449 - accuracy: 0.9584 - val_loss: 0.2301 - val_accuracy: 0.9010\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0526 - accuracy: 0.9898 - val_loss: 0.2909 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0244 - accuracy: 0.9982 - val_loss: 0.3060 - val_accuracy: 0.9090\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0134 - accuracy: 0.9996 - val_loss: 0.3567 - val_accuracy: 0.9000\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0107 - accuracy: 0.9994 - val_loss: 0.3814 - val_accuracy: 0.9060\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4327 - accuracy: 0.7782 - val_loss: 0.1939 - val_accuracy: 0.9280\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.1239 - accuracy: 0.9641 - val_loss: 0.1982 - val_accuracy: 0.9330\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0376 - accuracy: 0.9939 - val_loss: 0.2249 - val_accuracy: 0.9300\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0146 - accuracy: 0.9988 - val_loss: 0.2715 - val_accuracy: 0.9240\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0114 - accuracy: 0.9989 - val_loss: 0.3048 - val_accuracy: 0.9210\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0086 - accuracy: 0.9992 - val_loss: 0.3224 - val_accuracy: 0.9230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0061 - accuracy: 0.9996 - val_loss: 0.3492 - val_accuracy: 0.9180\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 93.30000281333923\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4425 - accuracy: 0.7703 - val_loss: 0.2433 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.1391 - accuracy: 0.9584 - val_loss: 0.2033 - val_accuracy: 0.9230\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0450 - accuracy: 0.9929 - val_loss: 0.2544 - val_accuracy: 0.9090\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0196 - accuracy: 0.9983 - val_loss: 0.2836 - val_accuracy: 0.9170\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0134 - accuracy: 0.9993 - val_loss: 0.3285 - val_accuracy: 0.9150\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0109 - accuracy: 0.9992 - val_loss: 0.3459 - val_accuracy: 0.9170\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.3692 - val_accuracy: 0.9180\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4318 - accuracy: 0.7811 - val_loss: 0.2612 - val_accuracy: 0.8970\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.1255 - accuracy: 0.9652 - val_loss: 0.2622 - val_accuracy: 0.9140\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0468 - accuracy: 0.9923 - val_loss: 0.2940 - val_accuracy: 0.9080\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0199 - accuracy: 0.9982 - val_loss: 0.3722 - val_accuracy: 0.9020\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0143 - accuracy: 0.9988 - val_loss: 0.4244 - val_accuracy: 0.9010\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0114 - accuracy: 0.9988 - val_loss: 0.4273 - val_accuracy: 0.9020\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0084 - accuracy: 0.9993 - val_loss: 0.4461 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4470 - accuracy: 0.7757 - val_loss: 0.2618 - val_accuracy: 0.8920\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1424 - accuracy: 0.9589 - val_loss: 0.2538 - val_accuracy: 0.9010\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0509 - accuracy: 0.9916 - val_loss: 0.2834 - val_accuracy: 0.9030\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0236 - accuracy: 0.9976 - val_loss: 0.3473 - val_accuracy: 0.9040\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0162 - accuracy: 0.9987 - val_loss: 0.3909 - val_accuracy: 0.9030\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0108 - accuracy: 0.9994 - val_loss: 0.4226 - val_accuracy: 0.9060\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0090 - accuracy: 0.9992 - val_loss: 0.4490 - val_accuracy: 0.9070\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0084 - accuracy: 0.9988 - val_loss: 0.4746 - val_accuracy: 0.9070\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.4954 - val_accuracy: 0.9060\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0067 - accuracy: 0.9988 - val_loss: 0.5225 - val_accuracy: 0.9070\n",
      "Epoch 11/15\n",
      "180/180 - 21s - loss: 0.0059 - accuracy: 0.9994 - val_loss: 0.5382 - val_accuracy: 0.9080\n",
      "Epoch 12/15\n",
      "180/180 - 21s - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.5477 - val_accuracy: 0.9100\n",
      "Epoch 13/15\n",
      "180/180 - 21s - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.5712 - val_accuracy: 0.9060\n",
      "Epoch 14/15\n",
      "180/180 - 21s - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.5895 - val_accuracy: 0.9070\n",
      "Epoch 15/15\n",
      "180/180 - 22s - loss: 0.0037 - accuracy: 0.9998 - val_loss: 0.6099 - val_accuracy: 0.9090\n",
      "Test Accuracy: 90.89999794960022\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4306 - accuracy: 0.7862 - val_loss: 0.2130 - val_accuracy: 0.9240\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1235 - accuracy: 0.9630 - val_loss: 0.2226 - val_accuracy: 0.9200\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0404 - accuracy: 0.9926 - val_loss: 0.2604 - val_accuracy: 0.9160\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0171 - accuracy: 0.9984 - val_loss: 0.3096 - val_accuracy: 0.9170\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0101 - accuracy: 0.9994 - val_loss: 0.3313 - val_accuracy: 0.9230\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0083 - accuracy: 0.9996 - val_loss: 0.3585 - val_accuracy: 0.9250\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0068 - accuracy: 0.9997 - val_loss: 0.3816 - val_accuracy: 0.9240\n",
      "Epoch 8/15\n",
      "180/180 - 22s - loss: 0.0055 - accuracy: 0.9998 - val_loss: 0.4030 - val_accuracy: 0.9240\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0052 - accuracy: 0.9996 - val_loss: 0.4221 - val_accuracy: 0.9220\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.4411 - val_accuracy: 0.9230\n",
      "Epoch 11/15\n",
      "180/180 - 21s - loss: 0.0042 - accuracy: 0.9996 - val_loss: 0.4611 - val_accuracy: 0.9240\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4818 - accuracy: 0.7588 - val_loss: 0.2724 - val_accuracy: 0.8910\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1669 - accuracy: 0.9556 - val_loss: 0.2224 - val_accuracy: 0.9180\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0697 - accuracy: 0.9892 - val_loss: 0.2570 - val_accuracy: 0.9130\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0395 - accuracy: 0.9962 - val_loss: 0.2917 - val_accuracy: 0.9110\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0237 - accuracy: 0.9981 - val_loss: 0.3215 - val_accuracy: 0.9160\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0160 - accuracy: 0.9997 - val_loss: 0.3484 - val_accuracy: 0.9170\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0141 - accuracy: 0.9992 - val_loss: 0.4143 - val_accuracy: 0.9060\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Epoch 1/15\n",
      "180/180 - 21s - loss: 0.4282 - accuracy: 0.7830 - val_loss: 0.2319 - val_accuracy: 0.9110\n",
      "Epoch 2/15\n",
      "180/180 - 20s - loss: 0.1239 - accuracy: 0.9610 - val_loss: 0.2533 - val_accuracy: 0.9050\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0387 - accuracy: 0.9931 - val_loss: 0.2936 - val_accuracy: 0.9100\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0169 - accuracy: 0.9984 - val_loss: 0.3407 - val_accuracy: 0.9060\n",
      "Epoch 5/15\n",
      "180/180 - 20s - loss: 0.0107 - accuracy: 0.9993 - val_loss: 0.3821 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0081 - accuracy: 0.9996 - val_loss: 0.4116 - val_accuracy: 0.9070\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "Epoch 1/15\n",
      "180/180 - 23s - loss: 0.4527 - accuracy: 0.7758 - val_loss: 0.2846 - val_accuracy: 0.8830\n",
      "Epoch 2/15\n",
      "180/180 - 22s - loss: 0.1447 - accuracy: 0.9599 - val_loss: 0.2557 - val_accuracy: 0.9080\n",
      "Epoch 3/15\n",
      "180/180 - 22s - loss: 0.0559 - accuracy: 0.9916 - val_loss: 0.3236 - val_accuracy: 0.9000\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0276 - accuracy: 0.9964 - val_loss: 0.3836 - val_accuracy: 0.8960\n",
      "Epoch 5/15\n",
      "180/180 - 22s - loss: 0.0174 - accuracy: 0.9990 - val_loss: 0.4445 - val_accuracy: 0.8870\n",
      "Epoch 6/15\n",
      "180/180 - 22s - loss: 0.0136 - accuracy: 0.9987 - val_loss: 0.5209 - val_accuracy: 0.8830\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0197 - accuracy: 0.9967 - val_loss: 0.4899 - val_accuracy: 0.8800\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4351 - accuracy: 0.7738 - val_loss: 0.2134 - val_accuracy: 0.9110\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1288 - accuracy: 0.9610 - val_loss: 0.1976 - val_accuracy: 0.9200\n",
      "Epoch 3/15\n",
      "180/180 - 21s - loss: 0.0446 - accuracy: 0.9924 - val_loss: 0.2475 - val_accuracy: 0.9210\n",
      "Epoch 4/15\n",
      "180/180 - 21s - loss: 0.0204 - accuracy: 0.9981 - val_loss: 0.2770 - val_accuracy: 0.9200\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0116 - accuracy: 0.9994 - val_loss: 0.3097 - val_accuracy: 0.9220\n",
      "Epoch 6/15\n",
      "180/180 - 21s - loss: 0.0092 - accuracy: 0.9997 - val_loss: 0.3318 - val_accuracy: 0.9160\n",
      "Epoch 7/15\n",
      "180/180 - 21s - loss: 0.0075 - accuracy: 0.9996 - val_loss: 0.3634 - val_accuracy: 0.9150\n",
      "Epoch 8/15\n",
      "180/180 - 21s - loss: 0.0062 - accuracy: 0.9993 - val_loss: 0.3849 - val_accuracy: 0.9160\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0051 - accuracy: 0.9997 - val_loss: 0.4079 - val_accuracy: 0.9170\n",
      "Epoch 10/15\n",
      "180/180 - 21s - loss: 0.0048 - accuracy: 0.9993 - val_loss: 0.4250 - val_accuracy: 0.9160\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 92.1999990940094\n",
      "\n",
      "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0        relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1        relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2        relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3        relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4        relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5        relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "6        tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
      "7        tanh       2  91.700000  91.100001  90.899998  91.900003  91.299999   \n",
      "8        tanh       3  91.500002  92.000002  91.299999  93.000001  90.300000   \n",
      "9        tanh       4  91.900003  90.700001  90.600002  92.500001  91.700000   \n",
      "10       tanh       5  91.799998  93.300003  92.299998  91.399997  90.899998   \n",
      "\n",
      "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0   92.299998  92.900002  91.700000  91.600001  90.300000  91.880000  \n",
      "1   91.600001  91.299999  92.699999  92.299998  92.000002  91.830000  \n",
      "2   92.600000  92.299998  92.400002  92.500001  93.099999  92.050000  \n",
      "3   90.799999  92.900002  92.500001  91.100001  89.700001  87.300000  \n",
      "4   92.500001  91.700000  90.899998  91.200000  91.799998  91.630000  \n",
      "5   93.099999  91.900003  91.100001  90.300000  91.600001  91.690000  \n",
      "6   91.299999  90.399998  92.600000  92.500001  93.800002  91.960000  \n",
      "7   93.099999  92.299998  91.299999  91.200000  91.900003  91.670000  \n",
      "8   91.900003  92.699999  91.600001  92.199999  91.100001  91.760001  \n",
      "9   90.200001  92.100000  90.799999  93.199998  92.100000  91.580001  \n",
      "10  92.500001  91.799998  91.100001  90.799999  92.199999  91.809999  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4424 - accuracy: 0.7682 - val_loss: 0.2176 - val_accuracy: 0.9130\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1263 - accuracy: 0.9649 - val_loss: 0.2321 - val_accuracy: 0.9190\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0434 - accuracy: 0.9933 - val_loss: 0.2647 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 22s - loss: 0.0176 - accuracy: 0.9990 - val_loss: 0.3189 - val_accuracy: 0.9150\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0131 - accuracy: 0.9990 - val_loss: 0.3680 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.4061 - val_accuracy: 0.9110\n",
      "Epoch 7/15\n",
      "180/180 - 22s - loss: 0.0070 - accuracy: 0.9997 - val_loss: 0.4272 - val_accuracy: 0.9150\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4358 - accuracy: 0.7762 - val_loss: 0.2455 - val_accuracy: 0.9040\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1303 - accuracy: 0.9629 - val_loss: 0.2579 - val_accuracy: 0.9070\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0459 - accuracy: 0.9932 - val_loss: 0.3058 - val_accuracy: 0.9020\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0216 - accuracy: 0.9981 - val_loss: 0.3589 - val_accuracy: 0.8990\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.4051 - val_accuracy: 0.8990\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0102 - accuracy: 0.9996 - val_loss: 0.4486 - val_accuracy: 0.9000\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0088 - accuracy: 0.9997 - val_loss: 0.4731 - val_accuracy: 0.9010\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.70000052452087\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4452 - accuracy: 0.7712 - val_loss: 0.2218 - val_accuracy: 0.9130\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1365 - accuracy: 0.9614 - val_loss: 0.2329 - val_accuracy: 0.9120\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0491 - accuracy: 0.9912 - val_loss: 0.2712 - val_accuracy: 0.9110\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0252 - accuracy: 0.9971 - val_loss: 0.2873 - val_accuracy: 0.9100\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0165 - accuracy: 0.9986 - val_loss: 0.3067 - val_accuracy: 0.9170\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0123 - accuracy: 0.9994 - val_loss: 0.3335 - val_accuracy: 0.9200\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0092 - accuracy: 0.9994 - val_loss: 0.3335 - val_accuracy: 0.9240\n",
      "Epoch 8/15\n",
      "180/180 - 23s - loss: 0.0079 - accuracy: 0.9996 - val_loss: 0.3706 - val_accuracy: 0.9200\n",
      "Epoch 9/15\n",
      "180/180 - 23s - loss: 0.0090 - accuracy: 0.9986 - val_loss: 0.4300 - val_accuracy: 0.9120\n",
      "Epoch 10/15\n",
      "180/180 - 23s - loss: 0.0200 - accuracy: 0.9953 - val_loss: 0.4592 - val_accuracy: 0.9020\n",
      "Epoch 11/15\n",
      "180/180 - 23s - loss: 0.0189 - accuracy: 0.9950 - val_loss: 0.4866 - val_accuracy: 0.8950\n",
      "Epoch 12/15\n",
      "180/180 - 23s - loss: 0.0140 - accuracy: 0.9970 - val_loss: 0.5042 - val_accuracy: 0.9020\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4346 - accuracy: 0.7827 - val_loss: 0.2483 - val_accuracy: 0.9120\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1407 - accuracy: 0.9607 - val_loss: 0.2177 - val_accuracy: 0.9240\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0486 - accuracy: 0.9923 - val_loss: 0.2715 - val_accuracy: 0.9170\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0243 - accuracy: 0.9977 - val_loss: 0.3426 - val_accuracy: 0.9100\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0137 - accuracy: 0.9988 - val_loss: 0.3963 - val_accuracy: 0.9060\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0102 - accuracy: 0.9997 - val_loss: 0.4066 - val_accuracy: 0.9130\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0094 - accuracy: 0.9991 - val_loss: 0.4336 - val_accuracy: 0.9140\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4441 - accuracy: 0.7744 - val_loss: 0.2394 - val_accuracy: 0.9080\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1402 - accuracy: 0.9628 - val_loss: 0.2428 - val_accuracy: 0.9010\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0507 - accuracy: 0.9924 - val_loss: 0.2804 - val_accuracy: 0.9120\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0260 - accuracy: 0.9970 - val_loss: 0.3247 - val_accuracy: 0.9100\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0157 - accuracy: 0.9991 - val_loss: 0.3755 - val_accuracy: 0.8970\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0115 - accuracy: 0.9992 - val_loss: 0.4025 - val_accuracy: 0.9090\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0098 - accuracy: 0.9989 - val_loss: 0.4401 - val_accuracy: 0.9020\n",
      "Epoch 8/15\n",
      "180/180 - 22s - loss: 0.0077 - accuracy: 0.9993 - val_loss: 0.4653 - val_accuracy: 0.9040\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.20000004768372\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4428 - accuracy: 0.7763 - val_loss: 0.2195 - val_accuracy: 0.9080\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1299 - accuracy: 0.9616 - val_loss: 0.2387 - val_accuracy: 0.8990\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0416 - accuracy: 0.9937 - val_loss: 0.2838 - val_accuracy: 0.9060\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0190 - accuracy: 0.9984 - val_loss: 0.3266 - val_accuracy: 0.9060\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0117 - accuracy: 0.9993 - val_loss: 0.3812 - val_accuracy: 0.9070\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0087 - accuracy: 0.9994 - val_loss: 0.4234 - val_accuracy: 0.9030\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Epoch 1/15\n",
      "180/180 - 22s - loss: 0.4427 - accuracy: 0.7776 - val_loss: 0.2400 - val_accuracy: 0.9040\n",
      "Epoch 2/15\n",
      "180/180 - 21s - loss: 0.1355 - accuracy: 0.9609 - val_loss: 0.2539 - val_accuracy: 0.9000\n",
      "Epoch 3/15\n",
      "180/180 - 20s - loss: 0.0470 - accuracy: 0.9918 - val_loss: 0.3093 - val_accuracy: 0.9010\n",
      "Epoch 4/15\n",
      "180/180 - 20s - loss: 0.0223 - accuracy: 0.9980 - val_loss: 0.3856 - val_accuracy: 0.8960\n",
      "Epoch 5/15\n",
      "180/180 - 21s - loss: 0.0151 - accuracy: 0.9989 - val_loss: 0.3696 - val_accuracy: 0.9080\n",
      "Epoch 6/15\n",
      "180/180 - 20s - loss: 0.0105 - accuracy: 0.9994 - val_loss: 0.4093 - val_accuracy: 0.9050\n",
      "Epoch 7/15\n",
      "180/180 - 20s - loss: 0.0084 - accuracy: 0.9997 - val_loss: 0.4249 - val_accuracy: 0.9040\n",
      "Epoch 8/15\n",
      "180/180 - 20s - loss: 0.0067 - accuracy: 0.9997 - val_loss: 0.4628 - val_accuracy: 0.9020\n",
      "Epoch 9/15\n",
      "180/180 - 21s - loss: 0.0061 - accuracy: 0.9997 - val_loss: 0.4835 - val_accuracy: 0.9020\n",
      "Epoch 10/15\n",
      "180/180 - 20s - loss: 0.0050 - accuracy: 0.9997 - val_loss: 0.5063 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4298 - accuracy: 0.7783 - val_loss: 0.2551 - val_accuracy: 0.8970\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1221 - accuracy: 0.9644 - val_loss: 0.2633 - val_accuracy: 0.9020\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0458 - accuracy: 0.9921 - val_loss: 0.3270 - val_accuracy: 0.9020\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0212 - accuracy: 0.9974 - val_loss: 0.3711 - val_accuracy: 0.8970\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0124 - accuracy: 0.9990 - val_loss: 0.4014 - val_accuracy: 0.9050\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0090 - accuracy: 0.9996 - val_loss: 0.4628 - val_accuracy: 0.8990\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.4708 - val_accuracy: 0.8980\n",
      "Epoch 8/15\n",
      "180/180 - 23s - loss: 0.0063 - accuracy: 0.9996 - val_loss: 0.5017 - val_accuracy: 0.8990\n",
      "Epoch 9/15\n",
      "180/180 - 23s - loss: 0.0052 - accuracy: 0.9994 - val_loss: 0.5271 - val_accuracy: 0.8990\n",
      "Epoch 10/15\n",
      "180/180 - 23s - loss: 0.0047 - accuracy: 0.9997 - val_loss: 0.5561 - val_accuracy: 0.8990\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.49999713897705\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4524 - accuracy: 0.7709 - val_loss: 0.2446 - val_accuracy: 0.9090\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1515 - accuracy: 0.9598 - val_loss: 0.2399 - val_accuracy: 0.9100\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0540 - accuracy: 0.9906 - val_loss: 0.2783 - val_accuracy: 0.9040\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0288 - accuracy: 0.9969 - val_loss: 0.3102 - val_accuracy: 0.9200\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0172 - accuracy: 0.9993 - val_loss: 0.3670 - val_accuracy: 0.9010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0144 - accuracy: 0.9994 - val_loss: 0.3768 - val_accuracy: 0.9130\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0107 - accuracy: 0.9993 - val_loss: 0.4014 - val_accuracy: 0.9100\n",
      "Epoch 8/15\n",
      "180/180 - 23s - loss: 0.0098 - accuracy: 0.9996 - val_loss: 0.4394 - val_accuracy: 0.9070\n",
      "Epoch 9/15\n",
      "180/180 - 23s - loss: 0.0124 - accuracy: 0.9970 - val_loss: 0.4309 - val_accuracy: 0.9050\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.00000166893005\n",
      "Epoch 1/15\n",
      "180/180 - 24s - loss: 0.4353 - accuracy: 0.7749 - val_loss: 0.2560 - val_accuracy: 0.8990\n",
      "Epoch 2/15\n",
      "180/180 - 23s - loss: 0.1411 - accuracy: 0.9602 - val_loss: 0.2175 - val_accuracy: 0.9210\n",
      "Epoch 3/15\n",
      "180/180 - 23s - loss: 0.0493 - accuracy: 0.9910 - val_loss: 0.2561 - val_accuracy: 0.9220\n",
      "Epoch 4/15\n",
      "180/180 - 23s - loss: 0.0268 - accuracy: 0.9972 - val_loss: 0.2660 - val_accuracy: 0.9250\n",
      "Epoch 5/15\n",
      "180/180 - 23s - loss: 0.0171 - accuracy: 0.9993 - val_loss: 0.3076 - val_accuracy: 0.9220\n",
      "Epoch 6/15\n",
      "180/180 - 23s - loss: 0.0110 - accuracy: 0.9998 - val_loss: 0.3287 - val_accuracy: 0.9220\n",
      "Epoch 7/15\n",
      "180/180 - 23s - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.3495 - val_accuracy: 0.9210\n",
      "Epoch 8/15\n",
      "180/180 - 23s - loss: 0.0077 - accuracy: 0.9996 - val_loss: 0.3699 - val_accuracy: 0.9170\n",
      "Epoch 9/15\n",
      "180/180 - 22s - loss: 0.0064 - accuracy: 0.9996 - val_loss: 0.3877 - val_accuracy: 0.9190\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.5000011920929\n",
      "\n",
      "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0        relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
      "1        relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
      "2        relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
      "3        relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
      "4        relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
      "5        relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
      "6        tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
      "7        tanh       2  91.700000  91.100001  90.899998  91.900003  91.299999   \n",
      "8        tanh       3  91.500002  92.000002  91.299999  93.000001  90.300000   \n",
      "9        tanh       4  91.900003  90.700001  90.600002  92.500001  91.700000   \n",
      "10       tanh       5  91.799998  93.300003  92.299998  91.399997  90.899998   \n",
      "11       tanh       6  91.900003  90.700001  92.400002  92.400002  91.200000   \n",
      "\n",
      "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0   92.299998  92.900002  91.700000  91.600001  90.300000  91.880000  \n",
      "1   91.600001  91.299999  92.699999  92.299998  92.000002  91.830000  \n",
      "2   92.600000  92.299998  92.400002  92.500001  93.099999  92.050000  \n",
      "3   90.799999  92.900002  92.500001  91.100001  89.700001  87.300000  \n",
      "4   92.500001  91.700000  90.899998  91.200000  91.799998  91.630000  \n",
      "5   93.099999  91.900003  91.100001  90.300000  91.600001  91.690000  \n",
      "6   91.299999  90.399998  92.600000  92.500001  93.800002  91.960000  \n",
      "7   93.099999  92.299998  91.299999  91.200000  91.900003  91.670000  \n",
      "8   91.900003  92.699999  91.600001  92.199999  91.100001  91.760001  \n",
      "9   90.200001  92.100000  90.799999  93.199998  92.100000  91.580001  \n",
      "10  92.500001  91.799998  91.100001  90.799999  92.199999  91.809999  \n",
      "11  90.799999  90.799999  90.499997  92.000002  92.500001  91.520001  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu', 'tanh']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "\n",
    "            # Define the input shape\n",
    "            model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=15, verbose=2, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record = record.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>92.100000</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>90.499997</td>\n",
       "      <td>92.600000</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>93.099999</td>\n",
       "      <td>92.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>89.700001</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>92.699999</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>90.399998</td>\n",
       "      <td>92.600000</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>93.800002</td>\n",
       "      <td>91.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>92.600000</td>\n",
       "      <td>92.100000</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>92.199999</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>92.900002</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>90.300000</td>\n",
       "      <td>91.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>92.000002</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>92.699999</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>92.000002</td>\n",
       "      <td>91.830000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>5</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>93.300003</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>92.199999</td>\n",
       "      <td>91.809999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>92.000002</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>93.000001</td>\n",
       "      <td>90.300000</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>92.699999</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>92.199999</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>91.760001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>92.799997</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>93.099999</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>90.300000</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>91.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>93.099999</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>91.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>92.699999</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>91.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>90.700001</td>\n",
       "      <td>90.600002</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>90.200001</td>\n",
       "      <td>92.100000</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>93.199998</td>\n",
       "      <td>92.100000</td>\n",
       "      <td>91.580001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>90.700001</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>90.499997</td>\n",
       "      <td>92.000002</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.520001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>50.099999</td>\n",
       "      <td>92.199999</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>90.499997</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>92.900002</td>\n",
       "      <td>92.500001</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>89.700001</td>\n",
       "      <td>87.300000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "2        relu       3  91.600001  92.100000  91.500002  91.900003  90.499997   \n",
       "6        tanh       1  92.299998  92.400002  89.700001  91.900003  92.699999   \n",
       "0        relu       1  91.399997  92.600000  92.100000  91.700000  92.199999   \n",
       "1        relu       2  90.899998  92.000002  91.500002  92.400002  91.600001   \n",
       "10       tanh       5  91.799998  93.300003  92.299998  91.399997  90.899998   \n",
       "8        tanh       3  91.500002  92.000002  91.299999  93.000001  90.300000   \n",
       "5        relu       6  92.799997  91.600001  90.899998  91.900003  91.700000   \n",
       "7        tanh       2  91.700000  91.100001  90.899998  91.900003  91.299999   \n",
       "4        relu       5  91.100001  91.900003  90.799999  91.700000  92.699999   \n",
       "9        tanh       4  91.900003  90.700001  90.600002  92.500001  91.700000   \n",
       "11       tanh       6  91.900003  90.700001  92.400002  92.400002  91.200000   \n",
       "3        relu       4  91.299999  50.099999  92.199999  91.900003  90.499997   \n",
       "\n",
       "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "2   92.600000  92.299998  92.400002  92.500001  93.099999  92.050000  \n",
       "6   91.299999  90.399998  92.600000  92.500001  93.800002  91.960000  \n",
       "0   92.299998  92.900002  91.700000  91.600001  90.300000  91.880000  \n",
       "1   91.600001  91.299999  92.699999  92.299998  92.000002  91.830000  \n",
       "10  92.500001  91.799998  91.100001  90.799999  92.199999  91.809999  \n",
       "8   91.900003  92.699999  91.600001  92.199999  91.100001  91.760001  \n",
       "5   93.099999  91.900003  91.100001  90.300000  91.600001  91.690000  \n",
       "7   93.099999  92.299998  91.299999  91.200000  91.900003  91.670000  \n",
       "4   92.500001  91.700000  90.899998  91.200000  91.799998  91.630000  \n",
       "9   90.200001  92.100000  90.799999  93.199998  92.100000  91.580001  \n",
       "11  90.799999  90.799999  90.499997  92.000002  92.500001  91.520001  \n",
       "3   90.799999  92.900002  92.500001  91.100001  89.700001  87.300000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>92.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>91.96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              AVG\n",
       "Activation       \n",
       "relu        92.05\n",
       "tanh        91.96"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_SUBJ.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17913 words present from 21324 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    \n",
    "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
    "            \n",
    "        # initialize the unknown word with standard normal distribution values\n",
    "        else:\n",
    "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.93121508,  0.34473418, -0.70878697, ...,  0.25505658,\n",
       "         0.08051993,  0.51291611],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(filters = 100, kernel_size = 3, activation='relu', \n",
    "                 input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_121\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_121 (Embedding)    (None, 100, 300)          6089700   \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_121 (Flatten)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_242 (Dropout)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_243 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,228,821\n",
      "Trainable params: 139,121\n",
      "Non-trainable params: 6,089,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(vocab_size, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 89.99999761581421\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 88.30000162124634\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 84.79999899864197\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 89.49999809265137\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 85.50000190734863\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.19999861717224\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.19999980926514\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 90.10000228881836\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 89.0999972820282\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "\n",
      "        acc6  acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.2  90.100002  89.099997  91.399997  87.409999  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 88.59999775886536\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 87.40000128746033\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.79999899864197\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 83.89999866485596\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 89.80000019073486\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 81.19999766349792\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.70000052452087\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 83.39999914169312\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 88.7000024318695\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 80.50000071525574\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.79999709129333\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 88.09999823570251\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 89.20000195503235\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 89.0999972820282\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 85.69999933242798\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 88.09999823570251\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.00000262260437\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 87.59999871253967\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 88.89999985694885\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 82.99999833106995\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 87.1999979019165\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.00000238418579\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 85.79999804496765\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 87.09999918937683\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.99999856948853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 85.6000006198883\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 87.00000047683716\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.50000166893005\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.6000006198883\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
      "3       relu       4  87.199998  85.000002  85.799998  87.099999  90.799999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
      "3  88.999999  85.600001  87.000000  79.500002  85.600001  86.260000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.6999990940094\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.50000286102295\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.99999856948853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.49999904632568\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 86.2999975681305\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 84.79999899864197\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 83.39999914169312\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 83.20000171661377\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 88.20000290870667\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.90000247955322\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
      "3       relu       4  87.199998  85.000002  85.799998  87.099999  90.799999   \n",
      "4       relu       5  79.699999  84.500003  88.999999  88.499999  86.299998   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
      "3  88.999999  85.600001  87.000000  79.500002  85.600001  86.260000  \n",
      "4  84.799999  83.399999  83.200002  88.200003  79.900002  84.750000  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.10000109672546\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.89999985694885\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.10000014305115\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 88.7000024318695\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 84.79999899864197\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 76.49999856948853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.2999975681305\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 88.7000024318695\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 76.30000114440918\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 82.09999799728394\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
      "3       relu       4  87.199998  85.000002  85.799998  87.099999  90.799999   \n",
      "4       relu       5  79.699999  84.500003  88.999999  88.499999  86.299998   \n",
      "5       relu       6  85.100001  88.900000  86.100000  88.700002  84.799999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
      "3  88.999999  85.600001  87.000000  79.500002  85.600001  86.260000  \n",
      "4  84.799999  83.399999  83.200002  88.200003  79.900002  84.750000  \n",
      "5  76.499999  86.299998  88.700002  76.300001  82.099998  84.350000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.9000015258789\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 87.8000020980835\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.49999904632568\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 77.89999842643738\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 82.99999833106995\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 84.79999899864197\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 84.7000002861023\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 89.49999809265137\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 85.29999852180481\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 86.10000014305115\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
      "3       relu       4  87.199998  85.000002  85.799998  87.099999  90.799999   \n",
      "4       relu       5  79.699999  84.500003  88.999999  88.499999  86.299998   \n",
      "5       relu       6  85.100001  88.900000  86.100000  88.700002  84.799999   \n",
      "6       relu       7  80.900002  87.800002  88.499999  77.899998  82.999998   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
      "3  88.999999  85.600001  87.000000  79.500002  85.600001  86.260000  \n",
      "4  84.799999  83.399999  83.200002  88.200003  79.900002  84.750000  \n",
      "5  76.499999  86.299998  88.700002  76.300001  82.099998  84.350000  \n",
      "6  84.799999  84.700000  89.499998  85.299999  86.100000  84.850000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 86.69999837875366\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 84.50000286102295\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 84.3999981880188\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.09999799728394\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.99999952316284\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 87.59999871253967\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 85.6000006198883\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 71.8999981880188\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 85.39999723434448\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 88.09999823570251\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
      "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
      "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
      "3       relu       4  87.199998  85.000002  85.799998  87.099999  90.799999   \n",
      "4       relu       5  79.699999  84.500003  88.999999  88.499999  86.299998   \n",
      "5       relu       6  85.100001  88.900000  86.100000  88.700002  84.799999   \n",
      "6       relu       7  80.900002  87.800002  88.499999  77.899998  82.999998   \n",
      "7       relu       8  86.699998  84.500003  84.399998  82.099998  88.000000   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
      "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
      "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
      "3  88.999999  85.600001  87.000000  79.500002  85.600001  86.260000  \n",
      "4  84.799999  83.399999  83.200002  88.200003  79.900002  84.750000  \n",
      "5  76.499999  86.299998  88.700002  76.300001  82.099998  84.350000  \n",
      "6  84.799999  84.700000  89.499998  85.299999  86.100000  84.850000  \n",
      "7  87.599999  85.600001  71.899998  85.399997  88.099998  84.429999  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "            \n",
    "            \n",
    "            emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "            \n",
    "            # Define the input shape\n",
    "            model = define_model_2(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                 max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=30, verbose=0, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record2 = record2.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record2)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>86.799997</td>\n",
       "      <td>88.099998</td>\n",
       "      <td>89.200002</td>\n",
       "      <td>89.099997</td>\n",
       "      <td>85.699999</td>\n",
       "      <td>88.099998</td>\n",
       "      <td>91.000003</td>\n",
       "      <td>87.599999</td>\n",
       "      <td>88.900000</td>\n",
       "      <td>82.999998</td>\n",
       "      <td>87.749999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>89.999998</td>\n",
       "      <td>88.300002</td>\n",
       "      <td>84.799999</td>\n",
       "      <td>89.499998</td>\n",
       "      <td>85.500002</td>\n",
       "      <td>80.199999</td>\n",
       "      <td>85.200000</td>\n",
       "      <td>90.100002</td>\n",
       "      <td>89.099997</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>87.409999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>87.199998</td>\n",
       "      <td>85.000002</td>\n",
       "      <td>85.799998</td>\n",
       "      <td>87.099999</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>88.999999</td>\n",
       "      <td>85.600001</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>79.500002</td>\n",
       "      <td>85.600001</td>\n",
       "      <td>86.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>87.400001</td>\n",
       "      <td>84.799999</td>\n",
       "      <td>83.899999</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>81.199998</td>\n",
       "      <td>90.700001</td>\n",
       "      <td>83.399999</td>\n",
       "      <td>88.700002</td>\n",
       "      <td>80.500001</td>\n",
       "      <td>85.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>80.900002</td>\n",
       "      <td>87.800002</td>\n",
       "      <td>88.499999</td>\n",
       "      <td>77.899998</td>\n",
       "      <td>82.999998</td>\n",
       "      <td>84.799999</td>\n",
       "      <td>84.700000</td>\n",
       "      <td>89.499998</td>\n",
       "      <td>85.299999</td>\n",
       "      <td>86.100000</td>\n",
       "      <td>84.850000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>79.699999</td>\n",
       "      <td>84.500003</td>\n",
       "      <td>88.999999</td>\n",
       "      <td>88.499999</td>\n",
       "      <td>86.299998</td>\n",
       "      <td>84.799999</td>\n",
       "      <td>83.399999</td>\n",
       "      <td>83.200002</td>\n",
       "      <td>88.200003</td>\n",
       "      <td>79.900002</td>\n",
       "      <td>84.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>86.699998</td>\n",
       "      <td>84.500003</td>\n",
       "      <td>84.399998</td>\n",
       "      <td>82.099998</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>87.599999</td>\n",
       "      <td>85.600001</td>\n",
       "      <td>71.899998</td>\n",
       "      <td>85.399997</td>\n",
       "      <td>88.099998</td>\n",
       "      <td>84.429999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>85.100001</td>\n",
       "      <td>88.900000</td>\n",
       "      <td>86.100000</td>\n",
       "      <td>88.700002</td>\n",
       "      <td>84.799999</td>\n",
       "      <td>76.499999</td>\n",
       "      <td>86.299998</td>\n",
       "      <td>88.700002</td>\n",
       "      <td>76.300001</td>\n",
       "      <td>82.099998</td>\n",
       "      <td>84.350000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "2       relu       3  86.799997  88.099998  89.200002  89.099997  85.699999   \n",
       "0       relu       1  89.999998  88.300002  84.799999  89.499998  85.500002   \n",
       "3       relu       4  87.199998  85.000002  85.799998  87.099999  90.799999   \n",
       "1       relu       2  88.599998  87.400001  84.799999  83.899999  89.800000   \n",
       "6       relu       7  80.900002  87.800002  88.499999  77.899998  82.999998   \n",
       "4       relu       5  79.699999  84.500003  88.999999  88.499999  86.299998   \n",
       "7       relu       8  86.699998  84.500003  84.399998  82.099998  88.000000   \n",
       "5       relu       6  85.100001  88.900000  86.100000  88.700002  84.799999   \n",
       "\n",
       "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "2  88.099998  91.000003  87.599999  88.900000  82.999998  87.749999  \n",
       "0  80.199999  85.200000  90.100002  89.099997  91.399997  87.409999  \n",
       "3  88.999999  85.600001  87.000000  79.500002  85.600001  86.260000  \n",
       "1  81.199998  90.700001  83.399999  88.700002  80.500001  85.900000  \n",
       "6  84.799999  84.700000  89.499998  85.299999  86.100000  84.850000  \n",
       "4  84.799999  83.399999  83.200002  88.200003  79.900002  84.750000  \n",
       "7  87.599999  85.600001  71.899998  85.399997  88.099998  84.429999  \n",
       "5  76.499999  86.299998  88.700002  76.300001  82.099998  84.350000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>87.749999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AVG\n",
       "Activation           \n",
       "relu        87.749999"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_SUBJ_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(filters = 100, kernel_size = 3, activation='relu', \n",
    "                 input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_202\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_202 (Embedding)    (None, 100, 300)          6088200   \n",
      "_________________________________________________________________\n",
      "conv1d_202 (Conv1D)          (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_202 (MaxPoolin (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_202 (Flatten)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_404 (Dropout)        (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_404 (Dense)            (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_405 (Dropout)        (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_405 (Dense)            (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 6,227,321\n",
      "Trainable params: 6,227,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(vocab_size, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 89.49999809265137\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 88.59999775886536\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.39999842643738\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 90.10000228881836\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "\n",
      "  Activation Filters  acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.7  91.799998  89.499998  88.599998  92.299998   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 88.80000114440918\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.90000295639038\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 86.10000014305115\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.00000166893005\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.50000214576721\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Test Accuracy: 89.80000019073486\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 93.90000104904175\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 89.0999972820282\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.80000114440918\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 86.19999885559082\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 89.80000019073486\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 88.7000024318695\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 86.2999975681305\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.79999828338623\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 86.90000176429749\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
      "3       relu       4  89.800000  91.799998  88.700002  91.299999  91.299999   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
      "3  86.299998  91.799998  90.799999  86.900002  91.600001  90.030000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 90.39999842643738\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 92.1999990940094\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 88.89999985694885\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 91.00000262260437\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 88.59999775886536\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 90.2999997138977\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 93.19999814033508\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 89.70000147819519\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.69999957084656\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.10000038146973\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
      "3       relu       4  89.800000  91.799998  88.700002  91.299999  91.299999   \n",
      "4       relu       5  90.399998  92.199999  88.900000  91.000003  88.599998   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
      "3  86.299998  91.799998  90.799999  86.900002  91.600001  90.030000  \n",
      "4  90.300000  93.199998  89.700001  91.700000  92.100000  90.810000  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.49999809265137\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 91.20000004768372\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 88.30000162124634\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 91.29999876022339\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 89.80000019073486\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 93.30000281333923\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.7000024318695\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 89.3999993801117\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 90.10000228881836\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
      "3       relu       4  89.800000  91.799998  88.700002  91.299999  91.299999   \n",
      "4       relu       5  90.399998  92.199999  88.900000  91.000003  88.599998   \n",
      "5       relu       6  89.499998  91.200000  88.300002  91.299999  89.800000   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
      "3  86.299998  91.799998  90.799999  86.900002  91.600001  90.030000  \n",
      "4  90.300000  93.199998  89.700001  91.700000  92.100000  90.810000  \n",
      "5  90.799999  93.300003  88.700002  89.399999  90.100002  90.240000  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 92.69999861717224\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.6000018119812\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 92.29999780654907\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 87.30000257492065\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 90.10000228881836\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 90.20000100135803\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 91.10000133514404\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
      "3       relu       4  89.800000  91.799998  88.700002  91.299999  91.299999   \n",
      "4       relu       5  90.399998  92.199999  88.900000  91.000003  88.599998   \n",
      "5       relu       6  89.499998  91.200000  88.300002  91.299999  89.800000   \n",
      "6       relu       7  92.699999  91.399997  91.600001  91.100001  90.600002   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
      "3  86.299998  91.799998  90.799999  86.900002  91.600001  90.030000  \n",
      "4  90.300000  93.199998  89.700001  91.700000  92.100000  90.810000  \n",
      "5  90.799999  93.300003  88.700002  89.399999  90.100002  90.240000  \n",
      "6  92.299998  87.300003  90.100002  90.200001  91.100001  90.840001  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 88.99999856948853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 88.99999856948853\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 90.79999923706055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 90.89999794960022\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 91.39999747276306\n",
      "Test Accuracy: 89.0999972820282\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 90.89999794960022\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 92.40000247955322\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 91.60000085830688\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
      "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
      "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
      "3       relu       4  89.800000  91.799998  88.700002  91.299999  91.299999   \n",
      "4       relu       5  90.399998  92.199999  88.900000  91.000003  88.599998   \n",
      "5       relu       6  89.499998  91.200000  88.300002  91.299999  89.800000   \n",
      "6       relu       7  92.699999  91.399997  91.600001  91.100001  90.600002   \n",
      "7       relu       8  88.999999  90.799999  88.999999  90.799999  90.899998   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
      "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
      "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
      "3  86.299998  91.799998  90.799999  86.900002  91.600001  90.030000  \n",
      "4  90.300000  93.199998  89.700001  91.700000  92.100000  90.810000  \n",
      "5  90.799999  93.300003  88.700002  89.399999  90.100002  90.240000  \n",
      "6  92.299998  87.300003  90.100002  90.200001  91.100001  90.840001  \n",
      "7  91.399997  89.099997  90.899998  92.400002  91.600001  90.589999  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "            \n",
    "            \n",
    "            emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "            \n",
    "            # Define the input shape\n",
    "            model = define_model_3(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                 max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=20, verbose=0, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record3 = record3.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record3)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>89.499998</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>90.399998</td>\n",
       "      <td>90.100002</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>90.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>88.800001</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>91.900003</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>86.100000</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>90.870001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>92.699999</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>90.600002</td>\n",
       "      <td>92.299998</td>\n",
       "      <td>87.300003</td>\n",
       "      <td>90.100002</td>\n",
       "      <td>90.200001</td>\n",
       "      <td>91.100001</td>\n",
       "      <td>90.840001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>90.399998</td>\n",
       "      <td>92.199999</td>\n",
       "      <td>88.900000</td>\n",
       "      <td>91.000003</td>\n",
       "      <td>88.599998</td>\n",
       "      <td>90.300000</td>\n",
       "      <td>93.199998</td>\n",
       "      <td>89.700001</td>\n",
       "      <td>91.700000</td>\n",
       "      <td>92.100000</td>\n",
       "      <td>90.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>92.000002</td>\n",
       "      <td>91.500002</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>93.900001</td>\n",
       "      <td>89.099997</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>88.800001</td>\n",
       "      <td>86.199999</td>\n",
       "      <td>90.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>88.999999</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>88.999999</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>91.399997</td>\n",
       "      <td>89.099997</td>\n",
       "      <td>90.899998</td>\n",
       "      <td>92.400002</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>90.589999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>89.499998</td>\n",
       "      <td>91.200000</td>\n",
       "      <td>88.300002</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>93.300003</td>\n",
       "      <td>88.700002</td>\n",
       "      <td>89.399999</td>\n",
       "      <td>90.100002</td>\n",
       "      <td>90.240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>89.800000</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>88.700002</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>91.299999</td>\n",
       "      <td>86.299998</td>\n",
       "      <td>91.799998</td>\n",
       "      <td>90.799999</td>\n",
       "      <td>86.900002</td>\n",
       "      <td>91.600001</td>\n",
       "      <td>90.030000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "0       relu       1  91.700000  91.799998  89.499998  88.599998  92.299998   \n",
       "1       relu       2  88.800001  92.400002  90.799999  91.900003  91.299999   \n",
       "6       relu       7  92.699999  91.399997  91.600001  91.100001  90.600002   \n",
       "4       relu       5  90.399998  92.199999  88.900000  91.000003  88.599998   \n",
       "2       relu       3  92.000002  91.500002  91.600001  89.800000  91.399997   \n",
       "7       relu       8  88.999999  90.799999  88.999999  90.799999  90.899998   \n",
       "5       relu       6  89.499998  91.200000  88.300002  91.299999  89.800000   \n",
       "3       relu       4  89.800000  91.799998  88.700002  91.299999  91.299999   \n",
       "\n",
       "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "0  90.399998  90.100002  91.399997  91.500002  91.600001  90.889999  \n",
       "1  91.900003  92.400002  86.100000  91.600001  91.500002  90.870001  \n",
       "6  92.299998  87.300003  90.100002  90.200001  91.100001  90.840001  \n",
       "4  90.300000  93.199998  89.700001  91.700000  92.100000  90.810000  \n",
       "2  93.900001  89.099997  91.799998  88.800001  86.199999  90.610000  \n",
       "7  91.399997  89.099997  90.899998  92.400002  91.600001  90.589999  \n",
       "5  90.799999  93.300003  88.700002  89.399999  90.100002  90.240000  \n",
       "3  86.299998  91.799998  90.799999  86.900002  91.600001  90.030000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_SUBJ_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
