{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Classification with CR Dataset\n",
    "<hr>\n",
    "\n",
    "The __modus operandi__ for text classification is to use __word embedding__ for representing words and a Convolutional neural network to learn how to discriminate documents on classification problems. \n",
    "\n",
    "__Yoav Goldberg__ commented in _A Primer on Neural Network Models for Natural Language Processing, 2015._ :\n",
    "> _The non-linearity of the network, as well as the ability to easily integrate pre-trained\n",
    "word embeddings, often lead to superior classification accuracy._\n",
    "\n",
    "He also commented in _Neural Network Methods for Natural Language Processing, 2017_ :\n",
    "> ... _the CNN is in essence a feature-extracting architecture. ... . The CNNs layer's responsibility is to extract meaningful sub-structures that are useful for the overall prediction task at hand._\n",
    "\n",
    "We will build a text classification model using CNN model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 3, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2): 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3775, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>weaknesses are minor the feel and layout of th...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>many of our disney movies do n 't play on this...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>player has a problem with dual layer dvd 's su...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i know the saying is you get what you pay for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>will never purchase apex again .</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3770</th>\n",
       "      <td>so far , the anti spam feature seems to be ver...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3771</th>\n",
       "      <td>i downloaded a trial version of computer assoc...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>i did not have any of the installation problem...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>their products have been great and have saved ...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3775 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentence  label  split\n",
       "0     weaknesses are minor the feel and layout of th...      0  train\n",
       "1     many of our disney movies do n 't play on this...      0  train\n",
       "2     player has a problem with dual layer dvd 's su...      0  train\n",
       "3     i know the saying is you get what you pay for ...      0  train\n",
       "4                      will never purchase apex again .      0  train\n",
       "...                                                 ...    ...    ...\n",
       "3770  so far , the anti spam feature seems to be ver...      1  train\n",
       "3771  i downloaded a trial version of computer assoc...      1  train\n",
       "3772  i did not have any of the installation problem...      1  train\n",
       "3773  their products have been great and have saved ...      1  train\n",
       "3774                                                         1  train\n",
       "\n",
       "[3775 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/CR/CR.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3775 entries, 0 to 3774\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3775 non-null   object\n",
      " 1   label     3775 non-null   int32 \n",
      " 2   split     3775 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 73.9+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1368</td>\n",
       "      <td>1368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2407</td>\n",
       "      <td>2407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          1368   1368\n",
       "1          2407   2407"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  will never purchase apex again .\n",
      "Into a sequence of int: [72, 194, 285, 207, 286]\n",
      "Into a padded sequence: [ 72 194 285 207 286   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "and 3\n",
      "i 4\n",
      "it 5\n",
      "to 6\n",
      "a 7\n",
      "is 8\n",
      "of 9\n",
      "this 10\n",
      "5336\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "A __standard model__ for document classification is to use (quoted from __Jason Brownlee__, the author of [machinelearningmastery.com](https://machinelearningmastery.com)):\n",
    ">- Word Embedding: A distributed representation of words where different words that have a similar meaning (based on their usage) also have a similar representation.\n",
    ">- Convolutional Model: A feature extraction model that learns to extract salient features from documents represented using a word embedding.\n",
    ">- Fully Connected Model: The interpretation of extracted features in terms of a predictive output.\n",
    "\n",
    "\n",
    "Therefore, the model is comprised of the following elements:\n",
    "- __Input layer__ that defines the length of input sequences.\n",
    "- __Embedding layer__ set to the size of the vocabulary and 100-dimensional real-valued representations.\n",
    "- __Conv1D layer__ with 32 filters and a kernel size set to the number of words to read at once.\n",
    "- __MaxPooling1D layer__ to consolidate the output from the convolutional layer.\n",
    "- __Flatten layer__ to reduce the three-dimensional output to two dimensional for concatenation.\n",
    "\n",
    "The CNN model is inspired by __Yoon Kim__ paper in his study on the use of Word Embedding + CNN for text classification. The hyperparameters we use based on his study are as follows:\n",
    "- Transfer function: rectified linear.\n",
    "- Kernel sizes: 3, 4, 5.\n",
    "- Number of filters: 100.\n",
    "- Dropout rate: 0.5.\n",
    "- Weight regularization (L2): 3.\n",
    "- Batch Size: 50.\n",
    "- Update Rule: Adam\n",
    "\n",
    "We will perform the best parameter using __grid search__ and 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "\n",
    "Now, we will build Convolutional Neural Network (CNN) models to classify encoded documents as either positive or negative.\n",
    "\n",
    "The model takes inspiration from `CNN for Sentence Classification` by *Yoon Kim*.\n",
    "\n",
    "Now, we will define our CNN model as follows:\n",
    "- One Conv layer with 100 filters, kernel size 5, and relu activation function;\n",
    "- One MaxPool layer with pool size = 2;\n",
    "- One Dropout layer after flattened;\n",
    "- Optimizer: Adam (The best learning algorithm so far)\n",
    "- Loss function: binary cross-entropy (suited for binary classification problem)\n",
    "\n",
    "**Note**: \n",
    "- The whole purpose of dropout layers is to tackle the problem of over-fitting and to introduce generalization to the model. Hence it is advisable to keep dropout parameter near 0.5 in hidden layers. \n",
    "- https://missinglink.ai/guides/keras/keras-conv1d-working-1d-convolutional-neural-networks-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(filters = 100, kernel_size = 3, activation='relu', input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1012\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1019 (Embedding)   (None, 100, 300)          1530000   \n",
      "_________________________________________________________________\n",
      "conv1d_1014 (Conv1D)         (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1014 (MaxPooli (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1014 (Flatten)       (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2021 (Dropout)       (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_2019 (Dense)           (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_2022 (Dropout)       (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2020 (Dense)           (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,669,121\n",
      "Trainable params: 1,669,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6557 - accuracy: 0.6359 - val_loss: 0.6421 - val_accuracy: 0.6270\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5799 - accuracy: 0.6479 - val_loss: 0.5172 - val_accuracy: 0.7196\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4034 - accuracy: 0.8101 - val_loss: 0.4896 - val_accuracy: 0.7646\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.2734 - accuracy: 0.8973 - val_loss: 0.4734 - val_accuracy: 0.7804\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.1999 - accuracy: 0.9320 - val_loss: 0.5114 - val_accuracy: 0.7963\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.1623 - accuracy: 0.9520 - val_loss: 0.6358 - val_accuracy: 0.7751\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.1230 - accuracy: 0.9661 - val_loss: 0.7181 - val_accuracy: 0.7831\n",
      "Epoch 8/15\n",
      "68/68 - 3s - loss: 0.0856 - accuracy: 0.9756 - val_loss: 0.8507 - val_accuracy: 0.7698\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.0752 - accuracy: 0.9800 - val_loss: 0.9476 - val_accuracy: 0.7831\n",
      "Epoch 10/15\n",
      "68/68 - 3s - loss: 0.0654 - accuracy: 0.9794 - val_loss: 1.0139 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6547 - accuracy: 0.6370 - val_loss: 0.6539 - val_accuracy: 0.6032\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5855 - accuracy: 0.6414 - val_loss: 0.5530 - val_accuracy: 0.6032\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4621 - accuracy: 0.7495 - val_loss: 0.5227 - val_accuracy: 0.7487\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3113 - accuracy: 0.8899 - val_loss: 0.5438 - val_accuracy: 0.7540\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1959 - accuracy: 0.9382 - val_loss: 0.5326 - val_accuracy: 0.7646\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1504 - accuracy: 0.9600 - val_loss: 0.5990 - val_accuracy: 0.7619\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1271 - accuracy: 0.9691 - val_loss: 0.6281 - val_accuracy: 0.7804\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0943 - accuracy: 0.9806 - val_loss: 0.8501 - val_accuracy: 0.7698\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0898 - accuracy: 0.9817 - val_loss: 0.8808 - val_accuracy: 0.7725\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0616 - accuracy: 0.9868 - val_loss: 0.9030 - val_accuracy: 0.7751\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0556 - accuracy: 0.9862 - val_loss: 1.0119 - val_accuracy: 0.7831\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0529 - accuracy: 0.9903 - val_loss: 1.0345 - val_accuracy: 0.7778\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0494 - accuracy: 0.9885 - val_loss: 1.1066 - val_accuracy: 0.7963\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0448 - accuracy: 0.9915 - val_loss: 1.0687 - val_accuracy: 0.7778\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0417 - accuracy: 0.9912 - val_loss: 1.1221 - val_accuracy: 0.7831\n",
      "Test Accuracy: 78.30687761306763\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6571 - accuracy: 0.6394 - val_loss: 0.6478 - val_accuracy: 0.6164\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5705 - accuracy: 0.6668 - val_loss: 0.5026 - val_accuracy: 0.7487\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4093 - accuracy: 0.7775 - val_loss: 0.4915 - val_accuracy: 0.7540\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.2827 - accuracy: 0.8943 - val_loss: 0.5186 - val_accuracy: 0.7725\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.2003 - accuracy: 0.9335 - val_loss: 0.6306 - val_accuracy: 0.7619\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.1611 - accuracy: 0.9452 - val_loss: 0.6206 - val_accuracy: 0.7751\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1299 - accuracy: 0.9597 - val_loss: 0.7439 - val_accuracy: 0.7725\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1161 - accuracy: 0.9656 - val_loss: 0.8271 - val_accuracy: 0.7672\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.1055 - accuracy: 0.9682 - val_loss: 0.9112 - val_accuracy: 0.7487\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0931 - accuracy: 0.9747 - val_loss: 1.0470 - val_accuracy: 0.7698\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0985 - accuracy: 0.9712 - val_loss: 1.0585 - val_accuracy: 0.7540\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 77.51322984695435\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6633 - accuracy: 0.6320 - val_loss: 0.6280 - val_accuracy: 0.6667\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.6083 - accuracy: 0.6344 - val_loss: 0.5424 - val_accuracy: 0.6667\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4998 - accuracy: 0.6600 - val_loss: 0.4791 - val_accuracy: 0.7381\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.4105 - accuracy: 0.8452 - val_loss: 0.4780 - val_accuracy: 0.7989\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.3603 - accuracy: 0.8840 - val_loss: 0.5183 - val_accuracy: 0.8016\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.3044 - accuracy: 0.9102 - val_loss: 0.5091 - val_accuracy: 0.8254\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.2299 - accuracy: 0.9370 - val_loss: 0.5951 - val_accuracy: 0.8042\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1646 - accuracy: 0.9479 - val_loss: 0.6549 - val_accuracy: 0.7778\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.1197 - accuracy: 0.9608 - val_loss: 0.8003 - val_accuracy: 0.7937\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.1137 - accuracy: 0.9679 - val_loss: 0.7864 - val_accuracy: 0.7963\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.1038 - accuracy: 0.9632 - val_loss: 0.8639 - val_accuracy: 0.8122\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6638 - accuracy: 0.6273 - val_loss: 0.6231 - val_accuracy: 0.6772\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5973 - accuracy: 0.6332 - val_loss: 0.5314 - val_accuracy: 0.6772\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4775 - accuracy: 0.7142 - val_loss: 0.4391 - val_accuracy: 0.8016\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.3337 - accuracy: 0.8705 - val_loss: 0.4271 - val_accuracy: 0.8016\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.2239 - accuracy: 0.9140 - val_loss: 0.4536 - val_accuracy: 0.7804\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1467 - accuracy: 0.9461 - val_loss: 0.6503 - val_accuracy: 0.7910\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1225 - accuracy: 0.9485 - val_loss: 0.6577 - val_accuracy: 0.7937\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0830 - accuracy: 0.9670 - val_loss: 0.8021 - val_accuracy: 0.7963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n",
      "68/68 - 4s - loss: 0.6581 - accuracy: 0.6389 - val_loss: 0.6419 - val_accuracy: 0.6233\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5728 - accuracy: 0.6392 - val_loss: 0.5221 - val_accuracy: 0.6233\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4312 - accuracy: 0.7725 - val_loss: 0.5118 - val_accuracy: 0.7639\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.3192 - accuracy: 0.8902 - val_loss: 0.5133 - val_accuracy: 0.7613\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2255 - accuracy: 0.9250 - val_loss: 0.5608 - val_accuracy: 0.7613\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1517 - accuracy: 0.9491 - val_loss: 0.6738 - val_accuracy: 0.7586\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1079 - accuracy: 0.9656 - val_loss: 0.7425 - val_accuracy: 0.7745\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0726 - accuracy: 0.9717 - val_loss: 0.8874 - val_accuracy: 0.7639\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0569 - accuracy: 0.9800 - val_loss: 0.9795 - val_accuracy: 0.7719\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0574 - accuracy: 0.9800 - val_loss: 0.9944 - val_accuracy: 0.7745\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0474 - accuracy: 0.9838 - val_loss: 1.0682 - val_accuracy: 0.7825\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0454 - accuracy: 0.9838 - val_loss: 1.1556 - val_accuracy: 0.7692\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0361 - accuracy: 0.9871 - val_loss: 1.2585 - val_accuracy: 0.7613\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0465 - accuracy: 0.9856 - val_loss: 1.2733 - val_accuracy: 0.7719\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0374 - accuracy: 0.9856 - val_loss: 1.2173 - val_accuracy: 0.7825\n",
      "Test Accuracy: 78.24933528900146\n",
      "Epoch 1/15\n",
      "68/68 - 4s - loss: 0.6636 - accuracy: 0.6345 - val_loss: 0.6404 - val_accuracy: 0.6313\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.6007 - accuracy: 0.6383 - val_loss: 0.5301 - val_accuracy: 0.6313\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4556 - accuracy: 0.7216 - val_loss: 0.4251 - val_accuracy: 0.8011\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.2915 - accuracy: 0.8835 - val_loss: 0.4410 - val_accuracy: 0.7878\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.1846 - accuracy: 0.9385 - val_loss: 0.4905 - val_accuracy: 0.8223\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1392 - accuracy: 0.9597 - val_loss: 0.5269 - val_accuracy: 0.8143\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1017 - accuracy: 0.9709 - val_loss: 0.6627 - val_accuracy: 0.8143\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0829 - accuracy: 0.9738 - val_loss: 0.7209 - val_accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0720 - accuracy: 0.9782 - val_loss: 0.7699 - val_accuracy: 0.8011\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0599 - accuracy: 0.9809 - val_loss: 0.8111 - val_accuracy: 0.8011\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "Epoch 1/15\n",
      "68/68 - 4s - loss: 0.6578 - accuracy: 0.6324 - val_loss: 0.6326 - val_accuracy: 0.6711\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5823 - accuracy: 0.6342 - val_loss: 0.5137 - val_accuracy: 0.6711\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4440 - accuracy: 0.7828 - val_loss: 0.4896 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.3115 - accuracy: 0.8952 - val_loss: 0.5309 - val_accuracy: 0.7745\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.2441 - accuracy: 0.9341 - val_loss: 0.5694 - val_accuracy: 0.7984\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.2008 - accuracy: 0.9562 - val_loss: 0.5949 - val_accuracy: 0.7851\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.1715 - accuracy: 0.9644 - val_loss: 0.6604 - val_accuracy: 0.7851\n",
      "Epoch 8/15\n",
      "68/68 - 3s - loss: 0.1494 - accuracy: 0.9765 - val_loss: 0.7158 - val_accuracy: 0.7719\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.1400 - accuracy: 0.9823 - val_loss: 0.8592 - val_accuracy: 0.7772\n",
      "Epoch 10/15\n",
      "68/68 - 3s - loss: 0.1229 - accuracy: 0.9853 - val_loss: 0.9073 - val_accuracy: 0.7745\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6582 - accuracy: 0.6351 - val_loss: 0.6428 - val_accuracy: 0.6286\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5993 - accuracy: 0.6407 - val_loss: 0.5640 - val_accuracy: 0.6366\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4320 - accuracy: 0.7805 - val_loss: 0.4577 - val_accuracy: 0.7878\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2911 - accuracy: 0.8788 - val_loss: 0.4747 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1920 - accuracy: 0.9300 - val_loss: 0.5341 - val_accuracy: 0.7931\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1405 - accuracy: 0.9461 - val_loss: 0.5993 - val_accuracy: 0.7878\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1109 - accuracy: 0.9585 - val_loss: 0.6324 - val_accuracy: 0.7798\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0899 - accuracy: 0.9635 - val_loss: 0.7318 - val_accuracy: 0.7825\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0818 - accuracy: 0.9620 - val_loss: 0.8229 - val_accuracy: 0.7851\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6544 - accuracy: 0.6371 - val_loss: 0.6366 - val_accuracy: 0.6313\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5572 - accuracy: 0.6978 - val_loss: 0.5138 - val_accuracy: 0.7507\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3810 - accuracy: 0.8237 - val_loss: 0.4725 - val_accuracy: 0.7692\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2567 - accuracy: 0.9064 - val_loss: 0.4853 - val_accuracy: 0.7905\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1637 - accuracy: 0.9423 - val_loss: 0.5490 - val_accuracy: 0.7878\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1316 - accuracy: 0.9597 - val_loss: 0.5841 - val_accuracy: 0.7878\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1022 - accuracy: 0.9715 - val_loss: 0.6120 - val_accuracy: 0.7851\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0841 - accuracy: 0.9723 - val_loss: 0.7677 - val_accuracy: 0.7586\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0730 - accuracy: 0.9759 - val_loss: 0.8199 - val_accuracy: 0.7719\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "\n",
      "  Activation Filters      acc1       acc2      acc3       acc4       acc5  \\\n",
      "0       relu       1  79.62963  78.306878  77.51323  82.539684  80.158728   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 4s - loss: 0.6645 - accuracy: 0.6297 - val_loss: 0.6487 - val_accuracy: 0.6270\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.6154 - accuracy: 0.6388 - val_loss: 0.5810 - val_accuracy: 0.6270\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.4977 - accuracy: 0.7112 - val_loss: 0.5121 - val_accuracy: 0.7302\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.3478 - accuracy: 0.8555 - val_loss: 0.5241 - val_accuracy: 0.7434\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.2584 - accuracy: 0.9176 - val_loss: 0.5759 - val_accuracy: 0.7751\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.1919 - accuracy: 0.9558 - val_loss: 0.6463 - val_accuracy: 0.7540\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.1519 - accuracy: 0.9717 - val_loss: 0.7156 - val_accuracy: 0.7672\n",
      "Epoch 8/15\n",
      "68/68 - 3s - loss: 0.1337 - accuracy: 0.9747 - val_loss: 0.8331 - val_accuracy: 0.7381\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.1248 - accuracy: 0.9803 - val_loss: 0.9117 - val_accuracy: 0.7513\n",
      "Epoch 10/15\n",
      "68/68 - 3s - loss: 0.1138 - accuracy: 0.9812 - val_loss: 0.9910 - val_accuracy: 0.7593\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 77.51322984695435\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6600 - accuracy: 0.6329 - val_loss: 0.6191 - val_accuracy: 0.6587\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5811 - accuracy: 0.6353 - val_loss: 0.5132 - val_accuracy: 0.6587\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4212 - accuracy: 0.7925 - val_loss: 0.4829 - val_accuracy: 0.7884\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2760 - accuracy: 0.8893 - val_loss: 0.4576 - val_accuracy: 0.8148\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1831 - accuracy: 0.9252 - val_loss: 0.5166 - val_accuracy: 0.7963\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1289 - accuracy: 0.9452 - val_loss: 0.6052 - val_accuracy: 0.7937\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1018 - accuracy: 0.9594 - val_loss: 0.6794 - val_accuracy: 0.7857\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0776 - accuracy: 0.9644 - val_loss: 0.7136 - val_accuracy: 0.7989\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0860 - accuracy: 0.9620 - val_loss: 0.7987 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6642 - accuracy: 0.6311 - val_loss: 0.6410 - val_accuracy: 0.6587\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5829 - accuracy: 0.6353 - val_loss: 0.5214 - val_accuracy: 0.6587\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4281 - accuracy: 0.7769 - val_loss: 0.4908 - val_accuracy: 0.7804\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3015 - accuracy: 0.8923 - val_loss: 0.5127 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2084 - accuracy: 0.9299 - val_loss: 0.6071 - val_accuracy: 0.7698\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1455 - accuracy: 0.9520 - val_loss: 0.6553 - val_accuracy: 0.7804\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1014 - accuracy: 0.9682 - val_loss: 1.0042 - val_accuracy: 0.7646\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0719 - accuracy: 0.9788 - val_loss: 0.9289 - val_accuracy: 0.7963\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0769 - accuracy: 0.9764 - val_loss: 0.9986 - val_accuracy: 0.7698\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0600 - accuracy: 0.9817 - val_loss: 0.9973 - val_accuracy: 0.7751\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0545 - accuracy: 0.9806 - val_loss: 1.1011 - val_accuracy: 0.7725\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0570 - accuracy: 0.9876 - val_loss: 1.1782 - val_accuracy: 0.7857\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0463 - accuracy: 0.9850 - val_loss: 1.1554 - val_accuracy: 0.7672\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6685 - accuracy: 0.6406 - val_loss: 0.6676 - val_accuracy: 0.5979\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6274 - accuracy: 0.6420 - val_loss: 0.5857 - val_accuracy: 0.5979\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.5047 - accuracy: 0.7306 - val_loss: 0.4302 - val_accuracy: 0.7884\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3529 - accuracy: 0.8817 - val_loss: 0.4363 - val_accuracy: 0.7804\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2436 - accuracy: 0.9302 - val_loss: 0.4588 - val_accuracy: 0.7884\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1770 - accuracy: 0.9688 - val_loss: 0.5300 - val_accuracy: 0.7831\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1348 - accuracy: 0.9803 - val_loss: 0.6117 - val_accuracy: 0.7910\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1212 - accuracy: 0.9841 - val_loss: 0.6311 - val_accuracy: 0.7937\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.1084 - accuracy: 0.9900 - val_loss: 0.6897 - val_accuracy: 0.8016\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0946 - accuracy: 0.9953 - val_loss: 0.7870 - val_accuracy: 0.7884\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.1000 - accuracy: 0.9926 - val_loss: 0.7859 - val_accuracy: 0.8042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0828 - accuracy: 0.9965 - val_loss: 0.8773 - val_accuracy: 0.8122\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0849 - accuracy: 0.9929 - val_loss: 0.8501 - val_accuracy: 0.7937\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0802 - accuracy: 0.9950 - val_loss: 0.9222 - val_accuracy: 0.8069\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0728 - accuracy: 0.9965 - val_loss: 0.9144 - val_accuracy: 0.8042\n",
      "Test Accuracy: 80.42327761650085\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6681 - accuracy: 0.6241 - val_loss: 0.6353 - val_accuracy: 0.6640\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.6240 - accuracy: 0.6347 - val_loss: 0.5481 - val_accuracy: 0.6640\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4957 - accuracy: 0.6347 - val_loss: 0.5100 - val_accuracy: 0.6640\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3625 - accuracy: 0.8516 - val_loss: 0.5474 - val_accuracy: 0.7831\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2441 - accuracy: 0.8893 - val_loss: 0.5706 - val_accuracy: 0.7857\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1661 - accuracy: 0.9176 - val_loss: 0.6003 - val_accuracy: 0.7857\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1103 - accuracy: 0.9397 - val_loss: 0.7385 - val_accuracy: 0.8016\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0953 - accuracy: 0.9426 - val_loss: 0.8248 - val_accuracy: 0.7884\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0818 - accuracy: 0.9526 - val_loss: 0.8624 - val_accuracy: 0.7804\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0756 - accuracy: 0.9520 - val_loss: 1.0052 - val_accuracy: 0.7593\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0634 - accuracy: 0.9712 - val_loss: 1.0940 - val_accuracy: 0.7513\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0601 - accuracy: 0.9709 - val_loss: 1.2287 - val_accuracy: 0.7460\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6585 - accuracy: 0.6374 - val_loss: 0.6557 - val_accuracy: 0.6127\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.6063 - accuracy: 0.6404 - val_loss: 0.5436 - val_accuracy: 0.6127\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4731 - accuracy: 0.7113 - val_loss: 0.4753 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3746 - accuracy: 0.8061 - val_loss: 0.4814 - val_accuracy: 0.7984\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.3052 - accuracy: 0.8664 - val_loss: 0.4957 - val_accuracy: 0.7958\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.2510 - accuracy: 0.8793 - val_loss: 0.5200 - val_accuracy: 0.7984\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1734 - accuracy: 0.8938 - val_loss: 0.6178 - val_accuracy: 0.7878\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1403 - accuracy: 0.8988 - val_loss: 0.6385 - val_accuracy: 0.8011\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.1133 - accuracy: 0.9108 - val_loss: 0.7460 - val_accuracy: 0.7984\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0936 - accuracy: 0.9582 - val_loss: 0.8158 - val_accuracy: 0.7931\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0924 - accuracy: 0.9688 - val_loss: 0.8262 - val_accuracy: 0.7984\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0892 - accuracy: 0.9703 - val_loss: 0.8840 - val_accuracy: 0.7878\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0796 - accuracy: 0.9738 - val_loss: 1.0156 - val_accuracy: 0.7745\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6615 - accuracy: 0.6360 - val_loss: 0.6581 - val_accuracy: 0.6260\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6096 - accuracy: 0.6542 - val_loss: 0.5462 - val_accuracy: 0.7241\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4708 - accuracy: 0.7263 - val_loss: 0.4798 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3685 - accuracy: 0.7602 - val_loss: 0.4961 - val_accuracy: 0.7692\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2832 - accuracy: 0.8408 - val_loss: 0.5418 - val_accuracy: 0.7931\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.2051 - accuracy: 0.8961 - val_loss: 0.6394 - val_accuracy: 0.7772\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1601 - accuracy: 0.9108 - val_loss: 0.7924 - val_accuracy: 0.7745\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1180 - accuracy: 0.9656 - val_loss: 0.8640 - val_accuracy: 0.7745\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0938 - accuracy: 0.9750 - val_loss: 0.9770 - val_accuracy: 0.7745\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0823 - accuracy: 0.9832 - val_loss: 0.9951 - val_accuracy: 0.7692\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "Epoch 1/15\n",
      "68/68 - 9s - loss: 0.6625 - accuracy: 0.6321 - val_loss: 0.6292 - val_accuracy: 0.6578\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5794 - accuracy: 0.6351 - val_loss: 0.4953 - val_accuracy: 0.6578\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4493 - accuracy: 0.7728 - val_loss: 0.4468 - val_accuracy: 0.8170\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3292 - accuracy: 0.8882 - val_loss: 0.4687 - val_accuracy: 0.7878\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2615 - accuracy: 0.9235 - val_loss: 0.4349 - val_accuracy: 0.7984\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.2066 - accuracy: 0.9494 - val_loss: 0.4561 - val_accuracy: 0.8170\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1732 - accuracy: 0.9665 - val_loss: 0.5334 - val_accuracy: 0.8143\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1469 - accuracy: 0.9732 - val_loss: 0.5429 - val_accuracy: 0.8143\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6657 - accuracy: 0.6366 - val_loss: 0.6374 - val_accuracy: 0.6525\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5899 - accuracy: 0.6360 - val_loss: 0.5188 - val_accuracy: 0.6525\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4539 - accuracy: 0.7345 - val_loss: 0.4383 - val_accuracy: 0.7666\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3150 - accuracy: 0.8735 - val_loss: 0.4251 - val_accuracy: 0.7905\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2038 - accuracy: 0.9197 - val_loss: 0.4578 - val_accuracy: 0.8196\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1371 - accuracy: 0.9535 - val_loss: 0.5689 - val_accuracy: 0.8011\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1021 - accuracy: 0.9614 - val_loss: 0.6298 - val_accuracy: 0.8037\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0916 - accuracy: 0.9632 - val_loss: 0.6524 - val_accuracy: 0.8117\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0849 - accuracy: 0.9709 - val_loss: 0.7685 - val_accuracy: 0.7958\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0677 - accuracy: 0.9694 - val_loss: 0.9037 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.9628655910492\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6673 - accuracy: 0.6366 - val_loss: 0.6522 - val_accuracy: 0.6207\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5988 - accuracy: 0.6616 - val_loss: 0.5281 - val_accuracy: 0.7851\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4290 - accuracy: 0.7763 - val_loss: 0.4307 - val_accuracy: 0.8117\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2944 - accuracy: 0.8534 - val_loss: 0.5258 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2258 - accuracy: 0.9288 - val_loss: 0.5217 - val_accuracy: 0.7931\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1475 - accuracy: 0.9576 - val_loss: 0.6563 - val_accuracy: 0.7958\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1202 - accuracy: 0.9723 - val_loss: 0.7507 - val_accuracy: 0.8143\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0910 - accuracy: 0.9738 - val_loss: 0.8381 - val_accuracy: 0.7984\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0697 - accuracy: 0.9806 - val_loss: 0.8843 - val_accuracy: 0.8011\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0649 - accuracy: 0.9782 - val_loss: 1.0041 - val_accuracy: 0.7745\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0519 - accuracy: 0.9829 - val_loss: 0.9552 - val_accuracy: 0.7984\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0507 - accuracy: 0.9844 - val_loss: 1.0293 - val_accuracy: 0.8117\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "\n",
      "  Activation Filters      acc1       acc2      acc3       acc4       acc5  \\\n",
      "0       relu       1  79.62963  78.306878  77.51323  82.539684  80.158728   \n",
      "1       relu       2  77.51323  81.481481  79.62963  80.423278  80.158728   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 94s - loss: 0.6619 - accuracy: 0.6338 - val_loss: 0.6205 - val_accuracy: 0.6614\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5760 - accuracy: 0.6565 - val_loss: 0.4504 - val_accuracy: 0.7831\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4002 - accuracy: 0.7565 - val_loss: 0.3934 - val_accuracy: 0.8042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2767 - accuracy: 0.8955 - val_loss: 0.4368 - val_accuracy: 0.8175\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1776 - accuracy: 0.9373 - val_loss: 0.4952 - val_accuracy: 0.8069\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1222 - accuracy: 0.9594 - val_loss: 0.6063 - val_accuracy: 0.8042\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0852 - accuracy: 0.9661 - val_loss: 0.7405 - val_accuracy: 0.8095\n",
      "Epoch 8/15\n",
      "68/68 - 3s - loss: 0.0586 - accuracy: 0.9723 - val_loss: 0.7804 - val_accuracy: 0.8201\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.0537 - accuracy: 0.9750 - val_loss: 0.9274 - val_accuracy: 0.8201\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0493 - accuracy: 0.9738 - val_loss: 0.9827 - val_accuracy: 0.8175\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0485 - accuracy: 0.9741 - val_loss: 1.0872 - val_accuracy: 0.8016\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0424 - accuracy: 0.9735 - val_loss: 1.1858 - val_accuracy: 0.8122\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0327 - accuracy: 0.9823 - val_loss: 1.2833 - val_accuracy: 0.8148\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 82.0105791091919\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6649 - accuracy: 0.6326 - val_loss: 0.6512 - val_accuracy: 0.6481\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5656 - accuracy: 0.6441 - val_loss: 0.4971 - val_accuracy: 0.7619\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3875 - accuracy: 0.8125 - val_loss: 0.4575 - val_accuracy: 0.7698\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2554 - accuracy: 0.9070 - val_loss: 0.5039 - val_accuracy: 0.7910\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1880 - accuracy: 0.9420 - val_loss: 0.5691 - val_accuracy: 0.7672\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1114 - accuracy: 0.9594 - val_loss: 0.7233 - val_accuracy: 0.7804\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0906 - accuracy: 0.9650 - val_loss: 0.8218 - val_accuracy: 0.7857\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0703 - accuracy: 0.9744 - val_loss: 0.9165 - val_accuracy: 0.7751\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0622 - accuracy: 0.9679 - val_loss: 1.0048 - val_accuracy: 0.7725\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6613 - accuracy: 0.6297 - val_loss: 0.6423 - val_accuracy: 0.6481\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5560 - accuracy: 0.6364 - val_loss: 0.5094 - val_accuracy: 0.6481\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.3952 - accuracy: 0.8231 - val_loss: 0.4880 - val_accuracy: 0.7698\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.2598 - accuracy: 0.9058 - val_loss: 0.5819 - val_accuracy: 0.7619\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1529 - accuracy: 0.9547 - val_loss: 0.7037 - val_accuracy: 0.7566\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0955 - accuracy: 0.9747 - val_loss: 0.8905 - val_accuracy: 0.7540\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0826 - accuracy: 0.9750 - val_loss: 0.8477 - val_accuracy: 0.7672\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0640 - accuracy: 0.9870 - val_loss: 0.9495 - val_accuracy: 0.7566\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 76.98412537574768\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6644 - accuracy: 0.6329 - val_loss: 0.6321 - val_accuracy: 0.6429\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5764 - accuracy: 0.6367 - val_loss: 0.5004 - val_accuracy: 0.6429\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4415 - accuracy: 0.7439 - val_loss: 0.4916 - val_accuracy: 0.7672\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3761 - accuracy: 0.8687 - val_loss: 0.5293 - val_accuracy: 0.7910\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2909 - accuracy: 0.8976 - val_loss: 0.5069 - val_accuracy: 0.8122\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1993 - accuracy: 0.9176 - val_loss: 0.5631 - val_accuracy: 0.7804\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1452 - accuracy: 0.9379 - val_loss: 0.5901 - val_accuracy: 0.7804\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1005 - accuracy: 0.9485 - val_loss: 0.7386 - val_accuracy: 0.8042\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0781 - accuracy: 0.9538 - val_loss: 0.7906 - val_accuracy: 0.8069\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0715 - accuracy: 0.9517 - val_loss: 0.7402 - val_accuracy: 0.7989\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6632 - accuracy: 0.6335 - val_loss: 0.6331 - val_accuracy: 0.6376\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5752 - accuracy: 0.6376 - val_loss: 0.5056 - val_accuracy: 0.6376\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4276 - accuracy: 0.7616 - val_loss: 0.4867 - val_accuracy: 0.8122\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2853 - accuracy: 0.8967 - val_loss: 0.5529 - val_accuracy: 0.8069\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2068 - accuracy: 0.9394 - val_loss: 0.5672 - val_accuracy: 0.8175\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1399 - accuracy: 0.9576 - val_loss: 0.7452 - val_accuracy: 0.8069\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0990 - accuracy: 0.9697 - val_loss: 0.7882 - val_accuracy: 0.8148\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0609 - accuracy: 0.9800 - val_loss: 1.1211 - val_accuracy: 0.7989\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0469 - accuracy: 0.9841 - val_loss: 1.1129 - val_accuracy: 0.7989\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0440 - accuracy: 0.9850 - val_loss: 1.2166 - val_accuracy: 0.8016\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6651 - accuracy: 0.6377 - val_loss: 0.6496 - val_accuracy: 0.6101\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5570 - accuracy: 0.6407 - val_loss: 0.5535 - val_accuracy: 0.6101\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4193 - accuracy: 0.7819 - val_loss: 0.5454 - val_accuracy: 0.7321\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3061 - accuracy: 0.8943 - val_loss: 0.6706 - val_accuracy: 0.7347\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2380 - accuracy: 0.9338 - val_loss: 0.6950 - val_accuracy: 0.7056\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1962 - accuracy: 0.9553 - val_loss: 0.7988 - val_accuracy: 0.7321\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1615 - accuracy: 0.9653 - val_loss: 0.9123 - val_accuracy: 0.7321\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1422 - accuracy: 0.9770 - val_loss: 1.2405 - val_accuracy: 0.7401\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0921 - accuracy: 0.9785 - val_loss: 1.1211 - val_accuracy: 0.7347\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0703 - accuracy: 0.9815 - val_loss: 1.1387 - val_accuracy: 0.7401\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0596 - accuracy: 0.9871 - val_loss: 1.3347 - val_accuracy: 0.7454\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0505 - accuracy: 0.9885 - val_loss: 1.1557 - val_accuracy: 0.7560\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0402 - accuracy: 0.9906 - val_loss: 1.3651 - val_accuracy: 0.7586\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0387 - accuracy: 0.9932 - val_loss: 1.4057 - val_accuracy: 0.7613\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0378 - accuracy: 0.9915 - val_loss: 1.5348 - val_accuracy: 0.7613\n",
      "Test Accuracy: 76.1273205280304\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6624 - accuracy: 0.6392 - val_loss: 0.6534 - val_accuracy: 0.6154\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5640 - accuracy: 0.6622 - val_loss: 0.5291 - val_accuracy: 0.7825\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3817 - accuracy: 0.8308 - val_loss: 0.4961 - val_accuracy: 0.7851\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2455 - accuracy: 0.9152 - val_loss: 0.5189 - val_accuracy: 0.8037\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1658 - accuracy: 0.9517 - val_loss: 0.6502 - val_accuracy: 0.7851\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1371 - accuracy: 0.9638 - val_loss: 0.7282 - val_accuracy: 0.7692\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0823 - accuracy: 0.9735 - val_loss: 0.8155 - val_accuracy: 0.7825\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0593 - accuracy: 0.9832 - val_loss: 0.9940 - val_accuracy: 0.7931\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0481 - accuracy: 0.9862 - val_loss: 1.1922 - val_accuracy: 0.8011\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6677 - accuracy: 0.6198 - val_loss: 0.6472 - val_accuracy: 0.6764\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6044 - accuracy: 0.6351 - val_loss: 0.5015 - val_accuracy: 0.7135\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4361 - accuracy: 0.7869 - val_loss: 0.4114 - val_accuracy: 0.7958\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2686 - accuracy: 0.9058 - val_loss: 0.4203 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1836 - accuracy: 0.9447 - val_loss: 0.5298 - val_accuracy: 0.7905\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 5s - loss: 0.1265 - accuracy: 0.9709 - val_loss: 0.5807 - val_accuracy: 0.8064\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0927 - accuracy: 0.9773 - val_loss: 0.7008 - val_accuracy: 0.7931\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0755 - accuracy: 0.9871 - val_loss: 0.7652 - val_accuracy: 0.7851\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0795 - accuracy: 0.9865 - val_loss: 0.8609 - val_accuracy: 0.7931\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0637 - accuracy: 0.9894 - val_loss: 0.9140 - val_accuracy: 0.7958\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0557 - accuracy: 0.9921 - val_loss: 1.0168 - val_accuracy: 0.7851\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6671 - accuracy: 0.6342 - val_loss: 0.6523 - val_accuracy: 0.6446\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.6155 - accuracy: 0.6368 - val_loss: 0.5317 - val_accuracy: 0.6446\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4553 - accuracy: 0.7281 - val_loss: 0.4536 - val_accuracy: 0.8064\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2853 - accuracy: 0.8879 - val_loss: 0.5085 - val_accuracy: 0.7825\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1783 - accuracy: 0.9391 - val_loss: 0.5942 - val_accuracy: 0.7958\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1267 - accuracy: 0.9585 - val_loss: 0.6919 - val_accuracy: 0.7931\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0866 - accuracy: 0.9750 - val_loss: 0.7610 - val_accuracy: 0.7905\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0664 - accuracy: 0.9788 - val_loss: 0.9063 - val_accuracy: 0.7931\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6697 - accuracy: 0.6360 - val_loss: 0.6705 - val_accuracy: 0.5915\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.6073 - accuracy: 0.6513 - val_loss: 0.5608 - val_accuracy: 0.7215\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4390 - accuracy: 0.7501 - val_loss: 0.4911 - val_accuracy: 0.7427\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3353 - accuracy: 0.7690 - val_loss: 0.5542 - val_accuracy: 0.7427\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2386 - accuracy: 0.9082 - val_loss: 0.6818 - val_accuracy: 0.7427\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1592 - accuracy: 0.9461 - val_loss: 0.7507 - val_accuracy: 0.7374\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1275 - accuracy: 0.9662 - val_loss: 0.9963 - val_accuracy: 0.7347\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0992 - accuracy: 0.9697 - val_loss: 1.1007 - val_accuracy: 0.7480\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0762 - accuracy: 0.9709 - val_loss: 1.1417 - val_accuracy: 0.7454\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0680 - accuracy: 0.9720 - val_loss: 1.3147 - val_accuracy: 0.7427\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0603 - accuracy: 0.9738 - val_loss: 1.4498 - val_accuracy: 0.7533\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0558 - accuracy: 0.9794 - val_loss: 1.4036 - val_accuracy: 0.7427\n",
      "Epoch 13/15\n",
      "68/68 - 5s - loss: 0.0511 - accuracy: 0.9770 - val_loss: 1.4101 - val_accuracy: 0.7427\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0506 - accuracy: 0.9770 - val_loss: 1.6362 - val_accuracy: 0.7374\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0506 - accuracy: 0.9785 - val_loss: 1.5334 - val_accuracy: 0.7480\n",
      "Test Accuracy: 74.80106353759766\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6678 - accuracy: 0.6350 - val_loss: 0.6547 - val_accuracy: 0.6561\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5640 - accuracy: 0.6479 - val_loss: 0.5119 - val_accuracy: 0.7566\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3632 - accuracy: 0.8393 - val_loss: 0.4820 - val_accuracy: 0.7937\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2319 - accuracy: 0.9293 - val_loss: 0.6174 - val_accuracy: 0.7884\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1561 - accuracy: 0.9570 - val_loss: 0.6355 - val_accuracy: 0.7910\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1130 - accuracy: 0.9764 - val_loss: 0.7668 - val_accuracy: 0.8016\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0870 - accuracy: 0.9870 - val_loss: 0.8934 - val_accuracy: 0.7857\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0815 - accuracy: 0.9882 - val_loss: 0.9585 - val_accuracy: 0.7910\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0737 - accuracy: 0.9921 - val_loss: 1.0571 - val_accuracy: 0.7989\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0628 - accuracy: 0.9935 - val_loss: 1.1549 - val_accuracy: 0.7989\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0656 - accuracy: 0.9947 - val_loss: 1.1155 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6593 - accuracy: 0.6388 - val_loss: 0.6536 - val_accuracy: 0.6190\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5736 - accuracy: 0.6509 - val_loss: 0.4889 - val_accuracy: 0.7593\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3884 - accuracy: 0.8281 - val_loss: 0.4701 - val_accuracy: 0.7619\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2563 - accuracy: 0.9193 - val_loss: 0.4645 - val_accuracy: 0.7937\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1664 - accuracy: 0.9541 - val_loss: 0.5845 - val_accuracy: 0.7725\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1299 - accuracy: 0.9694 - val_loss: 0.5789 - val_accuracy: 0.7910\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1069 - accuracy: 0.9788 - val_loss: 0.6483 - val_accuracy: 0.7937\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0915 - accuracy: 0.9879 - val_loss: 0.9685 - val_accuracy: 0.7778\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0849 - accuracy: 0.9870 - val_loss: 0.8782 - val_accuracy: 0.7804\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6679 - accuracy: 0.6370 - val_loss: 0.6508 - val_accuracy: 0.6296\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5710 - accuracy: 0.6385 - val_loss: 0.5311 - val_accuracy: 0.6296\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4181 - accuracy: 0.7530 - val_loss: 0.5041 - val_accuracy: 0.7725\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3031 - accuracy: 0.8914 - val_loss: 0.5704 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2281 - accuracy: 0.9367 - val_loss: 0.6812 - val_accuracy: 0.7804\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1750 - accuracy: 0.9608 - val_loss: 0.7120 - val_accuracy: 0.7910\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1156 - accuracy: 0.9738 - val_loss: 0.8292 - val_accuracy: 0.8016\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0948 - accuracy: 0.9788 - val_loss: 0.8835 - val_accuracy: 0.7910\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0915 - accuracy: 0.9803 - val_loss: 1.1522 - val_accuracy: 0.7831\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0827 - accuracy: 0.9794 - val_loss: 1.0489 - val_accuracy: 0.7725\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0805 - accuracy: 0.9823 - val_loss: 1.3010 - val_accuracy: 0.7646\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0666 - accuracy: 0.9873 - val_loss: 1.4758 - val_accuracy: 0.7672\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6680 - accuracy: 0.6356 - val_loss: 0.6649 - val_accuracy: 0.6138\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6161 - accuracy: 0.6420 - val_loss: 0.5329 - val_accuracy: 0.7540\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4397 - accuracy: 0.7386 - val_loss: 0.4888 - val_accuracy: 0.7989\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2913 - accuracy: 0.8399 - val_loss: 0.5031 - val_accuracy: 0.7910\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1904 - accuracy: 0.9155 - val_loss: 0.5219 - val_accuracy: 0.8095\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1299 - accuracy: 0.9450 - val_loss: 0.7145 - val_accuracy: 0.8069\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0929 - accuracy: 0.9635 - val_loss: 0.7139 - val_accuracy: 0.8122\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0722 - accuracy: 0.9653 - val_loss: 0.8569 - val_accuracy: 0.7963\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0592 - accuracy: 0.9732 - val_loss: 1.0031 - val_accuracy: 0.8016\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0579 - accuracy: 0.9720 - val_loss: 1.0174 - val_accuracy: 0.7963\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0532 - accuracy: 0.9756 - val_loss: 1.0724 - val_accuracy: 0.8069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0548 - accuracy: 0.9709 - val_loss: 1.1440 - val_accuracy: 0.8042\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6649 - accuracy: 0.6332 - val_loss: 0.6344 - val_accuracy: 0.6376\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5838 - accuracy: 0.6644 - val_loss: 0.4767 - val_accuracy: 0.7884\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4289 - accuracy: 0.7418 - val_loss: 0.4447 - val_accuracy: 0.8042\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3119 - accuracy: 0.8122 - val_loss: 0.4310 - val_accuracy: 0.7937\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2231 - accuracy: 0.9111 - val_loss: 0.4556 - val_accuracy: 0.7989\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1546 - accuracy: 0.9394 - val_loss: 0.5313 - val_accuracy: 0.7989\n",
      "Epoch 7/15\n",
      "68/68 - 6s - loss: 0.1089 - accuracy: 0.9488 - val_loss: 0.6628 - val_accuracy: 0.7989\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0910 - accuracy: 0.9529 - val_loss: 0.7336 - val_accuracy: 0.8069\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0834 - accuracy: 0.9482 - val_loss: 0.8069 - val_accuracy: 0.7963\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0807 - accuracy: 0.9494 - val_loss: 0.7369 - val_accuracy: 0.7989\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0693 - accuracy: 0.9582 - val_loss: 0.8314 - val_accuracy: 0.7989\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0666 - accuracy: 0.9614 - val_loss: 0.9567 - val_accuracy: 0.8042\n",
      "Epoch 13/15\n",
      "68/68 - 5s - loss: 0.0685 - accuracy: 0.9591 - val_loss: 0.9450 - val_accuracy: 0.7937\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6697 - accuracy: 0.6366 - val_loss: 0.6553 - val_accuracy: 0.6207\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6068 - accuracy: 0.6395 - val_loss: 0.5454 - val_accuracy: 0.6207\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.5001 - accuracy: 0.6789 - val_loss: 0.4540 - val_accuracy: 0.7905\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3947 - accuracy: 0.8199 - val_loss: 0.4663 - val_accuracy: 0.7692\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2693 - accuracy: 0.9144 - val_loss: 0.5260 - val_accuracy: 0.7905\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1997 - accuracy: 0.9520 - val_loss: 0.6124 - val_accuracy: 0.7878\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1589 - accuracy: 0.9653 - val_loss: 0.6999 - val_accuracy: 0.7692\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1389 - accuracy: 0.9732 - val_loss: 0.8065 - val_accuracy: 0.7772\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6666 - accuracy: 0.6345 - val_loss: 0.6461 - val_accuracy: 0.6578\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6132 - accuracy: 0.6354 - val_loss: 0.5095 - val_accuracy: 0.6578\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4497 - accuracy: 0.7010 - val_loss: 0.4487 - val_accuracy: 0.8170\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.3168 - accuracy: 0.8582 - val_loss: 0.4816 - val_accuracy: 0.8302\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2572 - accuracy: 0.9094 - val_loss: 0.5120 - val_accuracy: 0.7984\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.2152 - accuracy: 0.9288 - val_loss: 0.5983 - val_accuracy: 0.8117\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.1789 - accuracy: 0.9585 - val_loss: 0.6915 - val_accuracy: 0.8302\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.1252 - accuracy: 0.9676 - val_loss: 0.8470 - val_accuracy: 0.7878\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0715 - accuracy: 0.9697 - val_loss: 0.8283 - val_accuracy: 0.8011\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.02386999130249\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6637 - accuracy: 0.6336 - val_loss: 0.6116 - val_accuracy: 0.6764\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5708 - accuracy: 0.6404 - val_loss: 0.4575 - val_accuracy: 0.7613\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4015 - accuracy: 0.8302 - val_loss: 0.4605 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2621 - accuracy: 0.9126 - val_loss: 0.4528 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1799 - accuracy: 0.9488 - val_loss: 0.5225 - val_accuracy: 0.8090\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1319 - accuracy: 0.9656 - val_loss: 0.5553 - val_accuracy: 0.7905\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1027 - accuracy: 0.9809 - val_loss: 0.7152 - val_accuracy: 0.8064\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0828 - accuracy: 0.9871 - val_loss: 0.7435 - val_accuracy: 0.7798\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0759 - accuracy: 0.9894 - val_loss: 0.9020 - val_accuracy: 0.7851\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0759 - accuracy: 0.9859 - val_loss: 0.8957 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6642 - accuracy: 0.6351 - val_loss: 0.6452 - val_accuracy: 0.6366\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5866 - accuracy: 0.6557 - val_loss: 0.5249 - val_accuracy: 0.7321\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3930 - accuracy: 0.8237 - val_loss: 0.5005 - val_accuracy: 0.7772\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2436 - accuracy: 0.9076 - val_loss: 0.5631 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1538 - accuracy: 0.9403 - val_loss: 0.7064 - val_accuracy: 0.7507\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1066 - accuracy: 0.9529 - val_loss: 0.7668 - val_accuracy: 0.7639\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0630 - accuracy: 0.9744 - val_loss: 0.9162 - val_accuracy: 0.7639\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0485 - accuracy: 0.9818 - val_loss: 1.1457 - val_accuracy: 0.7480\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 77.71883010864258\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6662 - accuracy: 0.6354 - val_loss: 0.6602 - val_accuracy: 0.6286\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6037 - accuracy: 0.6386 - val_loss: 0.5402 - val_accuracy: 0.6286\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4611 - accuracy: 0.6733 - val_loss: 0.5328 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3215 - accuracy: 0.8790 - val_loss: 0.5401 - val_accuracy: 0.8090\n",
      "Epoch 5/15\n",
      "68/68 - 6s - loss: 0.2159 - accuracy: 0.9273 - val_loss: 0.5731 - val_accuracy: 0.7958\n",
      "Epoch 6/15\n",
      "68/68 - 7s - loss: 0.1602 - accuracy: 0.9479 - val_loss: 0.7316 - val_accuracy: 0.8037\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1295 - accuracy: 0.9594 - val_loss: 0.7888 - val_accuracy: 0.7984\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1107 - accuracy: 0.9665 - val_loss: 0.7391 - val_accuracy: 0.7958\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0773 - accuracy: 0.9762 - val_loss: 1.1928 - val_accuracy: 0.7905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6656 - accuracy: 0.6359 - val_loss: 0.6556 - val_accuracy: 0.6058\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5694 - accuracy: 0.6591 - val_loss: 0.5275 - val_accuracy: 0.7196\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3757 - accuracy: 0.7836 - val_loss: 0.4990 - val_accuracy: 0.7751\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2540 - accuracy: 0.9143 - val_loss: 0.5882 - val_accuracy: 0.7751\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1530 - accuracy: 0.9494 - val_loss: 0.6385 - val_accuracy: 0.8016\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1049 - accuracy: 0.9688 - val_loss: 0.8371 - val_accuracy: 0.7884\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0723 - accuracy: 0.9762 - val_loss: 0.9379 - val_accuracy: 0.7857\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0605 - accuracy: 0.9841 - val_loss: 1.0788 - val_accuracy: 0.7778\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0601 - accuracy: 0.9826 - val_loss: 0.9423 - val_accuracy: 0.7963\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0568 - accuracy: 0.9812 - val_loss: 1.2723 - val_accuracy: 0.7751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6636 - accuracy: 0.6397 - val_loss: 0.6577 - val_accuracy: 0.6190\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5661 - accuracy: 0.6397 - val_loss: 0.5245 - val_accuracy: 0.6190\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4186 - accuracy: 0.8019 - val_loss: 0.5441 - val_accuracy: 0.7672\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2957 - accuracy: 0.9020 - val_loss: 0.5285 - val_accuracy: 0.7831\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2139 - accuracy: 0.9432 - val_loss: 0.6643 - val_accuracy: 0.7487\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1440 - accuracy: 0.9647 - val_loss: 0.7755 - val_accuracy: 0.7434\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1063 - accuracy: 0.9744 - val_loss: 1.0978 - val_accuracy: 0.7354\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0680 - accuracy: 0.9838 - val_loss: 1.0765 - val_accuracy: 0.7460\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0503 - accuracy: 0.9906 - val_loss: 1.2581 - val_accuracy: 0.7593\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6715 - accuracy: 0.6270 - val_loss: 0.6321 - val_accuracy: 0.6720\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5934 - accuracy: 0.6388 - val_loss: 0.4921 - val_accuracy: 0.7751\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4088 - accuracy: 0.8110 - val_loss: 0.4427 - val_accuracy: 0.7778\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2453 - accuracy: 0.9193 - val_loss: 0.4408 - val_accuracy: 0.7831\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1576 - accuracy: 0.9555 - val_loss: 0.5704 - val_accuracy: 0.8042\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1150 - accuracy: 0.9664 - val_loss: 0.5769 - val_accuracy: 0.8095\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0939 - accuracy: 0.9776 - val_loss: 0.6905 - val_accuracy: 0.8042\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0858 - accuracy: 0.9832 - val_loss: 0.7560 - val_accuracy: 0.8148\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0767 - accuracy: 0.9812 - val_loss: 0.8460 - val_accuracy: 0.8122\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0609 - accuracy: 0.9885 - val_loss: 0.8704 - val_accuracy: 0.8016\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0583 - accuracy: 0.9900 - val_loss: 1.0110 - val_accuracy: 0.8016\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0613 - accuracy: 0.9856 - val_loss: 1.0314 - val_accuracy: 0.8069\n",
      "Epoch 13/15\n",
      "68/68 - 5s - loss: 0.0579 - accuracy: 0.9865 - val_loss: 1.1447 - val_accuracy: 0.8148\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6651 - accuracy: 0.6320 - val_loss: 0.6567 - val_accuracy: 0.6534\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5925 - accuracy: 0.6579 - val_loss: 0.4698 - val_accuracy: 0.7354\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3830 - accuracy: 0.8004 - val_loss: 0.4513 - val_accuracy: 0.7540\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2185 - accuracy: 0.9185 - val_loss: 0.5212 - val_accuracy: 0.7725\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1472 - accuracy: 0.9503 - val_loss: 0.6124 - val_accuracy: 0.7487\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1066 - accuracy: 0.9691 - val_loss: 0.7307 - val_accuracy: 0.7646\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0800 - accuracy: 0.9776 - val_loss: 0.8181 - val_accuracy: 0.7672\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0661 - accuracy: 0.9809 - val_loss: 0.8003 - val_accuracy: 0.7778\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0557 - accuracy: 0.9841 - val_loss: 0.8897 - val_accuracy: 0.7831\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0424 - accuracy: 0.9856 - val_loss: 1.0240 - val_accuracy: 0.7831\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0379 - accuracy: 0.9859 - val_loss: 1.1548 - val_accuracy: 0.7804\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0364 - accuracy: 0.9817 - val_loss: 1.2211 - val_accuracy: 0.7884\n",
      "Epoch 13/15\n",
      "68/68 - 5s - loss: 0.0352 - accuracy: 0.9841 - val_loss: 1.2460 - val_accuracy: 0.7672\n",
      "Epoch 14/15\n",
      "68/68 - 5s - loss: 0.0318 - accuracy: 0.9873 - val_loss: 1.2893 - val_accuracy: 0.7672\n",
      "Epoch 15/15\n",
      "68/68 - 5s - loss: 0.0341 - accuracy: 0.9835 - val_loss: 1.2734 - val_accuracy: 0.7831\n",
      "Test Accuracy: 78.30687761306763\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6608 - accuracy: 0.6370 - val_loss: 0.6493 - val_accuracy: 0.6270\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5666 - accuracy: 0.6388 - val_loss: 0.5132 - val_accuracy: 0.6270\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3952 - accuracy: 0.7931 - val_loss: 0.4527 - val_accuracy: 0.8042\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2488 - accuracy: 0.9076 - val_loss: 0.4734 - val_accuracy: 0.8069\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1703 - accuracy: 0.9408 - val_loss: 0.5454 - val_accuracy: 0.8042\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1049 - accuracy: 0.9617 - val_loss: 0.6451 - val_accuracy: 0.8042\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0897 - accuracy: 0.9656 - val_loss: 0.7202 - val_accuracy: 0.8254\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0733 - accuracy: 0.9729 - val_loss: 0.7522 - val_accuracy: 0.8069\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0561 - accuracy: 0.9723 - val_loss: 0.9017 - val_accuracy: 0.8122\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0463 - accuracy: 0.9770 - val_loss: 1.0430 - val_accuracy: 0.8175\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0376 - accuracy: 0.9794 - val_loss: 1.1648 - val_accuracy: 0.8122\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0438 - accuracy: 0.9764 - val_loss: 1.0373 - val_accuracy: 0.8016\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6647 - accuracy: 0.6345 - val_loss: 0.6363 - val_accuracy: 0.6419\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5728 - accuracy: 0.6613 - val_loss: 0.4596 - val_accuracy: 0.7798\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3849 - accuracy: 0.7934 - val_loss: 0.4529 - val_accuracy: 0.7931\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2433 - accuracy: 0.8973 - val_loss: 0.4643 - val_accuracy: 0.7905\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1533 - accuracy: 0.9500 - val_loss: 0.5220 - val_accuracy: 0.7878\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1254 - accuracy: 0.9673 - val_loss: 0.6195 - val_accuracy: 0.8196\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0782 - accuracy: 0.9791 - val_loss: 0.7836 - val_accuracy: 0.8196\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0637 - accuracy: 0.9815 - val_loss: 0.8297 - val_accuracy: 0.8302\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0566 - accuracy: 0.9847 - val_loss: 0.9475 - val_accuracy: 0.8196\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0530 - accuracy: 0.9838 - val_loss: 1.0052 - val_accuracy: 0.8117\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0461 - accuracy: 0.9873 - val_loss: 1.0664 - val_accuracy: 0.8037\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0319 - accuracy: 0.9862 - val_loss: 1.0978 - val_accuracy: 0.8223\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0250 - accuracy: 0.9915 - val_loss: 1.2339 - val_accuracy: 0.8249\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 83.02386999130249\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6588 - accuracy: 0.6368 - val_loss: 0.6468 - val_accuracy: 0.6180\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5489 - accuracy: 0.6486 - val_loss: 0.4945 - val_accuracy: 0.7745\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3658 - accuracy: 0.8381 - val_loss: 0.4876 - val_accuracy: 0.7878\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2555 - accuracy: 0.9282 - val_loss: 0.5552 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1661 - accuracy: 0.9564 - val_loss: 0.7402 - val_accuracy: 0.7878\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1098 - accuracy: 0.9779 - val_loss: 0.7826 - val_accuracy: 0.7851\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0912 - accuracy: 0.9815 - val_loss: 0.9338 - val_accuracy: 0.7692\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0828 - accuracy: 0.9888 - val_loss: 1.1306 - val_accuracy: 0.7639\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.77984046936035\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6689 - accuracy: 0.6318 - val_loss: 0.6343 - val_accuracy: 0.6552\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5776 - accuracy: 0.6727 - val_loss: 0.4712 - val_accuracy: 0.7745\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3730 - accuracy: 0.7763 - val_loss: 0.4432 - val_accuracy: 0.7692\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2602 - accuracy: 0.9138 - val_loss: 0.4964 - val_accuracy: 0.8037\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.2052 - accuracy: 0.9459 - val_loss: 0.5339 - val_accuracy: 0.7851\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.1740 - accuracy: 0.9656 - val_loss: 0.5893 - val_accuracy: 0.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/15\n",
      "68/68 - 6s - loss: 0.1244 - accuracy: 0.9747 - val_loss: 0.6729 - val_accuracy: 0.7719\n",
      "Epoch 8/15\n",
      "68/68 - 6s - loss: 0.0896 - accuracy: 0.9844 - val_loss: 0.7736 - val_accuracy: 0.7586\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0685 - accuracy: 0.9906 - val_loss: 0.8737 - val_accuracy: 0.7560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6656 - accuracy: 0.6336 - val_loss: 0.6557 - val_accuracy: 0.6260\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.6063 - accuracy: 0.6389 - val_loss: 0.5369 - val_accuracy: 0.6260\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4594 - accuracy: 0.6483 - val_loss: 0.5642 - val_accuracy: 0.7639\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3856 - accuracy: 0.8602 - val_loss: 0.6092 - val_accuracy: 0.7745\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.3407 - accuracy: 0.8846 - val_loss: 0.6375 - val_accuracy: 0.8117\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.2628 - accuracy: 0.9073 - val_loss: 0.7002 - val_accuracy: 0.8064\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.2384 - accuracy: 0.9135 - val_loss: 0.7494 - val_accuracy: 0.8090\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1726 - accuracy: 0.9297 - val_loss: 0.7747 - val_accuracy: 0.8064\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.1262 - accuracy: 0.9408 - val_loss: 0.9268 - val_accuracy: 0.7984\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0949 - accuracy: 0.9576 - val_loss: 0.9693 - val_accuracy: 0.8064\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6691 - accuracy: 0.6345 - val_loss: 0.6369 - val_accuracy: 0.6578\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.6096 - accuracy: 0.6354 - val_loss: 0.5369 - val_accuracy: 0.6578\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4603 - accuracy: 0.7042 - val_loss: 0.4835 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3018 - accuracy: 0.8840 - val_loss: 0.5253 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1964 - accuracy: 0.9408 - val_loss: 0.5634 - val_accuracy: 0.7745\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1235 - accuracy: 0.9617 - val_loss: 0.7051 - val_accuracy: 0.7905\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0846 - accuracy: 0.9726 - val_loss: 0.7530 - val_accuracy: 0.7798\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0685 - accuracy: 0.9803 - val_loss: 0.9147 - val_accuracy: 0.7772\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0508 - accuracy: 0.9853 - val_loss: 1.1083 - val_accuracy: 0.7745\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0366 - accuracy: 0.9871 - val_loss: 1.2759 - val_accuracy: 0.7772\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0298 - accuracy: 0.9918 - val_loss: 1.2797 - val_accuracy: 0.7825\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4       relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4  83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6614 - accuracy: 0.6385 - val_loss: 0.6404 - val_accuracy: 0.6243\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5398 - accuracy: 0.7012 - val_loss: 0.4801 - val_accuracy: 0.7857\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3391 - accuracy: 0.8546 - val_loss: 0.4941 - val_accuracy: 0.7672\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2135 - accuracy: 0.9167 - val_loss: 0.5566 - val_accuracy: 0.7831\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1242 - accuracy: 0.9503 - val_loss: 0.6596 - val_accuracy: 0.8069\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0716 - accuracy: 0.9653 - val_loss: 0.8946 - val_accuracy: 0.7804\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0651 - accuracy: 0.9694 - val_loss: 0.9514 - val_accuracy: 0.7831\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0517 - accuracy: 0.9697 - val_loss: 1.0952 - val_accuracy: 0.7725\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0464 - accuracy: 0.9709 - val_loss: 1.1564 - val_accuracy: 0.7725\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0406 - accuracy: 0.9714 - val_loss: 1.4774 - val_accuracy: 0.7593\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6687 - accuracy: 0.6347 - val_loss: 0.6613 - val_accuracy: 0.6164\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.6112 - accuracy: 0.6400 - val_loss: 0.5394 - val_accuracy: 0.6164\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4352 - accuracy: 0.7745 - val_loss: 0.4479 - val_accuracy: 0.8016\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2638 - accuracy: 0.9023 - val_loss: 0.4449 - val_accuracy: 0.8122\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1673 - accuracy: 0.9399 - val_loss: 0.5123 - val_accuracy: 0.7989\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1129 - accuracy: 0.9576 - val_loss: 0.6247 - val_accuracy: 0.7857\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0814 - accuracy: 0.9697 - val_loss: 0.8705 - val_accuracy: 0.7884\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0616 - accuracy: 0.9820 - val_loss: 0.9312 - val_accuracy: 0.7778\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0525 - accuracy: 0.9829 - val_loss: 1.0563 - val_accuracy: 0.7937\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6653 - accuracy: 0.6353 - val_loss: 0.6555 - val_accuracy: 0.6190\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5619 - accuracy: 0.6429 - val_loss: 0.5445 - val_accuracy: 0.7328\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3994 - accuracy: 0.8098 - val_loss: 0.5490 - val_accuracy: 0.7328\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2615 - accuracy: 0.9014 - val_loss: 0.6345 - val_accuracy: 0.7619\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1520 - accuracy: 0.9420 - val_loss: 0.8721 - val_accuracy: 0.7460\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.0900 - accuracy: 0.9617 - val_loss: 1.0007 - val_accuracy: 0.7302\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0648 - accuracy: 0.9673 - val_loss: 1.1485 - val_accuracy: 0.7381\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0445 - accuracy: 0.9756 - val_loss: 1.3648 - val_accuracy: 0.7302\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0452 - accuracy: 0.9732 - val_loss: 1.4788 - val_accuracy: 0.7381\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 76.1904776096344\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6682 - accuracy: 0.6300 - val_loss: 0.6310 - val_accuracy: 0.6561\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5865 - accuracy: 0.6588 - val_loss: 0.4887 - val_accuracy: 0.7698\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3715 - accuracy: 0.7916 - val_loss: 0.4725 - val_accuracy: 0.7725\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2437 - accuracy: 0.8852 - val_loss: 0.5195 - val_accuracy: 0.7910\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1499 - accuracy: 0.9473 - val_loss: 0.6283 - val_accuracy: 0.7857\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1010 - accuracy: 0.9623 - val_loss: 0.6958 - val_accuracy: 0.7804\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0750 - accuracy: 0.9694 - val_loss: 0.8161 - val_accuracy: 0.7963\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0757 - accuracy: 0.9673 - val_loss: 0.9425 - val_accuracy: 0.7884\n",
      "Epoch 9/15\n",
      "68/68 - 6s - loss: 0.0632 - accuracy: 0.9703 - val_loss: 1.0664 - val_accuracy: 0.8016\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0562 - accuracy: 0.9770 - val_loss: 1.1885 - val_accuracy: 0.7884\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0484 - accuracy: 0.9791 - val_loss: 1.2316 - val_accuracy: 0.7884\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0535 - accuracy: 0.9732 - val_loss: 1.1803 - val_accuracy: 0.8016\n",
      "Epoch 13/15\n",
      "68/68 - 5s - loss: 0.0570 - accuracy: 0.9776 - val_loss: 1.3842 - val_accuracy: 0.7831\n",
      "Epoch 14/15\n",
      "68/68 - 5s - loss: 0.0497 - accuracy: 0.9779 - val_loss: 1.3998 - val_accuracy: 0.7857\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 6s - loss: 0.6732 - accuracy: 0.6297 - val_loss: 0.6532 - val_accuracy: 0.6667\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.6338 - accuracy: 0.6344 - val_loss: 0.5430 - val_accuracy: 0.6667\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.5241 - accuracy: 0.6729 - val_loss: 0.4144 - val_accuracy: 0.8175\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3835 - accuracy: 0.7648 - val_loss: 0.3877 - val_accuracy: 0.8360\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2524 - accuracy: 0.8790 - val_loss: 0.4823 - val_accuracy: 0.8016\n",
      "Epoch 6/15\n",
      "68/68 - 6s - loss: 0.1613 - accuracy: 0.9255 - val_loss: 0.6054 - val_accuracy: 0.8042\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1249 - accuracy: 0.9332 - val_loss: 0.6363 - val_accuracy: 0.8095\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0900 - accuracy: 0.9567 - val_loss: 0.7054 - val_accuracy: 0.8254\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0684 - accuracy: 0.9576 - val_loss: 0.8522 - val_accuracy: 0.8122\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.59788656234741\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6676 - accuracy: 0.6339 - val_loss: 0.6410 - val_accuracy: 0.6313\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5710 - accuracy: 0.6451 - val_loss: 0.5051 - val_accuracy: 0.7533\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3804 - accuracy: 0.8031 - val_loss: 0.4753 - val_accuracy: 0.7692\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2521 - accuracy: 0.8782 - val_loss: 0.5344 - val_accuracy: 0.7613\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1880 - accuracy: 0.9244 - val_loss: 0.5810 - val_accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1477 - accuracy: 0.9376 - val_loss: 0.6424 - val_accuracy: 0.7825\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1374 - accuracy: 0.9461 - val_loss: 0.7683 - val_accuracy: 0.7878\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1092 - accuracy: 0.9511 - val_loss: 0.8679 - val_accuracy: 0.7745\n",
      "Epoch 9/15\n",
      "68/68 - 6s - loss: 0.1136 - accuracy: 0.9500 - val_loss: 0.9178 - val_accuracy: 0.7905\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.1009 - accuracy: 0.9550 - val_loss: 1.0352 - val_accuracy: 0.7745\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0988 - accuracy: 0.9562 - val_loss: 1.0984 - val_accuracy: 0.7851\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0992 - accuracy: 0.9547 - val_loss: 1.0596 - val_accuracy: 0.7772\n",
      "Epoch 13/15\n",
      "68/68 - 5s - loss: 0.0953 - accuracy: 0.9585 - val_loss: 1.2601 - val_accuracy: 0.7798\n",
      "Epoch 14/15\n",
      "68/68 - 5s - loss: 0.0998 - accuracy: 0.9544 - val_loss: 1.1051 - val_accuracy: 0.7931\n",
      "Epoch 15/15\n",
      "68/68 - 5s - loss: 0.0910 - accuracy: 0.9588 - val_loss: 1.2045 - val_accuracy: 0.7878\n",
      "Test Accuracy: 78.77984046936035\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6772 - accuracy: 0.6251 - val_loss: 0.6566 - val_accuracy: 0.6737\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.6668 - accuracy: 0.6342 - val_loss: 0.6204 - val_accuracy: 0.6737\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.5770 - accuracy: 0.6883 - val_loss: 0.4342 - val_accuracy: 0.8037\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3885 - accuracy: 0.8526 - val_loss: 0.4204 - val_accuracy: 0.7984\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2796 - accuracy: 0.9105 - val_loss: 0.4681 - val_accuracy: 0.8064\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.2173 - accuracy: 0.9411 - val_loss: 0.5188 - val_accuracy: 0.8143\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1649 - accuracy: 0.9597 - val_loss: 0.5831 - val_accuracy: 0.8037\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1523 - accuracy: 0.9670 - val_loss: 0.6333 - val_accuracy: 0.8011\n",
      "Epoch 9/15\n",
      "68/68 - 6s - loss: 0.1296 - accuracy: 0.9662 - val_loss: 0.6609 - val_accuracy: 0.7931\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.1154 - accuracy: 0.9729 - val_loss: 0.8136 - val_accuracy: 0.8037\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.1165 - accuracy: 0.9729 - val_loss: 0.8785 - val_accuracy: 0.7931\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6634 - accuracy: 0.6339 - val_loss: 0.6581 - val_accuracy: 0.6154\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5955 - accuracy: 0.6622 - val_loss: 0.5106 - val_accuracy: 0.7188\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.4112 - accuracy: 0.8002 - val_loss: 0.4978 - val_accuracy: 0.7533\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.2905 - accuracy: 0.8596 - val_loss: 0.4977 - val_accuracy: 0.7719\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2153 - accuracy: 0.8920 - val_loss: 0.5765 - val_accuracy: 0.7507\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.1555 - accuracy: 0.9326 - val_loss: 0.6820 - val_accuracy: 0.7586\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1232 - accuracy: 0.9406 - val_loss: 0.8369 - val_accuracy: 0.7533\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1014 - accuracy: 0.9650 - val_loss: 1.0556 - val_accuracy: 0.7374\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0861 - accuracy: 0.9712 - val_loss: 1.1052 - val_accuracy: 0.7533\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6657 - accuracy: 0.6248 - val_loss: 0.6286 - val_accuracy: 0.6552\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5513 - accuracy: 0.6757 - val_loss: 0.4821 - val_accuracy: 0.7745\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3542 - accuracy: 0.8217 - val_loss: 0.5028 - val_accuracy: 0.7984\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.2144 - accuracy: 0.9176 - val_loss: 0.5948 - val_accuracy: 0.7560\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1388 - accuracy: 0.9509 - val_loss: 0.6997 - val_accuracy: 0.7931\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.0966 - accuracy: 0.9612 - val_loss: 0.8011 - val_accuracy: 0.7825\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0794 - accuracy: 0.9723 - val_loss: 0.9206 - val_accuracy: 0.7905\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0665 - accuracy: 0.9720 - val_loss: 1.1316 - val_accuracy: 0.7878\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6585 - accuracy: 0.6389 - val_loss: 0.6524 - val_accuracy: 0.6180\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5920 - accuracy: 0.6398 - val_loss: 0.4988 - val_accuracy: 0.6180\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.4317 - accuracy: 0.7637 - val_loss: 0.4814 - val_accuracy: 0.7772\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.3385 - accuracy: 0.9052 - val_loss: 0.4364 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.2461 - accuracy: 0.9276 - val_loss: 0.5171 - val_accuracy: 0.8117\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.2054 - accuracy: 0.9500 - val_loss: 0.4968 - val_accuracy: 0.8302\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.1700 - accuracy: 0.9688 - val_loss: 0.6821 - val_accuracy: 0.8117\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.1447 - accuracy: 0.9729 - val_loss: 0.7159 - val_accuracy: 0.8037\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.1361 - accuracy: 0.9800 - val_loss: 0.6949 - val_accuracy: 0.8064\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.1192 - accuracy: 0.9850 - val_loss: 0.7359 - val_accuracy: 0.8090\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.1180 - accuracy: 0.9853 - val_loss: 0.6752 - val_accuracy: 0.8090\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 83.02386999130249\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4       relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5       relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4  83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5  78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6621 - accuracy: 0.6309 - val_loss: 0.6438 - val_accuracy: 0.6640\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5205 - accuracy: 0.7563 - val_loss: 0.5003 - val_accuracy: 0.7381\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2965 - accuracy: 0.8923 - val_loss: 0.5121 - val_accuracy: 0.7434\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1556 - accuracy: 0.9606 - val_loss: 0.5520 - val_accuracy: 0.7751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0809 - accuracy: 0.9853 - val_loss: 0.6548 - val_accuracy: 0.7698\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0556 - accuracy: 0.9918 - val_loss: 0.6977 - val_accuracy: 0.7698\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.0402 - accuracy: 0.9947 - val_loss: 0.7936 - val_accuracy: 0.7487\n",
      "Epoch 8/15\n",
      "68/68 - 3s - loss: 0.0250 - accuracy: 0.9976 - val_loss: 0.8446 - val_accuracy: 0.7540\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.0225 - accuracy: 0.9979 - val_loss: 0.9088 - val_accuracy: 0.7354\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 77.51322984695435\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6595 - accuracy: 0.6250 - val_loss: 0.6466 - val_accuracy: 0.5979\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5234 - accuracy: 0.7471 - val_loss: 0.5002 - val_accuracy: 0.7646\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3113 - accuracy: 0.8917 - val_loss: 0.4900 - val_accuracy: 0.7778\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.1652 - accuracy: 0.9597 - val_loss: 0.5629 - val_accuracy: 0.7593\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.0940 - accuracy: 0.9809 - val_loss: 0.6199 - val_accuracy: 0.7593\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0554 - accuracy: 0.9923 - val_loss: 0.6631 - val_accuracy: 0.7619\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0414 - accuracy: 0.9941 - val_loss: 0.7650 - val_accuracy: 0.7434\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0319 - accuracy: 0.9959 - val_loss: 0.7986 - val_accuracy: 0.7566\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 77.77777910232544\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6493 - accuracy: 0.6426 - val_loss: 0.6263 - val_accuracy: 0.6138\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.4717 - accuracy: 0.7889 - val_loss: 0.4782 - val_accuracy: 0.7698\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2726 - accuracy: 0.8984 - val_loss: 0.4467 - val_accuracy: 0.7857\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1362 - accuracy: 0.9623 - val_loss: 0.5117 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0702 - accuracy: 0.9847 - val_loss: 0.5720 - val_accuracy: 0.7857\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0469 - accuracy: 0.9921 - val_loss: 0.6551 - val_accuracy: 0.7698\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0314 - accuracy: 0.9956 - val_loss: 0.7264 - val_accuracy: 0.7804\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0220 - accuracy: 0.9976 - val_loss: 0.7924 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.57142686843872\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6616 - accuracy: 0.6282 - val_loss: 0.6144 - val_accuracy: 0.6455\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5229 - accuracy: 0.7492 - val_loss: 0.4329 - val_accuracy: 0.7857\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2897 - accuracy: 0.9017 - val_loss: 0.4416 - val_accuracy: 0.7963\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1545 - accuracy: 0.9585 - val_loss: 0.4598 - val_accuracy: 0.8069\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0780 - accuracy: 0.9856 - val_loss: 0.5266 - val_accuracy: 0.7963\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0486 - accuracy: 0.9944 - val_loss: 0.6052 - val_accuracy: 0.7910\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0303 - accuracy: 0.9976 - val_loss: 0.6479 - val_accuracy: 0.7831\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0250 - accuracy: 0.9971 - val_loss: 0.6753 - val_accuracy: 0.8122\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0206 - accuracy: 0.9974 - val_loss: 0.7224 - val_accuracy: 0.7937\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0175 - accuracy: 0.9985 - val_loss: 0.7764 - val_accuracy: 0.7937\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0140 - accuracy: 0.9982 - val_loss: 0.8185 - val_accuracy: 0.7989\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0112 - accuracy: 0.9988 - val_loss: 0.8376 - val_accuracy: 0.8042\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0111 - accuracy: 0.9994 - val_loss: 0.9115 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6599 - accuracy: 0.6253 - val_loss: 0.6101 - val_accuracy: 0.6720\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5228 - accuracy: 0.7536 - val_loss: 0.4345 - val_accuracy: 0.7989\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.3012 - accuracy: 0.8881 - val_loss: 0.3986 - val_accuracy: 0.8095\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1556 - accuracy: 0.9582 - val_loss: 0.4449 - val_accuracy: 0.8042\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0914 - accuracy: 0.9817 - val_loss: 0.4975 - val_accuracy: 0.8148\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0570 - accuracy: 0.9888 - val_loss: 0.5489 - val_accuracy: 0.8201\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.0368 - accuracy: 0.9968 - val_loss: 0.5881 - val_accuracy: 0.8122\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0277 - accuracy: 0.9971 - val_loss: 0.6394 - val_accuracy: 0.8201\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0223 - accuracy: 0.9974 - val_loss: 0.6942 - val_accuracy: 0.8069\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0169 - accuracy: 0.9985 - val_loss: 0.7024 - val_accuracy: 0.8148\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0150 - accuracy: 0.9994 - val_loss: 0.7567 - val_accuracy: 0.8069\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.0105791091919\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6606 - accuracy: 0.6345 - val_loss: 0.6279 - val_accuracy: 0.6446\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5333 - accuracy: 0.7448 - val_loss: 0.4942 - val_accuracy: 0.7692\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.3106 - accuracy: 0.8855 - val_loss: 0.4810 - val_accuracy: 0.7772\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1622 - accuracy: 0.9591 - val_loss: 0.5437 - val_accuracy: 0.7851\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0955 - accuracy: 0.9800 - val_loss: 0.6114 - val_accuracy: 0.7719\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0613 - accuracy: 0.9885 - val_loss: 0.6664 - val_accuracy: 0.7613\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0400 - accuracy: 0.9944 - val_loss: 0.7410 - val_accuracy: 0.7507\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0292 - accuracy: 0.9976 - val_loss: 0.8179 - val_accuracy: 0.7427\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0263 - accuracy: 0.9968 - val_loss: 0.8858 - val_accuracy: 0.7454\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6574 - accuracy: 0.6336 - val_loss: 0.6389 - val_accuracy: 0.6180\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5046 - accuracy: 0.7699 - val_loss: 0.4922 - val_accuracy: 0.7586\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2893 - accuracy: 0.8958 - val_loss: 0.4872 - val_accuracy: 0.7745\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1496 - accuracy: 0.9623 - val_loss: 0.5599 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0807 - accuracy: 0.9829 - val_loss: 0.6554 - val_accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0471 - accuracy: 0.9926 - val_loss: 0.7101 - val_accuracy: 0.7851\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0336 - accuracy: 0.9962 - val_loss: 0.8192 - val_accuracy: 0.7745\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0312 - accuracy: 0.9956 - val_loss: 0.8293 - val_accuracy: 0.7692\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0253 - accuracy: 0.9959 - val_loss: 0.8475 - val_accuracy: 0.7798\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0186 - accuracy: 0.9976 - val_loss: 0.9381 - val_accuracy: 0.7560\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0158 - accuracy: 0.9979 - val_loss: 0.9502 - val_accuracy: 0.7878\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0137 - accuracy: 0.9979 - val_loss: 0.9875 - val_accuracy: 0.7851\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0158 - accuracy: 0.9974 - val_loss: 1.0585 - val_accuracy: 0.7719\n",
      "Epoch 14/15\n",
      "68/68 - 5s - loss: 0.0123 - accuracy: 0.9988 - val_loss: 1.0791 - val_accuracy: 0.7745\n",
      "Epoch 15/15\n",
      "68/68 - 5s - loss: 0.0112 - accuracy: 0.9982 - val_loss: 1.1078 - val_accuracy: 0.7745\n",
      "Test Accuracy: 77.45358347892761\n",
      "Epoch 1/15\n",
      "68/68 - 8s - loss: 0.6578 - accuracy: 0.6233 - val_loss: 0.5995 - val_accuracy: 0.6711\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.4879 - accuracy: 0.7878 - val_loss: 0.4391 - val_accuracy: 0.7931\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.2766 - accuracy: 0.8996 - val_loss: 0.4329 - val_accuracy: 0.8037\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1399 - accuracy: 0.9632 - val_loss: 0.4611 - val_accuracy: 0.8090\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0779 - accuracy: 0.9838 - val_loss: 0.5139 - val_accuracy: 0.8170\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.0445 - accuracy: 0.9941 - val_loss: 0.5886 - val_accuracy: 0.8011\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0280 - accuracy: 0.9979 - val_loss: 0.6156 - val_accuracy: 0.8117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.6782 - val_accuracy: 0.8037\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0160 - accuracy: 0.9988 - val_loss: 0.7141 - val_accuracy: 0.7878\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0155 - accuracy: 0.9976 - val_loss: 0.7759 - val_accuracy: 0.7984\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6550 - accuracy: 0.6301 - val_loss: 0.6214 - val_accuracy: 0.6472\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5044 - accuracy: 0.7725 - val_loss: 0.4472 - val_accuracy: 0.7878\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2688 - accuracy: 0.9011 - val_loss: 0.4846 - val_accuracy: 0.7772\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1395 - accuracy: 0.9612 - val_loss: 0.4981 - val_accuracy: 0.7958\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0712 - accuracy: 0.9850 - val_loss: 0.5655 - val_accuracy: 0.7931\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0464 - accuracy: 0.9897 - val_loss: 0.5960 - val_accuracy: 0.8143\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0310 - accuracy: 0.9953 - val_loss: 0.6742 - val_accuracy: 0.7931\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0253 - accuracy: 0.9953 - val_loss: 0.6962 - val_accuracy: 0.7984\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.0194 - accuracy: 0.9971 - val_loss: 0.8107 - val_accuracy: 0.7931\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0160 - accuracy: 0.9982 - val_loss: 0.7973 - val_accuracy: 0.8011\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0127 - accuracy: 0.9976 - val_loss: 0.8444 - val_accuracy: 0.8037\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6643 - accuracy: 0.6304 - val_loss: 0.6020 - val_accuracy: 0.6684\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5156 - accuracy: 0.7646 - val_loss: 0.4352 - val_accuracy: 0.7931\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3007 - accuracy: 0.8955 - val_loss: 0.4484 - val_accuracy: 0.7692\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.1691 - accuracy: 0.9564 - val_loss: 0.4826 - val_accuracy: 0.7692\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0922 - accuracy: 0.9835 - val_loss: 0.5845 - val_accuracy: 0.7692\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0560 - accuracy: 0.9903 - val_loss: 0.6466 - val_accuracy: 0.7772\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0437 - accuracy: 0.9953 - val_loss: 0.7038 - val_accuracy: 0.7825\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4       relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5       relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "6       tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4  83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5  78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "6  78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6571 - accuracy: 0.6329 - val_loss: 0.6246 - val_accuracy: 0.6296\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4851 - accuracy: 0.7845 - val_loss: 0.4290 - val_accuracy: 0.8148\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2715 - accuracy: 0.9037 - val_loss: 0.4271 - val_accuracy: 0.7989\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1477 - accuracy: 0.9626 - val_loss: 0.4814 - val_accuracy: 0.7989\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0821 - accuracy: 0.9835 - val_loss: 0.5916 - val_accuracy: 0.7593\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0467 - accuracy: 0.9926 - val_loss: 0.6022 - val_accuracy: 0.7937\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0315 - accuracy: 0.9974 - val_loss: 0.6884 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6583 - accuracy: 0.6256 - val_loss: 0.6346 - val_accuracy: 0.6984\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5020 - accuracy: 0.7663 - val_loss: 0.4858 - val_accuracy: 0.7407\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.2802 - accuracy: 0.9011 - val_loss: 0.5077 - val_accuracy: 0.7619\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1504 - accuracy: 0.9626 - val_loss: 0.5912 - val_accuracy: 0.7540\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0853 - accuracy: 0.9850 - val_loss: 0.6850 - val_accuracy: 0.7407\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0557 - accuracy: 0.9909 - val_loss: 0.7187 - val_accuracy: 0.7593\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0331 - accuracy: 0.9971 - val_loss: 0.7965 - val_accuracy: 0.7513\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0275 - accuracy: 0.9982 - val_loss: 0.8596 - val_accuracy: 0.7698\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0218 - accuracy: 0.9985 - val_loss: 0.9066 - val_accuracy: 0.7646\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0194 - accuracy: 0.9991 - val_loss: 0.9501 - val_accuracy: 0.7646\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0162 - accuracy: 0.9991 - val_loss: 0.9801 - val_accuracy: 0.7698\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0168 - accuracy: 0.9976 - val_loss: 1.0396 - val_accuracy: 0.7593\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0143 - accuracy: 0.9988 - val_loss: 1.0896 - val_accuracy: 0.7487\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 76.98412537574768\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6560 - accuracy: 0.6232 - val_loss: 0.6323 - val_accuracy: 0.7222\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4884 - accuracy: 0.7763 - val_loss: 0.5051 - val_accuracy: 0.7593\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2771 - accuracy: 0.8976 - val_loss: 0.5094 - val_accuracy: 0.7646\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1392 - accuracy: 0.9623 - val_loss: 0.5946 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0743 - accuracy: 0.9847 - val_loss: 0.6609 - val_accuracy: 0.7619\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0419 - accuracy: 0.9938 - val_loss: 0.7523 - val_accuracy: 0.7672\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0294 - accuracy: 0.9971 - val_loss: 0.8375 - val_accuracy: 0.7646\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0227 - accuracy: 0.9974 - val_loss: 0.8943 - val_accuracy: 0.7646\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0184 - accuracy: 0.9979 - val_loss: 0.9235 - val_accuracy: 0.7646\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 76.98412537574768\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6607 - accuracy: 0.6323 - val_loss: 0.6464 - val_accuracy: 0.6111\n",
      "Epoch 2/15\n",
      "68/68 - 5s - loss: 0.5431 - accuracy: 0.7365 - val_loss: 0.4642 - val_accuracy: 0.7619\n",
      "Epoch 3/15\n",
      "68/68 - 5s - loss: 0.3405 - accuracy: 0.8820 - val_loss: 0.4971 - val_accuracy: 0.7646\n",
      "Epoch 4/15\n",
      "68/68 - 5s - loss: 0.1932 - accuracy: 0.9550 - val_loss: 0.5099 - val_accuracy: 0.7672\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.1170 - accuracy: 0.9767 - val_loss: 0.5945 - val_accuracy: 0.7751\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0705 - accuracy: 0.9903 - val_loss: 0.6654 - val_accuracy: 0.7646\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0509 - accuracy: 0.9959 - val_loss: 0.7087 - val_accuracy: 0.7910\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0388 - accuracy: 0.9974 - val_loss: 0.7633 - val_accuracy: 0.7698\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0338 - accuracy: 0.9971 - val_loss: 0.7875 - val_accuracy: 0.7751\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0305 - accuracy: 0.9971 - val_loss: 0.8484 - val_accuracy: 0.7831\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0253 - accuracy: 0.9976 - val_loss: 0.8550 - val_accuracy: 0.7857\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0237 - accuracy: 0.9971 - val_loss: 0.9143 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6584 - accuracy: 0.6250 - val_loss: 0.5947 - val_accuracy: 0.6799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4702 - accuracy: 0.7910 - val_loss: 0.4997 - val_accuracy: 0.7302\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2467 - accuracy: 0.9164 - val_loss: 0.5227 - val_accuracy: 0.7566\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1294 - accuracy: 0.9632 - val_loss: 0.5930 - val_accuracy: 0.7672\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0688 - accuracy: 0.9862 - val_loss: 0.7124 - val_accuracy: 0.7381\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0399 - accuracy: 0.9941 - val_loss: 0.7957 - val_accuracy: 0.7487\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0278 - accuracy: 0.9971 - val_loss: 0.8826 - val_accuracy: 0.7434\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0170 - accuracy: 0.9994 - val_loss: 0.9356 - val_accuracy: 0.7487\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0174 - accuracy: 0.9988 - val_loss: 1.0082 - val_accuracy: 0.7381\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Epoch 1/15\n",
      "68/68 - 7s - loss: 0.6553 - accuracy: 0.6274 - val_loss: 0.6261 - val_accuracy: 0.6180\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4661 - accuracy: 0.7890 - val_loss: 0.4687 - val_accuracy: 0.7347\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2467 - accuracy: 0.9102 - val_loss: 0.4474 - val_accuracy: 0.7666\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1207 - accuracy: 0.9670 - val_loss: 0.5356 - val_accuracy: 0.7692\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0640 - accuracy: 0.9879 - val_loss: 0.5983 - val_accuracy: 0.7745\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0380 - accuracy: 0.9947 - val_loss: 0.6903 - val_accuracy: 0.7533\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0250 - accuracy: 0.9968 - val_loss: 0.7259 - val_accuracy: 0.7692\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0199 - accuracy: 0.9976 - val_loss: 0.7899 - val_accuracy: 0.7692\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0155 - accuracy: 0.9985 - val_loss: 0.9260 - val_accuracy: 0.7719\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0165 - accuracy: 0.9985 - val_loss: 0.8979 - val_accuracy: 0.7480\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 77.45358347892761\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6618 - accuracy: 0.6221 - val_loss: 0.5807 - val_accuracy: 0.6844\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4730 - accuracy: 0.7943 - val_loss: 0.4296 - val_accuracy: 0.7905\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2670 - accuracy: 0.9023 - val_loss: 0.4343 - val_accuracy: 0.7984\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1369 - accuracy: 0.9623 - val_loss: 0.5106 - val_accuracy: 0.7719\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0713 - accuracy: 0.9862 - val_loss: 0.5888 - val_accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0444 - accuracy: 0.9944 - val_loss: 0.7401 - val_accuracy: 0.7586\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0287 - accuracy: 0.9971 - val_loss: 0.7670 - val_accuracy: 0.7639\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0221 - accuracy: 0.9979 - val_loss: 0.8278 - val_accuracy: 0.7692\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6617 - accuracy: 0.6218 - val_loss: 0.6406 - val_accuracy: 0.6605\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5152 - accuracy: 0.7705 - val_loss: 0.4319 - val_accuracy: 0.8037\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.3108 - accuracy: 0.8908 - val_loss: 0.4192 - val_accuracy: 0.8064\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1856 - accuracy: 0.9514 - val_loss: 0.4271 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.1026 - accuracy: 0.9794 - val_loss: 0.4586 - val_accuracy: 0.8143\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0609 - accuracy: 0.9912 - val_loss: 0.5186 - val_accuracy: 0.8117\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0403 - accuracy: 0.9982 - val_loss: 0.5774 - val_accuracy: 0.8117\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0316 - accuracy: 0.9976 - val_loss: 0.6229 - val_accuracy: 0.8090\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0254 - accuracy: 0.9982 - val_loss: 0.6828 - val_accuracy: 0.8196\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0198 - accuracy: 0.9997 - val_loss: 0.7111 - val_accuracy: 0.8117\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0193 - accuracy: 0.9985 - val_loss: 0.7400 - val_accuracy: 0.8117\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0207 - accuracy: 0.9979 - val_loss: 0.7888 - val_accuracy: 0.8117\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0161 - accuracy: 0.9991 - val_loss: 0.8047 - val_accuracy: 0.8090\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0156 - accuracy: 0.9985 - val_loss: 0.8184 - val_accuracy: 0.8037\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 81.9628655910492\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6585 - accuracy: 0.6242 - val_loss: 0.6117 - val_accuracy: 0.6684\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5050 - accuracy: 0.7675 - val_loss: 0.4266 - val_accuracy: 0.8011\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2736 - accuracy: 0.9026 - val_loss: 0.4381 - val_accuracy: 0.7958\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1384 - accuracy: 0.9662 - val_loss: 0.4816 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0724 - accuracy: 0.9868 - val_loss: 0.5660 - val_accuracy: 0.8064\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0442 - accuracy: 0.9956 - val_loss: 0.6196 - val_accuracy: 0.7958\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0299 - accuracy: 0.9974 - val_loss: 0.6402 - val_accuracy: 0.8011\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0247 - accuracy: 0.9974 - val_loss: 0.7251 - val_accuracy: 0.8064\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0208 - accuracy: 0.9979 - val_loss: 0.7616 - val_accuracy: 0.7931\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0155 - accuracy: 0.9988 - val_loss: 0.8342 - val_accuracy: 0.7851\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6621 - accuracy: 0.6298 - val_loss: 0.6317 - val_accuracy: 0.6207\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4998 - accuracy: 0.7705 - val_loss: 0.4250 - val_accuracy: 0.8064\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2739 - accuracy: 0.9049 - val_loss: 0.4108 - val_accuracy: 0.8064\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1518 - accuracy: 0.9579 - val_loss: 0.4799 - val_accuracy: 0.8143\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0758 - accuracy: 0.9897 - val_loss: 0.5475 - val_accuracy: 0.7958\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.0454 - accuracy: 0.9953 - val_loss: 0.5986 - val_accuracy: 0.7905\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0308 - accuracy: 0.9976 - val_loss: 0.6953 - val_accuracy: 0.7878\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0230 - accuracy: 0.9979 - val_loss: 0.7388 - val_accuracy: 0.7851\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0209 - accuracy: 0.9985 - val_loss: 0.7827 - val_accuracy: 0.7931\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4       relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5       relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "6       tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
      "7       tanh       2  81.481481  76.984125  76.984125  79.100531  76.719576   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4  83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5  78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "6  78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
      "7  77.453583  79.840851  81.962866  80.636603  81.432360  79.259610  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6583 - accuracy: 0.6253 - val_loss: 0.6139 - val_accuracy: 0.6455\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4991 - accuracy: 0.7666 - val_loss: 0.4164 - val_accuracy: 0.8148\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2826 - accuracy: 0.8973 - val_loss: 0.4086 - val_accuracy: 0.8122\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1502 - accuracy: 0.9641 - val_loss: 0.3950 - val_accuracy: 0.8360\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.0833 - accuracy: 0.9856 - val_loss: 0.4976 - val_accuracy: 0.8042\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.0464 - accuracy: 0.9950 - val_loss: 0.5717 - val_accuracy: 0.7963\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0363 - accuracy: 0.9971 - val_loss: 0.5701 - val_accuracy: 0.8175\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0258 - accuracy: 0.9985 - val_loss: 0.5950 - val_accuracy: 0.8069\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0215 - accuracy: 0.9979 - val_loss: 0.6865 - val_accuracy: 0.7884\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 83.59788656234741\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6615 - accuracy: 0.6241 - val_loss: 0.6299 - val_accuracy: 0.6852\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4974 - accuracy: 0.7775 - val_loss: 0.4834 - val_accuracy: 0.7540\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2746 - accuracy: 0.9055 - val_loss: 0.5199 - val_accuracy: 0.7778\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1531 - accuracy: 0.9617 - val_loss: 0.6116 - val_accuracy: 0.7593\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0847 - accuracy: 0.9838 - val_loss: 0.7034 - val_accuracy: 0.7593\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0553 - accuracy: 0.9935 - val_loss: 0.7668 - val_accuracy: 0.7698\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0335 - accuracy: 0.9974 - val_loss: 0.8270 - val_accuracy: 0.7698\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0268 - accuracy: 0.9976 - val_loss: 0.8978 - val_accuracy: 0.7619\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 77.77777910232544\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6601 - accuracy: 0.6270 - val_loss: 0.6267 - val_accuracy: 0.6217\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4871 - accuracy: 0.7813 - val_loss: 0.4878 - val_accuracy: 0.7407\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2750 - accuracy: 0.9073 - val_loss: 0.4901 - val_accuracy: 0.7725\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1448 - accuracy: 0.9623 - val_loss: 0.5614 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0768 - accuracy: 0.9856 - val_loss: 0.6442 - val_accuracy: 0.7778\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0410 - accuracy: 0.9965 - val_loss: 0.7107 - val_accuracy: 0.7698\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0296 - accuracy: 0.9971 - val_loss: 0.7679 - val_accuracy: 0.7778\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0244 - accuracy: 0.9979 - val_loss: 0.8041 - val_accuracy: 0.7937\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0175 - accuracy: 0.9988 - val_loss: 0.9235 - val_accuracy: 0.7778\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0159 - accuracy: 0.9985 - val_loss: 0.9359 - val_accuracy: 0.7698\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0164 - accuracy: 0.9985 - val_loss: 0.9357 - val_accuracy: 0.7751\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0167 - accuracy: 0.9985 - val_loss: 0.9645 - val_accuracy: 0.7884\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0124 - accuracy: 0.9985 - val_loss: 1.0099 - val_accuracy: 0.7778\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6597 - accuracy: 0.6197 - val_loss: 0.6095 - val_accuracy: 0.6508\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4848 - accuracy: 0.7763 - val_loss: 0.4512 - val_accuracy: 0.7698\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2701 - accuracy: 0.9034 - val_loss: 0.4583 - val_accuracy: 0.7989\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1338 - accuracy: 0.9679 - val_loss: 0.5439 - val_accuracy: 0.8042\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0802 - accuracy: 0.9844 - val_loss: 0.5888 - val_accuracy: 0.7884\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0419 - accuracy: 0.9956 - val_loss: 0.6376 - val_accuracy: 0.7857\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0302 - accuracy: 0.9971 - val_loss: 0.6951 - val_accuracy: 0.7804\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0231 - accuracy: 0.9982 - val_loss: 0.7449 - val_accuracy: 0.7831\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0204 - accuracy: 0.9985 - val_loss: 0.8252 - val_accuracy: 0.7725\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6692 - accuracy: 0.6300 - val_loss: 0.6338 - val_accuracy: 0.6349\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5009 - accuracy: 0.7671 - val_loss: 0.4523 - val_accuracy: 0.7884\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2950 - accuracy: 0.8949 - val_loss: 0.4218 - val_accuracy: 0.8122\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1460 - accuracy: 0.9659 - val_loss: 0.4363 - val_accuracy: 0.8095\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0822 - accuracy: 0.9847 - val_loss: 0.5302 - val_accuracy: 0.7963\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0492 - accuracy: 0.9941 - val_loss: 0.5622 - val_accuracy: 0.8175\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0341 - accuracy: 0.9968 - val_loss: 0.6093 - val_accuracy: 0.8095\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0264 - accuracy: 0.9979 - val_loss: 0.6553 - val_accuracy: 0.8095\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0213 - accuracy: 0.9994 - val_loss: 0.6693 - val_accuracy: 0.8069\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0189 - accuracy: 0.9982 - val_loss: 0.6987 - val_accuracy: 0.8042\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0167 - accuracy: 0.9985 - val_loss: 0.7196 - val_accuracy: 0.8069\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6563 - accuracy: 0.6186 - val_loss: 0.6064 - val_accuracy: 0.6286\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4589 - accuracy: 0.7919 - val_loss: 0.4412 - val_accuracy: 0.7692\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2473 - accuracy: 0.9167 - val_loss: 0.4560 - val_accuracy: 0.7798\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1274 - accuracy: 0.9659 - val_loss: 0.5439 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0614 - accuracy: 0.9909 - val_loss: 0.6308 - val_accuracy: 0.7719\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0375 - accuracy: 0.9950 - val_loss: 0.7275 - val_accuracy: 0.7666\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.7590 - val_accuracy: 0.7719\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0191 - accuracy: 0.9994 - val_loss: 0.8584 - val_accuracy: 0.7666\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6646 - accuracy: 0.6148 - val_loss: 0.6039 - val_accuracy: 0.6631\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4595 - accuracy: 0.8011 - val_loss: 0.4567 - val_accuracy: 0.7905\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2321 - accuracy: 0.9226 - val_loss: 0.5008 - val_accuracy: 0.7719\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1159 - accuracy: 0.9720 - val_loss: 0.5785 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0632 - accuracy: 0.9891 - val_loss: 0.6737 - val_accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0347 - accuracy: 0.9947 - val_loss: 0.7582 - val_accuracy: 0.7798\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0248 - accuracy: 0.9976 - val_loss: 0.8190 - val_accuracy: 0.7772\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6575 - accuracy: 0.6295 - val_loss: 0.6156 - val_accuracy: 0.6313\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4587 - accuracy: 0.7931 - val_loss: 0.4788 - val_accuracy: 0.7560\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2488 - accuracy: 0.9161 - val_loss: 0.4807 - val_accuracy: 0.7851\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1295 - accuracy: 0.9691 - val_loss: 0.5270 - val_accuracy: 0.7745\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0687 - accuracy: 0.9871 - val_loss: 0.6145 - val_accuracy: 0.7851\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0436 - accuracy: 0.9947 - val_loss: 0.6792 - val_accuracy: 0.7958\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0268 - accuracy: 0.9979 - val_loss: 0.7568 - val_accuracy: 0.7825\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0247 - accuracy: 0.9974 - val_loss: 0.7982 - val_accuracy: 0.7931\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0200 - accuracy: 0.9985 - val_loss: 0.8502 - val_accuracy: 0.7745\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0158 - accuracy: 0.9988 - val_loss: 0.9512 - val_accuracy: 0.7851\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0205 - accuracy: 0.9962 - val_loss: 0.9282 - val_accuracy: 0.7666\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6604 - accuracy: 0.6145 - val_loss: 0.6292 - val_accuracy: 0.6446\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4853 - accuracy: 0.7834 - val_loss: 0.4908 - val_accuracy: 0.7533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2578 - accuracy: 0.9111 - val_loss: 0.4495 - val_accuracy: 0.8037\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1339 - accuracy: 0.9662 - val_loss: 0.5287 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0717 - accuracy: 0.9912 - val_loss: 0.5584 - val_accuracy: 0.7851\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0419 - accuracy: 0.9959 - val_loss: 0.6373 - val_accuracy: 0.7745\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0273 - accuracy: 0.9985 - val_loss: 0.6877 - val_accuracy: 0.7851\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0206 - accuracy: 0.9985 - val_loss: 0.7207 - val_accuracy: 0.8117\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0194 - accuracy: 0.9991 - val_loss: 0.7451 - val_accuracy: 0.8064\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0150 - accuracy: 0.9994 - val_loss: 0.7818 - val_accuracy: 0.8011\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0150 - accuracy: 0.9991 - val_loss: 0.8250 - val_accuracy: 0.7825\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0129 - accuracy: 0.9994 - val_loss: 0.8518 - val_accuracy: 0.7958\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0133 - accuracy: 0.9982 - val_loss: 0.8824 - val_accuracy: 0.7905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6611 - accuracy: 0.6198 - val_loss: 0.6090 - val_accuracy: 0.6658\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4682 - accuracy: 0.7846 - val_loss: 0.4518 - val_accuracy: 0.7772\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2553 - accuracy: 0.9070 - val_loss: 0.4179 - val_accuracy: 0.7984\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1314 - accuracy: 0.9667 - val_loss: 0.4626 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0689 - accuracy: 0.9894 - val_loss: 0.5222 - val_accuracy: 0.7825\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0390 - accuracy: 0.9962 - val_loss: 0.6130 - val_accuracy: 0.7905\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0265 - accuracy: 0.9971 - val_loss: 0.6568 - val_accuracy: 0.7825\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0185 - accuracy: 0.9988 - val_loss: 0.7015 - val_accuracy: 0.7825\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4       relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5       relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "6       tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
      "7       tanh       2  81.481481  76.984125  76.984125  79.100531  76.719576   \n",
      "8       tanh       3  83.597887  77.777779  79.365081  80.423278  81.746030   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4  83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5  78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "6  78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
      "7  77.453583  79.840851  81.962866  80.636603  81.432360  79.259610  \n",
      "8  77.984083  79.045093  79.575598  81.167108  79.840851  80.052279  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6629 - accuracy: 0.6211 - val_loss: 0.6105 - val_accuracy: 0.7116\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4749 - accuracy: 0.7869 - val_loss: 0.4824 - val_accuracy: 0.7778\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2454 - accuracy: 0.9208 - val_loss: 0.4868 - val_accuracy: 0.7963\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1431 - accuracy: 0.9620 - val_loss: 0.5887 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0761 - accuracy: 0.9862 - val_loss: 0.6517 - val_accuracy: 0.7725\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0407 - accuracy: 0.9968 - val_loss: 0.7346 - val_accuracy: 0.7725\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0308 - accuracy: 0.9982 - val_loss: 0.7932 - val_accuracy: 0.7460\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0228 - accuracy: 0.9985 - val_loss: 0.8308 - val_accuracy: 0.7698\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6620 - accuracy: 0.6211 - val_loss: 0.6098 - val_accuracy: 0.6534\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.4881 - accuracy: 0.7872 - val_loss: 0.4119 - val_accuracy: 0.8201\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2629 - accuracy: 0.9087 - val_loss: 0.3879 - val_accuracy: 0.8201\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1394 - accuracy: 0.9691 - val_loss: 0.4419 - val_accuracy: 0.8439\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0740 - accuracy: 0.9897 - val_loss: 0.5194 - val_accuracy: 0.8280\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0444 - accuracy: 0.9962 - val_loss: 0.5498 - val_accuracy: 0.8016\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0364 - accuracy: 0.9965 - val_loss: 0.5913 - val_accuracy: 0.8175\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0270 - accuracy: 0.9976 - val_loss: 0.6252 - val_accuracy: 0.8175\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0264 - accuracy: 0.9971 - val_loss: 0.6577 - val_accuracy: 0.8148\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 84.3915343284607\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6727 - accuracy: 0.6102 - val_loss: 0.6231 - val_accuracy: 0.6508\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4652 - accuracy: 0.7922 - val_loss: 0.4828 - val_accuracy: 0.7672\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2376 - accuracy: 0.9232 - val_loss: 0.5126 - val_accuracy: 0.7619\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1185 - accuracy: 0.9735 - val_loss: 0.5885 - val_accuracy: 0.7646\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0575 - accuracy: 0.9918 - val_loss: 0.6810 - val_accuracy: 0.7831\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0341 - accuracy: 0.9968 - val_loss: 0.7768 - val_accuracy: 0.7698\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0248 - accuracy: 0.9988 - val_loss: 0.8436 - val_accuracy: 0.7698\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0201 - accuracy: 0.9979 - val_loss: 0.9082 - val_accuracy: 0.7725\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0190 - accuracy: 0.9982 - val_loss: 0.9515 - val_accuracy: 0.7778\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0163 - accuracy: 0.9994 - val_loss: 0.9847 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6652 - accuracy: 0.6205 - val_loss: 0.6028 - val_accuracy: 0.6534\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4807 - accuracy: 0.7845 - val_loss: 0.4175 - val_accuracy: 0.8148\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2581 - accuracy: 0.9152 - val_loss: 0.4460 - val_accuracy: 0.7989\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1404 - accuracy: 0.9673 - val_loss: 0.4679 - val_accuracy: 0.7989\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0737 - accuracy: 0.9909 - val_loss: 0.5526 - val_accuracy: 0.7963\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0446 - accuracy: 0.9965 - val_loss: 0.6414 - val_accuracy: 0.7963\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0319 - accuracy: 0.9976 - val_loss: 0.7002 - val_accuracy: 0.7963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6623 - accuracy: 0.6261 - val_loss: 0.6450 - val_accuracy: 0.6296\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.5130 - accuracy: 0.7704 - val_loss: 0.4604 - val_accuracy: 0.7884\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2864 - accuracy: 0.9073 - val_loss: 0.4786 - val_accuracy: 0.7725\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1520 - accuracy: 0.9647 - val_loss: 0.5381 - val_accuracy: 0.7725\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0864 - accuracy: 0.9868 - val_loss: 0.6008 - val_accuracy: 0.7751\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0514 - accuracy: 0.9938 - val_loss: 0.6488 - val_accuracy: 0.7831\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0371 - accuracy: 0.9976 - val_loss: 0.7072 - val_accuracy: 0.7672\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 78.83597612380981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6582 - accuracy: 0.6265 - val_loss: 0.6124 - val_accuracy: 0.6393\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4741 - accuracy: 0.7822 - val_loss: 0.4539 - val_accuracy: 0.7772\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2395 - accuracy: 0.9238 - val_loss: 0.5009 - val_accuracy: 0.7533\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1338 - accuracy: 0.9635 - val_loss: 0.5769 - val_accuracy: 0.7586\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0663 - accuracy: 0.9888 - val_loss: 0.6759 - val_accuracy: 0.7613\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0370 - accuracy: 0.9974 - val_loss: 0.7566 - val_accuracy: 0.7692\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0260 - accuracy: 0.9985 - val_loss: 0.8213 - val_accuracy: 0.7560\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 77.71883010864258\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6699 - accuracy: 0.6204 - val_loss: 0.6112 - val_accuracy: 0.6631\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4827 - accuracy: 0.7763 - val_loss: 0.4489 - val_accuracy: 0.7878\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2701 - accuracy: 0.9061 - val_loss: 0.4887 - val_accuracy: 0.7825\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1385 - accuracy: 0.9685 - val_loss: 0.5125 - val_accuracy: 0.7984\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0779 - accuracy: 0.9865 - val_loss: 0.6089 - val_accuracy: 0.7931\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0512 - accuracy: 0.9938 - val_loss: 0.6750 - val_accuracy: 0.7931\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0328 - accuracy: 0.9968 - val_loss: 0.7182 - val_accuracy: 0.7719\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0261 - accuracy: 0.9982 - val_loss: 0.7712 - val_accuracy: 0.7825\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0239 - accuracy: 0.9979 - val_loss: 0.8377 - val_accuracy: 0.7905\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6638 - accuracy: 0.6177 - val_loss: 0.6624 - val_accuracy: 0.6127\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.5127 - accuracy: 0.7637 - val_loss: 0.4486 - val_accuracy: 0.7772\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2830 - accuracy: 0.9002 - val_loss: 0.4909 - val_accuracy: 0.7639\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1435 - accuracy: 0.9709 - val_loss: 0.5574 - val_accuracy: 0.7666\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0829 - accuracy: 0.9868 - val_loss: 0.6712 - val_accuracy: 0.7586\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0482 - accuracy: 0.9953 - val_loss: 0.7373 - val_accuracy: 0.7507\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0327 - accuracy: 0.9982 - val_loss: 0.8320 - val_accuracy: 0.7586\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 77.71883010864258\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6643 - accuracy: 0.6183 - val_loss: 0.6112 - val_accuracy: 0.6552\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.4668 - accuracy: 0.7905 - val_loss: 0.4620 - val_accuracy: 0.7745\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2443 - accuracy: 0.9167 - val_loss: 0.4914 - val_accuracy: 0.7905\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1237 - accuracy: 0.9697 - val_loss: 0.5322 - val_accuracy: 0.7878\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0604 - accuracy: 0.9900 - val_loss: 0.5845 - val_accuracy: 0.7905\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0424 - accuracy: 0.9950 - val_loss: 0.6493 - val_accuracy: 0.8011\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0273 - accuracy: 0.9979 - val_loss: 0.7168 - val_accuracy: 0.7825\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0234 - accuracy: 0.9982 - val_loss: 0.7461 - val_accuracy: 0.8117\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0198 - accuracy: 0.9982 - val_loss: 0.7926 - val_accuracy: 0.8037\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0165 - accuracy: 0.9985 - val_loss: 0.8239 - val_accuracy: 0.7905\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0151 - accuracy: 0.9979 - val_loss: 0.8528 - val_accuracy: 0.7905\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0140 - accuracy: 0.9976 - val_loss: 0.8652 - val_accuracy: 0.7905\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.8800 - val_accuracy: 0.7958\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6545 - accuracy: 0.6304 - val_loss: 0.6410 - val_accuracy: 0.5862\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.4572 - accuracy: 0.7955 - val_loss: 0.4667 - val_accuracy: 0.7798\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2304 - accuracy: 0.9223 - val_loss: 0.5415 - val_accuracy: 0.7613\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1013 - accuracy: 0.9768 - val_loss: 0.6063 - val_accuracy: 0.7772\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0521 - accuracy: 0.9935 - val_loss: 0.6950 - val_accuracy: 0.7586\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0294 - accuracy: 0.9974 - val_loss: 0.7775 - val_accuracy: 0.7639\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.0229 - accuracy: 0.9979 - val_loss: 0.8487 - val_accuracy: 0.7507\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1       relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2       relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3       relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4       relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5       relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "6       tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
      "7       tanh       2  81.481481  76.984125  76.984125  79.100531  76.719576   \n",
      "8       tanh       3  83.597887  77.777779  79.365081  80.423278  81.746030   \n",
      "9       tanh       4  79.629630  84.391534  78.306878  81.481481  78.835976   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1  80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2  76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3  79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4  83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5  78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "6  78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
      "7  77.453583  79.840851  81.962866  80.636603  81.432360  79.259610  \n",
      "8  77.984083  79.045093  79.575598  81.167108  79.840851  80.052279  \n",
      "9  77.718830  79.840851  77.718830  81.167108  77.984083  79.707520  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6695 - accuracy: 0.6211 - val_loss: 0.6008 - val_accuracy: 0.7381\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4692 - accuracy: 0.7860 - val_loss: 0.3752 - val_accuracy: 0.8254\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2393 - accuracy: 0.9176 - val_loss: 0.4110 - val_accuracy: 0.8228\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1167 - accuracy: 0.9735 - val_loss: 0.4508 - val_accuracy: 0.8228\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0599 - accuracy: 0.9923 - val_loss: 0.5003 - val_accuracy: 0.8069\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0372 - accuracy: 0.9950 - val_loss: 0.5417 - val_accuracy: 0.8095\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0254 - accuracy: 0.9985 - val_loss: 0.6060 - val_accuracy: 0.8201\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6660 - accuracy: 0.6141 - val_loss: 0.5597 - val_accuracy: 0.7090\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4365 - accuracy: 0.8075 - val_loss: 0.4926 - val_accuracy: 0.7619\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2214 - accuracy: 0.9285 - val_loss: 0.5581 - val_accuracy: 0.7672\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1115 - accuracy: 0.9717 - val_loss: 0.5814 - val_accuracy: 0.7857\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0601 - accuracy: 0.9891 - val_loss: 0.6931 - val_accuracy: 0.7804\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0355 - accuracy: 0.9953 - val_loss: 0.7614 - val_accuracy: 0.7646\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0245 - accuracy: 0.9976 - val_loss: 0.8024 - val_accuracy: 0.7804\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0211 - accuracy: 0.9985 - val_loss: 0.8893 - val_accuracy: 0.7698\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0170 - accuracy: 0.9976 - val_loss: 0.9570 - val_accuracy: 0.7646\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.57142686843872\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6650 - accuracy: 0.6253 - val_loss: 0.6263 - val_accuracy: 0.6508\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4625 - accuracy: 0.7907 - val_loss: 0.4437 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2420 - accuracy: 0.9217 - val_loss: 0.4595 - val_accuracy: 0.7698\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1175 - accuracy: 0.9762 - val_loss: 0.5752 - val_accuracy: 0.7566\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0616 - accuracy: 0.9929 - val_loss: 0.6778 - val_accuracy: 0.7619\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0390 - accuracy: 0.9965 - val_loss: 0.6796 - val_accuracy: 0.7910\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0301 - accuracy: 0.9971 - val_loss: 0.7777 - val_accuracy: 0.7619\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0223 - accuracy: 0.9988 - val_loss: 0.8372 - val_accuracy: 0.7672\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0209 - accuracy: 0.9974 - val_loss: 0.8812 - val_accuracy: 0.7778\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0156 - accuracy: 0.9991 - val_loss: 0.9288 - val_accuracy: 0.7646\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0150 - accuracy: 0.9985 - val_loss: 0.9282 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6702 - accuracy: 0.6114 - val_loss: 0.5966 - val_accuracy: 0.6825\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.4662 - accuracy: 0.8007 - val_loss: 0.4243 - val_accuracy: 0.7989\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2527 - accuracy: 0.9185 - val_loss: 0.4665 - val_accuracy: 0.7698\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1212 - accuracy: 0.9726 - val_loss: 0.5057 - val_accuracy: 0.7884\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0631 - accuracy: 0.9894 - val_loss: 0.5813 - val_accuracy: 0.8042\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0388 - accuracy: 0.9959 - val_loss: 0.6623 - val_accuracy: 0.7937\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0299 - accuracy: 0.9979 - val_loss: 0.6992 - val_accuracy: 0.8042\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0229 - accuracy: 0.9979 - val_loss: 0.7559 - val_accuracy: 0.7989\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0202 - accuracy: 0.9979 - val_loss: 0.7726 - val_accuracy: 0.8069\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0198 - accuracy: 0.9982 - val_loss: 0.7899 - val_accuracy: 0.8069\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.8563 - val_accuracy: 0.7989\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0152 - accuracy: 0.9991 - val_loss: 0.8951 - val_accuracy: 0.8122\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.9038 - val_accuracy: 0.8042\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0130 - accuracy: 0.9991 - val_loss: 0.9756 - val_accuracy: 0.8016\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0119 - accuracy: 0.9985 - val_loss: 1.0101 - val_accuracy: 0.7857\n",
      "Test Accuracy: 78.57142686843872\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6671 - accuracy: 0.6161 - val_loss: 0.5982 - val_accuracy: 0.7275\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4451 - accuracy: 0.8089 - val_loss: 0.4455 - val_accuracy: 0.7857\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2088 - accuracy: 0.9302 - val_loss: 0.5068 - val_accuracy: 0.7884\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.0908 - accuracy: 0.9797 - val_loss: 0.6332 - val_accuracy: 0.7698\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0498 - accuracy: 0.9929 - val_loss: 0.6201 - val_accuracy: 0.7910\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0267 - accuracy: 0.9982 - val_loss: 0.7128 - val_accuracy: 0.7725\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0170 - accuracy: 0.9991 - val_loss: 0.7981 - val_accuracy: 0.7646\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0155 - accuracy: 0.9985 - val_loss: 0.7658 - val_accuracy: 0.7884\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0119 - accuracy: 0.9997 - val_loss: 0.8037 - val_accuracy: 0.7857\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0110 - accuracy: 0.9994 - val_loss: 0.7803 - val_accuracy: 0.8016\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0131 - accuracy: 0.9982 - val_loss: 1.0751 - val_accuracy: 0.7593\n",
      "Epoch 12/15\n",
      "68/68 - 4s - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.9900 - val_accuracy: 0.7778\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0102 - accuracy: 0.9985 - val_loss: 1.0153 - val_accuracy: 0.7804\n",
      "Epoch 14/15\n",
      "68/68 - 4s - loss: 0.0204 - accuracy: 0.9959 - val_loss: 1.1424 - val_accuracy: 0.7646\n",
      "Epoch 15/15\n",
      "68/68 - 4s - loss: 0.0243 - accuracy: 0.9950 - val_loss: 1.1353 - val_accuracy: 0.7646\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6630 - accuracy: 0.6286 - val_loss: 0.6031 - val_accuracy: 0.6446\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4802 - accuracy: 0.7763 - val_loss: 0.4479 - val_accuracy: 0.7984\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2552 - accuracy: 0.9182 - val_loss: 0.5111 - val_accuracy: 0.7825\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1359 - accuracy: 0.9691 - val_loss: 0.5555 - val_accuracy: 0.7745\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0738 - accuracy: 0.9871 - val_loss: 0.6032 - val_accuracy: 0.7851\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0434 - accuracy: 0.9968 - val_loss: 0.6642 - val_accuracy: 0.7931\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0372 - accuracy: 0.9974 - val_loss: 0.7371 - val_accuracy: 0.7798\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6589 - accuracy: 0.6224 - val_loss: 0.6205 - val_accuracy: 0.6286\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4451 - accuracy: 0.8022 - val_loss: 0.4659 - val_accuracy: 0.7905\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2156 - accuracy: 0.9347 - val_loss: 0.5263 - val_accuracy: 0.7639\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1039 - accuracy: 0.9782 - val_loss: 0.6124 - val_accuracy: 0.7560\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0514 - accuracy: 0.9923 - val_loss: 0.7071 - val_accuracy: 0.7745\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0343 - accuracy: 0.9962 - val_loss: 0.7558 - val_accuracy: 0.7613\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0222 - accuracy: 0.9985 - val_loss: 0.8391 - val_accuracy: 0.7825\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6581 - accuracy: 0.6227 - val_loss: 0.5758 - val_accuracy: 0.7082\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4521 - accuracy: 0.8008 - val_loss: 0.4374 - val_accuracy: 0.7851\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2280 - accuracy: 0.9305 - val_loss: 0.4858 - val_accuracy: 0.7772\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1141 - accuracy: 0.9750 - val_loss: 0.4966 - val_accuracy: 0.8011\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0609 - accuracy: 0.9891 - val_loss: 0.5934 - val_accuracy: 0.7772\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0376 - accuracy: 0.9971 - val_loss: 0.6360 - val_accuracy: 0.7772\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0286 - accuracy: 0.9976 - val_loss: 0.7317 - val_accuracy: 0.7772\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0219 - accuracy: 0.9982 - val_loss: 0.7916 - val_accuracy: 0.7719\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0169 - accuracy: 0.9988 - val_loss: 0.8306 - val_accuracy: 0.7586\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6680 - accuracy: 0.6162 - val_loss: 0.6424 - val_accuracy: 0.5968\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4582 - accuracy: 0.7919 - val_loss: 0.4661 - val_accuracy: 0.7798\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2351 - accuracy: 0.9188 - val_loss: 0.5051 - val_accuracy: 0.7613\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.0987 - accuracy: 0.9809 - val_loss: 0.6298 - val_accuracy: 0.7719\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0495 - accuracy: 0.9941 - val_loss: 0.6835 - val_accuracy: 0.7772\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0303 - accuracy: 0.9971 - val_loss: 0.7986 - val_accuracy: 0.7825\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0206 - accuracy: 0.9976 - val_loss: 0.8797 - val_accuracy: 0.7772\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0184 - accuracy: 0.9985 - val_loss: 0.9382 - val_accuracy: 0.7745\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0146 - accuracy: 0.9994 - val_loss: 1.0045 - val_accuracy: 0.7825\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0144 - accuracy: 0.9988 - val_loss: 1.0468 - val_accuracy: 0.7719\n",
      "Epoch 11/15\n",
      "68/68 - 4s - loss: 0.0136 - accuracy: 0.9988 - val_loss: 1.1516 - val_accuracy: 0.7613\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6618 - accuracy: 0.6251 - val_loss: 0.6185 - val_accuracy: 0.6286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4542 - accuracy: 0.7999 - val_loss: 0.4845 - val_accuracy: 0.7639\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2401 - accuracy: 0.9202 - val_loss: 0.5338 - val_accuracy: 0.7851\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1132 - accuracy: 0.9762 - val_loss: 0.6017 - val_accuracy: 0.7719\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0593 - accuracy: 0.9932 - val_loss: 0.6604 - val_accuracy: 0.7851\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0469 - accuracy: 0.9921 - val_loss: 0.7239 - val_accuracy: 0.7825\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0301 - accuracy: 0.9971 - val_loss: 0.7374 - val_accuracy: 0.7851\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0279 - accuracy: 0.9965 - val_loss: 0.8651 - val_accuracy: 0.7639\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "\n",
      "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0        relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1        relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2        relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3        relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4        relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5        relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "6        tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
      "7        tanh       2  81.481481  76.984125  76.984125  79.100531  76.719576   \n",
      "8        tanh       3  83.597887  77.777779  79.365081  80.423278  81.746030   \n",
      "9        tanh       4  79.629630  84.391534  78.306878  81.481481  78.835976   \n",
      "10       tanh       5  82.539684  78.571427  79.100531  78.571427  80.158728   \n",
      "\n",
      "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0   78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1   80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2   76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3   79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4   83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5   78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "6   78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
      "7   77.453583  79.840851  81.962866  80.636603  81.432360  79.259610  \n",
      "8   77.984083  79.045093  79.575598  81.167108  79.840851  80.052279  \n",
      "9   77.718830  79.840851  77.718830  81.167108  77.984083  79.707520  \n",
      "10  79.840851  79.045093  80.106103  78.249335  78.514588  79.469777  \n",
      "\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6702 - accuracy: 0.6061 - val_loss: 0.5991 - val_accuracy: 0.6402\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4523 - accuracy: 0.8063 - val_loss: 0.4459 - val_accuracy: 0.7884\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2253 - accuracy: 0.9279 - val_loss: 0.4623 - val_accuracy: 0.7910\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1011 - accuracy: 0.9779 - val_loss: 0.5441 - val_accuracy: 0.8042\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0490 - accuracy: 0.9929 - val_loss: 0.6238 - val_accuracy: 0.7804\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0307 - accuracy: 0.9979 - val_loss: 0.6934 - val_accuracy: 0.7831\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0216 - accuracy: 0.9976 - val_loss: 0.7686 - val_accuracy: 0.7831\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0180 - accuracy: 0.9994 - val_loss: 0.8048 - val_accuracy: 0.7884\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0156 - accuracy: 0.9991 - val_loss: 0.8547 - val_accuracy: 0.7963\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6594 - accuracy: 0.6253 - val_loss: 0.5851 - val_accuracy: 0.7513\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4339 - accuracy: 0.8122 - val_loss: 0.4632 - val_accuracy: 0.7804\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2215 - accuracy: 0.9299 - val_loss: 0.4986 - val_accuracy: 0.7725\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1082 - accuracy: 0.9759 - val_loss: 0.5760 - val_accuracy: 0.7831\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0529 - accuracy: 0.9935 - val_loss: 0.6495 - val_accuracy: 0.7910\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0328 - accuracy: 0.9968 - val_loss: 0.7213 - val_accuracy: 0.7672\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0230 - accuracy: 0.9991 - val_loss: 0.7626 - val_accuracy: 0.7963\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0233 - accuracy: 0.9979 - val_loss: 0.8112 - val_accuracy: 0.8042\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0186 - accuracy: 0.9988 - val_loss: 0.8321 - val_accuracy: 0.7989\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0169 - accuracy: 0.9982 - val_loss: 0.8810 - val_accuracy: 0.8016\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0182 - accuracy: 0.9979 - val_loss: 0.9573 - val_accuracy: 0.7857\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0125 - accuracy: 0.9988 - val_loss: 1.0087 - val_accuracy: 0.7804\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0181 - accuracy: 0.9974 - val_loss: 1.0166 - val_accuracy: 0.7831\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6530 - accuracy: 0.6279 - val_loss: 0.6120 - val_accuracy: 0.6376\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4364 - accuracy: 0.8119 - val_loss: 0.5115 - val_accuracy: 0.7407\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2350 - accuracy: 0.9235 - val_loss: 0.5270 - val_accuracy: 0.7487\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1181 - accuracy: 0.9759 - val_loss: 0.6399 - val_accuracy: 0.7434\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0690 - accuracy: 0.9926 - val_loss: 0.6633 - val_accuracy: 0.7566\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0391 - accuracy: 0.9968 - val_loss: 0.7654 - val_accuracy: 0.7434\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0310 - accuracy: 0.9982 - val_loss: 0.8014 - val_accuracy: 0.7513\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0245 - accuracy: 0.9991 - val_loss: 0.8494 - val_accuracy: 0.7460\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0209 - accuracy: 0.9988 - val_loss: 0.8936 - val_accuracy: 0.7487\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0191 - accuracy: 0.9976 - val_loss: 0.9199 - val_accuracy: 0.7407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 75.66137313842773\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6680 - accuracy: 0.6123 - val_loss: 0.6110 - val_accuracy: 0.6640\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4796 - accuracy: 0.7842 - val_loss: 0.4365 - val_accuracy: 0.8042\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2669 - accuracy: 0.9170 - val_loss: 0.4936 - val_accuracy: 0.7672\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1467 - accuracy: 0.9717 - val_loss: 0.5159 - val_accuracy: 0.7937\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0884 - accuracy: 0.9882 - val_loss: 0.6252 - val_accuracy: 0.7725\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0605 - accuracy: 0.9935 - val_loss: 0.6927 - val_accuracy: 0.7778\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0476 - accuracy: 0.9962 - val_loss: 0.7593 - val_accuracy: 0.7672\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6798 - accuracy: 0.6020 - val_loss: 0.5878 - val_accuracy: 0.6825\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4585 - accuracy: 0.7928 - val_loss: 0.4457 - val_accuracy: 0.7989\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2383 - accuracy: 0.9199 - val_loss: 0.4992 - val_accuracy: 0.7963\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1085 - accuracy: 0.9762 - val_loss: 0.5629 - val_accuracy: 0.7937\n",
      "Epoch 5/15\n",
      "68/68 - 5s - loss: 0.0583 - accuracy: 0.9926 - val_loss: 0.6168 - val_accuracy: 0.8069\n",
      "Epoch 6/15\n",
      "68/68 - 5s - loss: 0.0346 - accuracy: 0.9968 - val_loss: 0.6669 - val_accuracy: 0.8095\n",
      "Epoch 7/15\n",
      "68/68 - 5s - loss: 0.0235 - accuracy: 0.9985 - val_loss: 0.7342 - val_accuracy: 0.8042\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0199 - accuracy: 0.9985 - val_loss: 0.7730 - val_accuracy: 0.8069\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0185 - accuracy: 0.9985 - val_loss: 0.7984 - val_accuracy: 0.8148\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0149 - accuracy: 0.9988 - val_loss: 0.8273 - val_accuracy: 0.8095\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0135 - accuracy: 0.9991 - val_loss: 0.8594 - val_accuracy: 0.8122\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0128 - accuracy: 0.9988 - val_loss: 0.8767 - val_accuracy: 0.8069\n",
      "Epoch 13/15\n",
      "68/68 - 4s - loss: 0.0117 - accuracy: 0.9988 - val_loss: 0.9230 - val_accuracy: 0.8122\n",
      "Epoch 14/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 - 4s - loss: 0.0110 - accuracy: 0.9988 - val_loss: 1.0608 - val_accuracy: 0.7751\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6644 - accuracy: 0.6210 - val_loss: 0.6095 - val_accuracy: 0.6578\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4625 - accuracy: 0.8058 - val_loss: 0.5079 - val_accuracy: 0.7560\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2528 - accuracy: 0.9161 - val_loss: 0.5439 - val_accuracy: 0.7321\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1280 - accuracy: 0.9738 - val_loss: 0.6115 - val_accuracy: 0.7507\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0735 - accuracy: 0.9862 - val_loss: 0.6559 - val_accuracy: 0.7666\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0458 - accuracy: 0.9950 - val_loss: 0.7943 - val_accuracy: 0.7480\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0298 - accuracy: 0.9976 - val_loss: 0.8429 - val_accuracy: 0.7613\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0219 - accuracy: 0.9994 - val_loss: 0.9081 - val_accuracy: 0.7560\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0192 - accuracy: 0.9988 - val_loss: 0.9586 - val_accuracy: 0.7533\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0188 - accuracy: 0.9982 - val_loss: 1.0165 - val_accuracy: 0.7613\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 76.65782570838928\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6717 - accuracy: 0.6042 - val_loss: 0.5850 - val_accuracy: 0.6844\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4477 - accuracy: 0.8058 - val_loss: 0.4162 - val_accuracy: 0.7931\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2329 - accuracy: 0.9258 - val_loss: 0.3996 - val_accuracy: 0.8302\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1069 - accuracy: 0.9791 - val_loss: 0.4259 - val_accuracy: 0.8249\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0603 - accuracy: 0.9915 - val_loss: 0.4717 - val_accuracy: 0.8143\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0363 - accuracy: 0.9965 - val_loss: 0.5131 - val_accuracy: 0.8302\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0245 - accuracy: 0.9988 - val_loss: 0.5285 - val_accuracy: 0.8435\n",
      "Epoch 8/15\n",
      "68/68 - 5s - loss: 0.0198 - accuracy: 0.9988 - val_loss: 0.5855 - val_accuracy: 0.8408\n",
      "Epoch 9/15\n",
      "68/68 - 5s - loss: 0.0154 - accuracy: 0.9991 - val_loss: 0.5998 - val_accuracy: 0.8355\n",
      "Epoch 10/15\n",
      "68/68 - 5s - loss: 0.0151 - accuracy: 0.9988 - val_loss: 0.6453 - val_accuracy: 0.8408\n",
      "Epoch 11/15\n",
      "68/68 - 5s - loss: 0.0128 - accuracy: 0.9994 - val_loss: 0.6656 - val_accuracy: 0.8249\n",
      "Epoch 12/15\n",
      "68/68 - 5s - loss: 0.0114 - accuracy: 0.9985 - val_loss: 0.8067 - val_accuracy: 0.8090\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 84.3501329421997\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6608 - accuracy: 0.6171 - val_loss: 0.6280 - val_accuracy: 0.6340\n",
      "Epoch 2/15\n",
      "68/68 - 3s - loss: 0.4621 - accuracy: 0.8037 - val_loss: 0.4584 - val_accuracy: 0.7772\n",
      "Epoch 3/15\n",
      "68/68 - 3s - loss: 0.2286 - accuracy: 0.9267 - val_loss: 0.4800 - val_accuracy: 0.7905\n",
      "Epoch 4/15\n",
      "68/68 - 3s - loss: 0.1157 - accuracy: 0.9735 - val_loss: 0.5312 - val_accuracy: 0.7905\n",
      "Epoch 5/15\n",
      "68/68 - 3s - loss: 0.0604 - accuracy: 0.9923 - val_loss: 0.5971 - val_accuracy: 0.8011\n",
      "Epoch 6/15\n",
      "68/68 - 3s - loss: 0.0342 - accuracy: 0.9976 - val_loss: 0.6373 - val_accuracy: 0.7931\n",
      "Epoch 7/15\n",
      "68/68 - 3s - loss: 0.0253 - accuracy: 0.9979 - val_loss: 0.7026 - val_accuracy: 0.7931\n",
      "Epoch 8/15\n",
      "68/68 - 3s - loss: 0.0207 - accuracy: 0.9988 - val_loss: 0.7579 - val_accuracy: 0.7984\n",
      "Epoch 9/15\n",
      "68/68 - 3s - loss: 0.0192 - accuracy: 0.9982 - val_loss: 0.7772 - val_accuracy: 0.8011\n",
      "Epoch 10/15\n",
      "68/68 - 4s - loss: 0.0175 - accuracy: 0.9982 - val_loss: 0.8427 - val_accuracy: 0.7851\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Epoch 1/15\n",
      "68/68 - 6s - loss: 0.6612 - accuracy: 0.6204 - val_loss: 0.6274 - val_accuracy: 0.6684\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4710 - accuracy: 0.7928 - val_loss: 0.4565 - val_accuracy: 0.7798\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2574 - accuracy: 0.9161 - val_loss: 0.5031 - val_accuracy: 0.7719\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1296 - accuracy: 0.9712 - val_loss: 0.5548 - val_accuracy: 0.7905\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0726 - accuracy: 0.9897 - val_loss: 0.6394 - val_accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0459 - accuracy: 0.9959 - val_loss: 0.7032 - val_accuracy: 0.7825\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0326 - accuracy: 0.9968 - val_loss: 0.7552 - val_accuracy: 0.7878\n",
      "Epoch 8/15\n",
      "68/68 - 4s - loss: 0.0250 - accuracy: 0.9988 - val_loss: 0.8318 - val_accuracy: 0.7851\n",
      "Epoch 9/15\n",
      "68/68 - 4s - loss: 0.0238 - accuracy: 0.9976 - val_loss: 0.9047 - val_accuracy: 0.7666\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Epoch 1/15\n",
      "68/68 - 5s - loss: 0.6686 - accuracy: 0.6109 - val_loss: 0.5916 - val_accuracy: 0.7003\n",
      "Epoch 2/15\n",
      "68/68 - 4s - loss: 0.4746 - accuracy: 0.7852 - val_loss: 0.4420 - val_accuracy: 0.8170\n",
      "Epoch 3/15\n",
      "68/68 - 4s - loss: 0.2429 - accuracy: 0.9202 - val_loss: 0.4532 - val_accuracy: 0.8090\n",
      "Epoch 4/15\n",
      "68/68 - 4s - loss: 0.1154 - accuracy: 0.9738 - val_loss: 0.5343 - val_accuracy: 0.7798\n",
      "Epoch 5/15\n",
      "68/68 - 4s - loss: 0.0611 - accuracy: 0.9926 - val_loss: 0.5900 - val_accuracy: 0.7798\n",
      "Epoch 6/15\n",
      "68/68 - 4s - loss: 0.0407 - accuracy: 0.9956 - val_loss: 0.6615 - val_accuracy: 0.7825\n",
      "Epoch 7/15\n",
      "68/68 - 4s - loss: 0.0283 - accuracy: 0.9982 - val_loss: 0.7440 - val_accuracy: 0.7719\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n",
      "Test Accuracy: 81.69761300086975\n",
      "\n",
      "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0        relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
      "1        relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
      "2        relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
      "3        relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
      "4        relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
      "5        relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
      "6        tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
      "7        tanh       2  81.481481  76.984125  76.984125  79.100531  76.719576   \n",
      "8        tanh       3  83.597887  77.777779  79.365081  80.423278  81.746030   \n",
      "9        tanh       4  79.629630  84.391534  78.306878  81.481481  78.835976   \n",
      "10       tanh       5  82.539684  78.571427  79.100531  78.571427  80.158728   \n",
      "11       tanh       6  80.423278  80.423278  75.661373  80.423278  81.481481   \n",
      "\n",
      "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0   78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
      "1   80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
      "2   76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
      "3   79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
      "4   83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
      "5   78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
      "6   78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
      "7   77.453583  79.840851  81.962866  80.636603  81.432360  79.259610  \n",
      "8   77.984083  79.045093  79.575598  81.167108  79.840851  80.052279  \n",
      "9   77.718830  79.840851  77.718830  81.167108  77.984083  79.707520  \n",
      "10  79.840851  79.045093  80.106103  78.249335  78.514588  79.469777  \n",
      "11  76.657826  84.350133  80.106103  79.045093  81.697613  80.026945  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu', 'tanh']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "\n",
    "            # Define the input shape\n",
    "            model = define_model(filters, kernel_size, activation, input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=15, verbose=2, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record = record.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>77.513230</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>79.629630</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>81.962866</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>80.371563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>83.023870</td>\n",
       "      <td>78.779840</td>\n",
       "      <td>80.371350</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>80.318091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>79.365081</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>83.023870</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>77.718830</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>80.317881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>76.190478</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>83.597887</td>\n",
       "      <td>78.779840</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>77.188331</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>83.023870</td>\n",
       "      <td>80.211711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tanh</td>\n",
       "      <td>3</td>\n",
       "      <td>83.597887</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>79.365081</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>81.746030</td>\n",
       "      <td>77.984083</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>80.052279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>tanh</td>\n",
       "      <td>6</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>75.661373</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>76.657826</td>\n",
       "      <td>84.350133</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>80.026945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>79.629630</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>77.513230</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>82.228118</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>79.761765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tanh</td>\n",
       "      <td>4</td>\n",
       "      <td>79.629630</td>\n",
       "      <td>84.391534</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>78.835976</td>\n",
       "      <td>77.718830</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>77.718830</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>77.984083</td>\n",
       "      <td>79.707520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tanh</td>\n",
       "      <td>1</td>\n",
       "      <td>77.513230</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>82.010579</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>77.453583</td>\n",
       "      <td>81.697613</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>79.549844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>tanh</td>\n",
       "      <td>5</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>79.469777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>82.010579</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>76.984125</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>81.746030</td>\n",
       "      <td>76.127321</td>\n",
       "      <td>80.371350</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>74.801064</td>\n",
       "      <td>79.363114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tanh</td>\n",
       "      <td>2</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>76.984125</td>\n",
       "      <td>76.984125</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>76.719576</td>\n",
       "      <td>77.453583</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>81.962866</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>79.259610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "1        relu       2  77.513230  81.481481  79.629630  80.423278  80.158728   \n",
       "4        relu       5  80.158728  78.306878  81.481481  78.306878  82.539684   \n",
       "3        relu       4  80.158728  79.365081  80.158728  81.216931  80.687833   \n",
       "5        relu       6  80.687833  81.216931  76.190478  80.158728  83.597887   \n",
       "8        tanh       3  83.597887  77.777779  79.365081  80.423278  81.746030   \n",
       "11       tanh       6  80.423278  80.423278  75.661373  80.423278  81.481481   \n",
       "0        relu       1  79.629630  78.306878  77.513230  82.539684  80.158728   \n",
       "9        tanh       4  79.629630  84.391534  78.306878  81.481481  78.835976   \n",
       "6        tanh       1  77.513230  77.777779  78.571427  81.216931  82.010579   \n",
       "10       tanh       5  82.539684  78.571427  79.100531  78.571427  80.158728   \n",
       "2        relu       3  82.010579  79.100531  76.984125  81.216931  81.746030   \n",
       "7        tanh       2  81.481481  76.984125  76.984125  79.100531  76.719576   \n",
       "\n",
       "         acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "1   80.106103  79.310346  81.697613  81.962866  81.432360  80.371563  \n",
       "4   83.023870  78.779840  80.371350  81.167108  79.045093  80.318091  \n",
       "3   79.045093  83.023870  80.901855  77.718830  80.901855  80.317881  \n",
       "5   78.779840  81.432360  77.188331  79.840851  83.023870  80.211711  \n",
       "8   77.984083  79.045093  79.575598  81.167108  79.840851  80.052279  \n",
       "11  76.657826  84.350133  80.106103  79.045093  81.697613  80.026945  \n",
       "0   78.249335  82.228118  79.840851  80.106103  79.045093  79.761765  \n",
       "9   77.718830  79.840851  77.718830  81.167108  77.984083  79.707520  \n",
       "6   78.514588  77.453583  81.697613  81.432360  79.310346  79.549844  \n",
       "10  79.840851  79.045093  80.106103  78.249335  78.514588  79.469777  \n",
       "2   76.127321  80.371350  80.636603  80.636603  74.801064  79.363114  \n",
       "7   77.453583  79.840851  81.962866  80.636603  81.432360  79.259610  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>80.371563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tanh</th>\n",
       "      <td>80.052279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AVG\n",
       "Activation           \n",
       "relu        80.371563\n",
       "tanh        80.052279"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_CR.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5046 words present from 5336 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    \n",
    "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
    "            \n",
    "        # initialize the unknown word with standard normal distribution values\n",
    "        else:\n",
    "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.7603335 ,  0.41298582,  1.6051669 , ...,  0.07348683,\n",
       "        -0.93163275, -0.64774868],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(filters = 100, kernel_size = 3, activation='relu', \n",
    "                 input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1437\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1444 (Embedding)   (None, 100, 300)          1524600   \n",
      "_________________________________________________________________\n",
      "conv1d_1439 (Conv1D)         (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1439 (MaxPooli (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1439 (Flatten)       (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2871 (Dropout)       (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_2869 (Dense)           (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_2872 (Dropout)       (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2870 (Dense)           (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,663,721\n",
      "Trainable params: 139,121\n",
      "Non-trainable params: 1,524,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(vocab_size, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 74.0740716457367\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 73.01587462425232\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 78.04232835769653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 74.60317611694336\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 82.80423283576965\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 82.49337077140808\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 74.27055835723877\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 77.77777910232544\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 73.28042387962341\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 73.28042387962341\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 75.59681534767151\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 73.209547996521\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 82.49337077140808\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 75.86206793785095\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 76.1904776096344\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 73.8095223903656\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 76.4550268650055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 73.01587462425232\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 74.86772537231445\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 73.209547996521\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 76.92307829856873\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 75.33156275749207\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 78.77984046936035\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 75.39682388305664\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 79.89417910575867\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 74.60317611694336\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 72.75132536888123\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00024: early stopping\n",
      "Test Accuracy: 73.8095223903656\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 78.77984046936035\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 75.06631016731262\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 73.74005317687988\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 75.06631016731262\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
      "3       relu       4  75.396824  79.894179  74.603176  72.751325  73.809522   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
      "3  78.779840  78.249335  75.066310  73.740053  75.066310  75.735688  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 72.22222089767456\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 71.16402387619019\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 76.98412537574768\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 72.67904281616211\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00023: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 75.33156275749207\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 77.45358347892761\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
      "3       relu       4  75.396824  79.894179  74.603176  72.751325  73.809522   \n",
      "4       relu       5  72.222221  71.164024  81.481481  76.984125  81.216931   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
      "3  78.779840  78.249335  75.066310  73.740053  75.066310  75.735688  \n",
      "4  72.679043  77.984083  75.331563  77.453583  77.984083  76.450114  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 74.86772537231445\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 77.77777910232544\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 66.1375641822815\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 66.1375641822815\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 75.39682388305664\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 61.00795865058899\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 76.92307829856873\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 75.59681534767151\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 69.49602365493774\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
      "3       relu       4  75.396824  79.894179  74.603176  72.751325  73.809522   \n",
      "4       relu       5  72.222221  71.164024  81.481481  76.984125  81.216931   \n",
      "5       relu       6  74.867725  77.777779  66.137564  66.137564  75.396824   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
      "3  78.779840  78.249335  75.066310  73.740053  75.066310  75.735688  \n",
      "4  72.679043  77.984083  75.331563  77.453583  77.984083  76.450114  \n",
      "5  61.007959  76.923078  75.596815  78.249335  69.496024  72.159067  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00028: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 63.49206566810608\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 63.22751045227051\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00027: early stopping\n",
      "Test Accuracy: 77.24867463111877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00008: early stopping\n",
      "Test Accuracy: 63.22751045227051\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 70.82228064537048\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 68.43501329421997\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 77.71883010864258\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 62.59946823120117\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00029: early stopping\n",
      "Test Accuracy: 75.06631016731262\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
      "3       relu       4  75.396824  79.894179  74.603176  72.751325  73.809522   \n",
      "4       relu       5  72.222221  71.164024  81.481481  76.984125  81.216931   \n",
      "5       relu       6  74.867725  77.777779  66.137564  66.137564  75.396824   \n",
      "6       relu       7  79.365081  63.492066  63.227510  77.248675  63.227510   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
      "3  78.779840  78.249335  75.066310  73.740053  75.066310  75.735688  \n",
      "4  72.679043  77.984083  75.331563  77.453583  77.984083  76.450114  \n",
      "5  61.007959  76.923078  75.596815  78.249335  69.496024  72.159067  \n",
      "6  70.822281  68.435013  77.718830  62.599468  75.066310  70.120274  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 76.1904776096344\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 71.69312238693237\n",
      "Test Accuracy: 72.48677015304565\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 65.6084656715393\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 70.37037014961243\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 75.06631016731262\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 70.82228064537048\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 72.41379022598267\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 63.92573118209839\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 77.98408269882202\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
      "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
      "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
      "3       relu       4  75.396824  79.894179  74.603176  72.751325  73.809522   \n",
      "4       relu       5  72.222221  71.164024  81.481481  76.984125  81.216931   \n",
      "5       relu       6  74.867725  77.777779  66.137564  66.137564  75.396824   \n",
      "6       relu       7  79.365081  63.492066  63.227510  77.248675  63.227510   \n",
      "7       relu       8  76.190478  71.693122  72.486770  65.608466  70.370370   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
      "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
      "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
      "3  78.779840  78.249335  75.066310  73.740053  75.066310  75.735688  \n",
      "4  72.679043  77.984083  75.331563  77.453583  77.984083  76.450114  \n",
      "5  61.007959  76.923078  75.596815  78.249335  69.496024  72.159067  \n",
      "6  70.822281  68.435013  77.718830  62.599468  75.066310  70.120274  \n",
      "7  75.066310  70.822281  72.413790  63.925731  77.984083  71.656140  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "            \n",
    "            \n",
    "            emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "            \n",
    "            # Define the input shape\n",
    "            model = define_model_2(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                 max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=30, verbose=0, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record2 = record2.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record2)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>74.074072</td>\n",
       "      <td>73.015875</td>\n",
       "      <td>78.042328</td>\n",
       "      <td>74.603176</td>\n",
       "      <td>82.804233</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>82.493371</td>\n",
       "      <td>77.984083</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>74.270558</td>\n",
       "      <td>77.670414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>73.280424</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>73.280424</td>\n",
       "      <td>75.596815</td>\n",
       "      <td>77.188331</td>\n",
       "      <td>73.209548</td>\n",
       "      <td>82.493371</td>\n",
       "      <td>75.862068</td>\n",
       "      <td>77.165172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>72.222221</td>\n",
       "      <td>71.164024</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>76.984125</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>72.679043</td>\n",
       "      <td>77.984083</td>\n",
       "      <td>75.331563</td>\n",
       "      <td>77.453583</td>\n",
       "      <td>77.984083</td>\n",
       "      <td>76.450114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>75.396824</td>\n",
       "      <td>79.894179</td>\n",
       "      <td>74.603176</td>\n",
       "      <td>72.751325</td>\n",
       "      <td>73.809522</td>\n",
       "      <td>78.779840</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>75.066310</td>\n",
       "      <td>73.740053</td>\n",
       "      <td>75.066310</td>\n",
       "      <td>75.735688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>76.190478</td>\n",
       "      <td>73.809522</td>\n",
       "      <td>76.455027</td>\n",
       "      <td>73.015875</td>\n",
       "      <td>74.867725</td>\n",
       "      <td>73.209548</td>\n",
       "      <td>76.923078</td>\n",
       "      <td>77.188331</td>\n",
       "      <td>75.331563</td>\n",
       "      <td>78.779840</td>\n",
       "      <td>75.577099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>74.867725</td>\n",
       "      <td>77.777779</td>\n",
       "      <td>66.137564</td>\n",
       "      <td>66.137564</td>\n",
       "      <td>75.396824</td>\n",
       "      <td>61.007959</td>\n",
       "      <td>76.923078</td>\n",
       "      <td>75.596815</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>69.496024</td>\n",
       "      <td>72.159067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>76.190478</td>\n",
       "      <td>71.693122</td>\n",
       "      <td>72.486770</td>\n",
       "      <td>65.608466</td>\n",
       "      <td>70.370370</td>\n",
       "      <td>75.066310</td>\n",
       "      <td>70.822281</td>\n",
       "      <td>72.413790</td>\n",
       "      <td>63.925731</td>\n",
       "      <td>77.984083</td>\n",
       "      <td>71.656140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>79.365081</td>\n",
       "      <td>63.492066</td>\n",
       "      <td>63.227510</td>\n",
       "      <td>77.248675</td>\n",
       "      <td>63.227510</td>\n",
       "      <td>70.822281</td>\n",
       "      <td>68.435013</td>\n",
       "      <td>77.718830</td>\n",
       "      <td>62.599468</td>\n",
       "      <td>75.066310</td>\n",
       "      <td>70.120274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "0       relu       1  74.074072  73.015875  78.042328  74.603176  82.804233   \n",
       "1       relu       2  81.481481  77.777779  73.280424  81.481481  73.280424   \n",
       "4       relu       5  72.222221  71.164024  81.481481  76.984125  81.216931   \n",
       "3       relu       4  75.396824  79.894179  74.603176  72.751325  73.809522   \n",
       "2       relu       3  76.190478  73.809522  76.455027  73.015875  74.867725   \n",
       "5       relu       6  74.867725  77.777779  66.137564  66.137564  75.396824   \n",
       "7       relu       8  76.190478  71.693122  72.486770  65.608466  70.370370   \n",
       "6       relu       7  79.365081  63.492066  63.227510  77.248675  63.227510   \n",
       "\n",
       "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "0  80.901855  82.493371  77.984083  78.514588  74.270558  77.670414  \n",
       "1  75.596815  77.188331  73.209548  82.493371  75.862068  77.165172  \n",
       "4  72.679043  77.984083  75.331563  77.453583  77.984083  76.450114  \n",
       "3  78.779840  78.249335  75.066310  73.740053  75.066310  75.735688  \n",
       "2  73.209548  76.923078  77.188331  75.331563  78.779840  75.577099  \n",
       "5  61.007959  76.923078  75.596815  78.249335  69.496024  72.159067  \n",
       "7  75.066310  70.822281  72.413790  63.925731  77.984083  71.656140  \n",
       "6  70.822281  68.435013  77.718830  62.599468  75.066310  70.120274  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Activation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>relu</th>\n",
       "      <td>77.670414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  AVG\n",
       "Activation           \n",
       "relu        77.670414"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2[['Activation', 'AVG']].groupby(by='Activation').max().sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_CR_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(filters = 100, kernel_size = 3, activation='relu', \n",
    "                 input_dim = None, output_dim=300, max_length = None, emb_matrix = None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=vocab_size, \n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "        tf.keras.layers.Conv1D(filters=filters, kernel_size = kernel_size, activation = activation, \n",
    "                               # set 'axis' value to the first and second axis of conv1D weights (rows, cols)\n",
    "                               kernel_constraint= MaxNorm( max_value=3, axis=[0,1])),\n",
    "        \n",
    "        tf.keras.layers.MaxPool1D(2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(10, activation=activation, \n",
    "                              # set axis to 0 to constrain each weight vector of length (input_dim,) in dense layer\n",
    "                              kernel_constraint = MaxNorm( max_value=3, axis=0)),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1518\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1525 (Embedding)   (None, 100, 300)          1527300   \n",
      "_________________________________________________________________\n",
      "conv1d_1520 (Conv1D)         (None, 98, 100)           90100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1520 (MaxPooli (None, 49, 100)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1520 (Flatten)       (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3033 (Dropout)       (None, 4900)              0         \n",
      "_________________________________________________________________\n",
      "dense_3031 (Dense)           (None, 10)                49010     \n",
      "_________________________________________________________________\n",
      "dropout_3034 (Dropout)       (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3032 (Dense)           (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,666,421\n",
      "Trainable params: 1,666,421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(vocab_size, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=5, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 82.53968358039856\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.42327761650085\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 77.51322984695435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 83.59788656234741\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 78.51458787918091\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 74.80106353759766\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 79.84085083007812\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3      acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.51323  83.597887   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Test Accuracy: 79.10053133964539\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 82.22811818122864\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 81.21693134307861\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 81.7460298538208\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 76.71957612037659\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.10610342025757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 77.18833088874817\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 79.36508059501648\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 77.24867463111877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.95238208770752\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "Test Accuracy: 79.0450930595398\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 81.16710782051086\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
      "3       relu       4  80.687833  80.687833  79.365081  77.248675  80.952382   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
      "3  79.575598  79.045093  79.045093  81.432360  81.167108  79.920706  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00006: early stopping\n",
      "Test Accuracy: 64.55026268959045\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 76.65782570838928\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 75.33156275749207\n",
      "Test Accuracy: 80.63660264015198\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 82.75862336158752\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
      "3       relu       4  80.687833  80.687833  79.365081  77.248675  80.952382   \n",
      "4       relu       5  64.550263  81.481481  80.158728  78.306878  79.629630   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
      "3  79.575598  79.045093  79.045093  81.432360  81.167108  79.920706  \n",
      "4  76.657826  75.331563  80.636603  80.901855  82.758623  78.041345  \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 77.24867463111877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 79.62962985038757\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 78.30687761306763\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00010: early stopping\n",
      "Test Accuracy: 78.83597612380981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 81.4814805984497\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.37135004997253\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 83.02386999130249\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.90185523033142\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 81.9628655910492\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 80.63660264015198\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
      "3       relu       4  80.687833  80.687833  79.365081  77.248675  80.952382   \n",
      "4       relu       5  64.550263  81.481481  80.158728  78.306878  79.629630   \n",
      "5       relu       6  77.248675  79.629630  78.306878  78.835976  81.481481   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
      "3  79.575598  79.045093  79.045093  81.432360  81.167108  79.920706  \n",
      "4  76.657826  75.331563  80.636603  80.901855  82.758623  78.041345  \n",
      "5  80.371350  83.023870  80.901855  81.962866  80.636603  80.239918  \n",
      "\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 80.68783283233643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 79.10053133964539\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 80.15872836112976\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 75.33156275749207\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 74.27055835723877\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 79.31034564971924\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 79.57559823989868\n",
      "Test Accuracy: 76.1273205280304\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
      "3       relu       4  80.687833  80.687833  79.365081  77.248675  80.952382   \n",
      "4       relu       5  64.550263  81.481481  80.158728  78.306878  79.629630   \n",
      "5       relu       6  77.248675  79.629630  78.306878  78.835976  81.481481   \n",
      "6       relu       7  80.158728  80.158728  80.687833  79.100531  80.158728   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
      "3  79.575598  79.045093  79.045093  81.432360  81.167108  79.920706  \n",
      "4  76.657826  75.331563  80.636603  80.901855  82.758623  78.041345  \n",
      "5  80.371350  83.023870  80.901855  81.962866  80.636603  80.239918  \n",
      "6  75.331563  74.270558  79.310346  79.575598  76.127321  78.487993  \n",
      "\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 78.04232835769653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 76.4550268650055\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 82.27513432502747\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 78.57142686843872\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 78.04232835769653\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00009: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 78.24933528900146\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 81.43236041069031\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 76.65782570838928\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 79.0450930595398\n",
      "\n",
      "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
      "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
      "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
      "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
      "3       relu       4  80.687833  80.687833  79.365081  77.248675  80.952382   \n",
      "4       relu       5  64.550263  81.481481  80.158728  78.306878  79.629630   \n",
      "5       relu       6  77.248675  79.629630  78.306878  78.835976  81.481481   \n",
      "6       relu       7  80.158728  80.158728  80.687833  79.100531  80.158728   \n",
      "7       relu       8  78.042328  76.455027  82.275134  78.571427  78.042328   \n",
      "\n",
      "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
      "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
      "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
      "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
      "3  79.575598  79.045093  79.045093  81.432360  81.167108  79.920706  \n",
      "4  76.657826  75.331563  80.636603  80.901855  82.758623  78.041345  \n",
      "5  80.371350  83.023870  80.901855  81.962866  80.636603  80.239918  \n",
      "6  75.331563  74.270558  79.310346  79.575598  76.127321  78.487993  \n",
      "7  78.249335  78.249335  81.432360  76.657826  79.045093  78.702019  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "activations = ['relu']\n",
    "filters = 100\n",
    "kernel_sizes = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "columns = ['Activation', 'Filters', 'acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "for activation in activations:\n",
    "    for kernel_size in kernel_sizes:\n",
    "        # kfold.split() will return set indices for each split\n",
    "        acc_list = []\n",
    "        for train, test in kfold.split(sentences):\n",
    "            \n",
    "            train_x, test_x = [], []\n",
    "            train_y, test_y = [], []\n",
    "            \n",
    "            for i in train:\n",
    "                train_x.append(sentences[i])\n",
    "                train_y.append(labels[i])\n",
    "\n",
    "            for i in test:\n",
    "                test_x.append(sentences[i])\n",
    "                test_y.append(labels[i])\n",
    "\n",
    "            # Turn the labels into a numpy array\n",
    "            train_y = np.array(train_y)\n",
    "            test_y = np.array(test_y)\n",
    "\n",
    "            # encode data using\n",
    "            # Cleaning and Tokenization\n",
    "            tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "            tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "            # Turn the text into sequence\n",
    "            training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "            test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "            max_len = max_length(training_sequences)\n",
    "\n",
    "            # Pad the sequence to have the same size\n",
    "            Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "            Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "            word_index = tokenizer.word_index\n",
    "            vocab_size = len(word_index)+1\n",
    "            \n",
    "            \n",
    "            emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "            \n",
    "            # Define the input shape\n",
    "            model = define_model_3(filters, kernel_size, activation, input_dim=vocab_size, \n",
    "                                 max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(Xtrain, train_y, batch_size=50, epochs=20, verbose=0, \n",
    "                      callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "            # evaluate the model\n",
    "            loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "            print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "            acc_list.append(acc*100)\n",
    "            \n",
    "        mean_acc = np.array(acc_list).mean()\n",
    "        parameters = [activation, kernel_size]\n",
    "        entries = parameters + acc_list + [mean_acc]\n",
    "\n",
    "        temp = pd.DataFrame([entries], columns=columns)\n",
    "        record3 = record3.append(temp, ignore_index=True)\n",
    "        print()\n",
    "        print(record3)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activation</th>\n",
       "      <th>Filters</th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>relu</td>\n",
       "      <td>2</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>81.746030</td>\n",
       "      <td>79.365081</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>82.228118</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>80.715760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>relu</td>\n",
       "      <td>6</td>\n",
       "      <td>77.248675</td>\n",
       "      <td>79.629630</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>78.835976</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>80.371350</td>\n",
       "      <td>83.023870</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>81.962866</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>80.239918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>relu</td>\n",
       "      <td>4</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>79.365081</td>\n",
       "      <td>77.248675</td>\n",
       "      <td>80.952382</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>81.167108</td>\n",
       "      <td>79.920706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>relu</td>\n",
       "      <td>1</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>82.539684</td>\n",
       "      <td>80.423278</td>\n",
       "      <td>77.513230</td>\n",
       "      <td>83.597887</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>78.514588</td>\n",
       "      <td>74.801064</td>\n",
       "      <td>79.840851</td>\n",
       "      <td>79.627525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relu</td>\n",
       "      <td>3</td>\n",
       "      <td>81.216931</td>\n",
       "      <td>76.719576</td>\n",
       "      <td>81.746030</td>\n",
       "      <td>80.952382</td>\n",
       "      <td>76.719576</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>80.106103</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>77.188331</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>79.496723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>relu</td>\n",
       "      <td>8</td>\n",
       "      <td>78.042328</td>\n",
       "      <td>76.455027</td>\n",
       "      <td>82.275134</td>\n",
       "      <td>78.571427</td>\n",
       "      <td>78.042328</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>78.249335</td>\n",
       "      <td>81.432360</td>\n",
       "      <td>76.657826</td>\n",
       "      <td>79.045093</td>\n",
       "      <td>78.702019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>relu</td>\n",
       "      <td>7</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>80.687833</td>\n",
       "      <td>79.100531</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>75.331563</td>\n",
       "      <td>74.270558</td>\n",
       "      <td>79.310346</td>\n",
       "      <td>79.575598</td>\n",
       "      <td>76.127321</td>\n",
       "      <td>78.487993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>relu</td>\n",
       "      <td>5</td>\n",
       "      <td>64.550263</td>\n",
       "      <td>81.481481</td>\n",
       "      <td>80.158728</td>\n",
       "      <td>78.306878</td>\n",
       "      <td>79.629630</td>\n",
       "      <td>76.657826</td>\n",
       "      <td>75.331563</td>\n",
       "      <td>80.636603</td>\n",
       "      <td>80.901855</td>\n",
       "      <td>82.758623</td>\n",
       "      <td>78.041345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Activation Filters       acc1       acc2       acc3       acc4       acc5  \\\n",
       "1       relu       2  80.687833  81.746030  79.365081  79.100531  80.687833   \n",
       "5       relu       6  77.248675  79.629630  78.306878  78.835976  81.481481   \n",
       "3       relu       4  80.687833  80.687833  79.365081  77.248675  80.952382   \n",
       "0       relu       1  80.158728  82.539684  80.423278  77.513230  83.597887   \n",
       "2       relu       3  81.216931  76.719576  81.746030  80.952382  76.719576   \n",
       "7       relu       8  78.042328  76.455027  82.275134  78.571427  78.042328   \n",
       "6       relu       7  80.158728  80.158728  80.687833  79.100531  80.158728   \n",
       "4       relu       5  64.550263  81.481481  80.158728  78.306878  79.629630   \n",
       "\n",
       "        acc6       acc7       acc8       acc9      acc10        AVG  \n",
       "1  82.228118  80.901855  81.432360  80.901855  80.106103  80.715760  \n",
       "5  80.371350  83.023870  80.901855  81.962866  80.636603  80.239918  \n",
       "3  79.575598  79.045093  79.045093  81.432360  81.167108  79.920706  \n",
       "0  79.310346  79.575598  78.514588  74.801064  79.840851  79.627525  \n",
       "2  81.432360  80.106103  78.249335  77.188331  80.636603  79.496723  \n",
       "7  78.249335  78.249335  81.432360  76.657826  79.045093  78.702019  \n",
       "6  75.331563  74.270558  79.310346  79.575598  76.127321  78.487993  \n",
       "4  76.657826  75.331563  80.636603  80.901855  82.758623  78.041345  "
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3.sort_values(by='AVG', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3.sort_values(by='AVG', ascending=False)\n",
    "report = report.to_excel('CNN_CR_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
