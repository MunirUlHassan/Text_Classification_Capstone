{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Classification with MPQA Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using LSTM model on the MPQA Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10606, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complaining</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing to support</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desperately needs</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many years of decay</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no quick fix</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>urged</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>hope</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10606 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label  split\n",
       "0              complaining      0  train\n",
       "1       failing to support      0  train\n",
       "2        desperately needs      0  train\n",
       "3      many years of decay      0  train\n",
       "4             no quick fix      0  train\n",
       "...                    ...    ...    ...\n",
       "10601                urged      1  train\n",
       "10602       strictly abide      1  train\n",
       "10603                 hope      1  train\n",
       "10604       strictly abide      1  train\n",
       "10605                           1  train\n",
       "\n",
       "[10606 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/MPQA/MPQA.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10606 entries, 0 to 10605\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10606 non-null  object\n",
      " 1   label     10606 non-null  int32 \n",
      " 2   split     10606 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 207.3+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7294</td>\n",
       "      <td>7294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3312</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          7294   7294\n",
       "1          3312   3312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complaining'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  no quick fix\n",
      "Into a sequence of int: [25, 945, 1476]\n",
      "Into a padded sequence: [  25  945 1476    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "of 3\n",
      "to 4\n",
      "a 5\n",
      "and 6\n",
      "not 7\n",
      "is 8\n",
      "in 9\n",
      "be 10\n",
      "6236\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "<img src=\"model.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 128)          186880    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 585,825\n",
      "Trainable params: 585,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 109s 290ms/step - loss: 0.5525 - accuracy: 0.7437 - val_loss: 0.3866 - val_accuracy: 0.8303\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 72s 242ms/step - loss: 0.1998 - accuracy: 0.9338 - val_loss: 0.3882 - val_accuracy: 0.8426\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 70s 233ms/step - loss: 0.1369 - accuracy: 0.9524 - val_loss: 0.4199 - val_accuracy: 0.8445\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 68s 227ms/step - loss: 0.1041 - accuracy: 0.9646 - val_loss: 0.5014 - val_accuracy: 0.8407\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 70s 234ms/step - loss: 0.0834 - accuracy: 0.9716 - val_loss: 0.5926 - val_accuracy: 0.8435\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 69s 230ms/step - loss: 0.0602 - accuracy: 0.9757 - val_loss: 0.6757 - val_accuracy: 0.8398\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 69s 232ms/step - loss: 0.0481 - accuracy: 0.9804 - val_loss: 0.7265 - val_accuracy: 0.8426\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 69s 232ms/step - loss: 0.0423 - accuracy: 0.9816 - val_loss: 0.7143 - val_accuracy: 0.8379\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 69s 232ms/step - loss: 0.0347 - accuracy: 0.9853 - val_loss: 0.8435 - val_accuracy: 0.8313\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 69s 230ms/step - loss: 0.0388 - accuracy: 0.9818 - val_loss: 0.8383 - val_accuracy: 0.8417\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 69s 230ms/step - loss: 0.0336 - accuracy: 0.9844 - val_loss: 0.8901 - val_accuracy: 0.8256\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 69s 230ms/step - loss: 0.0339 - accuracy: 0.9863 - val_loss: 0.9577 - val_accuracy: 0.8351\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 69s 231ms/step - loss: 0.0331 - accuracy: 0.9847 - val_loss: 0.8530 - val_accuracy: 0.8266\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 84.44863557815552\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 116s 310ms/step - loss: 0.5624 - accuracy: 0.7339 - val_loss: 0.3442 - val_accuracy: 0.8615\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 83s 277ms/step - loss: 0.2135 - accuracy: 0.9270 - val_loss: 0.3603 - val_accuracy: 0.8558\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 83s 277ms/step - loss: 0.1447 - accuracy: 0.9488 - val_loss: 0.3905 - val_accuracy: 0.8520\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 82s 276ms/step - loss: 0.1108 - accuracy: 0.9612 - val_loss: 0.4084 - val_accuracy: 0.8520\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 83s 278ms/step - loss: 0.0884 - accuracy: 0.9699 - val_loss: 0.4632 - val_accuracy: 0.8558\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 83s 279ms/step - loss: 0.0646 - accuracy: 0.9760 - val_loss: 0.5043 - val_accuracy: 0.8615\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 83s 278ms/step - loss: 0.0501 - accuracy: 0.9788 - val_loss: 0.6092 - val_accuracy: 0.8492\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 83s 278ms/step - loss: 0.0489 - accuracy: 0.9787 - val_loss: 0.7052 - val_accuracy: 0.8473\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 83s 278ms/step - loss: 0.0347 - accuracy: 0.9844 - val_loss: 0.8098 - val_accuracy: 0.8483\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 83s 277ms/step - loss: 0.0297 - accuracy: 0.9862 - val_loss: 0.8112 - val_accuracy: 0.8435\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 83s 276ms/step - loss: 0.0323 - accuracy: 0.9846 - val_loss: 0.8015 - val_accuracy: 0.8435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.14514470100403\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 139s 385ms/step - loss: 0.5678 - accuracy: 0.7297 - val_loss: 0.3558 - val_accuracy: 0.8624\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 108s 362ms/step - loss: 0.1996 - accuracy: 0.9312 - val_loss: 0.3628 - val_accuracy: 0.8680\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 108s 362ms/step - loss: 0.1335 - accuracy: 0.9553 - val_loss: 0.4235 - val_accuracy: 0.8426\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 108s 362ms/step - loss: 0.1175 - accuracy: 0.9589 - val_loss: 0.4760 - val_accuracy: 0.8426\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 108s 361ms/step - loss: 0.0828 - accuracy: 0.9712 - val_loss: 0.4995 - val_accuracy: 0.8520\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 108s 362ms/step - loss: 0.0702 - accuracy: 0.9752 - val_loss: 0.6756 - val_accuracy: 0.8426\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 111s 372ms/step - loss: 0.0536 - accuracy: 0.9766 - val_loss: 0.8256 - val_accuracy: 0.8426\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 113s 377ms/step - loss: 0.0435 - accuracy: 0.9801 - val_loss: 0.8174 - val_accuracy: 0.8417\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 113s 377ms/step - loss: 0.0441 - accuracy: 0.9817 - val_loss: 0.8978 - val_accuracy: 0.8445\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 114s 380ms/step - loss: 0.0318 - accuracy: 0.9848 - val_loss: 0.9961 - val_accuracy: 0.8435\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 113s 378ms/step - loss: 0.0355 - accuracy: 0.9825 - val_loss: 0.9313 - val_accuracy: 0.8445\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 117s 391ms/step - loss: 0.0302 - accuracy: 0.9861 - val_loss: 0.9549 - val_accuracy: 0.8426\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 86.80490255355835\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 163s 461ms/step - loss: 0.5623 - accuracy: 0.7407 - val_loss: 0.3673 - val_accuracy: 0.8511\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 110s 369ms/step - loss: 0.1992 - accuracy: 0.9306 - val_loss: 0.3839 - val_accuracy: 0.8520\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 111s 371ms/step - loss: 0.1418 - accuracy: 0.9526 - val_loss: 0.4391 - val_accuracy: 0.8407\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 111s 370ms/step - loss: 0.1142 - accuracy: 0.9618 - val_loss: 0.4932 - val_accuracy: 0.8417\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 110s 367ms/step - loss: 0.0955 - accuracy: 0.9624 - val_loss: 0.5062 - val_accuracy: 0.8483\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 111s 370ms/step - loss: 0.0671 - accuracy: 0.9741 - val_loss: 0.5927 - val_accuracy: 0.8435\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 112s 373ms/step - loss: 0.0601 - accuracy: 0.9763 - val_loss: 0.6693 - val_accuracy: 0.8483\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 110s 369ms/step - loss: 0.0456 - accuracy: 0.9817 - val_loss: 0.7902 - val_accuracy: 0.8435\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 111s 372ms/step - loss: 0.0424 - accuracy: 0.9815 - val_loss: 0.8139 - val_accuracy: 0.8501\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 112s 374ms/step - loss: 0.0337 - accuracy: 0.9832 - val_loss: 0.9097 - val_accuracy: 0.8445\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 111s 369ms/step - loss: 0.0333 - accuracy: 0.9858 - val_loss: 0.8747 - val_accuracy: 0.8492\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 111s 371ms/step - loss: 0.0350 - accuracy: 0.9826 - val_loss: 0.7258 - val_accuracy: 0.8435\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 85.20264029502869\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 140s 372ms/step - loss: 0.5615 - accuracy: 0.7406 - val_loss: 0.3544 - val_accuracy: 0.8624\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 113s 379ms/step - loss: 0.2115 - accuracy: 0.9258 - val_loss: 0.3718 - val_accuracy: 0.8643\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 108s 362ms/step - loss: 0.1388 - accuracy: 0.9511 - val_loss: 0.3872 - val_accuracy: 0.8577\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 106s 353ms/step - loss: 0.1042 - accuracy: 0.9636 - val_loss: 0.4084 - val_accuracy: 0.8549\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 105s 350ms/step - loss: 0.0892 - accuracy: 0.9703 - val_loss: 0.5188 - val_accuracy: 0.8549\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 104s 348ms/step - loss: 0.0682 - accuracy: 0.9758 - val_loss: 0.5637 - val_accuracy: 0.8558\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 104s 348ms/step - loss: 0.0480 - accuracy: 0.9799 - val_loss: 0.6639 - val_accuracy: 0.8492\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 103s 346ms/step - loss: 0.0447 - accuracy: 0.9803 - val_loss: 0.7027 - val_accuracy: 0.8454\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 105s 350ms/step - loss: 0.0369 - accuracy: 0.9831 - val_loss: 0.7941 - val_accuracy: 0.8501\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 103s 346ms/step - loss: 0.0363 - accuracy: 0.9828 - val_loss: 0.7940 - val_accuracy: 0.8501\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 102s 341ms/step - loss: 0.0346 - accuracy: 0.9845 - val_loss: 0.8739 - val_accuracy: 0.8483\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 101s 339ms/step - loss: 0.0361 - accuracy: 0.9847 - val_loss: 0.8246 - val_accuracy: 0.8501\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 86.42789721488953\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 152s 412ms/step - loss: 0.5566 - accuracy: 0.7339 - val_loss: 0.3549 - val_accuracy: 0.8662\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 115s 384ms/step - loss: 0.1982 - accuracy: 0.9306 - val_loss: 0.3683 - val_accuracy: 0.8662\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 117s 392ms/step - loss: 0.1318 - accuracy: 0.9565 - val_loss: 0.4323 - val_accuracy: 0.8577\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 118s 394ms/step - loss: 0.1123 - accuracy: 0.9606 - val_loss: 0.4832 - val_accuracy: 0.8454\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 118s 396ms/step - loss: 0.0720 - accuracy: 0.9748 - val_loss: 0.5607 - val_accuracy: 0.8511\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 116s 388ms/step - loss: 0.0530 - accuracy: 0.9778 - val_loss: 0.6014 - val_accuracy: 0.8483\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 116s 389ms/step - loss: 0.0513 - accuracy: 0.9804 - val_loss: 0.6608 - val_accuracy: 0.8435\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 118s 394ms/step - loss: 0.0403 - accuracy: 0.9837 - val_loss: 0.7532 - val_accuracy: 0.8464\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 116s 386ms/step - loss: 0.0338 - accuracy: 0.9857 - val_loss: 0.7982 - val_accuracy: 0.8501\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 112s 376ms/step - loss: 0.0342 - accuracy: 0.9868 - val_loss: 0.8244 - val_accuracy: 0.8435\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 112s 375ms/step - loss: 0.0332 - accuracy: 0.9842 - val_loss: 0.9060 - val_accuracy: 0.8351\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.6163969039917\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 167s 476ms/step - loss: 0.5601 - accuracy: 0.7316 - val_loss: 0.3525 - val_accuracy: 0.8547\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 118s 396ms/step - loss: 0.2126 - accuracy: 0.9283 - val_loss: 0.3463 - val_accuracy: 0.8377\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 119s 397ms/step - loss: 0.1488 - accuracy: 0.9488 - val_loss: 0.3807 - val_accuracy: 0.8406\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 119s 398ms/step - loss: 0.1231 - accuracy: 0.9576 - val_loss: 0.4114 - val_accuracy: 0.8585\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 120s 401ms/step - loss: 0.0829 - accuracy: 0.9690 - val_loss: 0.4375 - val_accuracy: 0.8566\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 118s 396ms/step - loss: 0.0663 - accuracy: 0.9752 - val_loss: 0.4759 - val_accuracy: 0.8528\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 122s 407ms/step - loss: 0.0566 - accuracy: 0.9771 - val_loss: 0.5541 - val_accuracy: 0.8585\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 120s 402ms/step - loss: 0.0518 - accuracy: 0.9771 - val_loss: 0.6261 - val_accuracy: 0.8519\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 121s 404ms/step - loss: 0.0382 - accuracy: 0.9850 - val_loss: 0.6509 - val_accuracy: 0.8632\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 121s 404ms/step - loss: 0.0396 - accuracy: 0.9832 - val_loss: 0.7098 - val_accuracy: 0.8585\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 120s 402ms/step - loss: 0.0385 - accuracy: 0.9822 - val_loss: 0.8035 - val_accuracy: 0.8415\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 122s 407ms/step - loss: 0.0364 - accuracy: 0.9851 - val_loss: 0.8027 - val_accuracy: 0.8481\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 120s 402ms/step - loss: 0.0288 - accuracy: 0.9863 - val_loss: 0.8340 - val_accuracy: 0.8481\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 121s 406ms/step - loss: 0.0327 - accuracy: 0.9834 - val_loss: 0.8667 - val_accuracy: 0.8509\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 120s 401ms/step - loss: 0.0299 - accuracy: 0.9847 - val_loss: 0.9146 - val_accuracy: 0.8500\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 117s 393ms/step - loss: 0.0292 - accuracy: 0.9869 - val_loss: 0.9196 - val_accuracy: 0.8538\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 119s 397ms/step - loss: 0.0308 - accuracy: 0.9829 - val_loss: 0.8628 - val_accuracy: 0.8538\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 120s 402ms/step - loss: 0.0325 - accuracy: 0.9844 - val_loss: 0.9286 - val_accuracy: 0.8557\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 119s 399ms/step - loss: 0.0281 - accuracy: 0.9868 - val_loss: 0.9189 - val_accuracy: 0.8528\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 86.32075190544128\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 174s 502ms/step - loss: 0.5607 - accuracy: 0.7332 - val_loss: 0.3765 - val_accuracy: 0.8538\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 131s 437ms/step - loss: 0.2068 - accuracy: 0.9237 - val_loss: 0.3809 - val_accuracy: 0.8604\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 131s 437ms/step - loss: 0.1366 - accuracy: 0.9539 - val_loss: 0.4247 - val_accuracy: 0.8642\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 133s 444ms/step - loss: 0.1098 - accuracy: 0.9631 - val_loss: 0.4795 - val_accuracy: 0.8604\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 135s 451ms/step - loss: 0.0851 - accuracy: 0.9677 - val_loss: 0.4913 - val_accuracy: 0.8566\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 133s 445ms/step - loss: 0.0623 - accuracy: 0.9756 - val_loss: 0.6056 - val_accuracy: 0.8443\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 134s 448ms/step - loss: 0.0491 - accuracy: 0.9803 - val_loss: 0.7166 - val_accuracy: 0.8425\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 133s 447ms/step - loss: 0.0416 - accuracy: 0.9818 - val_loss: 0.7484 - val_accuracy: 0.8500\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 130s 436ms/step - loss: 0.0361 - accuracy: 0.9843 - val_loss: 0.7811 - val_accuracy: 0.8311\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 130s 435ms/step - loss: 0.0337 - accuracy: 0.9836 - val_loss: 0.8495 - val_accuracy: 0.8396\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 130s 436ms/step - loss: 0.0298 - accuracy: 0.9866 - val_loss: 0.8950 - val_accuracy: 0.8500\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 131s 438ms/step - loss: 0.0298 - accuracy: 0.9850 - val_loss: 0.9690 - val_accuracy: 0.8434\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 131s 440ms/step - loss: 0.0250 - accuracy: 0.9873 - val_loss: 1.0523 - val_accuracy: 0.8425\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.41509413719177\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 161s 449ms/step - loss: 0.5585 - accuracy: 0.7418 - val_loss: 0.3547 - val_accuracy: 0.8585\n",
      "Epoch 2/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 119s 399ms/step - loss: 0.2065 - accuracy: 0.9297 - val_loss: 0.3972 - val_accuracy: 0.8481\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 115s 384ms/step - loss: 0.1368 - accuracy: 0.9531 - val_loss: 0.4553 - val_accuracy: 0.8406\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 114s 380ms/step - loss: 0.1094 - accuracy: 0.9639 - val_loss: 0.4892 - val_accuracy: 0.8462\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 113s 379ms/step - loss: 0.0854 - accuracy: 0.9687 - val_loss: 0.5569 - val_accuracy: 0.8415\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 114s 381ms/step - loss: 0.0682 - accuracy: 0.9730 - val_loss: 0.7185 - val_accuracy: 0.8358\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 113s 379ms/step - loss: 0.0525 - accuracy: 0.9775 - val_loss: 0.7469 - val_accuracy: 0.8387\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 113s 379ms/step - loss: 0.0366 - accuracy: 0.9849 - val_loss: 0.8872 - val_accuracy: 0.8349\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 114s 382ms/step - loss: 0.0385 - accuracy: 0.9846 - val_loss: 0.8437 - val_accuracy: 0.8491\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 115s 386ms/step - loss: 0.0351 - accuracy: 0.9837 - val_loss: 0.8219 - val_accuracy: 0.8443\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 119s 397ms/step - loss: 0.0333 - accuracy: 0.9840 - val_loss: 0.9220 - val_accuracy: 0.8415\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 85.84905862808228\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 177s 499ms/step - loss: 0.5572 - accuracy: 0.7417 - val_loss: 0.3517 - val_accuracy: 0.8547\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 141s 472ms/step - loss: 0.2025 - accuracy: 0.9293 - val_loss: 0.3542 - val_accuracy: 0.8623\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 142s 474ms/step - loss: 0.1401 - accuracy: 0.9522 - val_loss: 0.3689 - val_accuracy: 0.8660\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 140s 470ms/step - loss: 0.1046 - accuracy: 0.9652 - val_loss: 0.4575 - val_accuracy: 0.8623\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 140s 469ms/step - loss: 0.0846 - accuracy: 0.9706 - val_loss: 0.4913 - val_accuracy: 0.8500\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 141s 470ms/step - loss: 0.0619 - accuracy: 0.9780 - val_loss: 0.5496 - val_accuracy: 0.8566\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 142s 476ms/step - loss: 0.0481 - accuracy: 0.9793 - val_loss: 0.7100 - val_accuracy: 0.8481\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 142s 476ms/step - loss: 0.0421 - accuracy: 0.9824 - val_loss: 0.6702 - val_accuracy: 0.8443\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 142s 475ms/step - loss: 0.0394 - accuracy: 0.9829 - val_loss: 0.8470 - val_accuracy: 0.8519\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 143s 478ms/step - loss: 0.0351 - accuracy: 0.9845 - val_loss: 0.8085 - val_accuracy: 0.8377\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 143s 478ms/step - loss: 0.0367 - accuracy: 0.9827 - val_loss: 0.8683 - val_accuracy: 0.8358\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 142s 476ms/step - loss: 0.0283 - accuracy: 0.9868 - val_loss: 0.9301 - val_accuracy: 0.8283\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 142s 474ms/step - loss: 0.0249 - accuracy: 0.9886 - val_loss: 0.9834 - val_accuracy: 0.8302\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 86.60377264022827\n",
      "\n",
      "        acc1       acc2       acc3      acc4       acc5       acc6       acc7  \\\n",
      "0  84.448636  86.145145  86.804903  85.20264  86.427897  86.616397  86.320752   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  86.415094  85.849059  86.603773  86.083429  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model(input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>84.448636</td>\n",
       "      <td>86.145145</td>\n",
       "      <td>86.804903</td>\n",
       "      <td>85.20264</td>\n",
       "      <td>86.427897</td>\n",
       "      <td>86.616397</td>\n",
       "      <td>86.320752</td>\n",
       "      <td>86.415094</td>\n",
       "      <td>85.849059</td>\n",
       "      <td>86.603773</td>\n",
       "      <td>86.083429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3      acc4       acc5       acc6       acc7  \\\n",
       "0  84.448636  86.145145  86.804903  85.20264  86.427897  86.616397  86.320752   \n",
       "\n",
       "        acc8       acc9      acc10        AVG  \n",
       "0  86.415094  85.849059  86.603773  86.083429  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('LSTM_MPQA_v2.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6083 words present from 6236 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    \n",
    "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
    "            \n",
    "        # initialize the unknown word with standard normal distribution values\n",
    "        else:\n",
    "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.39502923, -0.19060103,  0.92061864, ..., -0.45392575,\n",
       "        -1.18848863, -1.29073577],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_19 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_38 (Bidirectio (None, 100, 128)          186880    \n",
      "_________________________________________________________________\n",
      "bidirectional_39 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 585,825\n",
      "Trainable params: 285,825\n",
      "Non-trainable params: 300,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 160s 448ms/step - loss: 0.4935 - accuracy: 0.7606 - val_loss: 0.3906 - val_accuracy: 0.8106\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 108s 361ms/step - loss: 0.2812 - accuracy: 0.8849 - val_loss: 0.4433 - val_accuracy: 0.8115\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 108s 360ms/step - loss: 0.2592 - accuracy: 0.8983 - val_loss: 0.4075 - val_accuracy: 0.8238\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 110s 368ms/step - loss: 0.2204 - accuracy: 0.9160 - val_loss: 0.3392 - val_accuracy: 0.8360\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 110s 368ms/step - loss: 0.2046 - accuracy: 0.9203 - val_loss: 0.3783 - val_accuracy: 0.8285\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 109s 366ms/step - loss: 0.1856 - accuracy: 0.9293 - val_loss: 0.3304 - val_accuracy: 0.8709\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 110s 368ms/step - loss: 0.1583 - accuracy: 0.9362 - val_loss: 0.3630 - val_accuracy: 0.8652\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 110s 367ms/step - loss: 0.1387 - accuracy: 0.9466 - val_loss: 0.4223 - val_accuracy: 0.8831\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 109s 364ms/step - loss: 0.1238 - accuracy: 0.9547 - val_loss: 0.4204 - val_accuracy: 0.8812\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 111s 371ms/step - loss: 0.1057 - accuracy: 0.9590 - val_loss: 0.4803 - val_accuracy: 0.8577\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 111s 372ms/step - loss: 0.0962 - accuracy: 0.9625 - val_loss: 0.6026 - val_accuracy: 0.8869\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 111s 370ms/step - loss: 0.0866 - accuracy: 0.9667 - val_loss: 0.5891 - val_accuracy: 0.8709\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 111s 370ms/step - loss: 0.0752 - accuracy: 0.9705 - val_loss: 0.5885 - val_accuracy: 0.8746\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 114s 379ms/step - loss: 0.0636 - accuracy: 0.9773 - val_loss: 0.5930 - val_accuracy: 0.8549\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 109s 364ms/step - loss: 0.0630 - accuracy: 0.9768 - val_loss: 0.6490 - val_accuracy: 0.8690\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 108s 361ms/step - loss: 0.0576 - accuracy: 0.9806 - val_loss: 0.8319 - val_accuracy: 0.8746\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 109s 365ms/step - loss: 0.0547 - accuracy: 0.9800 - val_loss: 0.8679 - val_accuracy: 0.8709\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 109s 366ms/step - loss: 0.0509 - accuracy: 0.9800 - val_loss: 0.8299 - val_accuracy: 0.8680\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 108s 361ms/step - loss: 0.0462 - accuracy: 0.9818 - val_loss: 1.0009 - val_accuracy: 0.8756\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 109s 366ms/step - loss: 0.0480 - accuracy: 0.9814 - val_loss: 1.1288 - val_accuracy: 0.8718\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 109s 364ms/step - loss: 0.0471 - accuracy: 0.9799 - val_loss: 1.0553 - val_accuracy: 0.8699\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 88.68991732597351\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 154s 434ms/step - loss: 0.4931 - accuracy: 0.7719 - val_loss: 0.4750 - val_accuracy: 0.7992\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 138s 460ms/step - loss: 0.2738 - accuracy: 0.8935 - val_loss: 0.5012 - val_accuracy: 0.8068\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 139s 466ms/step - loss: 0.2496 - accuracy: 0.9029 - val_loss: 0.5174 - val_accuracy: 0.8115\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 136s 456ms/step - loss: 0.2280 - accuracy: 0.9136 - val_loss: 0.5132 - val_accuracy: 0.8219\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 140s 467ms/step - loss: 0.2042 - accuracy: 0.9235 - val_loss: 0.5542 - val_accuracy: 0.8181\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 138s 462ms/step - loss: 0.1843 - accuracy: 0.9287 - val_loss: 0.5552 - val_accuracy: 0.8238\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 135s 451ms/step - loss: 0.1657 - accuracy: 0.9360 - val_loss: 0.6391 - val_accuracy: 0.8153\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 136s 455ms/step - loss: 0.1548 - accuracy: 0.9399 - val_loss: 0.5857 - val_accuracy: 0.8181\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 137s 460ms/step - loss: 0.1344 - accuracy: 0.9461 - val_loss: 0.6907 - val_accuracy: 0.8181\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 137s 458ms/step - loss: 0.1165 - accuracy: 0.9588 - val_loss: 0.6985 - val_accuracy: 0.8256\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 139s 464ms/step - loss: 0.1028 - accuracy: 0.9593 - val_loss: 0.7671 - val_accuracy: 0.8096\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 139s 467ms/step - loss: 0.0929 - accuracy: 0.9648 - val_loss: 0.8656 - val_accuracy: 0.8209\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 140s 469ms/step - loss: 0.0930 - accuracy: 0.9623 - val_loss: 0.9185 - val_accuracy: 0.8256\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 137s 458ms/step - loss: 0.0686 - accuracy: 0.9716 - val_loss: 1.0693 - val_accuracy: 0.7898\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 136s 456ms/step - loss: 0.0653 - accuracy: 0.9735 - val_loss: 1.1392 - val_accuracy: 0.8134\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 136s 456ms/step - loss: 0.0583 - accuracy: 0.9776 - val_loss: 1.1439 - val_accuracy: 0.8162\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 139s 466ms/step - loss: 0.0516 - accuracy: 0.9808 - val_loss: 1.1726 - val_accuracy: 0.7964\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 141s 470ms/step - loss: 0.0530 - accuracy: 0.9776 - val_loss: 1.1601 - val_accuracy: 0.8143\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 139s 466ms/step - loss: 0.0542 - accuracy: 0.9800 - val_loss: 1.1232 - val_accuracy: 0.8049\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 139s 464ms/step - loss: 0.0500 - accuracy: 0.9796 - val_loss: 1.0728 - val_accuracy: 0.7983\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 82.56362080574036\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 147s 401ms/step - loss: 0.5023 - accuracy: 0.7647 - val_loss: 0.3775 - val_accuracy: 0.8153\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 114s 382ms/step - loss: 0.2790 - accuracy: 0.8921 - val_loss: 0.4275 - val_accuracy: 0.8030\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 115s 383ms/step - loss: 0.2613 - accuracy: 0.9039 - val_loss: 0.3821 - val_accuracy: 0.8172\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 115s 384ms/step - loss: 0.2369 - accuracy: 0.9122 - val_loss: 0.3770 - val_accuracy: 0.8134\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 116s 387ms/step - loss: 0.2055 - accuracy: 0.9238 - val_loss: 0.4201 - val_accuracy: 0.8077\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 115s 383ms/step - loss: 0.1942 - accuracy: 0.9258 - val_loss: 0.4917 - val_accuracy: 0.8096\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 113s 379ms/step - loss: 0.1623 - accuracy: 0.9357 - val_loss: 0.4309 - val_accuracy: 0.8096\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 114s 380ms/step - loss: 0.1414 - accuracy: 0.9452 - val_loss: 0.3857 - val_accuracy: 0.8643\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 110s 370ms/step - loss: 0.1230 - accuracy: 0.9523 - val_loss: 0.4022 - val_accuracy: 0.8671\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 110s 368ms/step - loss: 0.1098 - accuracy: 0.9574 - val_loss: 0.4761 - val_accuracy: 0.8662\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 111s 370ms/step - loss: 0.0883 - accuracy: 0.9655 - val_loss: 0.4644 - val_accuracy: 0.8652\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 111s 373ms/step - loss: 0.0840 - accuracy: 0.9689 - val_loss: 0.4409 - val_accuracy: 0.8699\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 109s 364ms/step - loss: 0.0754 - accuracy: 0.9743 - val_loss: 0.4811 - val_accuracy: 0.8520\n",
      "Epoch 14/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 110s 368ms/step - loss: 0.0630 - accuracy: 0.9791 - val_loss: 0.5001 - val_accuracy: 0.8737\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 111s 371ms/step - loss: 0.0636 - accuracy: 0.9762 - val_loss: 0.5241 - val_accuracy: 0.8690\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 112s 375ms/step - loss: 0.0555 - accuracy: 0.9783 - val_loss: 0.5509 - val_accuracy: 0.8765\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 111s 372ms/step - loss: 0.0516 - accuracy: 0.9783 - val_loss: 0.5962 - val_accuracy: 0.8652\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 112s 373ms/step - loss: 0.0407 - accuracy: 0.9849 - val_loss: 0.6120 - val_accuracy: 0.8756\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 110s 366ms/step - loss: 0.0487 - accuracy: 0.9817 - val_loss: 0.5694 - val_accuracy: 0.8709\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 107s 358ms/step - loss: 0.0550 - accuracy: 0.9776 - val_loss: 0.5341 - val_accuracy: 0.8690\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 107s 358ms/step - loss: 0.0418 - accuracy: 0.9848 - val_loss: 0.6389 - val_accuracy: 0.8690\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 106s 355ms/step - loss: 0.0377 - accuracy: 0.9836 - val_loss: 0.6300 - val_accuracy: 0.8643\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 107s 357ms/step - loss: 0.0353 - accuracy: 0.9855 - val_loss: 0.6382 - val_accuracy: 0.8652\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 106s 354ms/step - loss: 0.0336 - accuracy: 0.9854 - val_loss: 0.6211 - val_accuracy: 0.8567\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 106s 356ms/step - loss: 0.0398 - accuracy: 0.9845 - val_loss: 0.6082 - val_accuracy: 0.8662\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 107s 357ms/step - loss: 0.0354 - accuracy: 0.9859 - val_loss: 0.6591 - val_accuracy: 0.8690\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00026: early stopping\n",
      "Test Accuracy: 87.65316009521484\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 152s 425ms/step - loss: 0.5041 - accuracy: 0.7529 - val_loss: 0.7896 - val_accuracy: 0.7418\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 125s 417ms/step - loss: 0.2883 - accuracy: 0.8914 - val_loss: 0.7015 - val_accuracy: 0.7842\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 124s 416ms/step - loss: 0.2588 - accuracy: 0.9042 - val_loss: 0.7776 - val_accuracy: 0.7804\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 126s 422ms/step - loss: 0.2289 - accuracy: 0.9126 - val_loss: 0.8582 - val_accuracy: 0.7908\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 124s 416ms/step - loss: 0.2182 - accuracy: 0.9162 - val_loss: 0.8747 - val_accuracy: 0.7983\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 124s 415ms/step - loss: 0.1930 - accuracy: 0.9212 - val_loss: 1.0250 - val_accuracy: 0.7861\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 126s 420ms/step - loss: 0.1734 - accuracy: 0.9298 - val_loss: 0.9656 - val_accuracy: 0.7983\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 125s 420ms/step - loss: 0.1438 - accuracy: 0.9404 - val_loss: 1.0451 - val_accuracy: 0.7926\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 133s 444ms/step - loss: 0.1224 - accuracy: 0.9504 - val_loss: 1.4309 - val_accuracy: 0.7710\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 131s 438ms/step - loss: 0.1095 - accuracy: 0.9568 - val_loss: 1.3252 - val_accuracy: 0.7898\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 132s 440ms/step - loss: 0.0975 - accuracy: 0.9603 - val_loss: 1.4441 - val_accuracy: 0.7681\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 132s 442ms/step - loss: 0.0817 - accuracy: 0.9667 - val_loss: 1.4684 - val_accuracy: 0.7964\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 131s 439ms/step - loss: 0.0747 - accuracy: 0.9700 - val_loss: 1.4692 - val_accuracy: 0.7992\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 129s 432ms/step - loss: 0.0738 - accuracy: 0.9704 - val_loss: 1.6360 - val_accuracy: 0.7889\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 131s 438ms/step - loss: 0.0595 - accuracy: 0.9765 - val_loss: 1.4850 - val_accuracy: 0.7983\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 131s 438ms/step - loss: 0.0682 - accuracy: 0.9745 - val_loss: 1.7356 - val_accuracy: 0.7870\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 129s 433ms/step - loss: 0.0497 - accuracy: 0.9823 - val_loss: 1.7327 - val_accuracy: 0.7700\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 131s 437ms/step - loss: 0.0615 - accuracy: 0.9759 - val_loss: 1.7651 - val_accuracy: 0.7917\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 127s 426ms/step - loss: 0.0463 - accuracy: 0.9807 - val_loss: 1.8248 - val_accuracy: 0.7955\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 130s 435ms/step - loss: 0.0409 - accuracy: 0.9845 - val_loss: 1.7470 - val_accuracy: 0.7879\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 129s 433ms/step - loss: 0.0456 - accuracy: 0.9813 - val_loss: 1.8648 - val_accuracy: 0.8030\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 130s 436ms/step - loss: 0.0381 - accuracy: 0.9848 - val_loss: 1.9647 - val_accuracy: 0.7917\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 130s 435ms/step - loss: 0.0342 - accuracy: 0.9867 - val_loss: 2.0274 - val_accuracy: 0.7917\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 130s 436ms/step - loss: 0.0445 - accuracy: 0.9829 - val_loss: 1.9218 - val_accuracy: 0.7898\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 126s 422ms/step - loss: 0.0388 - accuracy: 0.9842 - val_loss: 1.9007 - val_accuracy: 0.7908\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 126s 422ms/step - loss: 0.0339 - accuracy: 0.9839 - val_loss: 1.8707 - val_accuracy: 0.8011\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 127s 424ms/step - loss: 0.0329 - accuracy: 0.9852 - val_loss: 1.7653 - val_accuracy: 0.8040\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 126s 422ms/step - loss: 0.0367 - accuracy: 0.9852 - val_loss: 1.8519 - val_accuracy: 0.7926\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 127s 424ms/step - loss: 0.0337 - accuracy: 0.9860 - val_loss: 2.1290 - val_accuracy: 0.7851\n",
      "Epoch 30/40\n",
      "299/299 [==============================] - 127s 425ms/step - loss: 0.0303 - accuracy: 0.9866 - val_loss: 1.9689 - val_accuracy: 0.7851\n",
      "Epoch 31/40\n",
      "299/299 [==============================] - 129s 432ms/step - loss: 0.0309 - accuracy: 0.9869 - val_loss: 2.0129 - val_accuracy: 0.7813\n",
      "Epoch 32/40\n",
      "299/299 [==============================] - 128s 427ms/step - loss: 0.0366 - accuracy: 0.9846 - val_loss: 1.9784 - val_accuracy: 0.7955\n",
      "Epoch 33/40\n",
      "299/299 [==============================] - 128s 427ms/step - loss: 0.0424 - accuracy: 0.9821 - val_loss: 2.1175 - val_accuracy: 0.7870\n",
      "Epoch 34/40\n",
      "299/299 [==============================] - 127s 424ms/step - loss: 0.0374 - accuracy: 0.9842 - val_loss: 1.9877 - val_accuracy: 0.7870\n",
      "Epoch 35/40\n",
      "299/299 [==============================] - 127s 426ms/step - loss: 0.0350 - accuracy: 0.9859 - val_loss: 2.0692 - val_accuracy: 0.7785\n",
      "Epoch 36/40\n",
      "299/299 [==============================] - 129s 431ms/step - loss: 0.0269 - accuracy: 0.9873 - val_loss: 2.1134 - val_accuracy: 0.7719\n",
      "Epoch 37/40\n",
      "299/299 [==============================] - 128s 428ms/step - loss: 0.0257 - accuracy: 0.9886 - val_loss: 2.1998 - val_accuracy: 0.7823\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00037: early stopping\n",
      "Test Accuracy: 80.3958535194397\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 145s 386ms/step - loss: 0.4867 - accuracy: 0.7722 - val_loss: 0.3573 - val_accuracy: 0.8577\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 88s 294ms/step - loss: 0.2838 - accuracy: 0.8879 - val_loss: 0.3657 - val_accuracy: 0.8124\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 96s 320ms/step - loss: 0.2642 - accuracy: 0.8967 - val_loss: 0.3442 - val_accuracy: 0.8558\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 97s 325ms/step - loss: 0.2424 - accuracy: 0.9058 - val_loss: 0.3534 - val_accuracy: 0.8247\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 97s 323ms/step - loss: 0.2137 - accuracy: 0.9211 - val_loss: 0.3808 - val_accuracy: 0.8209\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 97s 324ms/step - loss: 0.1816 - accuracy: 0.9310 - val_loss: 0.4247 - val_accuracy: 0.8002\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 97s 323ms/step - loss: 0.1666 - accuracy: 0.9323 - val_loss: 0.4251 - val_accuracy: 0.8068\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 96s 322ms/step - loss: 0.1524 - accuracy: 0.9366 - val_loss: 0.4859 - val_accuracy: 0.8011\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 96s 323ms/step - loss: 0.1358 - accuracy: 0.9449 - val_loss: 0.4854 - val_accuracy: 0.8143\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 96s 323ms/step - loss: 0.1134 - accuracy: 0.9543 - val_loss: 0.4869 - val_accuracy: 0.8049\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 96s 322ms/step - loss: 0.1017 - accuracy: 0.9573 - val_loss: 0.6024 - val_accuracy: 0.8124\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 85.76814532279968\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 179s 483ms/step - loss: 0.5058 - accuracy: 0.7531 - val_loss: 0.3252 - val_accuracy: 0.8765\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 123s 412ms/step - loss: 0.2950 - accuracy: 0.8840 - val_loss: 0.2960 - val_accuracy: 0.8822\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 120s 400ms/step - loss: 0.2592 - accuracy: 0.9000 - val_loss: 0.2893 - val_accuracy: 0.8888\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 118s 394ms/step - loss: 0.2288 - accuracy: 0.9121 - val_loss: 0.2956 - val_accuracy: 0.8897\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 119s 398ms/step - loss: 0.2002 - accuracy: 0.9211 - val_loss: 0.3169 - val_accuracy: 0.8916\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 119s 397ms/step - loss: 0.1840 - accuracy: 0.9298 - val_loss: 0.3696 - val_accuracy: 0.8812\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 118s 395ms/step - loss: 0.1554 - accuracy: 0.9348 - val_loss: 0.4083 - val_accuracy: 0.8860\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 119s 398ms/step - loss: 0.1447 - accuracy: 0.9392 - val_loss: 0.4543 - val_accuracy: 0.8765\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 117s 392ms/step - loss: 0.1268 - accuracy: 0.9499 - val_loss: 0.4891 - val_accuracy: 0.8831\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 118s 396ms/step - loss: 0.1117 - accuracy: 0.9580 - val_loss: 0.4940 - val_accuracy: 0.8756\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 118s 393ms/step - loss: 0.0927 - accuracy: 0.9644 - val_loss: 0.5268 - val_accuracy: 0.8652\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 117s 392ms/step - loss: 0.0951 - accuracy: 0.9618 - val_loss: 0.5571 - val_accuracy: 0.8784\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 118s 395ms/step - loss: 0.0782 - accuracy: 0.9711 - val_loss: 0.6329 - val_accuracy: 0.8737\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 118s 393ms/step - loss: 0.0675 - accuracy: 0.9740 - val_loss: 0.7546 - val_accuracy: 0.8718\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 118s 395ms/step - loss: 0.0710 - accuracy: 0.9754 - val_loss: 0.6683 - val_accuracy: 0.8794\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 89.16116952896118\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 156s 434ms/step - loss: 0.4943 - accuracy: 0.7572 - val_loss: 0.4804 - val_accuracy: 0.7934\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 101s 337ms/step - loss: 0.2750 - accuracy: 0.8952 - val_loss: 0.3696 - val_accuracy: 0.8198\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 99s 330ms/step - loss: 0.2536 - accuracy: 0.9008 - val_loss: 0.4382 - val_accuracy: 0.8113\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 97s 325ms/step - loss: 0.2276 - accuracy: 0.9115 - val_loss: 0.3604 - val_accuracy: 0.8302\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 94s 315ms/step - loss: 0.2011 - accuracy: 0.9239 - val_loss: 0.3974 - val_accuracy: 0.8245\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 95s 318ms/step - loss: 0.1934 - accuracy: 0.9257 - val_loss: 0.5474 - val_accuracy: 0.8028\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 95s 318ms/step - loss: 0.1651 - accuracy: 0.9366 - val_loss: 0.5255 - val_accuracy: 0.8066\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 95s 318ms/step - loss: 0.1442 - accuracy: 0.9457 - val_loss: 0.6037 - val_accuracy: 0.8160\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 95s 318ms/step - loss: 0.1246 - accuracy: 0.9537 - val_loss: 0.5437 - val_accuracy: 0.8321\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 94s 316ms/step - loss: 0.1147 - accuracy: 0.9545 - val_loss: 0.5175 - val_accuracy: 0.8566\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 94s 314ms/step - loss: 0.0961 - accuracy: 0.9623 - val_loss: 0.9012 - val_accuracy: 0.7962\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 93s 310ms/step - loss: 0.0878 - accuracy: 0.9643 - val_loss: 0.8303 - val_accuracy: 0.8160\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 94s 314ms/step - loss: 0.0790 - accuracy: 0.9709 - val_loss: 0.6619 - val_accuracy: 0.8349\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 94s 315ms/step - loss: 0.0807 - accuracy: 0.9722 - val_loss: 0.8239 - val_accuracy: 0.8236\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 94s 315ms/step - loss: 0.0602 - accuracy: 0.9766 - val_loss: 1.0569 - val_accuracy: 0.8057\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 95s 319ms/step - loss: 0.0622 - accuracy: 0.9764 - val_loss: 1.0370 - val_accuracy: 0.8057\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 95s 316ms/step - loss: 0.0524 - accuracy: 0.9768 - val_loss: 0.9744 - val_accuracy: 0.8170\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 94s 315ms/step - loss: 0.0526 - accuracy: 0.9804 - val_loss: 0.9719 - val_accuracy: 0.8179\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 95s 317ms/step - loss: 0.0442 - accuracy: 0.9825 - val_loss: 0.8262 - val_accuracy: 0.8377\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 95s 318ms/step - loss: 0.0455 - accuracy: 0.9828 - val_loss: 0.8085 - val_accuracy: 0.8396\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 85.66038012504578\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 175s 480ms/step - loss: 0.4788 - accuracy: 0.7784 - val_loss: 0.4437 - val_accuracy: 0.8038\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 133s 446ms/step - loss: 0.2682 - accuracy: 0.8986 - val_loss: 0.4860 - val_accuracy: 0.7981\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 133s 445ms/step - loss: 0.2446 - accuracy: 0.9071 - val_loss: 0.4476 - val_accuracy: 0.8047\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 134s 448ms/step - loss: 0.2269 - accuracy: 0.9132 - val_loss: 0.4654 - val_accuracy: 0.8198\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 133s 446ms/step - loss: 0.2137 - accuracy: 0.9201 - val_loss: 0.4448 - val_accuracy: 0.8151\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 134s 449ms/step - loss: 0.1886 - accuracy: 0.9267 - val_loss: 0.3849 - val_accuracy: 0.8255\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 134s 450ms/step - loss: 0.1646 - accuracy: 0.9363 - val_loss: 0.4135 - val_accuracy: 0.8283\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 136s 456ms/step - loss: 0.1460 - accuracy: 0.9431 - val_loss: 0.5285 - val_accuracy: 0.8236\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 137s 458ms/step - loss: 0.1271 - accuracy: 0.9485 - val_loss: 0.6100 - val_accuracy: 0.8094\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 136s 456ms/step - loss: 0.1101 - accuracy: 0.9570 - val_loss: 0.4885 - val_accuracy: 0.8519\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 136s 454ms/step - loss: 0.1008 - accuracy: 0.9601 - val_loss: 0.5572 - val_accuracy: 0.8557\n",
      "Epoch 12/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 137s 459ms/step - loss: 0.1003 - accuracy: 0.9660 - val_loss: 0.5561 - val_accuracy: 0.8472\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 138s 462ms/step - loss: 0.0815 - accuracy: 0.9698 - val_loss: 0.7286 - val_accuracy: 0.8377\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 137s 459ms/step - loss: 0.0694 - accuracy: 0.9731 - val_loss: 0.7153 - val_accuracy: 0.8547\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 138s 461ms/step - loss: 0.0636 - accuracy: 0.9752 - val_loss: 0.8168 - val_accuracy: 0.8358\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 137s 460ms/step - loss: 0.0583 - accuracy: 0.9770 - val_loss: 0.9211 - val_accuracy: 0.8245\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 137s 459ms/step - loss: 0.0565 - accuracy: 0.9781 - val_loss: 0.7825 - val_accuracy: 0.8443\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 137s 459ms/step - loss: 0.0448 - accuracy: 0.9817 - val_loss: 0.8303 - val_accuracy: 0.8443\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 137s 458ms/step - loss: 0.0467 - accuracy: 0.9834 - val_loss: 0.9013 - val_accuracy: 0.8264\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 137s 458ms/step - loss: 0.0498 - accuracy: 0.9803 - val_loss: 0.8993 - val_accuracy: 0.8481\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 136s 456ms/step - loss: 0.0431 - accuracy: 0.9807 - val_loss: 0.9081 - val_accuracy: 0.8509\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "Test Accuracy: 85.56603789329529\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 165s 464ms/step - loss: 0.5040 - accuracy: 0.7539 - val_loss: 0.3436 - val_accuracy: 0.8670\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 120s 402ms/step - loss: 0.2823 - accuracy: 0.8889 - val_loss: 0.3317 - val_accuracy: 0.8745\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 117s 390ms/step - loss: 0.2536 - accuracy: 0.9063 - val_loss: 0.3355 - val_accuracy: 0.8585\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 115s 385ms/step - loss: 0.2286 - accuracy: 0.9172 - val_loss: 0.3481 - val_accuracy: 0.8575\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 115s 385ms/step - loss: 0.1968 - accuracy: 0.9247 - val_loss: 0.4014 - val_accuracy: 0.8113\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 115s 385ms/step - loss: 0.1804 - accuracy: 0.9307 - val_loss: 0.4026 - val_accuracy: 0.8057\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 114s 380ms/step - loss: 0.1593 - accuracy: 0.9357 - val_loss: 0.5392 - val_accuracy: 0.7925\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 114s 381ms/step - loss: 0.1388 - accuracy: 0.9427 - val_loss: 0.4665 - val_accuracy: 0.8396\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 114s 382ms/step - loss: 0.1236 - accuracy: 0.9495 - val_loss: 0.5567 - val_accuracy: 0.8311\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 114s 382ms/step - loss: 0.1081 - accuracy: 0.9562 - val_loss: 0.5329 - val_accuracy: 0.8387\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 114s 381ms/step - loss: 0.1031 - accuracy: 0.9619 - val_loss: 0.5897 - val_accuracy: 0.8406\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 110s 368ms/step - loss: 0.0883 - accuracy: 0.9675 - val_loss: 0.6152 - val_accuracy: 0.8358\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.45282888412476\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 160s 434ms/step - loss: 0.4948 - accuracy: 0.7574 - val_loss: 0.3756 - val_accuracy: 0.8528\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 119s 397ms/step - loss: 0.2791 - accuracy: 0.8953 - val_loss: 0.3642 - val_accuracy: 0.8698\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 117s 392ms/step - loss: 0.2445 - accuracy: 0.9089 - val_loss: 0.3675 - val_accuracy: 0.8679\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 112s 374ms/step - loss: 0.2204 - accuracy: 0.9187 - val_loss: 0.3602 - val_accuracy: 0.8670\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 115s 383ms/step - loss: 0.2015 - accuracy: 0.9232 - val_loss: 0.4097 - val_accuracy: 0.8726\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 115s 384ms/step - loss: 0.1838 - accuracy: 0.9310 - val_loss: 0.4242 - val_accuracy: 0.8717\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 119s 399ms/step - loss: 0.1597 - accuracy: 0.9366 - val_loss: 0.4490 - val_accuracy: 0.8698\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 120s 402ms/step - loss: 0.1407 - accuracy: 0.9433 - val_loss: 0.4400 - val_accuracy: 0.8651\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 118s 395ms/step - loss: 0.1271 - accuracy: 0.9513 - val_loss: 0.5509 - val_accuracy: 0.8670\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 115s 383ms/step - loss: 0.1262 - accuracy: 0.9484 - val_loss: 0.5098 - val_accuracy: 0.8708\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 116s 387ms/step - loss: 0.0949 - accuracy: 0.9625 - val_loss: 0.5726 - val_accuracy: 0.8632\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 116s 389ms/step - loss: 0.0810 - accuracy: 0.9699 - val_loss: 0.6071 - val_accuracy: 0.8632\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 116s 387ms/step - loss: 0.0788 - accuracy: 0.9706 - val_loss: 0.5949 - val_accuracy: 0.8585\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 117s 390ms/step - loss: 0.0771 - accuracy: 0.9696 - val_loss: 0.6262 - val_accuracy: 0.8670\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 116s 389ms/step - loss: 0.0662 - accuracy: 0.9757 - val_loss: 0.6673 - val_accuracy: 0.8575\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 87.26415038108826\n",
      "\n",
      "        acc1       acc2      acc3       acc4       acc5      acc6      acc7  \\\n",
      "0  88.689917  82.563621  87.65316  80.395854  85.768145  89.16117  85.66038   \n",
      "\n",
      "        acc8       acc9     acc10        AVG  \n",
      "0  85.566038  87.452829  87.26415  86.017526  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_2(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.689917</td>\n",
       "      <td>82.563621</td>\n",
       "      <td>87.65316</td>\n",
       "      <td>80.395854</td>\n",
       "      <td>85.768145</td>\n",
       "      <td>89.16117</td>\n",
       "      <td>85.66038</td>\n",
       "      <td>85.566038</td>\n",
       "      <td>87.452829</td>\n",
       "      <td>87.26415</td>\n",
       "      <td>86.017526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2      acc3       acc4       acc5      acc6      acc7  \\\n",
       "0  88.689917  82.563621  87.65316  80.395854  85.768145  89.16117  85.66038   \n",
       "\n",
       "        acc8       acc9     acc10        AVG  \n",
       "0  85.566038  87.452829  87.26415  86.017526  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('LSTM_MPQA_v2_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=False)),\n",
    "#         tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_60 (Bidirectio (None, 100, 128)          186880    \n",
      "_________________________________________________________________\n",
      "bidirectional_61 (Bidirectio (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 585,825\n",
      "Trainable params: 585,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 191s 552ms/step - loss: 0.4807 - accuracy: 0.7738 - val_loss: 0.2875 - val_accuracy: 0.8822\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 157s 526ms/step - loss: 0.1876 - accuracy: 0.9364 - val_loss: 0.2976 - val_accuracy: 0.8841\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 149s 500ms/step - loss: 0.1378 - accuracy: 0.9555 - val_loss: 0.3297 - val_accuracy: 0.8878\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 148s 494ms/step - loss: 0.0981 - accuracy: 0.9654 - val_loss: 0.3382 - val_accuracy: 0.8897\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 149s 498ms/step - loss: 0.0759 - accuracy: 0.9686 - val_loss: 0.4486 - val_accuracy: 0.8822\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 149s 498ms/step - loss: 0.0571 - accuracy: 0.9783 - val_loss: 0.5567 - val_accuracy: 0.8803\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 147s 493ms/step - loss: 0.0496 - accuracy: 0.9783 - val_loss: 0.5042 - val_accuracy: 0.8671\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 149s 499ms/step - loss: 0.0440 - accuracy: 0.9805 - val_loss: 0.5659 - val_accuracy: 0.8860\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 149s 499ms/step - loss: 0.0389 - accuracy: 0.9813 - val_loss: 0.6015 - val_accuracy: 0.8822\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 150s 502ms/step - loss: 0.0355 - accuracy: 0.9839 - val_loss: 0.6252 - val_accuracy: 0.8841\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 150s 503ms/step - loss: 0.0319 - accuracy: 0.9864 - val_loss: 0.6354 - val_accuracy: 0.8803\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 150s 501ms/step - loss: 0.0302 - accuracy: 0.9857 - val_loss: 0.7342 - val_accuracy: 0.8822\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 150s 501ms/step - loss: 0.0307 - accuracy: 0.9859 - val_loss: 0.7749 - val_accuracy: 0.8775\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 150s 501ms/step - loss: 0.0290 - accuracy: 0.9848 - val_loss: 0.8461 - val_accuracy: 0.8803\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 88.97266983985901\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 181s 514ms/step - loss: 0.4777 - accuracy: 0.7712 - val_loss: 0.3200 - val_accuracy: 0.8699\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 147s 492ms/step - loss: 0.1852 - accuracy: 0.9354 - val_loss: 0.3181 - val_accuracy: 0.8794\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 149s 498ms/step - loss: 0.1316 - accuracy: 0.9567 - val_loss: 0.3772 - val_accuracy: 0.8586\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 150s 500ms/step - loss: 0.0915 - accuracy: 0.9683 - val_loss: 0.4321 - val_accuracy: 0.8586\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 151s 504ms/step - loss: 0.0720 - accuracy: 0.9693 - val_loss: 0.4614 - val_accuracy: 0.8549\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 151s 503ms/step - loss: 0.0627 - accuracy: 0.9740 - val_loss: 0.5579 - val_accuracy: 0.8473\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 153s 513ms/step - loss: 0.0503 - accuracy: 0.9790 - val_loss: 0.6362 - val_accuracy: 0.8520\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 158s 528ms/step - loss: 0.0395 - accuracy: 0.9818 - val_loss: 0.7483 - val_accuracy: 0.8549\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 155s 520ms/step - loss: 0.0428 - accuracy: 0.9810 - val_loss: 0.7894 - val_accuracy: 0.8473\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 159s 532ms/step - loss: 0.0352 - accuracy: 0.9852 - val_loss: 0.7227 - val_accuracy: 0.8511\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 156s 522ms/step - loss: 0.0422 - accuracy: 0.9807 - val_loss: 0.7247 - val_accuracy: 0.8454\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 151s 504ms/step - loss: 0.0319 - accuracy: 0.9850 - val_loss: 0.8150 - val_accuracy: 0.8549\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.93590664863586\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 215s 610ms/step - loss: 0.4818 - accuracy: 0.7738 - val_loss: 0.3597 - val_accuracy: 0.8322\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 173s 578ms/step - loss: 0.1859 - accuracy: 0.9339 - val_loss: 0.3607 - val_accuracy: 0.8445\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 173s 578ms/step - loss: 0.1294 - accuracy: 0.9544 - val_loss: 0.3716 - val_accuracy: 0.8445\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 173s 580ms/step - loss: 0.0964 - accuracy: 0.9682 - val_loss: 0.4602 - val_accuracy: 0.8322\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 174s 581ms/step - loss: 0.0766 - accuracy: 0.9706 - val_loss: 0.4966 - val_accuracy: 0.8445\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 175s 585ms/step - loss: 0.0557 - accuracy: 0.9766 - val_loss: 0.5719 - val_accuracy: 0.8407\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 178s 595ms/step - loss: 0.0477 - accuracy: 0.9798 - val_loss: 0.6519 - val_accuracy: 0.8369\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 177s 593ms/step - loss: 0.0430 - accuracy: 0.9799 - val_loss: 0.7628 - val_accuracy: 0.8549\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 177s 593ms/step - loss: 0.0374 - accuracy: 0.9848 - val_loss: 0.7013 - val_accuracy: 0.8426\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 178s 595ms/step - loss: 0.0370 - accuracy: 0.9831 - val_loss: 0.8531 - val_accuracy: 0.8539\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 178s 594ms/step - loss: 0.0355 - accuracy: 0.9837 - val_loss: 0.8044 - val_accuracy: 0.8501\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 179s 599ms/step - loss: 0.0305 - accuracy: 0.9851 - val_loss: 0.8919 - val_accuracy: 0.8483\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 176s 590ms/step - loss: 0.0283 - accuracy: 0.9873 - val_loss: 0.9146 - val_accuracy: 0.8539\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 173s 578ms/step - loss: 0.0318 - accuracy: 0.9848 - val_loss: 0.8858 - val_accuracy: 0.8398\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 174s 581ms/step - loss: 0.0268 - accuracy: 0.9864 - val_loss: 0.9514 - val_accuracy: 0.8558\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 177s 592ms/step - loss: 0.0265 - accuracy: 0.9863 - val_loss: 1.0891 - val_accuracy: 0.8464\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 176s 588ms/step - loss: 0.0243 - accuracy: 0.9869 - val_loss: 1.0823 - val_accuracy: 0.8558\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 175s 585ms/step - loss: 0.0299 - accuracy: 0.9874 - val_loss: 0.9854 - val_accuracy: 0.8492\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 176s 587ms/step - loss: 0.0274 - accuracy: 0.9878 - val_loss: 1.0195 - val_accuracy: 0.8483\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 173s 580ms/step - loss: 0.0245 - accuracy: 0.9883 - val_loss: 1.0789 - val_accuracy: 0.8445\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.0234 - accuracy: 0.9894 - val_loss: 1.1026 - val_accuracy: 0.8464\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.0210 - accuracy: 0.9900 - val_loss: 1.1744 - val_accuracy: 0.8492\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 175s 585ms/step - loss: 0.0232 - accuracy: 0.9869 - val_loss: 1.1319 - val_accuracy: 0.8464\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 175s 584ms/step - loss: 0.0221 - accuracy: 0.9884 - val_loss: 1.1693 - val_accuracy: 0.8473\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 174s 582ms/step - loss: 0.0220 - accuracy: 0.9887 - val_loss: 1.2228 - val_accuracy: 0.8464\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00025: early stopping\n",
      "Test Accuracy: 85.57963967323303\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 179s 510ms/step - loss: 0.4886 - accuracy: 0.7673 - val_loss: 0.3979 - val_accuracy: 0.8671\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 144s 480ms/step - loss: 0.2003 - accuracy: 0.9298 - val_loss: 0.3876 - val_accuracy: 0.8643\n",
      "Epoch 3/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 134s 448ms/step - loss: 0.1333 - accuracy: 0.9536 - val_loss: 0.5030 - val_accuracy: 0.8709\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 134s 448ms/step - loss: 0.0969 - accuracy: 0.9673 - val_loss: 0.5122 - val_accuracy: 0.8709\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 133s 443ms/step - loss: 0.0747 - accuracy: 0.9698 - val_loss: 0.5572 - val_accuracy: 0.8718\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 135s 450ms/step - loss: 0.0635 - accuracy: 0.9730 - val_loss: 0.7561 - val_accuracy: 0.8728\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 135s 453ms/step - loss: 0.0516 - accuracy: 0.9784 - val_loss: 0.7016 - val_accuracy: 0.8586\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 134s 449ms/step - loss: 0.0414 - accuracy: 0.9819 - val_loss: 0.7477 - val_accuracy: 0.8577\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 134s 449ms/step - loss: 0.0353 - accuracy: 0.9835 - val_loss: 0.9907 - val_accuracy: 0.8633\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 135s 451ms/step - loss: 0.0366 - accuracy: 0.9836 - val_loss: 0.8393 - val_accuracy: 0.8737\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 135s 453ms/step - loss: 0.0307 - accuracy: 0.9861 - val_loss: 0.9354 - val_accuracy: 0.8680\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 131s 437ms/step - loss: 0.0330 - accuracy: 0.9836 - val_loss: 0.9204 - val_accuracy: 0.8643\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 132s 440ms/step - loss: 0.0307 - accuracy: 0.9863 - val_loss: 0.9825 - val_accuracy: 0.8605\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 133s 444ms/step - loss: 0.0293 - accuracy: 0.9871 - val_loss: 1.1796 - val_accuracy: 0.8615\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 133s 445ms/step - loss: 0.0286 - accuracy: 0.9873 - val_loss: 1.1206 - val_accuracy: 0.8652\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 134s 449ms/step - loss: 0.0255 - accuracy: 0.9866 - val_loss: 1.1512 - val_accuracy: 0.8577\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 139s 464ms/step - loss: 0.0304 - accuracy: 0.9859 - val_loss: 1.2289 - val_accuracy: 0.8690\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 135s 453ms/step - loss: 0.0286 - accuracy: 0.9865 - val_loss: 1.3466 - val_accuracy: 0.8662\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 134s 447ms/step - loss: 0.0257 - accuracy: 0.9870 - val_loss: 1.3344 - val_accuracy: 0.8680\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 136s 453ms/step - loss: 0.0241 - accuracy: 0.9879 - val_loss: 1.1736 - val_accuracy: 0.8662\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 87.37040758132935\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 182s 525ms/step - loss: 0.4891 - accuracy: 0.7601 - val_loss: 0.3177 - val_accuracy: 0.8888\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 166s 556ms/step - loss: 0.1905 - accuracy: 0.9307 - val_loss: 0.3309 - val_accuracy: 0.8718\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 168s 563ms/step - loss: 0.1180 - accuracy: 0.9615 - val_loss: 0.3680 - val_accuracy: 0.8633\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 168s 563ms/step - loss: 0.0959 - accuracy: 0.9643 - val_loss: 0.4563 - val_accuracy: 0.8718\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 169s 566ms/step - loss: 0.0663 - accuracy: 0.9751 - val_loss: 0.4836 - val_accuracy: 0.8671\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 168s 561ms/step - loss: 0.0599 - accuracy: 0.9741 - val_loss: 0.6102 - val_accuracy: 0.8662\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 169s 566ms/step - loss: 0.0509 - accuracy: 0.9780 - val_loss: 0.6510 - val_accuracy: 0.8690\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 171s 570ms/step - loss: 0.0412 - accuracy: 0.9825 - val_loss: 0.7163 - val_accuracy: 0.8294\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 171s 572ms/step - loss: 0.0343 - accuracy: 0.9853 - val_loss: 0.8726 - val_accuracy: 0.8341\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 170s 570ms/step - loss: 0.0339 - accuracy: 0.9841 - val_loss: 0.9133 - val_accuracy: 0.8313\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 169s 565ms/step - loss: 0.0288 - accuracy: 0.9873 - val_loss: 0.9921 - val_accuracy: 0.8360\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.87841701507568\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 190s 558ms/step - loss: 0.4831 - accuracy: 0.7673 - val_loss: 0.3273 - val_accuracy: 0.8784\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 179s 598ms/step - loss: 0.1880 - accuracy: 0.9382 - val_loss: 0.3422 - val_accuracy: 0.8746\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 169s 566ms/step - loss: 0.1268 - accuracy: 0.9560 - val_loss: 0.3633 - val_accuracy: 0.8737\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 169s 565ms/step - loss: 0.1011 - accuracy: 0.9617 - val_loss: 0.4370 - val_accuracy: 0.8699\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 168s 563ms/step - loss: 0.0712 - accuracy: 0.9725 - val_loss: 0.4668 - val_accuracy: 0.8435\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 171s 571ms/step - loss: 0.0543 - accuracy: 0.9766 - val_loss: 0.5345 - val_accuracy: 0.8539\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 169s 566ms/step - loss: 0.0514 - accuracy: 0.9787 - val_loss: 0.5710 - val_accuracy: 0.8511\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 169s 567ms/step - loss: 0.0388 - accuracy: 0.9834 - val_loss: 0.7758 - val_accuracy: 0.8275\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 169s 565ms/step - loss: 0.0356 - accuracy: 0.9866 - val_loss: 0.7118 - val_accuracy: 0.8303\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 168s 564ms/step - loss: 0.0336 - accuracy: 0.9851 - val_loss: 0.7583 - val_accuracy: 0.8388\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 167s 560ms/step - loss: 0.0295 - accuracy: 0.9873 - val_loss: 0.8242 - val_accuracy: 0.8464\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 87.84165978431702\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 221s 660ms/step - loss: 0.4864 - accuracy: 0.7723 - val_loss: 0.4777 - val_accuracy: 0.8151\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 196s 656ms/step - loss: 0.1948 - accuracy: 0.9308 - val_loss: 0.5511 - val_accuracy: 0.8160\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 198s 661ms/step - loss: 0.1313 - accuracy: 0.9563 - val_loss: 0.6524 - val_accuracy: 0.8113\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 198s 663ms/step - loss: 0.0991 - accuracy: 0.9638 - val_loss: 0.7077 - val_accuracy: 0.8047\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 199s 666ms/step - loss: 0.0676 - accuracy: 0.9710 - val_loss: 0.8359 - val_accuracy: 0.7840\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 197s 660ms/step - loss: 0.0619 - accuracy: 0.9727 - val_loss: 1.0019 - val_accuracy: 0.7934\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 195s 653ms/step - loss: 0.0455 - accuracy: 0.9832 - val_loss: 1.0065 - val_accuracy: 0.7830\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 197s 660ms/step - loss: 0.0436 - accuracy: 0.9772 - val_loss: 1.0285 - val_accuracy: 0.7849\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 196s 654ms/step - loss: 0.0382 - accuracy: 0.9831 - val_loss: 1.0799 - val_accuracy: 0.7887\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 196s 657ms/step - loss: 0.0357 - accuracy: 0.9827 - val_loss: 1.2264 - val_accuracy: 0.7830\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 197s 658ms/step - loss: 0.0359 - accuracy: 0.9838 - val_loss: 1.2684 - val_accuracy: 0.7896\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 196s 657ms/step - loss: 0.0332 - accuracy: 0.9837 - val_loss: 1.4351 - val_accuracy: 0.7858\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.60377144813538\n",
      "Training 8: \n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 188s 527ms/step - loss: 0.4748 - accuracy: 0.7820 - val_loss: 0.4687 - val_accuracy: 0.7991\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 152s 508ms/step - loss: 0.1941 - accuracy: 0.9309 - val_loss: 0.4357 - val_accuracy: 0.8047\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 146s 490ms/step - loss: 0.1312 - accuracy: 0.9555 - val_loss: 0.5537 - val_accuracy: 0.8038\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 144s 481ms/step - loss: 0.1066 - accuracy: 0.9614 - val_loss: 0.6355 - val_accuracy: 0.7943\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 143s 477ms/step - loss: 0.0769 - accuracy: 0.9690 - val_loss: 0.7197 - val_accuracy: 0.7858\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 142s 475ms/step - loss: 0.0563 - accuracy: 0.9767 - val_loss: 0.7540 - val_accuracy: 0.7840\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 142s 475ms/step - loss: 0.0528 - accuracy: 0.9770 - val_loss: 0.8263 - val_accuracy: 0.7887\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 141s 473ms/step - loss: 0.0413 - accuracy: 0.9821 - val_loss: 1.0072 - val_accuracy: 0.7830\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 141s 473ms/step - loss: 0.0345 - accuracy: 0.9844 - val_loss: 1.0767 - val_accuracy: 0.7821\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 141s 473ms/step - loss: 0.0322 - accuracy: 0.9859 - val_loss: 1.1657 - val_accuracy: 0.7811\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 141s 472ms/step - loss: 0.0296 - accuracy: 0.9855 - val_loss: 1.2404 - val_accuracy: 0.7868\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 141s 471ms/step - loss: 0.0378 - accuracy: 0.9830 - val_loss: 1.0888 - val_accuracy: 0.7792\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 80.47170042991638\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 186s 542ms/step - loss: 0.4680 - accuracy: 0.7848 - val_loss: 0.3196 - val_accuracy: 0.8792\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 148s 496ms/step - loss: 0.1900 - accuracy: 0.9337 - val_loss: 0.3445 - val_accuracy: 0.8689\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 146s 489ms/step - loss: 0.1327 - accuracy: 0.9558 - val_loss: 0.3997 - val_accuracy: 0.8679\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 149s 497ms/step - loss: 0.0975 - accuracy: 0.9645 - val_loss: 0.4929 - val_accuracy: 0.8670\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 146s 488ms/step - loss: 0.0730 - accuracy: 0.9719 - val_loss: 0.5092 - val_accuracy: 0.8566\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 146s 487ms/step - loss: 0.0578 - accuracy: 0.9762 - val_loss: 0.5616 - val_accuracy: 0.8491\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 146s 488ms/step - loss: 0.0481 - accuracy: 0.9781 - val_loss: 0.6677 - val_accuracy: 0.8566\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 145s 486ms/step - loss: 0.0360 - accuracy: 0.9848 - val_loss: 0.7070 - val_accuracy: 0.8509\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 146s 489ms/step - loss: 0.0364 - accuracy: 0.9850 - val_loss: 0.8102 - val_accuracy: 0.8538\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 146s 487ms/step - loss: 0.0361 - accuracy: 0.9830 - val_loss: 0.7454 - val_accuracy: 0.8575\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 146s 487ms/step - loss: 0.0301 - accuracy: 0.9869 - val_loss: 0.8064 - val_accuracy: 0.8642\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 87.92452812194824\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 195s 573ms/step - loss: 0.4884 - accuracy: 0.7726 - val_loss: 0.3397 - val_accuracy: 0.8349\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.1982 - accuracy: 0.9320 - val_loss: 0.3159 - val_accuracy: 0.8415\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.1342 - accuracy: 0.9544 - val_loss: 0.3997 - val_accuracy: 0.8292\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 171s 570ms/step - loss: 0.1054 - accuracy: 0.9630 - val_loss: 0.3973 - val_accuracy: 0.8321\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 171s 572ms/step - loss: 0.0775 - accuracy: 0.9719 - val_loss: 0.5379 - val_accuracy: 0.8274\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.0575 - accuracy: 0.9755 - val_loss: 0.5813 - val_accuracy: 0.8245\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 171s 572ms/step - loss: 0.0517 - accuracy: 0.9783 - val_loss: 0.7731 - val_accuracy: 0.8189\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.0425 - accuracy: 0.9819 - val_loss: 0.7200 - val_accuracy: 0.8236\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 171s 571ms/step - loss: 0.0385 - accuracy: 0.9818 - val_loss: 0.7956 - val_accuracy: 0.8170\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 171s 571ms/step - loss: 0.0334 - accuracy: 0.9830 - val_loss: 0.7792 - val_accuracy: 0.8264\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 171s 573ms/step - loss: 0.0339 - accuracy: 0.9821 - val_loss: 0.9479 - val_accuracy: 0.8264\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 173s 578ms/step - loss: 0.0281 - accuracy: 0.9869 - val_loss: 0.9350 - val_accuracy: 0.8274\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 84.1509461402893\n",
      "\n",
      "        acc1       acc2       acc3      acc4       acc5       acc6       acc7  \\\n",
      "0  84.448636  86.145145  86.804903  85.20264  86.427897  86.616397  86.320752   \n",
      "\n",
      "        acc8       acc9      acc10        AVG  \n",
      "0  86.415094  85.849059  86.603773  86.083429  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_3(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>88.97267</td>\n",
       "      <td>87.935907</td>\n",
       "      <td>85.57964</td>\n",
       "      <td>87.370408</td>\n",
       "      <td>88.878417</td>\n",
       "      <td>87.84166</td>\n",
       "      <td>81.603771</td>\n",
       "      <td>80.4717</td>\n",
       "      <td>87.924528</td>\n",
       "      <td>84.150946</td>\n",
       "      <td>86.072965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc1       acc2      acc3       acc4       acc5      acc6       acc7  \\\n",
       "0  88.97267  87.935907  85.57964  87.370408  88.878417  87.84166  81.603771   \n",
       "\n",
       "      acc8       acc9      acc10        AVG  \n",
       "0  80.4717  87.924528  84.150946  86.072965  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('LSTM_MPQA_v2_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
