{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "GRU_CR_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKA28DEUYPzJ"
      },
      "source": [
        "# GRU Classification with CR Dataset\n",
        "<hr>\n",
        "\n",
        "We will build a text classification model using GRU model on the Customer Reviews Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
        "\n",
        "## Load the library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWK_Q-ljYPzU",
        "outputId": "d0d9e217-e3dd-4fb5-c9a2-431118321727"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import nltk\n",
        "import random\n",
        "# from nltk.tokenize import TweetTokenizer\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "%config IPCompleter.greedy=True\n",
        "%config IPCompleter.use_jedi=False\n",
        "# nltk.download('twitter_samples')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: UserWarning: Config option `use_jedi` not recognized by `IPCompleter`.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSnNPyHzYPzW",
        "outputId": "19052305-ba5f-4c61-ad72-840f79d483ce"
      },
      "source": [
        "tf.config.list_physical_devices('GPU') "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KIXYTu2YPzZ"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "jcJ8JUudYPza",
        "outputId": "5b10781d-36a2-41c7-9df9-51c3f8ccd6f4"
      },
      "source": [
        "corpus = pd.read_pickle('/content/drive/MyDrive/Disertasi/0_data/CR/CR.pkl')\n",
        "corpus.label = corpus.label.astype(int)\n",
        "print(corpus.shape)\n",
        "corpus"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3775, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>weaknesses are minor the feel and layout of th...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>many of our disney movies do n 't play on this...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>player has a problem with dual layer dvd 's su...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i know the saying is you get what you pay for ...</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will never purchase apex again .</td>\n",
              "      <td>0</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3770</th>\n",
              "      <td>so far , the anti spam feature seems to be ver...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3771</th>\n",
              "      <td>i downloaded a trial version of computer assoc...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3772</th>\n",
              "      <td>i did not have any of the installation problem...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3773</th>\n",
              "      <td>their products have been great and have saved ...</td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3774</th>\n",
              "      <td></td>\n",
              "      <td>1</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3775 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label  split\n",
              "0     weaknesses are minor the feel and layout of th...      0  train\n",
              "1     many of our disney movies do n 't play on this...      0  train\n",
              "2     player has a problem with dual layer dvd 's su...      0  train\n",
              "3     i know the saying is you get what you pay for ...      0  train\n",
              "4                      will never purchase apex again .      0  train\n",
              "...                                                 ...    ...    ...\n",
              "3770  so far , the anti spam feature seems to be ver...      1  train\n",
              "3771  i downloaded a trial version of computer assoc...      1  train\n",
              "3772  i did not have any of the installation problem...      1  train\n",
              "3773  their products have been great and have saved ...      1  train\n",
              "3774                                                         1  train\n",
              "\n",
              "[3775 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YHwDzxpYPzb",
        "outputId": "0813bbe6-8318-4be2-fbcf-868833d5df8f"
      },
      "source": [
        "corpus.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3775 entries, 0 to 3774\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   sentence  3775 non-null   object\n",
            " 1   label     3775 non-null   int64 \n",
            " 2   split     3775 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 88.6+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "Dzi17sevYPzb",
        "outputId": "b78955b4-0d0f-4a62-ec20-1b9902d4a5ac"
      },
      "source": [
        "corpus.groupby( by='label').count()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1368</td>\n",
              "      <td>1368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2407</td>\n",
              "      <td>2407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       sentence  split\n",
              "label                 \n",
              "0          1368   1368\n",
              "1          2407   2407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnioByMAYPzc"
      },
      "source": [
        "# Separate the sentences and the labels\n",
        "sentences, labels = list(corpus.sentence), list(corpus.label)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "MwXfKjBZYPzd",
        "outputId": "4c9236c0-c6db-43bd-d8ec-4e3e1ca92703"
      },
      "source": [
        "sentences[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"weaknesses are minor the feel and layout of the remote control are only so so . it does n 't show the complete file names of mp3s with really long names . you must cycle through every zoom setting ( 2x , 3x , 4x , 1 2x , etc . ) before getting back to normal size sorry if i 'm just ignorant of a way to get back to 1x quickly .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLxjj-iYPzd"
      },
      "source": [
        "<!--## Split Dataset-->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NJog7pYmYPze"
      },
      "source": [
        "# Data Preprocessing\n",
        "<hr>\n",
        "\n",
        "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
        "\n",
        "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
        "In short, what we will do is:\n",
        "- Puntuations removal\n",
        "- Lower the letter case\n",
        "- Tokenization\n",
        "\n",
        "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
        "\n",
        "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4P9StZhkYPzf"
      },
      "source": [
        "# Define a function to compute the max length of sequence\n",
        "def max_length(sequences):\n",
        "    '''\n",
        "    input:\n",
        "        sequences: a 2D list of integer sequences\n",
        "    output:\n",
        "        max_length: the max length of the sequences\n",
        "    '''\n",
        "    max_length = 0\n",
        "    for i, seq in enumerate(sequences):\n",
        "        length = len(seq)\n",
        "        if max_length < length:\n",
        "            max_length = length\n",
        "    return max_length"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bOinS4qYPzf",
        "outputId": "599a48ad-19f8-4e32-98ab-1aeaf24f2bce"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "\n",
        "print(\"Example of sentence: \", sentences[4])\n",
        "\n",
        "# Cleaning and Tokenization\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Turn the text into sequence\n",
        "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
        "max_len = max_length(training_sequences)\n",
        "\n",
        "print('Into a sequence of int:', training_sequences[4])\n",
        "\n",
        "# Pad the sequence to have the same size\n",
        "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "print('Into a padded sequence:', training_padded[4])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Example of sentence:  will never purchase apex again .\n",
            "Into a sequence of int: [72, 194, 285, 207, 286]\n",
            "Into a padded sequence: [ 72 194 285 207 286   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVkf7xgwYPzg",
        "outputId": "4a569ae1-ca57-4eb0-ee0e-4f6c2ae83e5e"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "# See the first 10 words in the vocabulary\n",
        "for i, word in enumerate(word_index):\n",
        "    print(word, word_index.get(word))\n",
        "    if i==9:\n",
        "        break\n",
        "vocab_size = len(word_index)+1\n",
        "print(vocab_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<UNK> 1\n",
            "the 2\n",
            "and 3\n",
            "i 4\n",
            "it 5\n",
            "to 6\n",
            "a 7\n",
            "is 8\n",
            "of 9\n",
            "this 10\n",
            "5336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgM2ytQqYPzh"
      },
      "source": [
        "# Model 1: Embedding Random\n",
        "<hr>\n",
        "\n",
        "<img src=\"model.png\" style=\"width:700px;height:400px;\"> <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVam-lKUYPzh"
      },
      "source": [
        "## GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQ2GQWBRYPzi"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "def define_model(input_dim = None, output_dim=300, max_length = None ):\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
        "                                  mask_zero= True,\n",
        "                                  output_dim=output_dim, \n",
        "                                  input_length=max_length, \n",
        "                                  input_shape=(max_length, )),\n",
        "        \n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
        "        # tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "#     model.summary()\n",
        "    return model"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8g9fHVKYPzj",
        "outputId": "6821ba5f-cc61-4aa5-e7bf-c43eb7e378a2"
      },
      "source": [
        "model_0 = define_model( input_dim=1000, max_length=100)\n",
        "model_0.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_15 (Embedding)     (None, 100, 300)          300000    \n",
            "_________________________________________________________________\n",
            "bidirectional_30 (Bidirectio (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "bidirectional_31 (Bidirectio (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 515,169\n",
            "Trainable params: 515,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmbXpw1bYPzj"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Overide the method on_epoch_end() for our benefit\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') > 0.93):\n",
        "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=10, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbFpmDcxYPzk"
      },
      "source": [
        "## Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFQAIfevYPzk",
        "outputId": "d0e71b1a-6c8d-4d94-c313-3551330a6842"
      },
      "source": [
        "# Parameter Initialization\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "\n",
        "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
        "record = pd.DataFrame(columns = columns)\n",
        "\n",
        "# prepare cross validation with 10 splits and shuffle = True\n",
        "kfold = KFold(10, True)\n",
        "\n",
        "# Separate the sentences and the labels\n",
        "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
        "\n",
        "exp=0\n",
        "\n",
        "# kfold.split() will return set indices for each split\n",
        "acc_list = []\n",
        "for train, test in kfold.split(sentences):\n",
        "    \n",
        "    exp+=1\n",
        "    print('Training {}: '.format(exp))\n",
        "    \n",
        "    train_x, test_x = [], []\n",
        "    train_y, test_y = [], []\n",
        "\n",
        "    for i in train:\n",
        "        train_x.append(sentences[i])\n",
        "        train_y.append(labels[i])\n",
        "\n",
        "    for i in test:\n",
        "        test_x.append(sentences[i])\n",
        "        test_y.append(labels[i])\n",
        "\n",
        "    # Turn the labels into a numpy array\n",
        "    train_y = np.array(train_y)\n",
        "    test_y = np.array(test_y)\n",
        "\n",
        "    # encode data using\n",
        "    # Cleaning and Tokenization\n",
        "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "    # Turn the text into sequence\n",
        "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
        "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "    max_len = max_length(training_sequences)\n",
        "\n",
        "    # Pad the sequence to have the same size\n",
        "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    vocab_size = len(word_index)+1\n",
        "\n",
        "    # Define the input shape\n",
        "    model = define_model(input_dim=vocab_size, max_length=max_len)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(Xtrain, train_y, batch_size=32, epochs=30, verbose=1, \n",
        "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
        "\n",
        "    # evaluate the model\n",
        "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
        "    print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "    acc_list.append(acc*100)\n",
        "\n",
        "mean_acc = np.array(acc_list).mean()\n",
        "entries = acc_list + [mean_acc]\n",
        "\n",
        "temp = pd.DataFrame([entries], columns=columns)\n",
        "record = record.append(temp, ignore_index=True)\n",
        "print()\n",
        "print(record)\n",
        "print()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 25s 119ms/step - loss: 0.6104 - accuracy: 0.6610 - val_loss: 0.4242 - val_accuracy: 0.7937\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.2523 - accuracy: 0.8941 - val_loss: 0.4385 - val_accuracy: 0.8122\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.1002 - accuracy: 0.9640 - val_loss: 0.5779 - val_accuracy: 0.7989\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0501 - accuracy: 0.9837 - val_loss: 0.8091 - val_accuracy: 0.7989\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.8833 - val_accuracy: 0.7989\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0085 - accuracy: 0.9967 - val_loss: 1.0663 - val_accuracy: 0.7989\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 1.2112 - val_accuracy: 0.7910\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 1.3251 - val_accuracy: 0.8069\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0053 - accuracy: 0.9977 - val_loss: 1.1125 - val_accuracy: 0.8016\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 1.1999 - val_accuracy: 0.7804\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 9s 74ms/step - loss: 0.0316 - accuracy: 0.9886 - val_loss: 1.2541 - val_accuracy: 0.7698\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0130 - accuracy: 0.9947 - val_loss: 1.0335 - val_accuracy: 0.7963\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 81.21693134307861\n",
            "Training 2: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 24s 111ms/step - loss: 0.6111 - accuracy: 0.6674 - val_loss: 0.4002 - val_accuracy: 0.8069\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.2728 - accuracy: 0.8963 - val_loss: 0.4074 - val_accuracy: 0.8360\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.1267 - accuracy: 0.9565 - val_loss: 0.5913 - val_accuracy: 0.8042\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0490 - accuracy: 0.9853 - val_loss: 0.7626 - val_accuracy: 0.7831\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.8392 - val_accuracy: 0.8016\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0122 - accuracy: 0.9961 - val_loss: 1.0010 - val_accuracy: 0.7751\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0050 - accuracy: 0.9983 - val_loss: 1.0263 - val_accuracy: 0.7857\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.1267 - val_accuracy: 0.7884\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0025 - accuracy: 0.9980 - val_loss: 1.2265 - val_accuracy: 0.7804\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0015 - accuracy: 0.9989 - val_loss: 1.2875 - val_accuracy: 0.7910\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 9.8099e-04 - accuracy: 0.9996 - val_loss: 1.3366 - val_accuracy: 0.7884\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 7.1968e-04 - accuracy: 0.9994 - val_loss: 1.3771 - val_accuracy: 0.7884\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 83.59788656234741\n",
            "Training 3: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 28s 122ms/step - loss: 0.6005 - accuracy: 0.6692 - val_loss: 0.4315 - val_accuracy: 0.7910\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.2392 - accuracy: 0.9054 - val_loss: 0.4451 - val_accuracy: 0.7778\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.1186 - accuracy: 0.9584 - val_loss: 0.7333 - val_accuracy: 0.7857\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0453 - accuracy: 0.9838 - val_loss: 0.7527 - val_accuracy: 0.7778\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0293 - accuracy: 0.9900 - val_loss: 1.0180 - val_accuracy: 0.7672\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.9560 - val_accuracy: 0.7778\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 1.2343 - val_accuracy: 0.7646\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.0098 - accuracy: 0.9956 - val_loss: 1.4676 - val_accuracy: 0.7698\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0061 - accuracy: 0.9971 - val_loss: 1.4126 - val_accuracy: 0.7063\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 1.8770 - val_accuracy: 0.7698\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0148 - accuracy: 0.9947 - val_loss: 1.7061 - val_accuracy: 0.7407\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 79.10053133964539\n",
            "Training 4: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 23s 104ms/step - loss: 0.6110 - accuracy: 0.6525 - val_loss: 0.4580 - val_accuracy: 0.7725\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.2488 - accuracy: 0.9021 - val_loss: 0.4936 - val_accuracy: 0.7593\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 7s 66ms/step - loss: 0.1069 - accuracy: 0.9637 - val_loss: 0.6023 - val_accuracy: 0.7566\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0467 - accuracy: 0.9866 - val_loss: 0.8186 - val_accuracy: 0.7434\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0209 - accuracy: 0.9930 - val_loss: 1.2056 - val_accuracy: 0.7328\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0071 - accuracy: 0.9984 - val_loss: 1.4474 - val_accuracy: 0.7381\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0028 - accuracy: 0.9984 - val_loss: 1.5566 - val_accuracy: 0.7302\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 1.7822 - val_accuracy: 0.7354\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 1.9035 - val_accuracy: 0.7328\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0012 - accuracy: 0.9991 - val_loss: 2.0168 - val_accuracy: 0.7275\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 7s 67ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 2.1305 - val_accuracy: 0.7249\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 77.24867463111877\n",
            "Training 5: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 25s 120ms/step - loss: 0.6096 - accuracy: 0.6416 - val_loss: 0.4550 - val_accuracy: 0.7884\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.2415 - accuracy: 0.9052 - val_loss: 0.5981 - val_accuracy: 0.7646\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 8s 72ms/step - loss: 0.1016 - accuracy: 0.9639 - val_loss: 0.8185 - val_accuracy: 0.7566\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0423 - accuracy: 0.9825 - val_loss: 1.0868 - val_accuracy: 0.7275\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0186 - accuracy: 0.9931 - val_loss: 1.3258 - val_accuracy: 0.7566\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0116 - accuracy: 0.9944 - val_loss: 1.3868 - val_accuracy: 0.7487\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0036 - accuracy: 0.9985 - val_loss: 1.5688 - val_accuracy: 0.7460\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 1.6488 - val_accuracy: 0.7566\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0011 - accuracy: 0.9992 - val_loss: 1.7233 - val_accuracy: 0.7540\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 8.5226e-04 - accuracy: 0.9993 - val_loss: 1.7704 - val_accuracy: 0.7540\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.8198 - val_accuracy: 0.7513\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00011: early stopping\n",
            "Test Accuracy: 78.83597612380981\n",
            "Training 6: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 28s 120ms/step - loss: 0.6183 - accuracy: 0.6567 - val_loss: 0.3650 - val_accuracy: 0.8302\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.2872 - accuracy: 0.8839 - val_loss: 0.3509 - val_accuracy: 0.8382\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.1215 - accuracy: 0.9562 - val_loss: 0.4914 - val_accuracy: 0.8355\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0618 - accuracy: 0.9794 - val_loss: 0.6322 - val_accuracy: 0.8302\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0142 - accuracy: 0.9975 - val_loss: 0.8594 - val_accuracy: 0.8196\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0084 - accuracy: 0.9969 - val_loss: 0.8693 - val_accuracy: 0.8329\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.8925 - val_accuracy: 0.8276\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.0084 - accuracy: 0.9981 - val_loss: 0.9621 - val_accuracy: 0.8355\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0035 - accuracy: 0.9983 - val_loss: 0.9727 - val_accuracy: 0.8276\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0118 - accuracy: 0.9956 - val_loss: 0.9887 - val_accuracy: 0.8064\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0064 - accuracy: 0.9971 - val_loss: 1.0352 - val_accuracy: 0.8249\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.0047 - accuracy: 0.9973 - val_loss: 1.2565 - val_accuracy: 0.8355\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 83.81962776184082\n",
            "Training 7: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 25s 111ms/step - loss: 0.6055 - accuracy: 0.6746 - val_loss: 0.4627 - val_accuracy: 0.7745\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.2625 - accuracy: 0.8993 - val_loss: 0.5336 - val_accuracy: 0.7851\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.1115 - accuracy: 0.9629 - val_loss: 0.7530 - val_accuracy: 0.7772\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 9s 83ms/step - loss: 0.0395 - accuracy: 0.9876 - val_loss: 0.8883 - val_accuracy: 0.7772\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 8s 73ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 1.1954 - val_accuracy: 0.7719\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0106 - accuracy: 0.9965 - val_loss: 1.2301 - val_accuracy: 0.7586\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0191 - accuracy: 0.9929 - val_loss: 1.3409 - val_accuracy: 0.7507\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0133 - accuracy: 0.9953 - val_loss: 1.2675 - val_accuracy: 0.7772\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 8s 74ms/step - loss: 0.0082 - accuracy: 0.9963 - val_loss: 1.5145 - val_accuracy: 0.7719\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 1.3596 - val_accuracy: 0.7719\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0093 - accuracy: 0.9967 - val_loss: 1.7241 - val_accuracy: 0.7692\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 9s 74ms/step - loss: 0.0060 - accuracy: 0.9971 - val_loss: 1.6172 - val_accuracy: 0.7586\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 78.51458787918091\n",
            "Training 8: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 25s 118ms/step - loss: 0.6116 - accuracy: 0.6408 - val_loss: 0.4457 - val_accuracy: 0.7958\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.2624 - accuracy: 0.9029 - val_loss: 0.4770 - val_accuracy: 0.8011\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.1044 - accuracy: 0.9670 - val_loss: 0.7453 - val_accuracy: 0.7772\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 8s 65ms/step - loss: 0.0468 - accuracy: 0.9871 - val_loss: 0.9918 - val_accuracy: 0.7639\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0154 - accuracy: 0.9947 - val_loss: 1.3127 - val_accuracy: 0.7586\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 1.4740 - val_accuracy: 0.7639\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.4856 - val_accuracy: 0.7507\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0159 - accuracy: 0.9955 - val_loss: 1.6783 - val_accuracy: 0.7586\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0079 - accuracy: 0.9961 - val_loss: 1.5004 - val_accuracy: 0.7454\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 9s 82ms/step - loss: 0.0096 - accuracy: 0.9956 - val_loss: 1.7542 - val_accuracy: 0.7639\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0076 - accuracy: 0.9966 - val_loss: 1.8584 - val_accuracy: 0.7560\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 9s 81ms/step - loss: 0.0067 - accuracy: 0.9965 - val_loss: 1.8503 - val_accuracy: 0.7560\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 80.10610342025757\n",
            "Training 9: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 23s 104ms/step - loss: 0.6090 - accuracy: 0.6742 - val_loss: 0.4497 - val_accuracy: 0.7825\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.2513 - accuracy: 0.9018 - val_loss: 0.4776 - val_accuracy: 0.7905\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.1256 - accuracy: 0.9559 - val_loss: 0.7296 - val_accuracy: 0.7825\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.0496 - accuracy: 0.9820 - val_loss: 0.8031 - val_accuracy: 0.7692\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.0233 - accuracy: 0.9893 - val_loss: 1.0791 - val_accuracy: 0.7507\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 8s 76ms/step - loss: 0.0050 - accuracy: 0.9991 - val_loss: 1.4294 - val_accuracy: 0.7666\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 1.4389 - val_accuracy: 0.7560\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 8s 76ms/step - loss: 0.0121 - accuracy: 0.9968 - val_loss: 1.2557 - val_accuracy: 0.7772\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.0074 - accuracy: 0.9966 - val_loss: 1.2861 - val_accuracy: 0.7639\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 8s 76ms/step - loss: 0.0089 - accuracy: 0.9970 - val_loss: 1.2999 - val_accuracy: 0.7533\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 8s 67ms/step - loss: 0.0169 - accuracy: 0.9937 - val_loss: 1.3317 - val_accuracy: 0.7533\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 8s 75ms/step - loss: 0.0056 - accuracy: 0.9981 - val_loss: 1.3125 - val_accuracy: 0.7613\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 79.0450930595398\n",
            "Training 10: \n",
            "Epoch 1/30\n",
            "107/107 [==============================] - 23s 98ms/step - loss: 0.6189 - accuracy: 0.6563 - val_loss: 0.4928 - val_accuracy: 0.7692\n",
            "Epoch 2/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.2600 - accuracy: 0.9037 - val_loss: 0.4852 - val_accuracy: 0.7825\n",
            "Epoch 3/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.1139 - accuracy: 0.9653 - val_loss: 0.7302 - val_accuracy: 0.7639\n",
            "Epoch 4/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.0541 - accuracy: 0.9840 - val_loss: 0.8628 - val_accuracy: 0.7719\n",
            "Epoch 5/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.0186 - accuracy: 0.9942 - val_loss: 1.2690 - val_accuracy: 0.7692\n",
            "Epoch 6/30\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 1.2409 - val_accuracy: 0.7958\n",
            "Epoch 7/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.0114 - accuracy: 0.9962 - val_loss: 1.3289 - val_accuracy: 0.7560\n",
            "Epoch 8/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.0079 - accuracy: 0.9970 - val_loss: 1.5009 - val_accuracy: 0.7772\n",
            "Epoch 9/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 0.0040 - accuracy: 0.9985 - val_loss: 1.5300 - val_accuracy: 0.7798\n",
            "Epoch 10/30\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 1.6189 - val_accuracy: 0.7798\n",
            "Epoch 11/30\n",
            "107/107 [==============================] - 6s 52ms/step - loss: 0.0018 - accuracy: 0.9983 - val_loss: 1.6922 - val_accuracy: 0.7798\n",
            "Epoch 12/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 5.3921e-04 - accuracy: 0.9996 - val_loss: 1.7601 - val_accuracy: 0.7825\n",
            "Epoch 13/30\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 4.6011e-04 - accuracy: 0.9995 - val_loss: 1.8214 - val_accuracy: 0.7825\n",
            "Epoch 14/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 6.6879e-04 - accuracy: 0.9992 - val_loss: 1.8702 - val_accuracy: 0.7825\n",
            "Epoch 15/30\n",
            "107/107 [==============================] - 6s 61ms/step - loss: 3.0974e-04 - accuracy: 0.9998 - val_loss: 1.9159 - val_accuracy: 0.7825\n",
            "Epoch 16/30\n",
            "107/107 [==============================] - 6s 60ms/step - loss: 2.7687e-04 - accuracy: 0.9997 - val_loss: 1.9534 - val_accuracy: 0.7851\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00016: early stopping\n",
            "Test Accuracy: 79.57559823989868\n",
            "\n",
            "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
            "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
            "\n",
            "[1 rows x 11 columns]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHQDegZXYPzl"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "HpsR3FAyYPzn",
        "outputId": "a5df0068-38d4-4ff7-96e5-1cca35b7df7e"
      },
      "source": [
        "record"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>AVG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81.216931</td>\n",
              "      <td>83.597887</td>\n",
              "      <td>79.100531</td>\n",
              "      <td>77.248675</td>\n",
              "      <td>78.835976</td>\n",
              "      <td>83.819628</td>\n",
              "      <td>78.514588</td>\n",
              "      <td>80.106103</td>\n",
              "      <td>79.045093</td>\n",
              "      <td>79.575598</td>\n",
              "      <td>80.106101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
              "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "biTRtInbkwGz",
        "outputId": "bd8e73e5-90e6-4cc7-d5e1-c75a7254ab4e"
      },
      "source": [
        "# cols = ['acc1',\t'acc2',\t'acc3',\t'acc4',\t'acc5',\t'acc6',\t'acc7',\t'acc8',\t'acc9',\t'acc10',\t'AVG']\r\n",
        "# values = [81.216931,\t83.597887,\t79.100531,\t77.248675,\t78.835976,\t83.819628,\t78.514588,\t80.106103,\t79.045093, 79.575598,\t80.106101]\r\n",
        "# record = pd.DataFrame(data=[values] ,columns=cols)\r\n",
        "# record"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>AVG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>81.216931</td>\n",
              "      <td>83.597887</td>\n",
              "      <td>79.100531</td>\n",
              "      <td>77.248675</td>\n",
              "      <td>78.835976</td>\n",
              "      <td>83.819628</td>\n",
              "      <td>78.514588</td>\n",
              "      <td>80.106103</td>\n",
              "      <td>79.045093</td>\n",
              "      <td>79.575598</td>\n",
              "      <td>80.106101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
              "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URDmZ1QuYPzs"
      },
      "source": [
        "report = record\n",
        "report = report.to_excel('GRU_CR_v2.xlsx', sheet_name='random')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrRxBV9pYPzs"
      },
      "source": [
        "# Model 2: Word2Vec Static"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_RzjBnoYPzt"
      },
      "source": [
        "__Using and updating pre-trained embeddings__\n",
        "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
        "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2wFDPtkYPzt"
      },
      "source": [
        "1. __Load `Word2Vec` Pre-trained Word Embedding__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ls7_5Xm1YPzu"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Disertasi/WordEmbedding_Models/Word2Vec/GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMxwVkoBYPzu",
        "outputId": "0d0e93fb-35e7-4e4f-c486-87c7179566a4"
      },
      "source": [
        "# Access the dense vector value for the word 'handsome'\n",
        "# word2vec.word_vec('handsome') # 0.11376953\n",
        "word2vec.word_vec('cool') # 1.64062500e-01"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
              "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
              "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
              "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
              "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
              "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
              "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
              "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
              "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
              "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
              "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
              "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
              "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
              "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
              "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
              "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
              "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
              "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
              "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
              "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
              "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
              "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
              "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
              "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
              "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
              "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
              "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
              "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
              "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
              "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
              "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
              "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
              "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
              "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
              "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
              "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
              "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
              "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
              "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
              "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
              "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
              "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
              "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
              "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
              "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
              "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
              "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
              "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
              "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
              "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
              "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
              "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
              "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
              "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
              "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
              "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
              "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
              "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
              "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
              "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
              "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
              "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
              "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
              "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
              "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
              "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
              "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
              "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
              "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
              "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
              "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
              "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
              "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
              "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
              "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYNT-uSvYPzv"
      },
      "source": [
        "2. __Check number of training words present in Word2Vec__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EHN_hUEYPzv"
      },
      "source": [
        "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
        "    '''\n",
        "    input:\n",
        "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
        "        word_to_index: word to index mapping from training set\n",
        "    '''\n",
        "    \n",
        "    vocab_size = len(word_to_index) + 1\n",
        "    count = 0\n",
        "    # Set each row \"idx\" of the embedding matrix to be \n",
        "    # the word vector representation of the idx'th word of the vocabulary\n",
        "    for word, idx in word_to_index.items():\n",
        "        if word in word_to_vec_map:\n",
        "            count+=1\n",
        "            \n",
        "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnvUanAjYPzw",
        "outputId": "a0ed0efd-3989-4f69-ca6c-46271514bc97"
      },
      "source": [
        "# Separate the sentences and the labels\n",
        "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
        "\n",
        "# Cleaning and Tokenization\n",
        "tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "training_words_in_word2vector(word2vec, word_index)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5046 words present from 5336 training vocabulary in the set of pre-trained word vector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw9EUgADYPzw"
      },
      "source": [
        "2. __Define a `pretrained_embedding_layer` function__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiR9ukJfYPzw"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
        "    '''\n",
        "    input:\n",
        "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
        "        word_to_index: word to index mapping from training set\n",
        "    '''\n",
        "    \n",
        "    # adding 1 to fit Keras embedding (requirement)\n",
        "    vocab_size = len(word_to_index) + 1\n",
        "    # define dimensionality of your pre-trained word vectors (= 300)\n",
        "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
        "    \n",
        "    \n",
        "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
        "    \n",
        "    # Set each row \"idx\" of the embedding matrix to be \n",
        "    # the word vector representation of the idx'th word of the vocabulary\n",
        "    for word, idx in word_to_index.items():\n",
        "        if word in word_to_vec_map:\n",
        "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
        "            \n",
        "        # initialize the unknown word with standard normal distribution values\n",
        "        else:\n",
        "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
        "            \n",
        "    return embed_matrix"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0oP3TKkYPzx",
        "outputId": "d3af4420-b184-4836-b676-48d87cab3add"
      },
      "source": [
        "# Test the function\n",
        "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
        "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
        "em_matrix"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.83581778, -0.60709171,  2.11977743, ...,  1.38923623,\n",
              "        -1.07696715,  1.68967513],\n",
              "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
              "        -0.03930664,  0.20996094],\n",
              "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
              "        -0.01019287,  0.02075195],\n",
              "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
              "        -0.23144531,  0.04614258]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFuDpfbaYPzx"
      },
      "source": [
        "## GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJDgd66cYPzy"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "def define_model_2(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
        "                                  mask_zero= True,\n",
        "                                  output_dim=output_dim, \n",
        "                                  input_length=max_length, \n",
        "                                  input_shape=(max_length, ),\n",
        "                                  # Assign the embedding weight with word2vec embedding marix\n",
        "                                  weights = [emb_matrix],\n",
        "                                  # Set the weight to be not trainable (static)\n",
        "                                  trainable = False),\n",
        "        \n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
        "        # tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "#     model.summary()\n",
        "    return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4QEfU-gYPzy",
        "outputId": "65d56112-6a06-4933-a1b8-ebc1416701de"
      },
      "source": [
        "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
        "model_0.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 300)          300000    \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 515,169\n",
            "Trainable params: 215,169\n",
            "Non-trainable params: 300,000\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoPK6vPkYPzz"
      },
      "source": [
        "## Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHY1NNPRYPzz"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Overide the method on_epoch_end() for our benefit\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') >= 0.9):\n",
        "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=10, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNB2uep2YPz0",
        "outputId": "44350b2c-d565-4916-d8e4-491bdcecc3a4"
      },
      "source": [
        "# Parameter Initialization\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "\n",
        "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
        "record2 = pd.DataFrame(columns = columns)\n",
        "\n",
        "# prepare cross validation with 10 splits and shuffle = True\n",
        "kfold = KFold(10, True)\n",
        "\n",
        "# Separate the sentences and the labels\n",
        "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
        "\n",
        "exp=0\n",
        "\n",
        "# kfold.split() will return set indices for each split\n",
        "acc_list = []\n",
        "for train, test in kfold.split(sentences):\n",
        "    \n",
        "    exp+=1\n",
        "    print('Training {}: '.format(exp))\n",
        "    \n",
        "    train_x, test_x = [], []\n",
        "    train_y, test_y = [], []\n",
        "\n",
        "    for i in train:\n",
        "        train_x.append(sentences[i])\n",
        "        train_y.append(labels[i])\n",
        "\n",
        "    for i in test:\n",
        "        test_x.append(sentences[i])\n",
        "        test_y.append(labels[i])\n",
        "\n",
        "    # Turn the labels into a numpy array\n",
        "    train_y = np.array(train_y)\n",
        "    test_y = np.array(test_y)\n",
        "\n",
        "    # encode data using\n",
        "    # Cleaning and Tokenization\n",
        "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "    # Turn the text into sequence\n",
        "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
        "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "    max_len = max_length(training_sequences)\n",
        "\n",
        "    # Pad the sequence to have the same size\n",
        "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    vocab_size = len(word_index)+1\n",
        "    \n",
        "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
        "\n",
        "    # Define the input shape\n",
        "    model = define_model_2(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
        "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
        "\n",
        "    # evaluate the model\n",
        "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
        "    print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "    acc_list.append(acc*100)\n",
        "\n",
        "mean_acc = np.array(acc_list).mean()\n",
        "entries = acc_list + [mean_acc]\n",
        "\n",
        "temp = pd.DataFrame([entries], columns=columns)\n",
        "record2 = record2.append(temp, ignore_index=True)\n",
        "print()\n",
        "print(record2)\n",
        "print()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 50s 333ms/step - loss: 0.6302 - accuracy: 0.6514 - val_loss: 0.5194 - val_accuracy: 0.7328\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.4828 - accuracy: 0.7523 - val_loss: 0.5006 - val_accuracy: 0.7593\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.4044 - accuracy: 0.8202 - val_loss: 0.4658 - val_accuracy: 0.7831\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 29s 272ms/step - loss: 0.3419 - accuracy: 0.8546 - val_loss: 0.5158 - val_accuracy: 0.7487\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.3272 - accuracy: 0.8573 - val_loss: 0.4838 - val_accuracy: 0.7778\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 276ms/step - loss: 0.2710 - accuracy: 0.8763 - val_loss: 0.5323 - val_accuracy: 0.7937\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 29s 276ms/step - loss: 0.2541 - accuracy: 0.8915 - val_loss: 0.5788 - val_accuracy: 0.7593\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.2079 - accuracy: 0.9164 - val_loss: 0.6905 - val_accuracy: 0.7249\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.1720 - accuracy: 0.9370 - val_loss: 0.6215 - val_accuracy: 0.7619\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.1369 - accuracy: 0.9439 - val_loss: 0.6616 - val_accuracy: 0.7672\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 30s 276ms/step - loss: 0.1197 - accuracy: 0.9561 - val_loss: 0.8056 - val_accuracy: 0.7619\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 29s 275ms/step - loss: 0.0932 - accuracy: 0.9682 - val_loss: 0.9063 - val_accuracy: 0.7725\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 30s 276ms/step - loss: 0.0502 - accuracy: 0.9815 - val_loss: 0.9730 - val_accuracy: 0.7593\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 33s 308ms/step - loss: 0.0444 - accuracy: 0.9834 - val_loss: 1.1487 - val_accuracy: 0.7540\n",
            "Epoch 15/40\n",
            "107/107 [==============================] - 30s 277ms/step - loss: 0.0325 - accuracy: 0.9896 - val_loss: 1.0695 - val_accuracy: 0.7540\n",
            "Epoch 16/40\n",
            "107/107 [==============================] - 29s 276ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 1.0928 - val_accuracy: 0.7963\n",
            "Epoch 17/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.0389 - accuracy: 0.9864 - val_loss: 1.1590 - val_accuracy: 0.7593\n",
            "Epoch 18/40\n",
            "107/107 [==============================] - 29s 276ms/step - loss: 0.0865 - accuracy: 0.9717 - val_loss: 1.1108 - val_accuracy: 0.7566\n",
            "Epoch 19/40\n",
            "107/107 [==============================] - 29s 275ms/step - loss: 0.0113 - accuracy: 0.9974 - val_loss: 1.2986 - val_accuracy: 0.7513\n",
            "Epoch 20/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 1.2568 - val_accuracy: 0.7857\n",
            "Epoch 21/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 1.2904 - val_accuracy: 0.7937\n",
            "Epoch 22/40\n",
            "107/107 [==============================] - 33s 309ms/step - loss: 0.0044 - accuracy: 0.9982 - val_loss: 1.3870 - val_accuracy: 0.7646\n",
            "Epoch 23/40\n",
            "107/107 [==============================] - 29s 272ms/step - loss: 0.0054 - accuracy: 0.9981 - val_loss: 1.3574 - val_accuracy: 0.7672\n",
            "Epoch 24/40\n",
            "107/107 [==============================] - 30s 276ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 1.4429 - val_accuracy: 0.7566\n",
            "Epoch 25/40\n",
            "107/107 [==============================] - 29s 272ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.5142 - val_accuracy: 0.7407\n",
            "Epoch 26/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.0025 - accuracy: 0.9988 - val_loss: 1.5420 - val_accuracy: 0.7434\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00026: early stopping\n",
            "Test Accuracy: 79.62962985038757\n",
            "Training 2: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 41s 259ms/step - loss: 0.6319 - accuracy: 0.6383 - val_loss: 0.5354 - val_accuracy: 0.7275\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 23s 217ms/step - loss: 0.4289 - accuracy: 0.7870 - val_loss: 0.5972 - val_accuracy: 0.7751\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 23s 214ms/step - loss: 0.3857 - accuracy: 0.8209 - val_loss: 0.5367 - val_accuracy: 0.7910\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 23s 215ms/step - loss: 0.3556 - accuracy: 0.8408 - val_loss: 0.5097 - val_accuracy: 0.8016\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 23s 217ms/step - loss: 0.3289 - accuracy: 0.8476 - val_loss: 0.4997 - val_accuracy: 0.8095\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 23s 218ms/step - loss: 0.2866 - accuracy: 0.8761 - val_loss: 0.5020 - val_accuracy: 0.7937\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 23s 217ms/step - loss: 0.2479 - accuracy: 0.8920 - val_loss: 0.5410 - val_accuracy: 0.8095\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 23s 217ms/step - loss: 0.2138 - accuracy: 0.9088 - val_loss: 0.6254 - val_accuracy: 0.7937\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 24s 225ms/step - loss: 0.1800 - accuracy: 0.9277 - val_loss: 0.7379 - val_accuracy: 0.7989\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 26s 243ms/step - loss: 0.1318 - accuracy: 0.9474 - val_loss: 0.7413 - val_accuracy: 0.8095\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 23s 219ms/step - loss: 0.1390 - accuracy: 0.9503 - val_loss: 0.8112 - val_accuracy: 0.7963\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 23s 218ms/step - loss: 0.0839 - accuracy: 0.9673 - val_loss: 0.8856 - val_accuracy: 0.8016\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 23s 219ms/step - loss: 0.0568 - accuracy: 0.9825 - val_loss: 1.1398 - val_accuracy: 0.8095\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 23s 216ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 1.0622 - val_accuracy: 0.7989\n",
            "Epoch 15/40\n",
            "107/107 [==============================] - 23s 215ms/step - loss: 0.0416 - accuracy: 0.9857 - val_loss: 1.2275 - val_accuracy: 0.7989\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n",
            "Test Accuracy: 80.95238208770752\n",
            "Training 3: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 47s 312ms/step - loss: 0.6274 - accuracy: 0.6229 - val_loss: 0.4896 - val_accuracy: 0.7593\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 29s 268ms/step - loss: 0.4473 - accuracy: 0.7851 - val_loss: 0.4661 - val_accuracy: 0.7751\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 29s 271ms/step - loss: 0.3781 - accuracy: 0.8238 - val_loss: 0.5175 - val_accuracy: 0.7434\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 29s 271ms/step - loss: 0.3388 - accuracy: 0.8500 - val_loss: 0.6211 - val_accuracy: 0.6984\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 29s 270ms/step - loss: 0.3204 - accuracy: 0.8571 - val_loss: 0.5644 - val_accuracy: 0.7434\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.2674 - accuracy: 0.8870 - val_loss: 0.6218 - val_accuracy: 0.7540\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 29s 272ms/step - loss: 0.2242 - accuracy: 0.9120 - val_loss: 0.7163 - val_accuracy: 0.7196\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.2062 - accuracy: 0.9142 - val_loss: 0.7619 - val_accuracy: 0.7407\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 29s 272ms/step - loss: 0.1761 - accuracy: 0.9300 - val_loss: 1.1365 - val_accuracy: 0.6931\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 29s 272ms/step - loss: 0.1693 - accuracy: 0.9338 - val_loss: 0.9395 - val_accuracy: 0.7328\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.1149 - accuracy: 0.9503 - val_loss: 1.1705 - val_accuracy: 0.7143\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.0666 - accuracy: 0.9774 - val_loss: 1.1670 - val_accuracy: 0.7116\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 77.51322984695435\n",
            "Training 4: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 53s 331ms/step - loss: 0.6125 - accuracy: 0.6665 - val_loss: 0.5214 - val_accuracy: 0.7460\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 29s 275ms/step - loss: 0.4672 - accuracy: 0.7776 - val_loss: 0.5687 - val_accuracy: 0.7619\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 34s 317ms/step - loss: 0.3901 - accuracy: 0.8190 - val_loss: 0.6400 - val_accuracy: 0.7513\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 30s 285ms/step - loss: 0.3616 - accuracy: 0.8335 - val_loss: 0.8257 - val_accuracy: 0.7566\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.3172 - accuracy: 0.8567 - val_loss: 0.9297 - val_accuracy: 0.7328\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.2808 - accuracy: 0.8835 - val_loss: 0.7888 - val_accuracy: 0.7169\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.2592 - accuracy: 0.8947 - val_loss: 1.3273 - val_accuracy: 0.7169\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 30s 277ms/step - loss: 0.2182 - accuracy: 0.9081 - val_loss: 1.2610 - val_accuracy: 0.7302\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.1861 - accuracy: 0.9247 - val_loss: 1.6000 - val_accuracy: 0.7302\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.1887 - accuracy: 0.9188 - val_loss: 1.4045 - val_accuracy: 0.7143\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 32s 300ms/step - loss: 0.1099 - accuracy: 0.9570 - val_loss: 1.7006 - val_accuracy: 0.7196\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.0910 - accuracy: 0.9669 - val_loss: 1.9163 - val_accuracy: 0.7090\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 76.1904776096344\n",
            "Training 5: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 47s 320ms/step - loss: 0.6233 - accuracy: 0.6304 - val_loss: 0.6024 - val_accuracy: 0.7116\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.4455 - accuracy: 0.7945 - val_loss: 0.5547 - val_accuracy: 0.7487\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.3820 - accuracy: 0.8384 - val_loss: 0.6049 - val_accuracy: 0.7540\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 30s 277ms/step - loss: 0.3543 - accuracy: 0.8381 - val_loss: 0.5915 - val_accuracy: 0.7407\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.3074 - accuracy: 0.8597 - val_loss: 0.6611 - val_accuracy: 0.7407\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 277ms/step - loss: 0.2841 - accuracy: 0.8749 - val_loss: 0.7841 - val_accuracy: 0.7460\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 30s 276ms/step - loss: 0.2626 - accuracy: 0.8901 - val_loss: 0.8423 - val_accuracy: 0.7460\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.1887 - accuracy: 0.9274 - val_loss: 0.8646 - val_accuracy: 0.7407\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.1867 - accuracy: 0.9259 - val_loss: 0.8654 - val_accuracy: 0.7672\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.1429 - accuracy: 0.9430 - val_loss: 0.9798 - val_accuracy: 0.7646\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.1160 - accuracy: 0.9600 - val_loss: 1.0815 - val_accuracy: 0.7593\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.1040 - accuracy: 0.9583 - val_loss: 1.2864 - val_accuracy: 0.7540\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0608 - accuracy: 0.9791 - val_loss: 1.8365 - val_accuracy: 0.7222\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.0594 - accuracy: 0.9753 - val_loss: 1.5108 - val_accuracy: 0.7407\n",
            "Epoch 15/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.0517 - accuracy: 0.9797 - val_loss: 1.5658 - val_accuracy: 0.7434\n",
            "Epoch 16/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.0277 - accuracy: 0.9911 - val_loss: 1.6245 - val_accuracy: 0.7566\n",
            "Epoch 17/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.0230 - accuracy: 0.9919 - val_loss: 1.7189 - val_accuracy: 0.7646\n",
            "Epoch 18/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0072 - accuracy: 0.9990 - val_loss: 1.8243 - val_accuracy: 0.7566\n",
            "Epoch 19/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 1.9445 - val_accuracy: 0.7434\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00019: early stopping\n",
            "Test Accuracy: 76.71957612037659\n",
            "Training 6: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 47s 318ms/step - loss: 0.6129 - accuracy: 0.6668 - val_loss: 0.5287 - val_accuracy: 0.7188\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 30s 277ms/step - loss: 0.4517 - accuracy: 0.7919 - val_loss: 0.5158 - val_accuracy: 0.7560\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 29s 273ms/step - loss: 0.4022 - accuracy: 0.8091 - val_loss: 0.5079 - val_accuracy: 0.7613\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.3599 - accuracy: 0.8389 - val_loss: 0.5795 - val_accuracy: 0.7533\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.3296 - accuracy: 0.8555 - val_loss: 0.5590 - val_accuracy: 0.7507\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.2889 - accuracy: 0.8734 - val_loss: 0.6701 - val_accuracy: 0.7427\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.2568 - accuracy: 0.8883 - val_loss: 0.6948 - val_accuracy: 0.7586\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 29s 275ms/step - loss: 0.2149 - accuracy: 0.9091 - val_loss: 0.9052 - val_accuracy: 0.7533\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 277ms/step - loss: 0.1888 - accuracy: 0.9258 - val_loss: 1.0989 - val_accuracy: 0.7374\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.1429 - accuracy: 0.9472 - val_loss: 1.0902 - val_accuracy: 0.7586\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 29s 275ms/step - loss: 0.1182 - accuracy: 0.9582 - val_loss: 1.3039 - val_accuracy: 0.7454\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 29s 274ms/step - loss: 0.0854 - accuracy: 0.9659 - val_loss: 1.2578 - val_accuracy: 0.7294\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 29s 275ms/step - loss: 0.0602 - accuracy: 0.9815 - val_loss: 1.6569 - val_accuracy: 0.7321\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n",
            "Test Accuracy: 76.1273205280304\n",
            "Training 7: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 48s 319ms/step - loss: 0.6284 - accuracy: 0.6291 - val_loss: 0.4548 - val_accuracy: 0.8011\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.4536 - accuracy: 0.7877 - val_loss: 0.4361 - val_accuracy: 0.8064\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.3843 - accuracy: 0.8328 - val_loss: 0.4175 - val_accuracy: 0.8011\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.3548 - accuracy: 0.8411 - val_loss: 0.4078 - val_accuracy: 0.8329\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 30s 278ms/step - loss: 0.3197 - accuracy: 0.8556 - val_loss: 0.4247 - val_accuracy: 0.8170\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.2892 - accuracy: 0.8769 - val_loss: 0.4387 - val_accuracy: 0.8143\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.2754 - accuracy: 0.8821 - val_loss: 0.4578 - val_accuracy: 0.7931\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.2243 - accuracy: 0.9119 - val_loss: 0.4706 - val_accuracy: 0.8011\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.1953 - accuracy: 0.9182 - val_loss: 0.4970 - val_accuracy: 0.8037\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 30s 278ms/step - loss: 0.1386 - accuracy: 0.9480 - val_loss: 0.6224 - val_accuracy: 0.8037\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.1088 - accuracy: 0.9561 - val_loss: 0.5698 - val_accuracy: 0.8117\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 30s 279ms/step - loss: 0.0819 - accuracy: 0.9723 - val_loss: 0.7125 - val_accuracy: 0.8011\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 31s 290ms/step - loss: 0.0720 - accuracy: 0.9734 - val_loss: 0.7692 - val_accuracy: 0.7931\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 30s 278ms/step - loss: 0.0414 - accuracy: 0.9885 - val_loss: 1.0896 - val_accuracy: 0.7905\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "Test Accuracy: 83.28912258148193\n",
            "Training 8: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 47s 319ms/step - loss: 0.6260 - accuracy: 0.6382 - val_loss: 0.5987 - val_accuracy: 0.6870\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 30s 278ms/step - loss: 0.4428 - accuracy: 0.7893 - val_loss: 0.6543 - val_accuracy: 0.7029\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.3959 - accuracy: 0.8115 - val_loss: 0.6223 - val_accuracy: 0.7294\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.3400 - accuracy: 0.8564 - val_loss: 0.5858 - val_accuracy: 0.7347\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.3202 - accuracy: 0.8685 - val_loss: 0.7420 - val_accuracy: 0.6923\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.2792 - accuracy: 0.8787 - val_loss: 0.6843 - val_accuracy: 0.7560\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 30s 285ms/step - loss: 0.2448 - accuracy: 0.8890 - val_loss: 0.6931 - val_accuracy: 0.7454\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.2394 - accuracy: 0.8962 - val_loss: 0.7826 - val_accuracy: 0.7613\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.1760 - accuracy: 0.9285 - val_loss: 0.9755 - val_accuracy: 0.7294\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.1409 - accuracy: 0.9428 - val_loss: 1.1437 - val_accuracy: 0.7374\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.1300 - accuracy: 0.9467 - val_loss: 1.1170 - val_accuracy: 0.7427\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0817 - accuracy: 0.9668 - val_loss: 1.3454 - val_accuracy: 0.7347\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0431 - accuracy: 0.9895 - val_loss: 1.2051 - val_accuracy: 0.7454\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 30s 280ms/step - loss: 0.0836 - accuracy: 0.9714 - val_loss: 1.1339 - val_accuracy: 0.7692\n",
            "Epoch 15/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.0512 - accuracy: 0.9789 - val_loss: 1.3715 - val_accuracy: 0.7692\n",
            "Epoch 16/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 1.5816 - val_accuracy: 0.7427\n",
            "Epoch 17/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.0139 - accuracy: 0.9975 - val_loss: 1.6213 - val_accuracy: 0.7586\n",
            "Epoch 18/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.0104 - accuracy: 0.9979 - val_loss: 1.8456 - val_accuracy: 0.7427\n",
            "Epoch 19/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.0087 - accuracy: 0.9975 - val_loss: 1.9676 - val_accuracy: 0.7533\n",
            "Epoch 20/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.0339 - accuracy: 0.9854 - val_loss: 1.8702 - val_accuracy: 0.7294\n",
            "Epoch 21/40\n",
            "107/107 [==============================] - 30s 284ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 1.9192 - val_accuracy: 0.7533\n",
            "Epoch 22/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.0356 - accuracy: 0.9851 - val_loss: 1.9104 - val_accuracy: 0.7507\n",
            "Epoch 23/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.0109 - accuracy: 0.9967 - val_loss: 1.9403 - val_accuracy: 0.7480\n",
            "Epoch 24/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.0080 - accuracy: 0.9967 - val_loss: 2.1613 - val_accuracy: 0.7613\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00024: early stopping\n",
            "Test Accuracy: 76.92307829856873\n",
            "Training 9: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 51s 354ms/step - loss: 0.6286 - accuracy: 0.6528 - val_loss: 0.5367 - val_accuracy: 0.6950\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.4638 - accuracy: 0.7697 - val_loss: 0.4804 - val_accuracy: 0.7613\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 31s 287ms/step - loss: 0.4011 - accuracy: 0.8100 - val_loss: 0.4688 - val_accuracy: 0.7692\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.3423 - accuracy: 0.8598 - val_loss: 0.4343 - val_accuracy: 0.8037\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.3238 - accuracy: 0.8629 - val_loss: 0.4359 - val_accuracy: 0.7984\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.3004 - accuracy: 0.8650 - val_loss: 0.5014 - val_accuracy: 0.7639\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 30s 285ms/step - loss: 0.2520 - accuracy: 0.8923 - val_loss: 0.4906 - val_accuracy: 0.7825\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.2204 - accuracy: 0.9090 - val_loss: 0.5266 - val_accuracy: 0.7719\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.1810 - accuracy: 0.9296 - val_loss: 0.5383 - val_accuracy: 0.7798\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 30s 281ms/step - loss: 0.1562 - accuracy: 0.9412 - val_loss: 0.5811 - val_accuracy: 0.7745\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 30s 282ms/step - loss: 0.1268 - accuracy: 0.9510 - val_loss: 0.5973 - val_accuracy: 0.7825\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 30s 285ms/step - loss: 0.0878 - accuracy: 0.9691 - val_loss: 0.6678 - val_accuracy: 0.7825\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 32s 296ms/step - loss: 0.0573 - accuracy: 0.9820 - val_loss: 0.7143 - val_accuracy: 0.7825\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 30s 284ms/step - loss: 0.0470 - accuracy: 0.9885 - val_loss: 0.9085 - val_accuracy: 0.7825\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "Test Accuracy: 80.37135004997253\n",
            "Training 10: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 48s 322ms/step - loss: 0.6224 - accuracy: 0.6556 - val_loss: 0.5078 - val_accuracy: 0.7480\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 30s 284ms/step - loss: 0.4505 - accuracy: 0.7765 - val_loss: 0.4430 - val_accuracy: 0.7958\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.3845 - accuracy: 0.8348 - val_loss: 0.4497 - val_accuracy: 0.7825\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 31s 285ms/step - loss: 0.3593 - accuracy: 0.8399 - val_loss: 0.4457 - val_accuracy: 0.7905\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 31s 286ms/step - loss: 0.3065 - accuracy: 0.8647 - val_loss: 0.4583 - val_accuracy: 0.7878\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.2754 - accuracy: 0.8804 - val_loss: 0.4646 - val_accuracy: 0.7798\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 30s 284ms/step - loss: 0.2440 - accuracy: 0.8948 - val_loss: 0.4720 - val_accuracy: 0.7905\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.2099 - accuracy: 0.9105 - val_loss: 0.4658 - val_accuracy: 0.7905\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 30s 285ms/step - loss: 0.1697 - accuracy: 0.9376 - val_loss: 0.5252 - val_accuracy: 0.7905\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.1375 - accuracy: 0.9497 - val_loss: 0.5939 - val_accuracy: 0.7825\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 30s 283ms/step - loss: 0.1031 - accuracy: 0.9633 - val_loss: 0.6987 - val_accuracy: 0.7878\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 30s 284ms/step - loss: 0.1156 - accuracy: 0.9587 - val_loss: 0.7510 - val_accuracy: 0.7825\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 79.57559823989868\n",
            "\n",
            "       acc1       acc2      acc3  ...      acc9      acc10        AVG\n",
            "0  79.62963  80.952382  77.51323  ...  80.37135  79.575598  78.729177\n",
            "\n",
            "[1 rows x 11 columns]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eU1CKA71YPz0"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "V0nl-0oFYPz1",
        "outputId": "ddeb34c1-8a20-4245-aed5-49b42d2a6416"
      },
      "source": [
        "record2"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>AVG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>79.62963</td>\n",
              "      <td>80.952382</td>\n",
              "      <td>77.51323</td>\n",
              "      <td>76.190478</td>\n",
              "      <td>76.719576</td>\n",
              "      <td>76.127321</td>\n",
              "      <td>83.289123</td>\n",
              "      <td>76.923078</td>\n",
              "      <td>80.37135</td>\n",
              "      <td>79.575598</td>\n",
              "      <td>78.729177</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       acc1       acc2      acc3  ...      acc9      acc10        AVG\n",
              "0  79.62963  80.952382  77.51323  ...  80.37135  79.575598  78.729177\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJKVliAAYPz2"
      },
      "source": [
        "report = record2\n",
        "report = report.to_excel('GRU_CR_v2_2.xlsx', sheet_name='static')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLeoO2GIYPz2"
      },
      "source": [
        "# Model 3: Word2Vec - Dynamic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YO3OHNuYPz3"
      },
      "source": [
        "* In this part,  we will fine tune the embeddings while training (dynamic)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvYHnxUlYPz3"
      },
      "source": [
        "## GRU Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lx9ISs2YPz3"
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.constraints import MaxNorm\n",
        "\n",
        "def define_model_3(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
        "    \n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
        "                                  mask_zero= True,\n",
        "                                  output_dim=output_dim, \n",
        "                                  input_length=max_length, \n",
        "                                  input_shape=(max_length, ),\n",
        "                                  # Assign the embedding weight with word2vec embedding marix\n",
        "                                  weights = [emb_matrix],\n",
        "                                  # Set the weight to be not trainable (static)\n",
        "                                  trainable = True),\n",
        "        \n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
        "        # tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.5),\n",
        "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
        "    ])\n",
        "    \n",
        "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "#     model.summary()\n",
        "    return model"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5707NV6EYPz4",
        "outputId": "516babc0-14d4-4a5a-f4da-48c841d23860"
      },
      "source": [
        "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
        "model_0.summary()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_12 (Embedding)     (None, 100, 300)          300000    \n",
            "_________________________________________________________________\n",
            "bidirectional_24 (Bidirectio (None, 100, 128)          140544    \n",
            "_________________________________________________________________\n",
            "bidirectional_25 (Bidirectio (None, 128)               74496     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 515,169\n",
            "Trainable params: 515,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0hmpKMBYPz4"
      },
      "source": [
        "## Train and Test the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbebTECUYPz5"
      },
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "    # Overide the method on_epoch_end() for our benefit\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        if (logs.get('accuracy') > 0.93):\n",
        "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
        "            self.model.stop_training=True\n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
        "                                             patience=10, verbose=2, \n",
        "                                             mode='auto', restore_best_weights=True)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9fvfyaMYPz5",
        "outputId": "8f53ef1c-c42b-4ded-da89-8426fcbe1efc"
      },
      "source": [
        "# Parameter Initialization\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "oov_tok = \"<UNK>\"\n",
        "\n",
        "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
        "record3 = pd.DataFrame(columns = columns)\n",
        "\n",
        "# prepare cross validation with 10 splits and shuffle = True\n",
        "kfold = KFold(10, True)\n",
        "\n",
        "# Separate the sentences and the labels\n",
        "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
        "\n",
        "exp=0\n",
        "\n",
        "# kfold.split() will return set indices for each split\n",
        "acc_list = []\n",
        "for train, test in kfold.split(sentences):\n",
        "    \n",
        "    exp+=1\n",
        "    print('Training {}: '.format(exp))\n",
        "    \n",
        "    train_x, test_x = [], []\n",
        "    train_y, test_y = [], []\n",
        "\n",
        "    for i in train:\n",
        "        train_x.append(sentences[i])\n",
        "        train_y.append(labels[i])\n",
        "\n",
        "    for i in test:\n",
        "        test_x.append(sentences[i])\n",
        "        test_y.append(labels[i])\n",
        "\n",
        "    # Turn the labels into a numpy array\n",
        "    train_y = np.array(train_y)\n",
        "    test_y = np.array(test_y)\n",
        "\n",
        "    # encode data using\n",
        "    # Cleaning and Tokenization\n",
        "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
        "    tokenizer.fit_on_texts(train_x)\n",
        "\n",
        "    # Turn the text into sequence\n",
        "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
        "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
        "\n",
        "    max_len = max_length(training_sequences)\n",
        "\n",
        "    # Pad the sequence to have the same size\n",
        "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
        "\n",
        "    word_index = tokenizer.word_index\n",
        "    vocab_size = len(word_index)+1\n",
        "    \n",
        "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
        "\n",
        "    # Define the input shape\n",
        "    model = define_model_3(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
        "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
        "\n",
        "    # evaluate the model\n",
        "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
        "    print('Test Accuracy: {}'.format(acc*100))\n",
        "\n",
        "    acc_list.append(acc*100)\n",
        "\n",
        "mean_acc = np.array(acc_list).mean()\n",
        "entries = acc_list + [mean_acc]\n",
        "\n",
        "temp = pd.DataFrame([entries], columns=columns)\n",
        "record3 = record3.append(temp, ignore_index=True)\n",
        "print()\n",
        "print(record)\n",
        "print()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training 1: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 54s 380ms/step - loss: 0.6028 - accuracy: 0.6536 - val_loss: 0.5426 - val_accuracy: 0.7381\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.2958 - accuracy: 0.8826 - val_loss: 0.5824 - val_accuracy: 0.7566\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.1913 - accuracy: 0.9258 - val_loss: 0.5866 - val_accuracy: 0.7619\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.1022 - accuracy: 0.9700 - val_loss: 0.8004 - val_accuracy: 0.7804\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0461 - accuracy: 0.9857 - val_loss: 0.8545 - val_accuracy: 0.7566\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 1.1454 - val_accuracy: 0.7328\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0106 - accuracy: 0.9970 - val_loss: 1.4365 - val_accuracy: 0.7434\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0036 - accuracy: 0.9995 - val_loss: 1.6219 - val_accuracy: 0.7513\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 1.4246 - val_accuracy: 0.7328\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 334ms/step - loss: 0.0404 - accuracy: 0.9847 - val_loss: 1.2613 - val_accuracy: 0.7672\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 1.4904 - val_accuracy: 0.7434\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0043 - accuracy: 0.9981 - val_loss: 1.4435 - val_accuracy: 0.7540\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.5572 - val_accuracy: 0.7487\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 5.2552e-04 - accuracy: 0.9999 - val_loss: 1.6309 - val_accuracy: 0.7487\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00014: early stopping\n",
            "Test Accuracy: 78.04232835769653\n",
            "Training 2: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 59s 376ms/step - loss: 0.6045 - accuracy: 0.6632 - val_loss: 0.4451 - val_accuracy: 0.7804\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.3199 - accuracy: 0.8620 - val_loss: 0.4062 - val_accuracy: 0.8228\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 35s 331ms/step - loss: 0.1822 - accuracy: 0.9272 - val_loss: 0.5272 - val_accuracy: 0.8042\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 334ms/step - loss: 0.1070 - accuracy: 0.9609 - val_loss: 0.5766 - val_accuracy: 0.8095\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0462 - accuracy: 0.9839 - val_loss: 0.6642 - val_accuracy: 0.7910\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 334ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.8253 - val_accuracy: 0.8042\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.9321 - val_accuracy: 0.7989\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0065 - accuracy: 0.9979 - val_loss: 1.0229 - val_accuracy: 0.7963\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0232 - accuracy: 0.9907 - val_loss: 1.1101 - val_accuracy: 0.8042\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0106 - accuracy: 0.9953 - val_loss: 1.2909 - val_accuracy: 0.7884\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 334ms/step - loss: 0.0126 - accuracy: 0.9953 - val_loss: 1.0009 - val_accuracy: 0.8069\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0238 - accuracy: 0.9923 - val_loss: 1.1486 - val_accuracy: 0.7672\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 82.27513432502747\n",
            "Training 3: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 53s 377ms/step - loss: 0.6127 - accuracy: 0.6590 - val_loss: 0.4136 - val_accuracy: 0.7804\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 333ms/step - loss: 0.3080 - accuracy: 0.8690 - val_loss: 0.3891 - val_accuracy: 0.8148\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 334ms/step - loss: 0.2018 - accuracy: 0.9186 - val_loss: 0.4238 - val_accuracy: 0.8122\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.1022 - accuracy: 0.9666 - val_loss: 0.5115 - val_accuracy: 0.7937\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.0367 - accuracy: 0.9885 - val_loss: 0.7400 - val_accuracy: 0.7937\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0260 - accuracy: 0.9910 - val_loss: 0.8744 - val_accuracy: 0.7963\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0172 - accuracy: 0.9913 - val_loss: 0.9173 - val_accuracy: 0.8095\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0086 - accuracy: 0.9968 - val_loss: 0.9455 - val_accuracy: 0.7937\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0052 - accuracy: 0.9979 - val_loss: 1.0594 - val_accuracy: 0.7884\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0022 - accuracy: 0.9999 - val_loss: 1.2273 - val_accuracy: 0.8042\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 1.3241 - val_accuracy: 0.7989\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0012 - accuracy: 0.9990 - val_loss: 1.3725 - val_accuracy: 0.8016\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 81.4814805984497\n",
            "Training 4: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 57s 411ms/step - loss: 0.6203 - accuracy: 0.6431 - val_loss: 0.4338 - val_accuracy: 0.7884\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.3243 - accuracy: 0.8519 - val_loss: 0.4208 - val_accuracy: 0.8042\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 341ms/step - loss: 0.1771 - accuracy: 0.9336 - val_loss: 0.4824 - val_accuracy: 0.8175\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.0892 - accuracy: 0.9715 - val_loss: 0.6574 - val_accuracy: 0.8016\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 341ms/step - loss: 0.0441 - accuracy: 0.9860 - val_loss: 0.7590 - val_accuracy: 0.7989\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0207 - accuracy: 0.9931 - val_loss: 0.9669 - val_accuracy: 0.7963\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 1.1450 - val_accuracy: 0.8016\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0033 - accuracy: 0.9987 - val_loss: 1.2577 - val_accuracy: 0.7910\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 1.3373 - val_accuracy: 0.7857\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 37s 344ms/step - loss: 0.0015 - accuracy: 0.9987 - val_loss: 1.4361 - val_accuracy: 0.7937\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 37s 341ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 1.5050 - val_accuracy: 0.7910\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 1.5420 - val_accuracy: 0.7831\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 37s 341ms/step - loss: 0.0014 - accuracy: 0.9991 - val_loss: 1.5873 - val_accuracy: 0.7804\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n",
            "Test Accuracy: 81.7460298538208\n",
            "Training 5: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 54s 386ms/step - loss: 0.6019 - accuracy: 0.6778 - val_loss: 0.4099 - val_accuracy: 0.8201\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 332ms/step - loss: 0.3466 - accuracy: 0.8464 - val_loss: 0.3612 - val_accuracy: 0.8307\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.1800 - accuracy: 0.9332 - val_loss: 0.4292 - val_accuracy: 0.8280\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0902 - accuracy: 0.9701 - val_loss: 0.6073 - val_accuracy: 0.7989\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0458 - accuracy: 0.9815 - val_loss: 0.7471 - val_accuracy: 0.8042\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0257 - accuracy: 0.9939 - val_loss: 0.8500 - val_accuracy: 0.8095\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0081 - accuracy: 0.9960 - val_loss: 1.0185 - val_accuracy: 0.7937\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0082 - accuracy: 0.9951 - val_loss: 1.0685 - val_accuracy: 0.7989\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0019 - accuracy: 0.9991 - val_loss: 1.2124 - val_accuracy: 0.7937\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0026 - accuracy: 0.9977 - val_loss: 1.2729 - val_accuracy: 0.7937\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0018 - accuracy: 0.9991 - val_loss: 1.3354 - val_accuracy: 0.7963\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 7.1690e-04 - accuracy: 0.9998 - val_loss: 1.4084 - val_accuracy: 0.7937\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 83.06878209114075\n",
            "Training 6: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 54s 385ms/step - loss: 0.6120 - accuracy: 0.6634 - val_loss: 0.4550 - val_accuracy: 0.7798\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.3231 - accuracy: 0.8635 - val_loss: 0.4145 - val_accuracy: 0.8117\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.2016 - accuracy: 0.9155 - val_loss: 0.4683 - val_accuracy: 0.8011\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0966 - accuracy: 0.9634 - val_loss: 0.6290 - val_accuracy: 0.8090\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0432 - accuracy: 0.9868 - val_loss: 0.7934 - val_accuracy: 0.8090\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0338 - accuracy: 0.9889 - val_loss: 1.0741 - val_accuracy: 0.8090\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0165 - accuracy: 0.9937 - val_loss: 1.1962 - val_accuracy: 0.7745\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0116 - accuracy: 0.9942 - val_loss: 1.2210 - val_accuracy: 0.7958\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 1.3679 - val_accuracy: 0.7984\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 1.1841 - val_accuracy: 0.8011\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 1.0706 - val_accuracy: 0.7984\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0069 - accuracy: 0.9980 - val_loss: 1.2806 - val_accuracy: 0.7905\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 81.16710782051086\n",
            "Training 7: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 58s 380ms/step - loss: 0.6045 - accuracy: 0.6557 - val_loss: 0.4826 - val_accuracy: 0.7825\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.3249 - accuracy: 0.8642 - val_loss: 0.4574 - val_accuracy: 0.8090\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 37s 346ms/step - loss: 0.1758 - accuracy: 0.9447 - val_loss: 0.4475 - val_accuracy: 0.8223\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0965 - accuracy: 0.9633 - val_loss: 0.6335 - val_accuracy: 0.8037\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0367 - accuracy: 0.9869 - val_loss: 0.8578 - val_accuracy: 0.7878\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 37s 341ms/step - loss: 0.0252 - accuracy: 0.9905 - val_loss: 0.8713 - val_accuracy: 0.7984\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0282 - accuracy: 0.9875 - val_loss: 0.9522 - val_accuracy: 0.8037\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 1.0936 - val_accuracy: 0.7958\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.0037 - accuracy: 0.9985 - val_loss: 1.1287 - val_accuracy: 0.8037\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0025 - accuracy: 0.9985 - val_loss: 1.2551 - val_accuracy: 0.8011\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0021 - accuracy: 0.9987 - val_loss: 1.3312 - val_accuracy: 0.7958\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0010 - accuracy: 0.9992 - val_loss: 1.3812 - val_accuracy: 0.7931\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 9.4946e-04 - accuracy: 0.9990 - val_loss: 1.4684 - val_accuracy: 0.7931\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n",
            "Test Accuracy: 82.22811818122864\n",
            "Training 8: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 54s 378ms/step - loss: 0.6260 - accuracy: 0.6213 - val_loss: 0.4499 - val_accuracy: 0.7666\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.3462 - accuracy: 0.8564 - val_loss: 0.4506 - val_accuracy: 0.8064\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.1807 - accuracy: 0.9366 - val_loss: 0.5103 - val_accuracy: 0.7931\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0914 - accuracy: 0.9660 - val_loss: 0.5616 - val_accuracy: 0.8037\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0439 - accuracy: 0.9880 - val_loss: 0.8854 - val_accuracy: 0.7851\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0390 - accuracy: 0.9865 - val_loss: 0.8125 - val_accuracy: 0.8011\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0205 - accuracy: 0.9946 - val_loss: 0.9341 - val_accuracy: 0.7958\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0093 - accuracy: 0.9971 - val_loss: 1.0366 - val_accuracy: 0.7772\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 37s 345ms/step - loss: 0.0121 - accuracy: 0.9971 - val_loss: 0.9794 - val_accuracy: 0.8090\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0094 - accuracy: 0.9966 - val_loss: 1.0897 - val_accuracy: 0.8064\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0034 - accuracy: 0.9991 - val_loss: 1.1510 - val_accuracy: 0.8143\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0016 - accuracy: 0.9988 - val_loss: 1.2391 - val_accuracy: 0.8090\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.2327 - val_accuracy: 0.8117\n",
            "Epoch 14/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 9.9736e-04 - accuracy: 0.9992 - val_loss: 1.2662 - val_accuracy: 0.8117\n",
            "Epoch 15/40\n",
            "107/107 [==============================] - 36s 336ms/step - loss: 0.0012 - accuracy: 0.9995 - val_loss: 1.2987 - val_accuracy: 0.8117\n",
            "Epoch 16/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 8.8370e-04 - accuracy: 0.9997 - val_loss: 1.3305 - val_accuracy: 0.8090\n",
            "Epoch 17/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 5.0076e-04 - accuracy: 0.9997 - val_loss: 1.3560 - val_accuracy: 0.8037\n",
            "Epoch 18/40\n",
            "107/107 [==============================] - 36s 337ms/step - loss: 0.0010 - accuracy: 0.9989 - val_loss: 1.3849 - val_accuracy: 0.8064\n",
            "Epoch 19/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 8.3277e-04 - accuracy: 0.9996 - val_loss: 1.4065 - val_accuracy: 0.8037\n",
            "Epoch 20/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 1.4270 - val_accuracy: 0.8037\n",
            "Epoch 21/40\n",
            "107/107 [==============================] - 36s 335ms/step - loss: 2.7623e-04 - accuracy: 0.9998 - val_loss: 1.4488 - val_accuracy: 0.8011\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00021: early stopping\n",
            "Test Accuracy: 81.43236041069031\n",
            "Training 9: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 46s 304ms/step - loss: 0.6116 - accuracy: 0.6630 - val_loss: 0.5100 - val_accuracy: 0.7613\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 28s 262ms/step - loss: 0.3148 - accuracy: 0.8656 - val_loss: 0.5448 - val_accuracy: 0.7692\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 28s 263ms/step - loss: 0.1809 - accuracy: 0.9289 - val_loss: 0.6347 - val_accuracy: 0.7905\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 28s 263ms/step - loss: 0.0797 - accuracy: 0.9733 - val_loss: 0.7517 - val_accuracy: 0.7639\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 28s 264ms/step - loss: 0.0401 - accuracy: 0.9883 - val_loss: 1.1341 - val_accuracy: 0.7666\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 28s 266ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 1.3482 - val_accuracy: 0.7745\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 28s 264ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 1.4341 - val_accuracy: 0.7745\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 28s 266ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 1.6046 - val_accuracy: 0.7719\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 29s 267ms/step - loss: 0.0026 - accuracy: 0.9987 - val_loss: 1.7140 - val_accuracy: 0.7692\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 28s 266ms/step - loss: 0.0035 - accuracy: 0.9979 - val_loss: 1.9184 - val_accuracy: 0.7692\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 28s 264ms/step - loss: 0.0021 - accuracy: 0.9985 - val_loss: 1.8995 - val_accuracy: 0.7639\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 28s 265ms/step - loss: 0.0013 - accuracy: 0.9991 - val_loss: 1.9711 - val_accuracy: 0.7745\n",
            "Epoch 13/40\n",
            "107/107 [==============================] - 28s 264ms/step - loss: 0.0015 - accuracy: 0.9983 - val_loss: 2.0202 - val_accuracy: 0.7692\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00013: early stopping\n",
            "Test Accuracy: 79.0450930595398\n",
            "Training 10: \n",
            "Epoch 1/40\n",
            "107/107 [==============================] - 60s 384ms/step - loss: 0.6152 - accuracy: 0.6565 - val_loss: 0.4265 - val_accuracy: 0.8037\n",
            "Epoch 2/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.3180 - accuracy: 0.8683 - val_loss: 0.4201 - val_accuracy: 0.8170\n",
            "Epoch 3/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.1788 - accuracy: 0.9350 - val_loss: 0.5168 - val_accuracy: 0.7958\n",
            "Epoch 4/40\n",
            "107/107 [==============================] - 37s 342ms/step - loss: 0.1088 - accuracy: 0.9624 - val_loss: 0.5514 - val_accuracy: 0.8064\n",
            "Epoch 5/40\n",
            "107/107 [==============================] - 37s 341ms/step - loss: 0.0481 - accuracy: 0.9823 - val_loss: 0.8143 - val_accuracy: 0.7851\n",
            "Epoch 6/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0387 - accuracy: 0.9837 - val_loss: 0.8078 - val_accuracy: 0.8143\n",
            "Epoch 7/40\n",
            "107/107 [==============================] - 36s 339ms/step - loss: 0.0131 - accuracy: 0.9964 - val_loss: 0.9341 - val_accuracy: 0.8090\n",
            "Epoch 8/40\n",
            "107/107 [==============================] - 37s 342ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 1.0844 - val_accuracy: 0.7984\n",
            "Epoch 9/40\n",
            "107/107 [==============================] - 36s 340ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 1.1780 - val_accuracy: 0.8037\n",
            "Epoch 10/40\n",
            "107/107 [==============================] - 37s 349ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.2517 - val_accuracy: 0.8037\n",
            "Epoch 11/40\n",
            "107/107 [==============================] - 37s 342ms/step - loss: 0.0013 - accuracy: 0.9992 - val_loss: 1.3209 - val_accuracy: 0.8090\n",
            "Epoch 12/40\n",
            "107/107 [==============================] - 36s 338ms/step - loss: 0.0019 - accuracy: 0.9984 - val_loss: 1.3513 - val_accuracy: 0.8090\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00012: early stopping\n",
            "Test Accuracy: 81.69761300086975\n",
            "\n",
            "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
            "0  81.216931  83.597887  79.100531  ...  79.045093  79.575598  80.106101\n",
            "\n",
            "[1 rows x 11 columns]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPvTyfWoYPz6"
      },
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "MjN32qo5YPz6",
        "outputId": "ac2df982-6103-4f2c-e24f-fa2766c1d2a9"
      },
      "source": [
        "record3"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acc1</th>\n",
              "      <th>acc2</th>\n",
              "      <th>acc3</th>\n",
              "      <th>acc4</th>\n",
              "      <th>acc5</th>\n",
              "      <th>acc6</th>\n",
              "      <th>acc7</th>\n",
              "      <th>acc8</th>\n",
              "      <th>acc9</th>\n",
              "      <th>acc10</th>\n",
              "      <th>AVG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78.042328</td>\n",
              "      <td>82.275134</td>\n",
              "      <td>81.481481</td>\n",
              "      <td>81.74603</td>\n",
              "      <td>83.068782</td>\n",
              "      <td>81.167108</td>\n",
              "      <td>82.228118</td>\n",
              "      <td>81.43236</td>\n",
              "      <td>79.045093</td>\n",
              "      <td>81.697613</td>\n",
              "      <td>81.218405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
              "0  78.042328  82.275134  81.481481  ...  79.045093  81.697613  81.218405\n",
              "\n",
              "[1 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP7NifVSYPz6"
      },
      "source": [
        "report = record3\n",
        "report = report.to_excel('GRU_CR_v2_3.xlsx', sheet_name='dynamic')"
      ],
      "execution_count": 40,
      "outputs": []
    }
  ]
}