{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VtKoFBooZT-p"
   },
   "source": [
    "# GRU Classification with MPQA Dataset\n",
    "<hr>\n",
    "\n",
    "We will build a text classification model using GRU model on the MPQA Dataset. Since there is no standard train/test split for this dataset, we will use 10-Fold Cross Validation (CV). \n",
    "\n",
    "## Load the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xnbrBF4UZT-1",
    "outputId": "da6c3538-99aa-4f22-ade2-eecbaaef5999"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import nltk\n",
    "import random\n",
    "# from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%config IPCompleter.use_jedi=False\n",
    "# nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BzHns_OcZT-3",
    "outputId": "2e46186c-3b5b-4d2c-81b6-3dcde438cf62"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vYOheggZT-6"
   },
   "source": [
    "## Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "SXxjpeCrZT-6",
    "outputId": "be4cf304-2d68-48b9-ada2-3936499d1384"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10606, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>complaining</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing to support</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>desperately needs</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>many years of decay</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>no quick fix</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10601</th>\n",
       "      <td>urged</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10602</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10603</th>\n",
       "      <td>hope</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10604</th>\n",
       "      <td>strictly abide</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10605</th>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10606 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sentence  label  split\n",
       "0              complaining      0  train\n",
       "1       failing to support      0  train\n",
       "2        desperately needs      0  train\n",
       "3      many years of decay      0  train\n",
       "4             no quick fix      0  train\n",
       "...                    ...    ...    ...\n",
       "10601                urged      1  train\n",
       "10602       strictly abide      1  train\n",
       "10603                 hope      1  train\n",
       "10604       strictly abide      1  train\n",
       "10605                           1  train\n",
       "\n",
       "[10606 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = pd.read_pickle('../../../0_data/MPQA/MPQA.pkl')\n",
    "corpus.label = corpus.label.astype(int)\n",
    "print(corpus.shape)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mM2puyxaZT-7",
    "outputId": "e01daff8-7206-4f19-ea8d-712141efd59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10606 entries, 0 to 10605\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  10606 non-null  object\n",
      " 1   label     10606 non-null  int32 \n",
      " 2   split     10606 non-null  object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 207.3+ KB\n"
     ]
    }
   ],
   "source": [
    "corpus.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "2e3Rn9MqZT-8",
    "outputId": "38a6fbaa-2a9c-4571-9978-23475eedab70"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7294</td>\n",
       "      <td>7294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3312</td>\n",
       "      <td>3312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentence  split\n",
       "label                 \n",
       "0          7294   7294\n",
       "1          3312   3312"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.groupby( by='label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fdKkYCA1ZT-9"
   },
   "outputs": [],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "iSigZudxZT--",
    "outputId": "99a13387-79ac-49f1-ef03-0f8e5a289d27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'complaining'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1hyCj1-SZT--"
   },
   "source": [
    "<!--## Split Dataset-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XfWIv-akZT-_"
   },
   "source": [
    "# Data Preprocessing\n",
    "<hr>\n",
    "\n",
    "Preparing data for word embedding, especially for pre-trained word embedding like Word2Vec or GloVe, __don't use standard preprocessing steps like stemming or stopword removal__. Compared to our approach on cleaning the text when doing word count based feature extraction (e.g. TFIDF) such as removing stopwords, stemming etc, now we will keep these words as we do not want to lose such information that might help the model learn better.\n",
    "\n",
    "__Tomas Mikolov__, one of the developers of Word2Vec, in _word2vec-toolkit: google groups thread., 2015_, suggests only very minimal text cleaning is required when learning a word embedding model. Sometimes, it's good to disconnect\n",
    "In short, what we will do is:\n",
    "- Puntuations removal\n",
    "- Lower the letter case\n",
    "- Tokenization\n",
    "\n",
    "The process above will be handled by __Tokenizer__ class in TensorFlow\n",
    "\n",
    "- <b>One way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "pixqxgYDZT_A"
   },
   "outputs": [],
   "source": [
    "# Define a function to compute the max length of sequence\n",
    "def max_length(sequences):\n",
    "    '''\n",
    "    input:\n",
    "        sequences: a 2D list of integer sequences\n",
    "    output:\n",
    "        max_length: the max length of the sequences\n",
    "    '''\n",
    "    max_length = 0\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = len(seq)\n",
    "        if max_length < length:\n",
    "            max_length = length\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhRgyJJFZT_B",
    "outputId": "904eebdc-cbe7-4515-ce05-a2ea249bc73c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of sentence:  no quick fix\n",
      "Into a sequence of int: [25, 945, 1476]\n",
      "Into a padded sequence: [  25  945 1476    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "print(\"Example of sentence: \", sentences[4])\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "# Turn the text into sequence\n",
    "training_sequences = tokenizer.texts_to_sequences(sentences)\n",
    "max_len = max_length(training_sequences)\n",
    "\n",
    "print('Into a sequence of int:', training_sequences[4])\n",
    "\n",
    "# Pad the sequence to have the same size\n",
    "training_padded = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "print('Into a padded sequence:', training_padded[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tlJFsA50ZT_C",
    "outputId": "7e807ce7-5a88-40dc-d9a8-617f533f66ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK> 1\n",
      "the 2\n",
      "of 3\n",
      "to 4\n",
      "a 5\n",
      "and 6\n",
      "not 7\n",
      "is 8\n",
      "in 9\n",
      "be 10\n",
      "6236\n"
     ]
    }
   ],
   "source": [
    "word_index = tokenizer.word_index\n",
    "# See the first 10 words in the vocabulary\n",
    "for i, word in enumerate(word_index):\n",
    "    print(word, word_index.get(word))\n",
    "    if i==9:\n",
    "        break\n",
    "vocab_size = len(word_index)+1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQJqTkckZT_D"
   },
   "source": [
    "# Model 1: Embedding Random\n",
    "<hr>\n",
    "\n",
    "<img src=\"model.png\" style=\"width:700px;height:400px;\"> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rmAeP4v0ZT_D"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "g7EmzadeZT_E"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model(input_dim = None, output_dim=300, max_length = None ):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, )),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3iq60sF4ZT_F",
    "outputId": "f125e26f-1935-40b7-e870-4479b4ee56b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_20 (Bidirectio (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "bidirectional_21 (Bidirectio (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 515,169\n",
      "Trainable params: 515,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model( input_dim=1000, max_length=100)\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "iLlATCocZT_G"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HXqi67SZT_G"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hJXCNcV0ZT_H",
    "outputId": "bf091838-5bc1-4708-904f-e81d0f771ef3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 26s 48ms/step - loss: 0.5407 - accuracy: 0.7347 - val_loss: 0.3778 - val_accuracy: 0.8445\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.1923 - accuracy: 0.9330 - val_loss: 0.3706 - val_accuracy: 0.8407\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.1330 - accuracy: 0.9545 - val_loss: 0.4169 - val_accuracy: 0.8520\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.1046 - accuracy: 0.9634 - val_loss: 0.4712 - val_accuracy: 0.8388\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0761 - accuracy: 0.9697 - val_loss: 0.4566 - val_accuracy: 0.8539\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0585 - accuracy: 0.9761 - val_loss: 0.5242 - val_accuracy: 0.8520\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0466 - accuracy: 0.9824 - val_loss: 0.5278 - val_accuracy: 0.8596\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0474 - accuracy: 0.9807 - val_loss: 0.5889 - val_accuracy: 0.8520\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0404 - accuracy: 0.9838 - val_loss: 0.6188 - val_accuracy: 0.8473\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0344 - accuracy: 0.9838 - val_loss: 0.6686 - val_accuracy: 0.8473\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0343 - accuracy: 0.9850 - val_loss: 0.6929 - val_accuracy: 0.8464\n",
      "Epoch 12/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0357 - accuracy: 0.9836 - val_loss: 0.7315 - val_accuracy: 0.8360\n",
      "Epoch 13/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0304 - accuracy: 0.9855 - val_loss: 0.7951 - val_accuracy: 0.8379\n",
      "Epoch 14/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0253 - accuracy: 0.9887 - val_loss: 0.7431 - val_accuracy: 0.8464\n",
      "Epoch 15/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0318 - accuracy: 0.9841 - val_loss: 0.7923 - val_accuracy: 0.8435\n",
      "Epoch 16/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0291 - accuracy: 0.9870 - val_loss: 0.8175 - val_accuracy: 0.8426\n",
      "Epoch 17/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0276 - accuracy: 0.9862 - val_loss: 0.8721 - val_accuracy: 0.8426\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n",
      "Test Accuracy: 85.95664501190186\n",
      "Training 2: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 46ms/step - loss: 0.5368 - accuracy: 0.7388 - val_loss: 0.3326 - val_accuracy: 0.8709\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 10s 34ms/step - loss: 0.1865 - accuracy: 0.9348 - val_loss: 0.3522 - val_accuracy: 0.8615\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 10s 34ms/step - loss: 0.1308 - accuracy: 0.9564 - val_loss: 0.3663 - val_accuracy: 0.8718\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1021 - accuracy: 0.9638 - val_loss: 0.4240 - val_accuracy: 0.8596\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0765 - accuracy: 0.9726 - val_loss: 0.4615 - val_accuracy: 0.8530\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0554 - accuracy: 0.9782 - val_loss: 0.5228 - val_accuracy: 0.8549\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0484 - accuracy: 0.9819 - val_loss: 0.5289 - val_accuracy: 0.8624\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0410 - accuracy: 0.9845 - val_loss: 0.5710 - val_accuracy: 0.8615\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0409 - accuracy: 0.9822 - val_loss: 0.6302 - val_accuracy: 0.8643\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0349 - accuracy: 0.9852 - val_loss: 0.6506 - val_accuracy: 0.8680\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0374 - accuracy: 0.9820 - val_loss: 0.6490 - val_accuracy: 0.8643\n",
      "Epoch 12/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0331 - accuracy: 0.9855 - val_loss: 0.7359 - val_accuracy: 0.8605\n",
      "Epoch 13/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0288 - accuracy: 0.9870 - val_loss: 0.7258 - val_accuracy: 0.8586\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 87.1819019317627\n",
      "Training 3: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 28s 49ms/step - loss: 0.5314 - accuracy: 0.7380 - val_loss: 0.4104 - val_accuracy: 0.8473\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.2005 - accuracy: 0.9291 - val_loss: 0.4616 - val_accuracy: 0.8369\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1179 - accuracy: 0.9576 - val_loss: 0.4640 - val_accuracy: 0.8445\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0909 - accuracy: 0.9683 - val_loss: 0.5005 - val_accuracy: 0.8351\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0699 - accuracy: 0.9743 - val_loss: 0.5672 - val_accuracy: 0.8351\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0550 - accuracy: 0.9793 - val_loss: 0.6132 - val_accuracy: 0.8388\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0438 - accuracy: 0.9827 - val_loss: 0.6787 - val_accuracy: 0.8398\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0398 - accuracy: 0.9838 - val_loss: 0.7633 - val_accuracy: 0.8313\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0354 - accuracy: 0.9857 - val_loss: 0.7768 - val_accuracy: 0.8351\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0292 - accuracy: 0.9860 - val_loss: 0.8331 - val_accuracy: 0.8143\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0327 - accuracy: 0.9848 - val_loss: 0.7886 - val_accuracy: 0.8388\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 84.73138809204102\n",
      "Training 4: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 28s 49ms/step - loss: 0.5318 - accuracy: 0.7494 - val_loss: 0.3450 - val_accuracy: 0.8558\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.2005 - accuracy: 0.9289 - val_loss: 0.3472 - val_accuracy: 0.8275\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1347 - accuracy: 0.9569 - val_loss: 0.3642 - val_accuracy: 0.8615\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0977 - accuracy: 0.9665 - val_loss: 0.4238 - val_accuracy: 0.8303\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0714 - accuracy: 0.9723 - val_loss: 0.4911 - val_accuracy: 0.8633\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0508 - accuracy: 0.9814 - val_loss: 0.5163 - val_accuracy: 0.8511\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0473 - accuracy: 0.9813 - val_loss: 0.5846 - val_accuracy: 0.8596\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0457 - accuracy: 0.9830 - val_loss: 0.6190 - val_accuracy: 0.8190\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0387 - accuracy: 0.9825 - val_loss: 0.6603 - val_accuracy: 0.8624\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0337 - accuracy: 0.9856 - val_loss: 0.6514 - val_accuracy: 0.8539\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0335 - accuracy: 0.9857 - val_loss: 0.7127 - val_accuracy: 0.8567\n",
      "Epoch 12/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0264 - accuracy: 0.9879 - val_loss: 0.7353 - val_accuracy: 0.8501\n",
      "Epoch 13/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0281 - accuracy: 0.9856 - val_loss: 0.7793 - val_accuracy: 0.8294\n",
      "Epoch 14/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0260 - accuracy: 0.9878 - val_loss: 0.8328 - val_accuracy: 0.8492\n",
      "Epoch 15/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0293 - accuracy: 0.9872 - val_loss: 0.7749 - val_accuracy: 0.8501\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00015: early stopping\n",
      "Test Accuracy: 86.33365035057068\n",
      "Training 5: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 48ms/step - loss: 0.5390 - accuracy: 0.7470 - val_loss: 0.3601 - val_accuracy: 0.8539\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.1999 - accuracy: 0.9283 - val_loss: 0.3883 - val_accuracy: 0.8520\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.1433 - accuracy: 0.9471 - val_loss: 0.4110 - val_accuracy: 0.8586\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0982 - accuracy: 0.9638 - val_loss: 0.4449 - val_accuracy: 0.8586\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0742 - accuracy: 0.9725 - val_loss: 0.5316 - val_accuracy: 0.8388\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0592 - accuracy: 0.9759 - val_loss: 0.5375 - val_accuracy: 0.8483\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0453 - accuracy: 0.9800 - val_loss: 0.6087 - val_accuracy: 0.8501\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0420 - accuracy: 0.9814 - val_loss: 0.5706 - val_accuracy: 0.8341\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 10s 34ms/step - loss: 0.0343 - accuracy: 0.9856 - val_loss: 0.6429 - val_accuracy: 0.8483\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0330 - accuracy: 0.9855 - val_loss: 0.6476 - val_accuracy: 0.8388\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0330 - accuracy: 0.9849 - val_loss: 0.7474 - val_accuracy: 0.8388\n",
      "Epoch 12/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0352 - accuracy: 0.9814 - val_loss: 0.7626 - val_accuracy: 0.8379\n",
      "Epoch 13/30\n",
      "299/299 [==============================] - 10s 35ms/step - loss: 0.0351 - accuracy: 0.9847 - val_loss: 0.8138 - val_accuracy: 0.8294\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Training 6: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 49ms/step - loss: 0.5340 - accuracy: 0.7557 - val_loss: 0.3426 - val_accuracy: 0.8690\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.1997 - accuracy: 0.9306 - val_loss: 0.3529 - val_accuracy: 0.8652\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.1340 - accuracy: 0.9520 - val_loss: 0.4017 - val_accuracy: 0.8530\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0990 - accuracy: 0.9646 - val_loss: 0.4638 - val_accuracy: 0.8483\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0756 - accuracy: 0.9715 - val_loss: 0.5119 - val_accuracy: 0.8586\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0542 - accuracy: 0.9784 - val_loss: 0.5450 - val_accuracy: 0.8492\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0500 - accuracy: 0.9802 - val_loss: 0.6243 - val_accuracy: 0.8511\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0375 - accuracy: 0.9850 - val_loss: 0.5934 - val_accuracy: 0.8520\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0411 - accuracy: 0.9822 - val_loss: 0.6083 - val_accuracy: 0.8549\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0345 - accuracy: 0.9848 - val_loss: 0.6657 - val_accuracy: 0.8454\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0351 - accuracy: 0.9836 - val_loss: 0.7385 - val_accuracy: 0.8473\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.8991494178772\n",
      "Training 7: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 49ms/step - loss: 0.5376 - accuracy: 0.7431 - val_loss: 0.3525 - val_accuracy: 0.8500\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1988 - accuracy: 0.9271 - val_loss: 0.3890 - val_accuracy: 0.8472\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.1384 - accuracy: 0.9517 - val_loss: 0.4128 - val_accuracy: 0.8528\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0974 - accuracy: 0.9646 - val_loss: 0.4800 - val_accuracy: 0.8434\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0735 - accuracy: 0.9737 - val_loss: 0.5307 - val_accuracy: 0.8302\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0585 - accuracy: 0.9781 - val_loss: 0.6168 - val_accuracy: 0.8434\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0474 - accuracy: 0.9815 - val_loss: 0.6452 - val_accuracy: 0.8358\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 35ms/step - loss: 0.0452 - accuracy: 0.9798 - val_loss: 0.6260 - val_accuracy: 0.8443\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0382 - accuracy: 0.9818 - val_loss: 0.7129 - val_accuracy: 0.8425\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0391 - accuracy: 0.9832 - val_loss: 0.7156 - val_accuracy: 0.8396\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0313 - accuracy: 0.9870 - val_loss: 0.7918 - val_accuracy: 0.8358\n",
      "Epoch 12/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0310 - accuracy: 0.9844 - val_loss: 0.8778 - val_accuracy: 0.8311\n",
      "Epoch 13/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0359 - accuracy: 0.9823 - val_loss: 0.7899 - val_accuracy: 0.8387\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 85.2830171585083\n",
      "Training 8: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 49ms/step - loss: 0.5418 - accuracy: 0.7416 - val_loss: 0.3875 - val_accuracy: 0.8585\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.2001 - accuracy: 0.9303 - val_loss: 0.3899 - val_accuracy: 0.8632\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.1372 - accuracy: 0.9560 - val_loss: 0.4374 - val_accuracy: 0.8585\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 38ms/step - loss: 0.0956 - accuracy: 0.9657 - val_loss: 0.4663 - val_accuracy: 0.8670\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0773 - accuracy: 0.9713 - val_loss: 0.5090 - val_accuracy: 0.8594\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0550 - accuracy: 0.9779 - val_loss: 0.5517 - val_accuracy: 0.8594\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0460 - accuracy: 0.9821 - val_loss: 0.5909 - val_accuracy: 0.8585\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0423 - accuracy: 0.9810 - val_loss: 0.6127 - val_accuracy: 0.8500\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0395 - accuracy: 0.9819 - val_loss: 0.7508 - val_accuracy: 0.8340\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0332 - accuracy: 0.9853 - val_loss: 0.7210 - val_accuracy: 0.8519\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0325 - accuracy: 0.9838 - val_loss: 0.8267 - val_accuracy: 0.8453\n",
      "Epoch 12/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0348 - accuracy: 0.9826 - val_loss: 0.7969 - val_accuracy: 0.8500\n",
      "Epoch 13/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0269 - accuracy: 0.9876 - val_loss: 0.9158 - val_accuracy: 0.8321\n",
      "Epoch 14/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0333 - accuracy: 0.9833 - val_loss: 0.8092 - val_accuracy: 0.8443\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 86.69811487197876\n",
      "Training 9: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 49ms/step - loss: 0.5343 - accuracy: 0.7539 - val_loss: 0.3626 - val_accuracy: 0.8462\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1920 - accuracy: 0.9324 - val_loss: 0.4218 - val_accuracy: 0.8377\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1250 - accuracy: 0.9554 - val_loss: 0.4255 - val_accuracy: 0.8377\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0999 - accuracy: 0.9655 - val_loss: 0.4627 - val_accuracy: 0.8349\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0751 - accuracy: 0.9728 - val_loss: 0.5369 - val_accuracy: 0.8396\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0576 - accuracy: 0.9755 - val_loss: 0.5991 - val_accuracy: 0.8377\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0435 - accuracy: 0.9843 - val_loss: 0.6215 - val_accuracy: 0.8377\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0430 - accuracy: 0.9828 - val_loss: 0.6682 - val_accuracy: 0.8434\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0376 - accuracy: 0.9837 - val_loss: 0.6965 - val_accuracy: 0.8434\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0348 - accuracy: 0.9833 - val_loss: 0.7302 - val_accuracy: 0.8358\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0373 - accuracy: 0.9825 - val_loss: 0.7271 - val_accuracy: 0.8368\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 84.62263941764832\n",
      "Training 10: \n",
      "Epoch 1/30\n",
      "299/299 [==============================] - 27s 49ms/step - loss: 0.5290 - accuracy: 0.7470 - val_loss: 0.3591 - val_accuracy: 0.8509\n",
      "Epoch 2/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.1960 - accuracy: 0.9363 - val_loss: 0.3871 - val_accuracy: 0.8509\n",
      "Epoch 3/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.1224 - accuracy: 0.9563 - val_loss: 0.4424 - val_accuracy: 0.8377\n",
      "Epoch 4/30\n",
      "299/299 [==============================] - 11s 38ms/step - loss: 0.1006 - accuracy: 0.9656 - val_loss: 0.5181 - val_accuracy: 0.8415\n",
      "Epoch 5/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0747 - accuracy: 0.9701 - val_loss: 0.5729 - val_accuracy: 0.8340\n",
      "Epoch 6/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0578 - accuracy: 0.9778 - val_loss: 0.6354 - val_accuracy: 0.8302\n",
      "Epoch 7/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0433 - accuracy: 0.9832 - val_loss: 0.6575 - val_accuracy: 0.8340\n",
      "Epoch 8/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0341 - accuracy: 0.9859 - val_loss: 0.7295 - val_accuracy: 0.8217\n",
      "Epoch 9/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0344 - accuracy: 0.9866 - val_loss: 0.7071 - val_accuracy: 0.8274\n",
      "Epoch 10/30\n",
      "299/299 [==============================] - 11s 37ms/step - loss: 0.0320 - accuracy: 0.9865 - val_loss: 0.7823 - val_accuracy: 0.8198\n",
      "Epoch 11/30\n",
      "299/299 [==============================] - 11s 36ms/step - loss: 0.0329 - accuracy: 0.9860 - val_loss: 0.8406 - val_accuracy: 0.8340\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 85.0943386554718\n",
      "\n",
      "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
      "0  85.956645  87.181902  84.731388  ...  84.622639  85.094339  85.866324\n",
      "\n",
      "[1 rows x 11 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model(input_dim=vocab_size, max_length=max_len)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=30, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record = record.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cfa0i7wiZT_I"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "levj5is5ZT_J",
    "outputId": "155b98c5-ecdc-4430-e964-d069b5736aa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.956645</td>\n",
       "      <td>87.181902</td>\n",
       "      <td>84.731388</td>\n",
       "      <td>86.33365</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>86.899149</td>\n",
       "      <td>85.283017</td>\n",
       "      <td>86.698115</td>\n",
       "      <td>84.622639</td>\n",
       "      <td>85.094339</td>\n",
       "      <td>85.866324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3  ...       acc9      acc10        AVG\n",
       "0  85.956645  87.181902  84.731388  ...  84.622639  85.094339  85.866324\n",
       "\n",
       "[1 rows x 11 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "1vOEUHxuZT_K"
   },
   "outputs": [],
   "source": [
    "report = record\n",
    "report = report.to_excel('GRU_MPQA_v2.xlsx', sheet_name='random')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCHsRGvtZT_K"
   },
   "source": [
    "# Model 2: Word2Vec Static"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYuP2HtUZT_L"
   },
   "source": [
    "__Using and updating pre-trained embeddings__\n",
    "* In this part, we will create an Embedding layer in Tensorflow Keras using a pre-trained word embedding called Word2Vec 300-d tht has been trained 100 bilion words from Google News.\n",
    "* In this part,  we will leave the embeddings fixed instead of updating them (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flHiS9HKZT_L"
   },
   "source": [
    "1. __Load `Word2Vec` Pre-trained Word Embedding__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "J3XdEOfHZT_M"
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "word2vec = KeyedVectors.load_word2vec_format('../GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1QcTxqRZT_M",
    "outputId": "c51329f2-4aee-458f-c00b-26db3774a21e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.64062500e-01,  1.87500000e-01, -4.10156250e-02,  1.25000000e-01,\n",
       "       -3.22265625e-02,  8.69140625e-02,  1.19140625e-01, -1.26953125e-01,\n",
       "        1.77001953e-02,  8.83789062e-02,  2.12402344e-02, -2.00195312e-01,\n",
       "        4.83398438e-02, -1.01074219e-01, -1.89453125e-01,  2.30712891e-02,\n",
       "        1.17675781e-01,  7.51953125e-02, -8.39843750e-02, -1.33666992e-02,\n",
       "        1.53320312e-01,  4.08203125e-01,  3.80859375e-02,  3.36914062e-02,\n",
       "       -4.02832031e-02, -6.88476562e-02,  9.03320312e-02,  2.12890625e-01,\n",
       "        1.72119141e-02, -6.44531250e-02, -1.29882812e-01,  1.40625000e-01,\n",
       "        2.38281250e-01,  1.37695312e-01, -1.76757812e-01, -2.71484375e-01,\n",
       "       -1.36718750e-01, -1.69921875e-01, -9.15527344e-03,  3.47656250e-01,\n",
       "        2.22656250e-01, -3.06640625e-01,  1.98242188e-01,  1.33789062e-01,\n",
       "       -4.34570312e-02, -5.12695312e-02, -3.46679688e-02, -8.49609375e-02,\n",
       "        1.01562500e-01,  1.42578125e-01, -7.95898438e-02,  1.78710938e-01,\n",
       "        2.30468750e-01,  3.90625000e-02,  8.69140625e-02,  2.40234375e-01,\n",
       "       -7.61718750e-02,  8.64257812e-02,  1.02539062e-01,  2.64892578e-02,\n",
       "       -6.88476562e-02, -9.70458984e-03, -2.77343750e-01, -1.73828125e-01,\n",
       "        5.10253906e-02,  1.89208984e-02, -2.09960938e-01, -1.14257812e-01,\n",
       "       -2.81982422e-02,  7.81250000e-02,  2.01463699e-05,  5.76782227e-03,\n",
       "        2.38281250e-01,  2.55126953e-02, -3.41796875e-01,  2.23632812e-01,\n",
       "        2.48046875e-01,  1.61132812e-01, -7.95898438e-02,  2.55859375e-01,\n",
       "        5.46875000e-02, -1.19628906e-01,  2.81982422e-02,  2.13623047e-02,\n",
       "       -8.60595703e-03,  4.66308594e-02, -2.78320312e-02,  2.98828125e-01,\n",
       "       -1.82617188e-01,  2.42187500e-01, -7.37304688e-02,  7.81250000e-02,\n",
       "       -2.63671875e-01, -1.73828125e-01,  3.14941406e-02,  1.67968750e-01,\n",
       "       -6.39648438e-02,  1.69677734e-02,  4.68750000e-02, -1.64062500e-01,\n",
       "       -2.94921875e-01, -3.23486328e-03, -1.60156250e-01, -1.39648438e-01,\n",
       "       -8.78906250e-02, -1.47460938e-01,  9.71679688e-02, -1.60156250e-01,\n",
       "        3.36914062e-02, -1.18164062e-01, -2.28515625e-01, -9.08203125e-02,\n",
       "       -8.34960938e-02, -8.74023438e-02,  2.09960938e-01, -1.67968750e-01,\n",
       "        1.60156250e-01,  7.91015625e-02, -1.03515625e-01, -1.22558594e-01,\n",
       "       -1.39648438e-01,  2.99072266e-02,  5.00488281e-02, -4.46777344e-02,\n",
       "       -4.12597656e-02, -1.94335938e-01,  6.15234375e-02,  2.47070312e-01,\n",
       "        5.24902344e-02, -1.18164062e-01,  4.68750000e-02,  1.79290771e-03,\n",
       "        2.57812500e-01,  2.65625000e-01, -4.15039062e-02,  1.75781250e-01,\n",
       "        2.25830078e-02, -2.14843750e-02, -4.10156250e-02,  6.88476562e-02,\n",
       "        1.87500000e-01, -8.34960938e-02,  4.39453125e-02, -1.66015625e-01,\n",
       "        8.00781250e-02,  1.52343750e-01,  7.65991211e-03, -3.66210938e-02,\n",
       "        1.87988281e-02, -2.69531250e-01, -3.88183594e-02,  1.65039062e-01,\n",
       "       -8.85009766e-03,  3.37890625e-01, -2.63671875e-01, -1.63574219e-02,\n",
       "        8.20312500e-02, -2.17773438e-01, -1.14746094e-01,  9.57031250e-02,\n",
       "       -6.07910156e-02, -1.51367188e-01,  7.61718750e-02,  7.27539062e-02,\n",
       "        7.22656250e-02, -1.70898438e-02,  3.34472656e-02,  2.27539062e-01,\n",
       "        1.42578125e-01,  1.21093750e-01, -1.83593750e-01,  1.02050781e-01,\n",
       "        6.83593750e-02,  1.28906250e-01, -1.28784180e-02,  1.63085938e-01,\n",
       "        2.83203125e-02, -6.73828125e-02, -3.53515625e-01, -1.60980225e-03,\n",
       "       -4.17480469e-02, -2.87109375e-01,  3.75976562e-02, -1.20117188e-01,\n",
       "        7.08007812e-02,  2.56347656e-02,  5.66406250e-02,  1.14746094e-02,\n",
       "       -1.69921875e-01, -1.16577148e-02, -4.73632812e-02,  1.94335938e-01,\n",
       "        3.61328125e-02, -1.21093750e-01, -4.02832031e-02,  1.25000000e-01,\n",
       "       -4.44335938e-02, -1.10351562e-01, -8.30078125e-02, -6.59179688e-02,\n",
       "       -1.55029297e-02,  1.59179688e-01, -1.87500000e-01, -3.17382812e-02,\n",
       "        8.34960938e-02, -1.23535156e-01, -1.68945312e-01, -2.81250000e-01,\n",
       "       -1.50390625e-01,  9.47265625e-02, -2.53906250e-01,  1.04003906e-01,\n",
       "        1.07421875e-01, -2.70080566e-03,  1.42211914e-02, -1.01074219e-01,\n",
       "        3.61328125e-02, -6.64062500e-02, -2.73437500e-01, -1.17187500e-02,\n",
       "       -9.52148438e-02,  2.23632812e-01,  1.28906250e-01, -1.24511719e-01,\n",
       "       -2.57568359e-02,  3.12500000e-01, -6.93359375e-02, -1.57226562e-01,\n",
       "       -1.91406250e-01,  6.44531250e-02, -1.64062500e-01,  1.70898438e-02,\n",
       "       -1.02050781e-01, -2.30468750e-01,  2.12890625e-01, -4.41894531e-02,\n",
       "       -2.20703125e-01, -7.51953125e-02,  2.79296875e-01,  2.45117188e-01,\n",
       "        2.04101562e-01,  1.50390625e-01,  1.36718750e-01, -1.49414062e-01,\n",
       "       -1.79687500e-01,  1.10839844e-01, -8.10546875e-02, -1.22558594e-01,\n",
       "       -4.58984375e-02, -2.07031250e-01, -1.48437500e-01,  2.79296875e-01,\n",
       "        2.28515625e-01,  2.11914062e-01,  1.30859375e-01, -3.51562500e-02,\n",
       "        2.09960938e-01, -6.34765625e-02, -1.15722656e-01, -2.05078125e-01,\n",
       "        1.26953125e-01, -2.11914062e-01, -2.55859375e-01, -1.57470703e-02,\n",
       "        1.16699219e-01, -1.30004883e-02, -1.07910156e-01, -3.39843750e-01,\n",
       "        1.54296875e-01, -1.71875000e-01, -2.28271484e-02,  6.44531250e-02,\n",
       "        3.78906250e-01,  1.62109375e-01,  5.17578125e-02, -8.78906250e-02,\n",
       "       -1.78222656e-02, -4.58984375e-02, -2.06054688e-01,  6.59179688e-02,\n",
       "        2.26562500e-01,  1.34765625e-01,  1.03515625e-01,  2.64892578e-02,\n",
       "        1.97265625e-01, -9.47265625e-02, -7.71484375e-02,  1.04003906e-01,\n",
       "        9.71679688e-02, -1.41601562e-01,  1.17187500e-02,  1.97265625e-01,\n",
       "        3.61633301e-03,  2.53906250e-01, -1.30004883e-02,  3.46679688e-02,\n",
       "        1.73339844e-02,  1.08886719e-01, -1.01928711e-02,  2.07519531e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the dense vector value for the word 'handsome'\n",
    "# word2vec.word_vec('handsome') # 0.11376953\n",
    "word2vec.word_vec('cool') # 1.64062500e-01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aTNqKy9QZT_N"
   },
   "source": [
    "2. __Check number of training words present in Word2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4dUNC7vHZT_N"
   },
   "outputs": [],
   "source": [
    "def training_words_in_word2vector(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    count = 0\n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            count+=1\n",
    "            \n",
    "    return print('Found {} words present from {} training vocabulary in the set of pre-trained word vector'.format(count, vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WVLl6t6pZT_O",
    "outputId": "fde2e3fe-80e1-4a4f-e1ce-b4ab1087fc37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6083 words present from 6236 training vocabulary in the set of pre-trained word vector\n"
     ]
    }
   ],
   "source": [
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "# Cleaning and Tokenization\n",
    "tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "training_words_in_word2vector(word2vec, word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kA3okYHyZT_O"
   },
   "source": [
    "2. __Define a `pretrained_embedding_layer` function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "M1wLZvxmZT_P"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "def pretrained_embedding_matrix(word_to_vec_map, word_to_index):\n",
    "    '''\n",
    "    input:\n",
    "        word_to_vec_map: a word2vec GoogleNews-vectors-negative300.bin model loaded using gensim.models\n",
    "        word_to_index: word to index mapping from training set\n",
    "    '''\n",
    "    \n",
    "    # adding 1 to fit Keras embedding (requirement)\n",
    "    vocab_size = len(word_to_index) + 1\n",
    "    # define dimensionality of your pre-trained word vectors (= 300)\n",
    "    emb_dim = word_to_vec_map.word_vec('handsome').shape[0]\n",
    "    \n",
    "    \n",
    "    embed_matrix = np.zeros((vocab_size, emb_dim))\n",
    "    \n",
    "    # Set each row \"idx\" of the embedding matrix to be \n",
    "    # the word vector representation of the idx'th word of the vocabulary\n",
    "    for word, idx in word_to_index.items():\n",
    "        if word in word_to_vec_map:\n",
    "            embed_matrix[idx] = word_to_vec_map.word_vec(word)\n",
    "            \n",
    "        # initialize the unknown word with standard normal distribution values\n",
    "        else:\n",
    "            embed_matrix[idx] = np.random.randn(emb_dim)\n",
    "            \n",
    "    return embed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UnHVdZuPZT_P",
    "outputId": "9fceb681-b4b9-4aef-9fce-cd20005be854"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.21264265,  0.19275032, -0.82771199, ...,  2.05214657,\n",
       "         0.98992542, -0.45116016],\n",
       "       [ 0.11376953,  0.1796875 , -0.265625  , ..., -0.21875   ,\n",
       "        -0.03930664,  0.20996094],\n",
       "       [ 0.1640625 ,  0.1875    , -0.04101562, ...,  0.10888672,\n",
       "        -0.01019287,  0.02075195],\n",
       "       [ 0.10888672, -0.16699219,  0.08984375, ..., -0.19628906,\n",
       "        -0.23144531,  0.04614258]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the function\n",
    "w_2_i = {'<UNK>': 1, 'handsome': 2, 'cool': 3, 'shit': 4 }\n",
    "em_matrix = pretrained_embedding_matrix(word2vec, w_2_i)\n",
    "em_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6mQTpiQZT_Q"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "FnF5yyKHZT_Q"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_2(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = False),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KYzRbWEMZT_T",
    "outputId": "16b012f3-a113-4788-9b62-0798399a7f57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 515,169\n",
      "Trainable params: 215,169\n",
      "Non-trainable params: 300,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_2( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asRYvjzyZT_T"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "lEhNTDbDZT_T"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') >= 0.9):\n",
    "            print(\"\\nReached 90% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3ZvNNvIZT_U",
    "outputId": "270c9916-cdf3-4df0-d3ac-fef71a9e97e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "299/299 [==============================] - 78s 155ms/step - loss: 0.4487 - accuracy: 0.7924 - val_loss: 0.3460 - val_accuracy: 0.8567\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 39s 130ms/step - loss: 0.2829 - accuracy: 0.8940 - val_loss: 0.3441 - val_accuracy: 0.8709\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 38s 128ms/step - loss: 0.2587 - accuracy: 0.9051 - val_loss: 0.3532 - val_accuracy: 0.8379\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 38s 117ms/step - loss: 0.2357 - accuracy: 0.9087 - val_loss: 0.3686 - val_accuracy: 0.8322\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2121 - accuracy: 0.9155 - val_loss: 0.4035 - val_accuracy: 0.8228\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1960 - accuracy: 0.9263 - val_loss: 0.4010 - val_accuracy: 0.8190\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1794 - accuracy: 0.9308 - val_loss: 0.4736 - val_accuracy: 0.7983\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1533 - accuracy: 0.9406 - val_loss: 0.4097 - val_accuracy: 0.8143\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 38s 127ms/step - loss: 0.1372 - accuracy: 0.9484 - val_loss: 0.4289 - val_accuracy: 0.8106\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1177 - accuracy: 0.9538 - val_loss: 0.5054 - val_accuracy: 0.8275\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1095 - accuracy: 0.9584 - val_loss: 0.5308 - val_accuracy: 0.8275\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0999 - accuracy: 0.9607 - val_loss: 0.6210 - val_accuracy: 0.8238\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 87.08765506744385\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 72s 151ms/step - loss: 0.4512 - accuracy: 0.7827 - val_loss: 0.3402 - val_accuracy: 0.8124\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2847 - accuracy: 0.8896 - val_loss: 0.3335 - val_accuracy: 0.8134\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2573 - accuracy: 0.9053 - val_loss: 0.3648 - val_accuracy: 0.8021\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2298 - accuracy: 0.9110 - val_loss: 0.3589 - val_accuracy: 0.8002\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2236 - accuracy: 0.9134 - val_loss: 0.4356 - val_accuracy: 0.7898\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2039 - accuracy: 0.9263 - val_loss: 0.3393 - val_accuracy: 0.8124\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1731 - accuracy: 0.9341 - val_loss: 0.5550 - val_accuracy: 0.7747\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1609 - accuracy: 0.9381 - val_loss: 0.8252 - val_accuracy: 0.7729\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1440 - accuracy: 0.9455 - val_loss: 0.9554 - val_accuracy: 0.7766\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 39s 131ms/step - loss: 0.1164 - accuracy: 0.9573 - val_loss: 1.1287 - val_accuracy: 0.7785\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.1052 - accuracy: 0.9611 - val_loss: 1.1522 - val_accuracy: 0.7832\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 38s 128ms/step - loss: 0.0921 - accuracy: 0.9644 - val_loss: 1.1705 - val_accuracy: 0.7823\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 81.33835792541504\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 79s 161ms/step - loss: 0.4434 - accuracy: 0.7923 - val_loss: 0.3399 - val_accuracy: 0.8586\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 40s 134ms/step - loss: 0.2818 - accuracy: 0.8956 - val_loss: 0.4370 - val_accuracy: 0.8492\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 40s 132ms/step - loss: 0.2650 - accuracy: 0.9013 - val_loss: 0.4678 - val_accuracy: 0.8492\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.2243 - accuracy: 0.9177 - val_loss: 0.5522 - val_accuracy: 0.8520\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.2239 - accuracy: 0.9162 - val_loss: 0.5788 - val_accuracy: 0.8492\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 41s 136ms/step - loss: 0.1891 - accuracy: 0.9271 - val_loss: 0.5740 - val_accuracy: 0.8549\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 39s 129ms/step - loss: 0.1748 - accuracy: 0.9320 - val_loss: 0.6116 - val_accuracy: 0.8530\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1553 - accuracy: 0.9392 - val_loss: 0.6421 - val_accuracy: 0.8520\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1316 - accuracy: 0.9458 - val_loss: 0.7402 - val_accuracy: 0.8511\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1177 - accuracy: 0.9550 - val_loss: 0.7778 - val_accuracy: 0.8530\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 38s 127ms/step - loss: 0.0983 - accuracy: 0.9629 - val_loss: 0.8630 - val_accuracy: 0.8454\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 85.86239218711853\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 71s 161ms/step - loss: 0.4534 - accuracy: 0.7841 - val_loss: 0.4020 - val_accuracy: 0.8652\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 38s 127ms/step - loss: 0.2765 - accuracy: 0.8964 - val_loss: 0.4122 - val_accuracy: 0.8671\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2558 - accuracy: 0.9034 - val_loss: 0.4453 - val_accuracy: 0.8605\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2309 - accuracy: 0.9097 - val_loss: 0.4112 - val_accuracy: 0.8652\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 38s 127ms/step - loss: 0.2253 - accuracy: 0.9122 - val_loss: 0.4395 - val_accuracy: 0.8671\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2022 - accuracy: 0.9227 - val_loss: 0.4473 - val_accuracy: 0.8643\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1847 - accuracy: 0.9250 - val_loss: 0.4907 - val_accuracy: 0.8615\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1597 - accuracy: 0.9375 - val_loss: 0.5207 - val_accuracy: 0.8680\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1412 - accuracy: 0.9453 - val_loss: 0.5585 - val_accuracy: 0.8615\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1278 - accuracy: 0.9493 - val_loss: 0.6645 - val_accuracy: 0.8728\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 38s 129ms/step - loss: 0.1026 - accuracy: 0.9602 - val_loss: 0.6755 - val_accuracy: 0.8718\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 38s 127ms/step - loss: 0.0990 - accuracy: 0.9654 - val_loss: 0.7101 - val_accuracy: 0.8680\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 38s 127ms/step - loss: 0.0918 - accuracy: 0.9635 - val_loss: 0.8096 - val_accuracy: 0.8671\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0791 - accuracy: 0.9698 - val_loss: 0.7557 - val_accuracy: 0.8671\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 38s 128ms/step - loss: 0.0636 - accuracy: 0.9747 - val_loss: 0.7157 - val_accuracy: 0.8615\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0620 - accuracy: 0.9764 - val_loss: 0.8051 - val_accuracy: 0.8615\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0590 - accuracy: 0.9750 - val_loss: 0.8422 - val_accuracy: 0.8680\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0615 - accuracy: 0.9747 - val_loss: 0.8536 - val_accuracy: 0.8662\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0463 - accuracy: 0.9823 - val_loss: 0.9403 - val_accuracy: 0.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/40\n",
      "299/299 [==============================] - 37s 123ms/step - loss: 0.0529 - accuracy: 0.9805 - val_loss: 0.7873 - val_accuracy: 0.8567\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 87.27615475654602\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 63s 133ms/step - loss: 0.4570 - accuracy: 0.7778 - val_loss: 0.3223 - val_accuracy: 0.8746\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 33s 110ms/step - loss: 0.2889 - accuracy: 0.8906 - val_loss: 0.3364 - val_accuracy: 0.8746\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 32s 106ms/step - loss: 0.2656 - accuracy: 0.8998 - val_loss: 0.3418 - val_accuracy: 0.8803\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 32s 107ms/step - loss: 0.2227 - accuracy: 0.9150 - val_loss: 0.3513 - val_accuracy: 0.8765\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.2120 - accuracy: 0.9178 - val_loss: 0.4134 - val_accuracy: 0.8756\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.1951 - accuracy: 0.9268 - val_loss: 0.3943 - val_accuracy: 0.8728\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.1718 - accuracy: 0.9318 - val_loss: 0.3971 - val_accuracy: 0.8775\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.1449 - accuracy: 0.9424 - val_loss: 0.4568 - val_accuracy: 0.8652\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.1345 - accuracy: 0.9504 - val_loss: 0.5051 - val_accuracy: 0.8605\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.1239 - accuracy: 0.9548 - val_loss: 0.4867 - val_accuracy: 0.8567\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.1016 - accuracy: 0.9595 - val_loss: 0.6444 - val_accuracy: 0.8671\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 32s 107ms/step - loss: 0.0885 - accuracy: 0.9687 - val_loss: 0.6903 - val_accuracy: 0.8690\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 32s 108ms/step - loss: 0.0945 - accuracy: 0.9661 - val_loss: 0.6345 - val_accuracy: 0.8699\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 88.03015947341919\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 66s 142ms/step - loss: 0.4542 - accuracy: 0.7871 - val_loss: 0.4603 - val_accuracy: 0.8558\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 35s 117ms/step - loss: 0.2931 - accuracy: 0.8908 - val_loss: 0.3987 - val_accuracy: 0.8530\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.2708 - accuracy: 0.8955 - val_loss: 0.3951 - val_accuracy: 0.8605\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 35s 117ms/step - loss: 0.2332 - accuracy: 0.9130 - val_loss: 0.3554 - val_accuracy: 0.8709\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.2167 - accuracy: 0.9201 - val_loss: 0.3470 - val_accuracy: 0.8662\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.1848 - accuracy: 0.9322 - val_loss: 0.3553 - val_accuracy: 0.8624\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.1688 - accuracy: 0.9366 - val_loss: 0.3837 - val_accuracy: 0.8577\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.1561 - accuracy: 0.9443 - val_loss: 0.4147 - val_accuracy: 0.8501\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 35s 117ms/step - loss: 0.1234 - accuracy: 0.9535 - val_loss: 0.4687 - val_accuracy: 0.8369\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.1071 - accuracy: 0.9612 - val_loss: 0.5288 - val_accuracy: 0.8228\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 32s 106ms/step - loss: 0.0999 - accuracy: 0.9655 - val_loss: 0.5405 - val_accuracy: 0.8360\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 35s 116ms/step - loss: 0.0839 - accuracy: 0.9678 - val_loss: 0.6163 - val_accuracy: 0.8398\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 35s 117ms/step - loss: 0.0716 - accuracy: 0.9734 - val_loss: 0.6268 - val_accuracy: 0.8369\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 35s 117ms/step - loss: 0.0702 - accuracy: 0.9744 - val_loss: 0.6417 - val_accuracy: 0.8407\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00014: early stopping\n",
      "Test Accuracy: 87.08765506744385\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 73s 150ms/step - loss: 0.4495 - accuracy: 0.7853 - val_loss: 0.3247 - val_accuracy: 0.8689\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.2854 - accuracy: 0.8872 - val_loss: 0.3311 - val_accuracy: 0.8566\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.2536 - accuracy: 0.9060 - val_loss: 0.3235 - val_accuracy: 0.8708\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2401 - accuracy: 0.9081 - val_loss: 0.3634 - val_accuracy: 0.8604\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2163 - accuracy: 0.9162 - val_loss: 0.3453 - val_accuracy: 0.8660\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1875 - accuracy: 0.9317 - val_loss: 0.4085 - val_accuracy: 0.7962\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1678 - accuracy: 0.9340 - val_loss: 0.4482 - val_accuracy: 0.7934\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1557 - accuracy: 0.9373 - val_loss: 0.4877 - val_accuracy: 0.7934\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 37s 123ms/step - loss: 0.1379 - accuracy: 0.9495 - val_loss: 0.5710 - val_accuracy: 0.7868\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1176 - accuracy: 0.9547 - val_loss: 0.6407 - val_accuracy: 0.7783\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1018 - accuracy: 0.9605 - val_loss: 0.8337 - val_accuracy: 0.7632\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0979 - accuracy: 0.9597 - val_loss: 0.9398 - val_accuracy: 0.7755\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0860 - accuracy: 0.9659 - val_loss: 0.6617 - val_accuracy: 0.8094\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 87.07547187805176\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 67s 146ms/step - loss: 0.4582 - accuracy: 0.7847 - val_loss: 0.4502 - val_accuracy: 0.7868\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.2794 - accuracy: 0.8955 - val_loss: 0.5200 - val_accuracy: 0.7689\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.2517 - accuracy: 0.8972 - val_loss: 0.4442 - val_accuracy: 0.8123\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.2392 - accuracy: 0.9093 - val_loss: 0.4883 - val_accuracy: 0.8019\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 36s 122ms/step - loss: 0.2047 - accuracy: 0.9236 - val_loss: 0.4789 - val_accuracy: 0.8104\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.1882 - accuracy: 0.9262 - val_loss: 0.4923 - val_accuracy: 0.8094\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.1700 - accuracy: 0.9329 - val_loss: 0.4889 - val_accuracy: 0.8132\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 36s 122ms/step - loss: 0.1511 - accuracy: 0.9397 - val_loss: 0.5270 - val_accuracy: 0.8142\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.1396 - accuracy: 0.9410 - val_loss: 0.4948 - val_accuracy: 0.8094\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.1189 - accuracy: 0.9525 - val_loss: 0.5719 - val_accuracy: 0.8208\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0951 - accuracy: 0.9639 - val_loss: 0.6631 - val_accuracy: 0.8009\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0897 - accuracy: 0.9679 - val_loss: 0.6382 - val_accuracy: 0.8302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/40\n",
      "299/299 [==============================] - 36s 119ms/step - loss: 0.0817 - accuracy: 0.9685 - val_loss: 0.7153 - val_accuracy: 0.8208\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 36s 119ms/step - loss: 0.0730 - accuracy: 0.9734 - val_loss: 0.6965 - val_accuracy: 0.8217\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0653 - accuracy: 0.9740 - val_loss: 0.7436 - val_accuracy: 0.8113\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0657 - accuracy: 0.9753 - val_loss: 0.7907 - val_accuracy: 0.8208\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0595 - accuracy: 0.9782 - val_loss: 0.8061 - val_accuracy: 0.8189\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0513 - accuracy: 0.9803 - val_loss: 0.7276 - val_accuracy: 0.8481\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0535 - accuracy: 0.9789 - val_loss: 0.8002 - val_accuracy: 0.8142\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0499 - accuracy: 0.9814 - val_loss: 0.8375 - val_accuracy: 0.8179\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0436 - accuracy: 0.9833 - val_loss: 0.8651 - val_accuracy: 0.8179\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0384 - accuracy: 0.9846 - val_loss: 0.9006 - val_accuracy: 0.8274\n",
      "Epoch 23/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0420 - accuracy: 0.9815 - val_loss: 1.1015 - val_accuracy: 0.7962\n",
      "Epoch 24/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0393 - accuracy: 0.9851 - val_loss: 0.8954 - val_accuracy: 0.8406\n",
      "Epoch 25/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0468 - accuracy: 0.9813 - val_loss: 0.8872 - val_accuracy: 0.8198\n",
      "Epoch 26/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0370 - accuracy: 0.9856 - val_loss: 0.9823 - val_accuracy: 0.8160\n",
      "Epoch 27/40\n",
      "299/299 [==============================] - 37s 123ms/step - loss: 0.0350 - accuracy: 0.9856 - val_loss: 1.0648 - val_accuracy: 0.8189\n",
      "Epoch 28/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0357 - accuracy: 0.9847 - val_loss: 0.9057 - val_accuracy: 0.8538\n",
      "Epoch 29/40\n",
      "299/299 [==============================] - 36s 120ms/step - loss: 0.0308 - accuracy: 0.9866 - val_loss: 1.2931 - val_accuracy: 0.7953\n",
      "Epoch 30/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0454 - accuracy: 0.9830 - val_loss: 0.9289 - val_accuracy: 0.8094\n",
      "Epoch 31/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0389 - accuracy: 0.9841 - val_loss: 1.0229 - val_accuracy: 0.8151\n",
      "Epoch 32/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0293 - accuracy: 0.9871 - val_loss: 1.1173 - val_accuracy: 0.8142\n",
      "Epoch 33/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0273 - accuracy: 0.9888 - val_loss: 0.9858 - val_accuracy: 0.8396\n",
      "Epoch 34/40\n",
      "299/299 [==============================] - 36s 122ms/step - loss: 0.0304 - accuracy: 0.9886 - val_loss: 1.1267 - val_accuracy: 0.8151\n",
      "Epoch 35/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0347 - accuracy: 0.9862 - val_loss: 1.0917 - val_accuracy: 0.8160\n",
      "Epoch 36/40\n",
      "299/299 [==============================] - 37s 123ms/step - loss: 0.0314 - accuracy: 0.9862 - val_loss: 1.2379 - val_accuracy: 0.8019\n",
      "Epoch 37/40\n",
      "299/299 [==============================] - 37s 123ms/step - loss: 0.0306 - accuracy: 0.9873 - val_loss: 1.3156 - val_accuracy: 0.8066\n",
      "Epoch 38/40\n",
      "299/299 [==============================] - 36s 121ms/step - loss: 0.0312 - accuracy: 0.9855 - val_loss: 1.3238 - val_accuracy: 0.8057\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00038: early stopping\n",
      "Test Accuracy: 85.37735939025879\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 68s 150ms/step - loss: 0.4512 - accuracy: 0.7853 - val_loss: 0.3339 - val_accuracy: 0.8689\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2934 - accuracy: 0.8853 - val_loss: 0.3104 - val_accuracy: 0.8764\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2683 - accuracy: 0.8988 - val_loss: 0.2956 - val_accuracy: 0.8821\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.2311 - accuracy: 0.9080 - val_loss: 0.3009 - val_accuracy: 0.8811\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2176 - accuracy: 0.9142 - val_loss: 0.3080 - val_accuracy: 0.8840\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1923 - accuracy: 0.9241 - val_loss: 0.3162 - val_accuracy: 0.8811\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1756 - accuracy: 0.9316 - val_loss: 0.3379 - val_accuracy: 0.8821\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 35s 107ms/step - loss: 0.1620 - accuracy: 0.9378 - val_loss: 0.3457 - val_accuracy: 0.8802\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1315 - accuracy: 0.9502 - val_loss: 0.3922 - val_accuracy: 0.8887\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.1128 - accuracy: 0.9574 - val_loss: 0.4461 - val_accuracy: 0.8472\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0971 - accuracy: 0.9633 - val_loss: 0.4677 - val_accuracy: 0.8500\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.0903 - accuracy: 0.9666 - val_loss: 0.4548 - val_accuracy: 0.8745\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0810 - accuracy: 0.9677 - val_loss: 0.5321 - val_accuracy: 0.8792\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0792 - accuracy: 0.9697 - val_loss: 0.5644 - val_accuracy: 0.8792\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0711 - accuracy: 0.9761 - val_loss: 0.6431 - val_accuracy: 0.8283\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0689 - accuracy: 0.9741 - val_loss: 0.6347 - val_accuracy: 0.8623\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.0624 - accuracy: 0.9769 - val_loss: 0.6955 - val_accuracy: 0.8302\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.0501 - accuracy: 0.9827 - val_loss: 0.7271 - val_accuracy: 0.8377\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 38s 126ms/step - loss: 0.0488 - accuracy: 0.9819 - val_loss: 0.7977 - val_accuracy: 0.8245\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n",
      "Test Accuracy: 88.86792659759521\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 72s 149ms/step - loss: 0.4495 - accuracy: 0.7828 - val_loss: 0.5956 - val_accuracy: 0.7849\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.2880 - accuracy: 0.8880 - val_loss: 0.5743 - val_accuracy: 0.7877\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2655 - accuracy: 0.8965 - val_loss: 0.6641 - val_accuracy: 0.7953\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 37s 115ms/step - loss: 0.2388 - accuracy: 0.9093 - val_loss: 0.7231 - val_accuracy: 0.7906\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.2182 - accuracy: 0.9171 - val_loss: 0.7194 - val_accuracy: 0.7991\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1923 - accuracy: 0.9259 - val_loss: 0.7731 - val_accuracy: 0.7943\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1851 - accuracy: 0.9291 - val_loss: 0.7976 - val_accuracy: 0.7934\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 34s 114ms/step - loss: 0.1577 - accuracy: 0.9379 - val_loss: 0.8996 - val_accuracy: 0.7925\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1382 - accuracy: 0.9452 - val_loss: 0.9391 - val_accuracy: 0.7896\n",
      "Epoch 10/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 37s 125ms/step - loss: 0.1133 - accuracy: 0.9535 - val_loss: 0.9236 - val_accuracy: 0.8094\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.1029 - accuracy: 0.9607 - val_loss: 0.9019 - val_accuracy: 0.8075\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.0874 - accuracy: 0.9662 - val_loss: 1.2651 - val_accuracy: 0.7962\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0818 - accuracy: 0.9662 - val_loss: 1.1431 - val_accuracy: 0.7840\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0721 - accuracy: 0.9740 - val_loss: 1.4154 - val_accuracy: 0.7821\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.0699 - accuracy: 0.9738 - val_loss: 1.4241 - val_accuracy: 0.7906\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0654 - accuracy: 0.9730 - val_loss: 1.3795 - val_accuracy: 0.7934\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0590 - accuracy: 0.9790 - val_loss: 1.4231 - val_accuracy: 0.7887\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 37s 124ms/step - loss: 0.0540 - accuracy: 0.9792 - val_loss: 1.4323 - val_accuracy: 0.7906\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 37s 123ms/step - loss: 0.0554 - accuracy: 0.9775 - val_loss: 1.4358 - val_accuracy: 0.7962\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 37s 125ms/step - loss: 0.0458 - accuracy: 0.9788 - val_loss: 1.5987 - val_accuracy: 0.7943\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00020: early stopping\n",
      "Test Accuracy: 80.94339370727539\n",
      "\n",
      "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
      "0  87.087655  81.338358  85.862392  87.276155  88.030159  87.087655   \n",
      "\n",
      "        acc7       acc8       acc9      acc10        AVG  \n",
      "0  87.075472  85.377359  88.867927  80.943394  85.894653  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record2 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_2(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record2 = record2.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XJhKEZBiZT_V"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "wHCrVIZfZT_W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.087655</td>\n",
       "      <td>81.338358</td>\n",
       "      <td>85.862392</td>\n",
       "      <td>87.276155</td>\n",
       "      <td>88.030159</td>\n",
       "      <td>87.087655</td>\n",
       "      <td>87.075472</td>\n",
       "      <td>85.377359</td>\n",
       "      <td>88.867927</td>\n",
       "      <td>80.943394</td>\n",
       "      <td>85.894653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        acc1       acc2       acc3       acc4       acc5       acc6  \\\n",
       "0  87.087655  81.338358  85.862392  87.276155  88.030159  87.087655   \n",
       "\n",
       "        acc7       acc8       acc9      acc10        AVG  \n",
       "0  87.075472  85.377359  88.867927  80.943394  85.894653  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iQesIbOMZT_W"
   },
   "outputs": [],
   "source": [
    "report = record2\n",
    "report = report.to_excel('GRU_MPQA_v2_2.xlsx', sheet_name='static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyAjy7JdZT_X"
   },
   "source": [
    "# Model 3: Word2Vec - Dynamic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_16oO2DSZT_X"
   },
   "source": [
    "* In this part,  we will fine tune the embeddings while training (dynamic)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMSUb9KGZT_X"
   },
   "source": [
    "## GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Ggn_LhMDZT_Y"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "\n",
    "def define_model_3(input_dim = None, output_dim=300, max_length = None, emb_matrix=None):\n",
    "    \n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Embedding(input_dim=input_dim, \n",
    "                                  mask_zero= True,\n",
    "                                  output_dim=output_dim, \n",
    "                                  input_length=max_length, \n",
    "                                  input_shape=(max_length, ),\n",
    "                                  # Assign the embedding weight with word2vec embedding marix\n",
    "                                  weights = [emb_matrix],\n",
    "                                  # Set the weight to be not trainable (static)\n",
    "                                  trainable = True),\n",
    "        \n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, return_sequences=False)),\n",
    "        # tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile( loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YWXy4QWXZT_Y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 100, 300)          300000    \n",
      "_________________________________________________________________\n",
      "bidirectional_22 (Bidirectio (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "bidirectional_23 (Bidirectio (None, 128)               74496     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 515,169\n",
      "Trainable params: 515,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_0 = define_model_3( input_dim=1000, max_length=100, emb_matrix=np.random.rand(1000, 300))\n",
    "model_0.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yErgOnPWZT_Z"
   },
   "source": [
    "## Train and Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "G9BJbOfuZT_Z"
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    # Overide the method on_epoch_end() for our benefit\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (logs.get('accuracy') > 0.93):\n",
    "            print(\"\\nReached 93% accuracy so cancelling training!\")\n",
    "            self.model.stop_training=True\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', min_delta=0, \n",
    "                                             patience=10, verbose=2, \n",
    "                                             mode='auto', restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "EzDaNOidZT_Z",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training 1: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Diardano Raihan\\Anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\utils\\validation.py:72: FutureWarning: Pass shuffle=True as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "299/299 [==============================] - 75s 173ms/step - loss: 0.4337 - accuracy: 0.7952 - val_loss: 0.4348 - val_accuracy: 0.8040\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.1910 - accuracy: 0.9335 - val_loss: 0.4190 - val_accuracy: 0.8426\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.1215 - accuracy: 0.9605 - val_loss: 0.4894 - val_accuracy: 0.8398\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0963 - accuracy: 0.9663 - val_loss: 0.5037 - val_accuracy: 0.8473\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 44s 137ms/step - loss: 0.0661 - accuracy: 0.9747 - val_loss: 0.5797 - val_accuracy: 0.8417\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0599 - accuracy: 0.9766 - val_loss: 0.6612 - val_accuracy: 0.8369\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0505 - accuracy: 0.9806 - val_loss: 0.7001 - val_accuracy: 0.8351\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0422 - accuracy: 0.9816 - val_loss: 0.7518 - val_accuracy: 0.8087\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 44s 146ms/step - loss: 0.0396 - accuracy: 0.9836 - val_loss: 0.7265 - val_accuracy: 0.8388\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0349 - accuracy: 0.9835 - val_loss: 0.8680 - val_accuracy: 0.8256\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0355 - accuracy: 0.9861 - val_loss: 0.8874 - val_accuracy: 0.8058\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0325 - accuracy: 0.9857 - val_loss: 0.8049 - val_accuracy: 0.8520\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0336 - accuracy: 0.9831 - val_loss: 1.0018 - val_accuracy: 0.8030\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 44s 146ms/step - loss: 0.0336 - accuracy: 0.9843 - val_loss: 0.9244 - val_accuracy: 0.8030\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0263 - accuracy: 0.9882 - val_loss: 0.9126 - val_accuracy: 0.8303\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0320 - accuracy: 0.9854 - val_loss: 1.0417 - val_accuracy: 0.8011\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0275 - accuracy: 0.9878 - val_loss: 1.0496 - val_accuracy: 0.7917\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0257 - accuracy: 0.9883 - val_loss: 1.0544 - val_accuracy: 0.8002\n",
      "Epoch 19/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0253 - accuracy: 0.9867 - val_loss: 1.0709 - val_accuracy: 0.8011\n",
      "Epoch 20/40\n",
      "299/299 [==============================] - 44s 146ms/step - loss: 0.0252 - accuracy: 0.9873 - val_loss: 1.0838 - val_accuracy: 0.8058\n",
      "Epoch 21/40\n",
      "299/299 [==============================] - 44s 146ms/step - loss: 0.0217 - accuracy: 0.9898 - val_loss: 1.1363 - val_accuracy: 0.7955\n",
      "Epoch 22/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0234 - accuracy: 0.9873 - val_loss: 1.0985 - val_accuracy: 0.8077\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00022: early stopping\n",
      "Test Accuracy: 85.20264029502869\n",
      "Training 2: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 76s 163ms/step - loss: 0.4334 - accuracy: 0.7898 - val_loss: 0.3214 - val_accuracy: 0.8822\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.1981 - accuracy: 0.9283 - val_loss: 0.3385 - val_accuracy: 0.8794\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.1313 - accuracy: 0.9559 - val_loss: 0.3585 - val_accuracy: 0.8784\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0924 - accuracy: 0.9665 - val_loss: 0.3514 - val_accuracy: 0.8737\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0848 - accuracy: 0.9687 - val_loss: 0.4647 - val_accuracy: 0.8794\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 42s 140ms/step - loss: 0.0596 - accuracy: 0.9766 - val_loss: 0.4581 - val_accuracy: 0.8784\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0447 - accuracy: 0.9812 - val_loss: 0.5018 - val_accuracy: 0.8718\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0391 - accuracy: 0.9835 - val_loss: 0.5806 - val_accuracy: 0.8690\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0340 - accuracy: 0.9850 - val_loss: 0.5858 - val_accuracy: 0.8633\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0298 - accuracy: 0.9875 - val_loss: 0.6444 - val_accuracy: 0.8549\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0306 - accuracy: 0.9849 - val_loss: 0.6951 - val_accuracy: 0.8596\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.21865916252136\n",
      "Training 3: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 73s 164ms/step - loss: 0.4349 - accuracy: 0.7951 - val_loss: 0.3718 - val_accuracy: 0.8190\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.1936 - accuracy: 0.9302 - val_loss: 0.4465 - val_accuracy: 0.8124\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 42s 140ms/step - loss: 0.1292 - accuracy: 0.9554 - val_loss: 0.5299 - val_accuracy: 0.8077\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 42s 142ms/step - loss: 0.0998 - accuracy: 0.9639 - val_loss: 0.5272 - val_accuracy: 0.8058\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0760 - accuracy: 0.9716 - val_loss: 0.6938 - val_accuracy: 0.7926\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 42s 140ms/step - loss: 0.0598 - accuracy: 0.9768 - val_loss: 0.5253 - val_accuracy: 0.8351\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0497 - accuracy: 0.9784 - val_loss: 0.6741 - val_accuracy: 0.7908\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 42s 141ms/step - loss: 0.0429 - accuracy: 0.9815 - val_loss: 0.6502 - val_accuracy: 0.8294\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 42s 140ms/step - loss: 0.0353 - accuracy: 0.9841 - val_loss: 0.6196 - val_accuracy: 0.8313\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0329 - accuracy: 0.9845 - val_loss: 0.7364 - val_accuracy: 0.8228\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0314 - accuracy: 0.9864 - val_loss: 0.8532 - val_accuracy: 0.7917\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0392 - accuracy: 0.9838 - val_loss: 0.7797 - val_accuracy: 0.8256\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0266 - accuracy: 0.9886 - val_loss: 0.8425 - val_accuracy: 0.8190\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 42s 139ms/step - loss: 0.0291 - accuracy: 0.9855 - val_loss: 0.8143 - val_accuracy: 0.8256\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 41s 138ms/step - loss: 0.0234 - accuracy: 0.9880 - val_loss: 0.8350 - val_accuracy: 0.8294\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 42s 140ms/step - loss: 0.0241 - accuracy: 0.9890 - val_loss: 0.8639 - val_accuracy: 0.8341\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00016: early stopping\n",
      "Test Accuracy: 83.5061252117157\n",
      "Training 4: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 75s 173ms/step - loss: 0.4300 - accuracy: 0.8007 - val_loss: 0.3164 - val_accuracy: 0.8699\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 45s 149ms/step - loss: 0.2040 - accuracy: 0.9264 - val_loss: 0.3233 - val_accuracy: 0.8577\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 45s 149ms/step - loss: 0.1363 - accuracy: 0.9528 - val_loss: 0.3503 - val_accuracy: 0.8624\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.1053 - accuracy: 0.9597 - val_loss: 0.4104 - val_accuracy: 0.8633\n",
      "Epoch 5/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299/299 [==============================] - 44s 149ms/step - loss: 0.0791 - accuracy: 0.9723 - val_loss: 0.4447 - val_accuracy: 0.8596\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 44s 149ms/step - loss: 0.0580 - accuracy: 0.9787 - val_loss: 0.4980 - val_accuracy: 0.8624\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0566 - accuracy: 0.9777 - val_loss: 0.5389 - val_accuracy: 0.8605\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.0436 - accuracy: 0.9816 - val_loss: 0.5854 - val_accuracy: 0.8322\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.0378 - accuracy: 0.9823 - val_loss: 0.6368 - val_accuracy: 0.8549\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 47s 156ms/step - loss: 0.0328 - accuracy: 0.9853 - val_loss: 0.7066 - val_accuracy: 0.8313\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 44s 149ms/step - loss: 0.0293 - accuracy: 0.9863 - val_loss: 0.7566 - val_accuracy: 0.8303\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 86.99340224266052\n",
      "Training 5: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 74s 171ms/step - loss: 0.4367 - accuracy: 0.7947 - val_loss: 0.3670 - val_accuracy: 0.8209\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.1917 - accuracy: 0.9325 - val_loss: 0.3648 - val_accuracy: 0.8322\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 45s 150ms/step - loss: 0.1206 - accuracy: 0.9563 - val_loss: 0.4493 - val_accuracy: 0.8313\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 48s 161ms/step - loss: 0.1000 - accuracy: 0.9644 - val_loss: 0.5118 - val_accuracy: 0.8181\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 52s 174ms/step - loss: 0.0757 - accuracy: 0.9724 - val_loss: 0.5788 - val_accuracy: 0.8134\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 51s 172ms/step - loss: 0.0641 - accuracy: 0.9748 - val_loss: 0.6809 - val_accuracy: 0.8162\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 56s 187ms/step - loss: 0.0490 - accuracy: 0.9787 - val_loss: 0.6820 - val_accuracy: 0.8256\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0425 - accuracy: 0.9812 - val_loss: 0.7306 - val_accuracy: 0.8162\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 43s 146ms/step - loss: 0.0322 - accuracy: 0.9859 - val_loss: 0.7749 - val_accuracy: 0.8209\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0345 - accuracy: 0.9852 - val_loss: 0.7747 - val_accuracy: 0.8190\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 54s 180ms/step - loss: 0.0330 - accuracy: 0.9852 - val_loss: 0.7984 - val_accuracy: 0.8219\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 47s 156ms/step - loss: 0.0315 - accuracy: 0.9854 - val_loss: 0.8316 - val_accuracy: 0.8238\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 83.2233726978302\n",
      "Training 6: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 83s 181ms/step - loss: 0.4338 - accuracy: 0.7994 - val_loss: 0.4109 - val_accuracy: 0.8822\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 45s 150ms/step - loss: 0.1953 - accuracy: 0.9299 - val_loss: 0.5061 - val_accuracy: 0.8699\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 43s 146ms/step - loss: 0.1292 - accuracy: 0.9552 - val_loss: 0.5320 - val_accuracy: 0.8671\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 42s 141ms/step - loss: 0.1073 - accuracy: 0.9605 - val_loss: 0.6315 - val_accuracy: 0.8615\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 42s 141ms/step - loss: 0.0799 - accuracy: 0.9679 - val_loss: 0.6455 - val_accuracy: 0.8690\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 46s 153ms/step - loss: 0.0608 - accuracy: 0.9756 - val_loss: 0.7424 - val_accuracy: 0.8652\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 42s 142ms/step - loss: 0.0561 - accuracy: 0.9764 - val_loss: 0.7142 - val_accuracy: 0.8671\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 44s 148ms/step - loss: 0.0420 - accuracy: 0.9842 - val_loss: 0.7287 - val_accuracy: 0.8728\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 46s 153ms/step - loss: 0.0389 - accuracy: 0.9816 - val_loss: 0.8913 - val_accuracy: 0.8652\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 56s 187ms/step - loss: 0.0349 - accuracy: 0.9862 - val_loss: 0.9034 - val_accuracy: 0.8718\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 49s 165ms/step - loss: 0.0327 - accuracy: 0.9853 - val_loss: 0.9282 - val_accuracy: 0.8643\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00011: early stopping\n",
      "Test Accuracy: 88.21865916252136\n",
      "Training 7: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 152s 381ms/step - loss: 0.4416 - accuracy: 0.7782 - val_loss: 0.3322 - val_accuracy: 0.8425\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 56s 188ms/step - loss: 0.1893 - accuracy: 0.9314 - val_loss: 0.3807 - val_accuracy: 0.8311\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 55s 183ms/step - loss: 0.1349 - accuracy: 0.9520 - val_loss: 0.3926 - val_accuracy: 0.8755\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 50s 169ms/step - loss: 0.1010 - accuracy: 0.9624 - val_loss: 0.4813 - val_accuracy: 0.8283\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 48s 162ms/step - loss: 0.0773 - accuracy: 0.9678 - val_loss: 0.5458 - val_accuracy: 0.8113\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 56s 186ms/step - loss: 0.0618 - accuracy: 0.9755 - val_loss: 0.6593 - val_accuracy: 0.8208\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 46s 152ms/step - loss: 0.0460 - accuracy: 0.9810 - val_loss: 0.6441 - val_accuracy: 0.8160\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 45s 149ms/step - loss: 0.0445 - accuracy: 0.9793 - val_loss: 0.6662 - val_accuracy: 0.8519\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 45s 151ms/step - loss: 0.0352 - accuracy: 0.9843 - val_loss: 0.7180 - val_accuracy: 0.8179\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.0360 - accuracy: 0.9823 - val_loss: 0.7917 - val_accuracy: 0.8472\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0281 - accuracy: 0.9868 - val_loss: 0.7340 - val_accuracy: 0.8462\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0313 - accuracy: 0.9847 - val_loss: 0.8478 - val_accuracy: 0.8198\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0299 - accuracy: 0.9841 - val_loss: 0.9000 - val_accuracy: 0.8198\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00013: early stopping\n",
      "Test Accuracy: 87.54717111587524\n",
      "Training 8: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 74s 170ms/step - loss: 0.4367 - accuracy: 0.7976 - val_loss: 0.3165 - val_accuracy: 0.8453\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.2007 - accuracy: 0.9265 - val_loss: 0.3064 - val_accuracy: 0.8811\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.1351 - accuracy: 0.9499 - val_loss: 0.3348 - val_accuracy: 0.8698\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.1018 - accuracy: 0.9639 - val_loss: 0.3900 - val_accuracy: 0.8745\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0820 - accuracy: 0.9667 - val_loss: 0.4300 - val_accuracy: 0.8717\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0580 - accuracy: 0.9756 - val_loss: 0.4632 - val_accuracy: 0.8462\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0485 - accuracy: 0.9808 - val_loss: 0.5689 - val_accuracy: 0.8396\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0471 - accuracy: 0.9789 - val_loss: 0.5362 - val_accuracy: 0.8585\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0389 - accuracy: 0.9832 - val_loss: 0.6178 - val_accuracy: 0.8585\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0387 - accuracy: 0.9827 - val_loss: 0.5733 - val_accuracy: 0.8406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0337 - accuracy: 0.9849 - val_loss: 0.6291 - val_accuracy: 0.8557\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0301 - accuracy: 0.9867 - val_loss: 0.6196 - val_accuracy: 0.8509\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 88.11320662498474\n",
      "Training 9: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 75s 169ms/step - loss: 0.4298 - accuracy: 0.8016 - val_loss: 0.3962 - val_accuracy: 0.8217\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.1873 - accuracy: 0.9358 - val_loss: 0.3842 - val_accuracy: 0.8349\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.1316 - accuracy: 0.9529 - val_loss: 0.4785 - val_accuracy: 0.8255\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.1051 - accuracy: 0.9619 - val_loss: 0.5716 - val_accuracy: 0.8170\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0810 - accuracy: 0.9711 - val_loss: 0.5628 - val_accuracy: 0.8226\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.0627 - accuracy: 0.9730 - val_loss: 0.6555 - val_accuracy: 0.8160\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.0506 - accuracy: 0.9821 - val_loss: 0.6387 - val_accuracy: 0.8085\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0419 - accuracy: 0.9824 - val_loss: 0.7201 - val_accuracy: 0.8151\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0398 - accuracy: 0.9834 - val_loss: 0.8359 - val_accuracy: 0.8132\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 44s 147ms/step - loss: 0.0345 - accuracy: 0.9856 - val_loss: 0.8745 - val_accuracy: 0.8160\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 43s 145ms/step - loss: 0.0340 - accuracy: 0.9824 - val_loss: 0.9445 - val_accuracy: 0.8066\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 43s 144ms/step - loss: 0.0323 - accuracy: 0.9860 - val_loss: 0.9534 - val_accuracy: 0.8038\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00012: early stopping\n",
      "Test Accuracy: 83.49056839942932\n",
      "Training 10: \n",
      "Epoch 1/40\n",
      "299/299 [==============================] - 84s 168ms/step - loss: 0.4325 - accuracy: 0.7981 - val_loss: 0.3462 - val_accuracy: 0.8330\n",
      "Epoch 2/40\n",
      "299/299 [==============================] - 43s 142ms/step - loss: 0.1799 - accuracy: 0.9372 - val_loss: 0.3860 - val_accuracy: 0.8302\n",
      "Epoch 3/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.1370 - accuracy: 0.9513 - val_loss: 0.4048 - val_accuracy: 0.8340\n",
      "Epoch 4/40\n",
      "299/299 [==============================] - 43s 142ms/step - loss: 0.1040 - accuracy: 0.9642 - val_loss: 0.4142 - val_accuracy: 0.8443\n",
      "Epoch 5/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0739 - accuracy: 0.9736 - val_loss: 0.4438 - val_accuracy: 0.8264\n",
      "Epoch 6/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 0.5018 - val_accuracy: 0.8255\n",
      "Epoch 7/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0487 - accuracy: 0.9805 - val_loss: 0.5407 - val_accuracy: 0.8170\n",
      "Epoch 8/40\n",
      "299/299 [==============================] - 43s 142ms/step - loss: 0.0463 - accuracy: 0.9794 - val_loss: 0.5578 - val_accuracy: 0.8547\n",
      "Epoch 9/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0438 - accuracy: 0.9829 - val_loss: 0.6150 - val_accuracy: 0.8179\n",
      "Epoch 10/40\n",
      "299/299 [==============================] - 43s 142ms/step - loss: 0.0360 - accuracy: 0.9851 - val_loss: 0.6449 - val_accuracy: 0.8179\n",
      "Epoch 11/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0308 - accuracy: 0.9866 - val_loss: 0.7424 - val_accuracy: 0.8028\n",
      "Epoch 12/40\n",
      "299/299 [==============================] - 43s 142ms/step - loss: 0.0372 - accuracy: 0.9825 - val_loss: 0.7711 - val_accuracy: 0.7896\n",
      "Epoch 13/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0360 - accuracy: 0.9863 - val_loss: 0.9145 - val_accuracy: 0.7943\n",
      "Epoch 14/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0336 - accuracy: 0.9847 - val_loss: 0.8995 - val_accuracy: 0.7972\n",
      "Epoch 15/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0247 - accuracy: 0.9869 - val_loss: 0.8429 - val_accuracy: 0.7991\n",
      "Epoch 16/40\n",
      "299/299 [==============================] - 43s 142ms/step - loss: 0.0294 - accuracy: 0.9860 - val_loss: 0.8673 - val_accuracy: 0.8047\n",
      "Epoch 17/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0248 - accuracy: 0.9899 - val_loss: 0.7754 - val_accuracy: 0.8028\n",
      "Epoch 18/40\n",
      "299/299 [==============================] - 43s 143ms/step - loss: 0.0265 - accuracy: 0.9874 - val_loss: 0.9808 - val_accuracy: 0.7981\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00018: early stopping\n",
      "Test Accuracy: 85.4716956615448\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'record' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-65926cbd150c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mrecord3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecord3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'record' is not defined"
     ]
    }
   ],
   "source": [
    "# Parameter Initialization\n",
    "trunc_type='post'\n",
    "padding_type='post'\n",
    "oov_tok = \"<UNK>\"\n",
    "\n",
    "columns = ['acc1', 'acc2', 'acc3', 'acc4', 'acc5', 'acc6', 'acc7', 'acc8', 'acc9', 'acc10', 'AVG']\n",
    "record3 = pd.DataFrame(columns = columns)\n",
    "\n",
    "# prepare cross validation with 10 splits and shuffle = True\n",
    "kfold = KFold(10, True)\n",
    "\n",
    "# Separate the sentences and the labels\n",
    "sentences, labels = list(corpus.sentence), list(corpus.label)\n",
    "\n",
    "exp=0\n",
    "\n",
    "# kfold.split() will return set indices for each split\n",
    "acc_list = []\n",
    "for train, test in kfold.split(sentences):\n",
    "    \n",
    "    exp+=1\n",
    "    print('Training {}: '.format(exp))\n",
    "    \n",
    "    train_x, test_x = [], []\n",
    "    train_y, test_y = [], []\n",
    "\n",
    "    for i in train:\n",
    "        train_x.append(sentences[i])\n",
    "        train_y.append(labels[i])\n",
    "\n",
    "    for i in test:\n",
    "        test_x.append(sentences[i])\n",
    "        test_y.append(labels[i])\n",
    "\n",
    "    # Turn the labels into a numpy array\n",
    "    train_y = np.array(train_y)\n",
    "    test_y = np.array(test_y)\n",
    "\n",
    "    # encode data using\n",
    "    # Cleaning and Tokenization\n",
    "    tokenizer = Tokenizer(oov_token=oov_tok)\n",
    "    tokenizer.fit_on_texts(train_x)\n",
    "\n",
    "    # Turn the text into sequence\n",
    "    training_sequences = tokenizer.texts_to_sequences(train_x)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_x)\n",
    "\n",
    "    max_len = max_length(training_sequences)\n",
    "\n",
    "    # Pad the sequence to have the same size\n",
    "    Xtrain = pad_sequences(training_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "    Xtest = pad_sequences(test_sequences, maxlen=max_len, padding=padding_type, truncating=trunc_type)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    vocab_size = len(word_index)+1\n",
    "    \n",
    "    emb_matrix = pretrained_embedding_matrix(word2vec, word_index)\n",
    "\n",
    "    # Define the input shape\n",
    "    model = define_model_3(input_dim=vocab_size, max_length=max_len, emb_matrix=emb_matrix)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(Xtrain, train_y, batch_size=32, epochs=40, verbose=1, \n",
    "              callbacks=[callbacks], validation_data=(Xtest, test_y))\n",
    "\n",
    "    # evaluate the model\n",
    "    loss, acc = model.evaluate(Xtest, test_y, verbose=0)\n",
    "    print('Test Accuracy: {}'.format(acc*100))\n",
    "\n",
    "    acc_list.append(acc*100)\n",
    "\n",
    "mean_acc = np.array(acc_list).mean()\n",
    "entries = acc_list + [mean_acc]\n",
    "\n",
    "temp = pd.DataFrame([entries], columns=columns)\n",
    "record3 = record3.append(temp, ignore_index=True)\n",
    "print()\n",
    "print(record)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fUZ-RMhVZT_a"
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "XQjCT-UaZT_a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acc1</th>\n",
       "      <th>acc2</th>\n",
       "      <th>acc3</th>\n",
       "      <th>acc4</th>\n",
       "      <th>acc5</th>\n",
       "      <th>acc6</th>\n",
       "      <th>acc7</th>\n",
       "      <th>acc8</th>\n",
       "      <th>acc9</th>\n",
       "      <th>acc10</th>\n",
       "      <th>AVG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85.20264</td>\n",
       "      <td>88.218659</td>\n",
       "      <td>83.506125</td>\n",
       "      <td>86.993402</td>\n",
       "      <td>83.223373</td>\n",
       "      <td>88.218659</td>\n",
       "      <td>87.547171</td>\n",
       "      <td>88.113207</td>\n",
       "      <td>83.490568</td>\n",
       "      <td>85.471696</td>\n",
       "      <td>85.99855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       acc1       acc2       acc3       acc4       acc5       acc6       acc7  \\\n",
       "0  85.20264  88.218659  83.506125  86.993402  83.223373  88.218659  87.547171   \n",
       "\n",
       "        acc8       acc9      acc10       AVG  \n",
       "0  88.113207  83.490568  85.471696  85.99855  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "FL_qi5_LZT_b"
   },
   "outputs": [],
   "source": [
    "report = record3\n",
    "report = report.to_excel('GRU_MPQA_v2_3.xlsx', sheet_name='dynamic')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "XJhKEZBiZT_V",
    "fUZ-RMhVZT_a"
   ],
   "name": "GRU_MPQA_v2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
